{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "### importing all the required libraries \n",
    "from sklearn.datasets import load_files  # to load the images from the subfolders    \n",
    "from keras.utils import np_utils # to hot encode the label of the image\n",
    "import numpy as np \n",
    "from keras.preprocessing import image ,image                  \n",
    "from tqdm import tqdm \n",
    "from keras.applications.mobilenetv2 import MobileNetV2, preprocess_input #to load mobilenetv2 model\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input # to preprocess the image before transfer the image and generate the bottleneck features\n",
    "from keras.callbacks import ModelCheckpoint # to save the best weights for the model while training \n",
    "import cv2 # opencv library used for take a stream of input image \"real time\"\n",
    "from keras.layers import Conv2D, GlobalAveragePooling2D,Dense # to create convolutional 2d layer and average pooling layer and Dense for Dense layer\n",
    "from keras.models import Sequential \n",
    "from random import randint # to generate random nubmers to implement the random model classification \n",
    "import time # to calculate the time processing for one frame\n",
    "from keras.preprocessing.image import ImageDataGenerator # to augement the data\n",
    "import matplotlib.pyplot as plt # to draw barplot and etc...\n",
    "import win32com.client # to convert text to voice\n",
    "\n",
    "speaker = win32com.client.Dispatch(\"SAPI.SpVoice\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### loading all the dataset and give each subfolder a number to present each class\n",
    "\n",
    "###  loading training data\n",
    "data_training = load_files(\"./data/training/\")\n",
    "x_train = np.array(data_training['filenames'])\n",
    "y_train = np_utils.to_categorical(np.array(data_training['target']), 9)\n",
    "\n",
    "###  loading validation data\n",
    "\n",
    "data_validation = load_files(\"./data/validation/\")\n",
    "x_valid = np.array(data_validation['filenames'])\n",
    "y_valid = np_utils.to_categorical(np.array(data_validation['target']), 9)\n",
    "\n",
    "###  loading testing data\n",
    "\n",
    "data_testing = load_files(\"./data/testing/\")\n",
    "x_test = np.array(data_testing['filenames'])\n",
    "y_test = np_utils.to_categorical(np.array(data_testing['target']), 9)\n",
    "\n",
    "### loading the augmented data\n",
    "data_training_aug = load_files(\"./data/augmented//\")\n",
    "x_train_aug = np.array(data_training_aug['filenames'])\n",
    "y_train_aug = np_utils.to_categorical(np.array(data_training_aug['target']), 9)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current size: [6.0, 4.0]\n"
     ]
    }
   ],
   "source": [
    "# changing the size of ploting because the default size make the text interlapsed\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    " \n",
    "# Prints: [8.0, 6.0]\n",
    "print (\"Current size:\", fig_size)\n",
    " \n",
    "# Set figure width to 12 and height to 9\n",
    "fig_size[0] = 12\n",
    "fig_size[1] = 9\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtcAAAInCAYAAABTHHVEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xm4LGdZL+zfQwIyBQJki2FyA1+UA4gRtzgBRtQDgoKAoBxkOmjg+0RRnPDI5HREETzHgwxBcxJRmQcZohKRJKIyJJARmQ0SCCQgkAAKJnm+P6oWdFb2Wrt38vZaeyX3fV197eq3q6ueendX929Vv11V3R0AAOCqu9Z2FwAAAFcXwjUAAAwiXAMAwCDCNQAADCJcAwDAIMI1AAAMIlwDbLGqekFVPXX0vKNU1UlV9ZNbuU6AqwvhGmA/VdW5VfX9V/b53f347v7N0fNuh6vaFwfaegCuKuEaYKCqOni7awBg+wjXAPuhql6c5DZJXl9Vn6+qX66qrqrHVtW/Jvm7eb5XVNUnqupzVXVKVd1pYRnHVdVvzdNHVdV5VfULVXVBVZ1fVY+5kvPerKpeX1UXVdU7q+q3quqtS2zTD1TVe+dan5ukFh67fVX9XVV9uqo+VVV/XlWHbtQXS2z7favqPVV1cVV9rKp+ceGxH6qq06vqs1X1j1V1l83WA3AgEq4B9kN3PyLJvyb54e6+YZKXzw99T5L/kuTe8/2/SnJEkq9N8q4kf77JYr8uyY2T3DLJY5P8UVXd5ErM+0dJvjDP86j5tqmqOizJq5I8JclhST6U5LsXZ0nyO0luMW/frZM8I7liX3T37y2x7X+S5HHdfUiSO+erf4zcNcmxSR6X5GZJXpjkdVX1NZusB+CAI1wDjPGM7v5Cd/97knT3sd19cXd/KVMY/eaquvEGz/3PJL/R3f/Z3Sck+XySb9yfeavqoCQPTvL07v5id78nyfFL1H3fJO/p7ld2938m+V9JPrH2YHd/sLtP7O4vdfeFSZ6T6Q+JDe1j2/8zyR2r6kbd/Znuftfc/lNJXtjdb+/uS7v7+CRfSvIdS2wDwAFDuAYY46NrE1V1UFU9s6o+VFUXJTl3fuiwDZ776e6+ZOH+F5PccD/n3ZXk4MU61k1v5BaL83V3r9uWr62ql85DOC5K8mebbMcy2/7gTIH+I1V1clV959z+9Ul+YR4S8tmq+mymo+S3WGIbAA4YwjXA/ut9tP23JA9I8v2ZhnDsntsrq3NhkkuS3Gqh7dZLPO/8xfmqqtY973cybdtduvtGSX4il9+O9X2x6bZ39zu7+wGZhoy8Nl8dVvPRJL/d3Ycu3K7f3S/ZYD0AByThGmD/fTLJ7TZ5/JBMQxo+neT6Sf7nqgvq7kuTvDrJM6rq+lV1hySPXOKpb0xyp6p60Hymk5/NNGZ7zSGZhp58tqpumeSX1j1/fV9suO1VdZ2qenhV3XgegnJRkkvnh1+U5PFV9e01uUFV3a+qDtlgPQAHJOEaYP/9TpKnzEMXfnQvj/9pko8k+ViS9yR52xbV9YRMR4s/keTFSV6SKehuqLs/leQhSZ6ZKRAfkeQfFmb59SR3TfK5TEH81esW8ZW+mM/8sa9tf0SSc+chI4/PdCQ83X1qpnHXz03ymSQfTPLoTdYDcECqaXgdAFc3VfW7Sb6uu/d51hAAxnDkGuBqoqruUFV3mYdV3C3Tqfpes911AVyTuJIYwNXHIZmGgtwiyQVJnp3kL6vqHpnOPX0F87m6ARjEsBAAABjEsBAAABhEuAYAgEF29Jjrww47rHfv3r3dZQAAcDV32mmnfaq7d+1rvh0drnfv3p1TTz11u8sAAOBqrqo+ssx8hoUAAMAgwjUAAAwiXAMAwCDCNQAADCJcAwDAIMI1AAAMIlwDAMAgwjUAAAwiXAMAwCDCNQAADCJcAwDAIMI1AAAMIlwDAMAgwjUAAAwiXAMAwCDCNQAADCJcAwDAIMI1AAAMIlwDAMAgwjUAAAwiXAMAwCAHb3cBAHuz+8lv3PJ1nvvM+235OlkdryFgOzhyDQAAgwjXAAAwiGEhADuUYQ8ABx5HrgEAYBDhGgAABhGuAQBgEOEaAAAGEa4BAGCQlYXrqjq2qi6oqrMX2l5WVafPt3Or6vS5fXdV/fvCYy9YVV0AALAqqzwV33FJnpvkT9cauvvH1qar6tlJPrcw/4e6+8gV1gMAsDSnu+TKWFm47u5Tqmr33h6rqkry0CT3WtX6AQBgq23XmOt7JPlkd39goe22VfXuqjq5qu6xTXUBAMCVtl1XaHxYkpcs3D8/yW26+9NV9a1JXltVd+rui9Y/saqOTnJ0ktzmNrfZkmIB4OrIsAcYb8uPXFfVwUkelORla23d/aXu/vQ8fVqSDyX5hr09v7uP6e493b1n165dW1EyAAAsZTuGhXx/kvd293lrDVW1q6oOmqdvl+SIJB/ehtoAAOBKW+Wp+F6S5J+SfGNVnVdVj50f+vFcfkhIktwzyZlVdUaSVyZ5fHf/26pqAwCAVVjl2UIetkH7o/fS9qokr1pVLQAAsBVcoREAAAYRrgEAYBDhGgAABhGuAQBgEOEaAAAGEa4BAGAQ4RoAAAYRrgEAYBDhGgAABhGuAQBgEOEaAAAGEa4BAGAQ4RoAAAYRrgEAYBDhGgAABhGuAQBgEOEaAAAGEa4BAGAQ4RoAAAYRrgEAYBDhGgAABjl4uwvg6mn3k9+45es895n32/J1AgAscuQaAAAGEa4BAGAQ4RoAAAYRrgEAYBDhGgAABhGuAQBgEOEaAAAGEa4BAGAQ4RoAAAZxhcYryRUIAQBYz5FrAAAYRLgGAIBBhGsAABhEuAYAgEGEawAAGES4BgCAQYRrAAAYRLgGAIBBhGsAABhEuAYAgEGEawAAGES4BgCAQYRrAAAYRLgGAIBBhGsAABjk4O0uAACAnWn3k9+4pes795n329L1XRmOXAMAwCDCNQAADCJcAwDAIMI1AAAMIlwDAMAgwjUAAAwiXAMAwCDCNQAADLKycF1Vx1bVBVV19kLbM6rqY1V1+ny778Jjv1pVH6yq91XVvVdVFwAArMoqj1wfl+Q+e2n/g+4+cr6dkCRVdcckP57kTvNznldVB62wNgAAGG5l4bq7T0nyb0vO/oAkL+3uL3X3vyT5YJK7rao2AABYhe0Yc/2EqjpzHjZyk7ntlkk+ujDPeXMbAADsGFsdrp+f5PZJjkxyfpJnz+21l3l7bwuoqqOr6tSqOvXCCy9cTZUAAHAlbGm47u5Pdvel3X1Zkhflq0M/zkty64VZb5Xk4xss45ju3tPde3bt2rXaggEAYD8cvJUrq6rDu/v8+e4Dk6ydSeR1Sf6iqp6T5BZJjkjyjq2sDbba7ie/ccvXee4z77fl6wSAa5KVheuqekmSo5IcVlXnJXl6kqOq6shMQz7OTfK4JOnuc6rq5Unek+SSJD/d3ZeuqjYAAFiFlYXr7n7YXpr/ZJP5fzvJb6+qHgAAWDVXaAQAgEGEawAAGES4BgCAQYRrAAAYRLgGAIBBhGsAABhEuAYAgEGEawAAGES4BgCAQYRrAAAYRLgGAIBBhGsAABhEuAYAgEGEawAAGES4BgCAQYRrAAAYRLgGAIBBhGsAABhEuAYAgEGEawAAGES4BgCAQYRrAAAYRLgGAIBBhGsAABhEuAYAgEGEawAAGES4BgCAQYRrAAAYRLgGAIBBhGsAABhEuAYAgEGEawAAGES4BgCAQYRrAAAYRLgGAIBBhGsAABhEuAYAgEGEawAAGES4BgCAQYRrAAAYRLgGAIBBhGsAABhEuAYAgEGEawAAGES4BgCAQYRrAAAYRLgGAIBBhGsAABhEuAYAgEGEawAAGES4BgCAQYRrAAAYRLgGAIBBhGsAABhEuAYAgEGEawAAGGRl4bqqjq2qC6rq7IW2Z1XVe6vqzKp6TVUdOrfvrqp/r6rT59sLVlUXAACsyiqPXB+X5D7r2k5McufuvkuS9yf51YXHPtTdR863x6+wLgAAWImVhevuPiXJv61re1N3XzLffVuSW61q/QAAsNW2c8z1f0/yVwv3b1tV766qk6vqHhs9qaqOrqpTq+rUCy+8cPVVAgDAkrYlXFfVryW5JMmfz03nJ7lNd39Lkicl+YuqutHentvdx3T3nu7es2vXrq0pGAAAlrDl4bqqHpXkh5I8vLs7Sbr7S9396Xn6tCQfSvINW10bAABcFVsarqvqPkl+Jcn9u/uLC+27quqgefp2SY5I8uGtrA0AAK6qg1e14Kp6SZKjkhxWVecleXqms4N8TZITqypJ3jafGeSeSX6jqi5JcmmSx3f3v+11wQAAcIBaWbju7oftpflPNpj3VUletapaAABgK7hCIwAADCJcAwDAIMI1AAAMIlwDAMAgwjUAAAwiXAMAwCDCNQAADCJcAwDAIMI1AAAMIlwDAMAgwjUAAAwiXAMAwCDCNQAADCJcAwDAIMI1AAAMIlwDAMAgwjUAAAwiXAMAwCDCNQAADCJcAwDAIMI1AAAMIlwDAMAgwjUAAAwiXAMAwCDCNQAADCJcAwDAIMI1AAAMIlwDAMAgwjUAAAyyz3BdVQ+pqkPm6adU1aur6q6rLw0AAHaWZY5cP7W7L66quye5d5Ljkzx/tWUBAMDOs0y4vnT+935Jnt/df5nkOqsrCQAAdqZlwvXHquqFSR6a5ISq+polnwcAANcoy4Tkhyb5myT36e7PJrlpkl9aaVUAALAD7TNcd/cXk1yQ5O5z0yVJPrDKogAAYCda5mwhT0/yK0l+dW66dpI/W2VRAACwEy0zLOSBSe6f5AtJ0t0fT3LIKosCAICdaJlw/eXu7iSdJFV1g9WWBAAAO9My4frl89lCDq2qn0ryt0letNqyAABg5zl4XzN09+9X1Q8kuSjJNyZ5WnefuPLKAABgh9lnuE6SOUwL1AAAsIl9huuqujjzeOsFn0tyapJf6O4Pr6IwAADYaZY5cv2cJB9P8hdJKsmPJ/m6JO9LcmySo1ZVHAAA7CTL/KDxPt39wu6+uLsv6u5jkty3u1+W5CYrrg8AAHaMZcL1ZVX10Kq61nx76MJj64eLAADANdYy4frhSR6R6RLon5ynf6KqrpfkCSusDQAAdpRlTsX34SQ/vMHDbx1bDgAA7FzLnC3kukkem+ROSa671t7d/32FdQEAwI6zzLCQF2c6O8i9k5yc5FZJLl5lUQAAsBMtE67/n+5+apIvdPfxSe6X5JtWWxYAAOw8y4Tr/5z//WxV3TnJjZPsXllFAACwQy1zEZljquomSZ6a5HVJbpjkaSutCgAAdqBlzhbyx/PkyUlut9pyAABg51rmbCGHJnlkpqEgX5m/u392dWUBAMDOs8ywkBOSvC3JWUkuW205AACwcy0Trq/b3U9aeSUAALDDLXWe66r6qao6vKpuunZbZuFVdWxVXVBVZy+03bSqTqyqD8z/3mRur6r6w6r6YFWdWVV3vZLbBAAA22KZcP3lJM9K8k9JTptvpy65/OOS3Gdd25OTvLm7j0jy5vl+kvxgkiPm29FJnr/kOgAA4ICwzLCQJ2W6kMyn9nfh3X1KVe1e1/yAJEfN08cnOSnJr8ztf9rdneRtVXVoVR3e3efv73oBAGA7LHPk+pwkXxy4zpuvBeb536+d22+Z5KML8503t11OVR1dVadW1akXXnjhwLIAAOCqWebI9aVJTq+qtyT50lrjCk7FV3tp6ys0dB+T5Jgk2bNnzxUeBwCA7bJMuH7tfBvlk2vDParq8CQXzO3nJbn1wny3SvLxgesFAICVWuYKjccPXufrkjwqyTPnf/9yof0JVfXSJN+e5HPGWwMAsJNsGK6r6uXd/dCqOit7H55xl30tvKpekunHi4dV1XlJnp4pVL+8qh6b5F+TPGSe/YQk903ywUxjvB+zf5sCAADba7Mj10+c//2hK7vw7n7YBg99317m7SQ/fWXXBQAA223DcL1wRo+PbF05AACwcy1zKj4AAGAJwjUAAAyyYbiuqjfP//7u1pUDAAA712Y/aDy8qr4nyf3n0+Nd7iIv3f2ulVYGAAA7zGbh+mlJnpzpYi7PWfdYJ7nXqooCAICdaLOzhbwyySur6qnd/ZtbWBMAAOxIy1yh8Ter6v5J7jk3ndTdb1htWQAAsPPs82whVfU7mS4o85759sS5DQAAWLDPI9dJ7pfkyO6+LEmq6vgk707yq6ssDAAAdpplz3N96ML0jVdRCAAA7HTLHLn+nSTvrqq3ZDod3z3jqDUAAFzBMj9ofElVnZTk2zKF61/p7k+sujAAANhpljlyne4+P8nrVlwLAADsaMuOuQYAAPZBuAYAgEE2DddVda2qOnurigEAgJ1s03A9n9v6jKq6zRbVAwAAO9YyP2g8PMk5VfWOJF9Ya+zu+6+sKgAA2IGWCde/vvIqAADgamCZ81yfXFVfn+SI7v7bqrp+koNWXxoAAOws+zxbSFX9VJJXJnnh3HTLJK9dZVEAALATLXMqvp9O8t1JLkqS7v5Akq9dZVEAALATLROuv9TdX167U1UHJ+nVlQQAADvTMuH65Kr6H0muV1U/kOQVSV6/2rIAAGDnWSZcPznJhUnOSvK4JCckecoqiwIAgJ1ombOFXFZVxyd5e6bhIO/rbsNCAABgnX2G66q6X5IXJPlQkkpy26p6XHf/1aqLAwCAnWSZi8g8O8n3dvcHk6Sqbp/kjUmEawAAWLDMmOsL1oL17MNJLlhRPQAAsGNteOS6qh40T55TVSckeXmmMdcPSfLOLagNAAB2lM2GhfzwwvQnk3zPPH1hkpusrCIAANihNgzX3f2YrSwEAAB2umXOFnLbJD+TZPfi/N19/9WVBQAAO88yZwt5bZI/yXRVxstWWw4AAOxcy4Tr/+juP1x5JQAAsMMtE67/d1U9PcmbknxprbG737WyqgAAYAdaJlx/U5JHJLlXvjospOf7AADAbJlw/cAkt+vuL6+6GAAA2MmWuULjGUkOXXUhAACw0y1z5PrmSd5bVe/M5cdcOxUfAAAsWCZcP33lVQAAwNXAPsN1d5+8FYUAAMBOt8wVGi/OdHaQJLlOkmsn+UJ332iVhQEAwE6zzJHrQxbvV9WPJLnbyioCAIAdapmzhVxOd782znENAABXsMywkAct3L1Wkj356jARAABgtszZQn54YfqSJOcmecBKqgEAgB1smTHXj9mKQgAAYKfbMFxX1dM2eV5392+uoB4AANixNjty/YW9tN0gyWOT3CyJcA0AAAs2DNfd/ey16ao6JMkTkzwmyUuTPHuj5wEAwDXVpmOuq+qmSZ6U5OFJjk9y1+7+zFYUBgAAO81mY66fleRBSY5J8k3d/fktqwoAAHagzS4i8wtJbpHkKUk+XlUXzbeLq+qirSkPAAB2js3GXO/31RuXUVXfmORlC023S/K0JIcm+akkF87t/6O7T1hFDQAAsArLXERmqO5+X5Ijk6SqDkrysSSvyfRjyT/o7t/f6poAAGCElRyd3g/fl+RD3f2Rba4DAACusu0O1z+e5CUL959QVWdW1bFVdZPtKgoAAK6MbQvXVXWdJPdP8oq56flJbp9pyMj52eBc2lV1dFWdWlWnXnjhhXubBQAAtsV2Hrn+wSTv6u5PJkl3f7K7L+3uy5K8KMnd9vak7j6mu/d0955du3ZtYbkAALC57QzXD8vCkJCqOnzhsQcmOXvLKwIAgKtgy88WkiRVdf0kP5DkcQvNv1dVRybpJOeuewwAAA542xKuu/uLSW62ru0R21ELAACMst1nCwEAgKsN4RoAAAYRrgEAYBDhGgAABhGuAQBgEOEaAAAGEa4BAGAQ4RoAAAYRrgEAYBDhGgAABhGuAQBgEOEaAAAGEa4BAGAQ4RoAAAYRrgEAYBDhGgAABhGuAQBgEOEaAAAGEa4BAGAQ4RoAAAYRrgEAYBDhGgAABhGuAQBgEOEaAAAGEa4BAGAQ4RoAAAYRrgEAYBDhGgAABhGuAQBgEOEaAAAGEa4BAGAQ4RoAAAYRrgEAYBDhGgAABhGuAQBgEOEaAAAGEa4BAGAQ4RoAAAYRrgEAYBDhGgAABhGuAQBgEOEaAAAGEa4BAGAQ4RoAAAYRrgEAYBDhGgAABhGuAQBgEOEaAAAGEa4BAGAQ4RoAAAYRrgEAYBDhGgAABhGuAQBgEOEaAAAGEa4BAGAQ4RoAAAY5eLtWXFXnJrk4yaVJLunuPVV10yQvS7I7yblJHtrdn9muGgEAYH9s95Hr7+3uI7t7z3z/yUne3N1HJHnzfB8AAHaE7Q7X6z0gyfHz9PFJfmQbawEAgP2yneG6k7ypqk6rqqPntpt39/lJMv/7teufVFVHV9WpVXXqhRdeuIXlAgDA5rZtzHWS7+7uj1fV1yY5sareu8yTuvuYJMckyZ49e3qVBQIAwP7YtiPX3f3x+d8Lkrwmyd2SfLKqDk+S+d8Ltqs+AADYX9sSrqvqBlV1yNp0kv+a5Owkr0vyqHm2RyX5y+2oDwAAroztGhZy8ySvqaq1Gv6iu/+6qt6Z5OVV9dgk/5rkIdtUHwAA7LdtCdfd/eEk37yX9k8n+b6trwgAAK66A+1UfAAAsGMJ1wAAMIhwDQAAgwjXAAAwiHANAACDCNcAADCIcA0AAIMI1wAAMIhwDQAAgwjXAAAwiHANAACDCNcAADCIcA0AAIMI1wAAMIhwDQAAgwjXAAAwiHANAACDCNcAADCIcA0AAIMI1wAAMIhwDQAAgwjXAAAwiHANAACDCNcAADCIcA0AAIMI1wAAMIhwDQAAgwjXAAAwiHANAACDCNcAADCIcA0AAIMI1wAAMIhwDQAAgwjXAAAwiHANAACDCNcAADCIcA0AAIMI1wAAMIhwDQAAgwjXAAAwiHANAACDCNcAADCIcA0AAIMI1wAAMIhwDQAAgwjXAAAwiHANAACDCNcAADCIcA0AAIMI1wAAMIhwDQAAgwjXAAAwiHANAACDCNcAADCIcA0AAIMI1wAAMMiWh+uqunVVvaWq/rmqzqmqJ87tz6iqj1XV6fPtvltdGwAAXBUHb8M6L0nyC939rqo6JMlpVXXi/NgfdPfvb0NNAABwlW15uO7u85OcP09fXFX/nOSWW10HAACMtq1jrqtqd5JvSfL2uekJVXVmVR1bVTfZ4DlHV9WpVXXqhRdeuEWVAgDAvm1buK6qGyZ5VZKf6+6Lkjw/ye2THJnpyPaz9/a87j6mu/d0955du3ZtWb0AALAv2xKuq+ramYL1n3f3q5Okuz/Z3Zd292VJXpTkbttRGwAAXFnbcbaQSvInSf65u5+z0H74wmwPTHL2VtcGAABXxXacLeS7kzwiyVlVdfrc9j+SPKyqjkzSSc5N8rhtqA0AAK607ThbyFuT1F4eOmGrawEAgJFcoREAAAYRrgEAYBDhGgAABhGuAQBgEOEaAAAGEa4BAGAQ4RoAAAYRrgEAYBDhGgAABhGuAQBgEOEaAAAGEa4BAGAQ4RoAAAYRrgEAYBDhGgAABhGuAQBgEOEaAAAGEa4BAGAQ4RoAAAYRrgEAYBDhGgAABhGuAQBgEOEaAAAGEa4BAGAQ4RoAAAYRrgEAYBDhGgAABhGuAQBgEOEaAAAGEa4BAGAQ4RoAAAYRrgEAYBDhGgAABhGuAQBgEOEaAAAGEa4BAGAQ4RoAAAYRrgEAYBDhGgAABhGuAQBgEOEaAAAGEa4BAGAQ4RoAAAYRrgEAYBDhGgAABhGuAQBgEOEaAAAGEa4BAGAQ4RoAAAYRrgEAYBDhGgAABhGuAQBgEOEaAAAGEa4BAGAQ4RoAAAY54MJ1Vd2nqt5XVR+sqidvdz0AALCsAypcV9VBSf4oyQ8muWOSh1XVHbe3KgAAWM4BFa6T3C3JB7v7w9395SQvTfKAba4JAACWcqCF61sm+ejC/fPmNgAAOOBVd293DV9RVQ9Jcu/u/sn5/iOS3K27f2ZhnqOTHD3f/cYk79vyQq+aw5J8aruLOMDpo83pn33TR5vTP/umjzanf/ZNH21uJ/bP13f3rn3NdPBWVLIfzkty64X7t0ry8cUZuvuYJMdsZVEjVdWp3b1nu+s4kOmjzemffdNHm9M/+6aPNqd/9k0fbe7q3D8H2rCQdyY5oqpuW1XXSfLjSV63zTUBAMBSDqgj1919SVU9IcnfJDkoybHdfc42lwUAAEs5oMJ1knT3CUlO2O46VmjHDmnZQvpoc/pn3/TR5vTPvumjzemffdNHm7va9s8B9YNGAADYyQ60MdcAALBjCdd7UVW7q+rs/Zj/0VV1i4X751bVYaup7sCxv/006rlXZ1X1jKr6xYHLO7Kq7jtqeTtFVe2pqj/c4LFrxP55TbW395bF10NVHVVV37W/y9hJqurz87+3qKpX7mPe+1fVk7emsmumq8v7cFX9XFVdf4n5/viafnXtA27M9Q716CRnZ91pAzdTVQd39yUrq2iH0i/DHZlkT67Gv2NY/5qZ75+a5NQBy65Mw+cuu6rLWnJ9z0jy+SQ3SnJKd//tJvPeP8kdu/uZW1HbTrbu9XBUpj7+x20raIt098eT/Og+5nldBp2Vq6oO6u5LRyzrambD9+Ed9pn3c0n+LMkXN5tp7Vol612TXh+OXG/s4Ko6vqrOrKpXVtX1q+ppVfXOqjq7qo6pyY9m2mn+vKpOr6rrzc//map6V1WdVVV3SL5yVPKYqnpTkj+tqutW1f+d53l3VX3vPN9G7Y+uqtdW1eur6l+q6glV9aR5nrdV1U0PkH761qo6uapOq6q/qarD5/q/tarOqKp/SvLTawuYt+sVVfX6JG+a+/VZcz+fVVU/Ns+3UftR8/peXlXvr6pnVtXDq+od83y334Z+WUpVPXLuuzOq6sXrHjty/n89s6peU1U3mdt/tqreM7e/dG67QVUdO78+311VD6jpdJa/keTH5tfmj239Fu6f9f1RVV9fVW+e295cVbeZ5zuuqp5TVW9J8rt72beOqqo3zPPerKreNPfLC5PUwvqeNL+ezq6qn5vbdlfVP1fV85K8K5c/9/6W6O6nbRas53let8pgXVUHrWrZW6Wqbjf/v/9SVb2hqnYneXySn5/3iXtU1c3n/euM+bZ2VPugqnpRVZ0zv36uNy/z9lX11/MFql7PAAANRElEQVT729/XV9/fj6uqP6yqf6yqD9f02bCtauEIfFW9varutPDYSfN78qOr6rlz2163oaquVVXPm/viDVV1wsJj59b02fjWJA/Z5H1ro/aTquoPquqUeb/7tqp6dVV9oKp+a4u77HLm/ntvLZEFFrbld2v67Hn//Pq6wvvwXt6v/r6qjlxY7z9U1V22abPXarhBVb1x3ifOrqqnJ7lFkrfM77upqudX1anz6+LXF557UlXtmac/X1W/UVVvT/KdNX0+r31+/f48z173wZryzmnz8o+e2w6aX6drOeDn5/a97pfbprvd1t2S7E7SSb57vn9skl9MctOFeV6c5Ifn6ZOS7Fl47NwkPzNP/39J/niefkaS05Jcb77/C0n+7zx9hyT/muS6m7Q/OskHkxySZFeSzyV5/DzfHyT5uQOgn34p0xGhXXPbj2U6pWKSnJnke+bpZyU5e55+dKYLCN10vv/gJCdmOh3jzeftP3yT9qOSfHae/pokH0vy6/Oynpjkf233a2qD/rtTpiuMHjbfv+n8GvnFvfTXb6xtR6ZvSL5mnj50/vd/JvmJtbYk709yg7lvn7vd23oV+uP1SR413//vSV47Tx+X5A1JDuq971tHJXnDPP2HSZ42T99vfs0eluRbk5w199MNk5yT5Fvm1/VlSb5ji7b71+bt/tskL8n0XnNckh+dHz83ya9nCvpnJbnDwn7z3IX++MNM+96HF557rSTPm7ftDZmOnP3oJrWcm+RpSd6a6ToDRyZ52/xafE2Sm8zzbdR+Uqb3olOS/HOSb0vy6iQfSPJbW9SfuzN9k/iNSd4917r4enhG5n1svv+yzO+dmd5bbjwv45IkR87tL89X9683Jzlinv72JH+38H/wirnP75jkg9u4L31+sS/m6Z/PV98XD0/y/g1eR1fYhkxHv0+Y278uyWfWvT5/eWHdG71vbdR+UpLfnaefmOn9be29/LwkN9vGftyd/c8Cz56n75vkb9f38cJrcPH96lEL/fENSU7drm1eqPHBSV60cP/G8//1YQtta5/ZB83bfpeFftgzT3eSh67Nn+m9bu1kGmufX1fYB9ct/3qZ9umbZXrfPnGhhrVl7HW/3K6bI9cb+2h3/8M8/WdJ7p7ke+e//s9Kcq9MYWAjr57/PS3TDrrmdd397/P03TPtmOnu9yb5SKYda6P2JHlLd1/c3RdmCtevn9vPWreerbK+n+6d5M5JTqyq05M8JcmtqurGmXaCk+d5X7xuOSd297/N03dP8pLuvrS7P5nk5Ewf0hu1J8k7u/v87v5Skg8ledPcvl39sox7JXlld38qSRa2P3vpr+OT3HOePjPTNyU/kSkAJMl/TfLkuc9PyvTH2G1WvgVj7a0/vjPJX8yPvzjTa2DNK/ryXzEu7luL7pnptZnufmOmYJB5Wa/p7i909+cz7bP3mB/7SHe/bcA2baqqvjVTiP2WJA/KV1/P632qu++a5PmZPtz35vBM2/RDSdaOaD8o0+v/m5L8ZKb+3Jf/6O67d/dLk/xpkl/p7rtk2peePs+zUXuSfLm775nkBUn+MtO3VHdO8uiqutkS6x9h17zun+ju0/cx770y9Wvm95bPze3/svDc05LsrqobJvmuJK+Y97UXZur3Na/t7su6+z2ZDgAcSF6e5CHz9EMzhei92ds23D3T/nZZd38iyVvWPedlycbvW/t4P0u+OizlrCTnLLyXfzjb8M3ROvubBTb67F9v8f3qFUl+qKqunekgwnGDar8qzkry/fOR+Hss7BeLHlpV78r0R+ydMv1Btt6lSV41T1+U5D+S/HFVPShfHV6y0T74s1V1RqY/5G+d5IhMr4nbVdX/qar7JLloif1yyxlzvbH15yjsTEeA9nT3R2saG3ndTZ7/pfnfS3P5fv7CwnRl7zZqX1xuMh1d+9LC9Hb8f67vp4szvTle7kO8qg7dy7yLrm79sozK5n2ykftl+mC6f5Kn1vRVbyV5cHe/73IrqPr2q1zl1lmmPxYf/8K6x9bf3+h5i+vbyGbLGukemQL+F5OkqjYa+7r4gf2gDeZ5bU9jw99TVVcIRUk+sfZ17j5sFpResVH7wvOvEJTm5a0FpU8vUcNV9bkkH03y3ZmO2l8Zi+8pl2Y6enatJJ/t7iP3/pTLPWez19eW6+6PVdWn5+EGP5bkcRvMurdt2Ne2XNX9ZfH9ev17+Xa/f+9vFtjos3+9r/RZd3+xqk5M8oBMf/hs+yXBu/v98x//903yO/MQlq+oqttm+kP/27r7M1V1XPaeif5j7SBITxcKvFuS78t0UOEJmYL1FVTVUUm+P8l3zv1zUpLrzuv65kwH8n46U3/9XDbfL7ecI9cbu01VrQXEh2X6mjRJPjX/lbQ4nu7iTEM19tcpSR6eJFX1DZmONL5vk/YD0fp+eluSXWttVXXtqrpTd382yeeqau3I48M3WeYpmcanHVRVuzIFyXds0r5TvTnTX/43S5JaGDM//+X+mapaO5L6iCQnV9W1kty6u9+S5JczDQG5Yaarmv7Mwti/b5mfd2Vfm9thb/3xj5nehJPpNfPWDZ67mcX96QeT3GSh/UdqGkN5gyQPTPL3V778K22ZP7CW+cC+MqFob64OQenLSX4kySOr6r+te2z9PvHmJP9v8pXxnDfaaKHdfVGSf6mqh8zz1/xBv1O8NNP7xo27+6z9eN5bkzy4prHXN880zOYKNnrf2qj9ymzANtifLLCRZd6H/zjT0K53Ln6LuV1qOgPaF7v7z5L8fpK75vLbcaNM7xWfm18TP7jEMm+Y6bV3QqZAvBaG97YP3jjJZ+ZgfYck3zE/fliSa3X3q5I8NcldD8T9Urje2D8neVRVnZlpnNDzk7wo09GY1yZ558K8xyV5QV3+B43LeF6mH82clelo0aPnr8I2aj8Qre+n/5PpzeZ3569zTs/0dU2SPCbJH9X0g8a9fX2/5jWZhj6ckeTvMo3n+8Qm7TtSd5+T5LczheYzkjxn3SyPSvKsuW+PzDRO8aAkfza/Nt6d5A/mP1x+M8m1k5xZ0w+YfnNexluS3LF2wA8aN+iPn03ymLkPHpFpTOb++vVMX02/K9PwmX+d1/euTPvuO5K8PdNvI959VbdjP52S5IFVdb2qOiTJDw9e/lKhaG92elDq7i9kGiLz85k+qNe8PlOfnz5vwxMzfc1/VqZvBjYb7pdMf6g9dn6NnpPpaONO8cpMf6y+fD+f96pM45/PzvSV+9szfTuwN3t739qs/UC3P1lgI/t8H+7u0zINm/i/Q6q+6r4pyTvmYRa/luS3Ml1R8a+q6i3dfUamz6BzMo1F/4cNl/RVhyR5w9yXJ2faN5O974N/nemECWdm+jxbG6Z3yyQnzXUdl+RX5/YDar90hUaAbVRVv5bkkZl+W3FekvdkGqP8hu5+ZVWdm+kr6E/V9Av83+/uo6rq0XP7E+avZN/Q3a+cl/n57r7h/E3H8zJ9y/P+TD8Se053n7hBLV9Z13z/yExjp6+faazjY+avZTdqPynTjwVPnb/W/cXu/qF5WV95bFTfsXWq6obd/fn5m6V3ZPqR3449uLGMms4u84buvvMWrOsWmX4vc4feolN/sjrCNcDV2DUxFDHe/MfRoUmuk+T3uvu4bS1oC2xVuK6qR2b61u5J3b3RD03ZQYRrgKuxa2IoAthOwjXANUxVvSbJbdc1/0p3/8121ANwdSJcAwDAIM4WAgAAgwjXAAAwiHANsINU1ddV1Uur6kNV9Z6qOqGqvmE+vzkA22y7LysKwJLmK3C+Jsnx3f3jc9uRSW6+6RMB2DKOXAPsHN+b5D+7+wVrDd19epKPrt2vqt1V9fdV9a759l1z++FVdcp8lbizq+oe86WGj5vvn1VVPz/Pe/uq+uuqOm1e1h3m9ofM855RVads7aYD7AyOXAPsHHfOdHngzVyQ5Ae6+z+q6ogkL0myJ8l/S/I33f3bVXVQpqsrHpnklmsXyaiqQ+dlHJPk8d39gar69kxXebxXkqcluXd3f2xhXgAWCNcAVy/XTvLcebjIpUm+YW5/Z5Jjq+raSV7b3adX1YeT3K6q/k+SNyZ5U1XdMMl3JXnFNAolyXTZ9CT5hyTHVdXLk7x6azYHYGcxLARg5zgnybfuY56fT/LJJN+c6Yj1dZKku09Jcs8kH0vy4qp6ZHd/Zp7vpCQ/neSPM30ufLa7j1y4/Zd5GY9P8pQkt05y+nxJdQAWCNcAO8ffJfmaqvqptYaq+rYkX78wz42TnN/dlyV5RJKD5vm+PskF3f2iJH+S5K5VdViSa3X3q5I8Ncldu/uiJP9SVQ+Zn1dV9c3z9O27++3d/bQkn8oUsgFYIFwD7BA9XVL3gUl+YD4V3zlJnpHk4wuzPS/Jo6rqbZmGhHxhbj8q09Hmdyd5cJL/neSWSU6qqtOTHJfkV+d5H57ksVV1Rqaj5Q+Y2581//Dx7CSnJDljFdsJsJO5/DkAAAziyDUAAAwiXAMAwCDCNQAADCJcAwDAIMI1AAAMIlwDAMAgwjUAAAwiXAMAwCD/P+2V2/ee1WUDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# number of training image per each class\n",
    "training_num=[161,165,149,180,179,180,175,176,155]\n",
    "# number of training image per each class\n",
    "\n",
    "testing_num=[36,38,38,40,41,45,45,40,36]\n",
    "# number of testing image per each class\n",
    "\n",
    "validation_num=[27,27,27,27,27,27,27,27,27]\n",
    "# number of validation image per each class\n",
    "\n",
    "# places of ploting in the x axis\n",
    "y_pos=[-0,5,10,15,20,25,30,35,40]\n",
    "\n",
    "# ploting the number of training image in each class\n",
    "plt.bar(y_pos,training_num  ,label='Training dataset',width=2)\n",
    "plt.xticks(y_pos, classes_name)\n",
    "\n",
    "plt.xlabel(\"Classes\")\n",
    "plt.ylabel(\"Number of images\")\n",
    "plt.savefig('training_dataset.png')\n",
    "plt.title(\"training_dataset\")\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ploting the number of testing image in each class\n",
    "\n",
    "plt.bar(y_pos,testing_num ,label='Testing dataset',width=2)\n",
    "plt.xticks(y_pos, classes_name)\n",
    "\n",
    "plt.xlabel(\"Classes\")\n",
    "plt.ylabel(\"Number of images\")\n",
    "plt.savefig('testing_dataset.png')\n",
    "plt.title(\"testing_dataset\")\n",
    "\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ploting the number of validation image in each class\n",
    "\n",
    "plt.bar(y_pos,validation_num  ,label='Validation dataset',width=2)\n",
    "plt.xticks(y_pos, classes_name)\n",
    "\n",
    "plt.xlabel(\"Classes\")\n",
    "plt.ylabel(\"Number of images\")\n",
    "plt.savefig('validation_dataset.png')\n",
    "plt.title(\"validation_dataset\")\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtcAAAInCAYAAABTHHVEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xm4LFV9L/zvD3BGRQUNInrUYLwOCerRmDgE9SbO4oRDVNDrFXNfZ02uaBSneKOv09UkGnEIqIkKDohIVCQMaqIyyOyEiIKgHI3K4KsGWO8fVVuazd779IHVe58+fD7P009Xr15VtXrtrurvrl5dVa21AAAAV99Wa90AAADYUgjXAADQiXANAACdCNcAANCJcA0AAJ0I1wAA0IlwDQAAnQjXAJuRqnp6VX1p4nGrqt+9OssAYPUI1wDXYFX16qr60JayHoC1JlwDAEAnwjXAGqiqfarqu1V1YVWdXlWPuRrLullVHVJVF1TV15LcftHzb6+qs8fnj6+q+43lD0ny8iRPrKqLquqksfwZVfWNsW1nVtWzJ5a1fVUdWlU/r6r/rKovVtVW43O3rKqPV9WGqvpeVT1/pfUAbIm2WesGAFxDfTfJ/ZL8KMkeST60qWOrJ/xDkl8l2THJbZN8Lsn3Jp4/Nslrk/wiyQuSHFRV61prn62q/5Pkd1trT52of36SRyQ5M8n9k/xrVR3bWjshyUuSnJNkh7HuvZO0MWB/Osmnkjw5ya2SfKGqvrXCegC2OI5cA6yB1tpBrbVzW2uXtdY+muQ7Se61qcupqq2TPC7Jvq21i1trpyY5YNG6PtRa+2lr7ZLW2luSXCfJ763Qts+01r7bBkcn+XyGfwSS5L8yhPjbtNb+q7X2xdZaS3LPJDu01l7bWvtNa+3MJO9J8qRNfU0A80y4BlgDVbVnVZ04Dq/4eZK7JNn+KixqhwzfQp49Ufb9Ret6yTjM4xfjum680rqq6qFV9ZVx2MfPkzxsov6bkpyR5PPjkJF9xvLbJLnlwusZ53t5kltchdcEMLcMCwFYZVV1mwxHdR+U5D9aa5dW1YlJ6iosbkOSS5LsnOSbY9mtJ9Z1vyQvHdd1Wmvtsqr62cS62qK2XSfJx5PsmeRTrbX/qqqDF+q31i7MMDTkJVV15yRHVtWxGcL991pruyzTzrZMOcAWxZFrgNV3gwxhc0My/IAww5HrTdZauzTJJ5K8uqquX1V3SrLXRJUbZgjfG5JsU1X7JrnRxPM/TrJu4UeJSa6dYdjIhiSXVNVDk/zZQuWqekRV/W5VVZILklw63r6W5IKqemlVXa+qtq6qu1TVPZdZD8AWyU4OYJW11k5P8pYk/5EhdN41yZevxiKfm2TbDD+O3D/JP00897kk/5rk2xmGi/wqVxxCctB4/9OqOmE8Mv38JAcm+VmSP09yyET9XZJ8IclFY/vf2Vo7agz5j0yya4YfU/4kyXszDEG50nquxmsF2KzV8DsUAADg6nLkGgAAOhGuAeZAVZ02XoBl8e0pa902AC5nWAgAAHTiyDUAAHQy1+e53n777du6devWuhkAAGzhjj/++J+01nbYWL25Dtfr1q3Lcccdt9bNAABgC1dV3994LcNCAACgG+EaAAA6Ea4BAKAT4RoAADoRrgEAoBPhGgAAOhGuAQCgE+EaAAA6Ea4BAKAT4RoAADoRrgEAoBPhGgAAOhGuAQCgE+EaAAA6Ea4BAKAT4RoAADoRrgEAoBPhGgAAOhGuAQCgE+EaAAA6Ea4BAKCTbWa14KraOckHkvxOksuS7Ndae3tVvTrJs5JsGKu+vLV22DjPy5I8M8mlSZ7fWvvcrNoHwJZt3T6fWfV1nvWGh6/6OoHNy8zCdZJLkryktXZCVd0wyfFVdfj43Ntaa2+erFxVd0rypCR3TnLLJF+oqju01i6dYRsBAKCbmQ0Laa2d11o7YZy+MMk3kuy0wiy7J/lIa+3XrbXvJTkjyb1m1T4AAOhtVcZcV9W6JHdL8tWx6LlVdXJVvb+qbjKW7ZTk7InZzsnKYRwAADYrMw/XVbVtko8neWFr7YIk70py+yS7JjkvyVsWqi4xe1tieXtX1XFVddyGDRuWmAUAANbGTMN1VV0rQ7D+59baJ5Kktfbj1tqlrbXLkrwnlw/9OCfJzhOz3yrJuYuX2Vrbr7W2vrW2focddphl8wEAYJPMLFxXVSV5X5JvtNbeOlG+40S1xyQ5dZw+JMmTquo6VXXbJLsk+dqs2gcAAL3N8mwh90nytCSnVNWJY9nLkzy5qnbNMOTjrCTPTpLW2mlVdWCS0zOcaeQ5zhQCAMA8mVm4bq19KUuPoz5shXlen+T1s2oTAADM0iyPXANcZS4AsnGr3Ufz1j+szDYGs+Hy5wAA0IlwDQAAnQjXAADQiXANAACdCNcAANCJcA0AAJ0I1wAA0InzXAMALMG5wLkqHLkGAIBOhGsAAOhEuAYAgE6EawAA6ES4BgCAToRrAADoRLgGAIBOhGsAAOhEuAYAgE6EawAA6ES4BgCAToRrAADoRLgGAIBOhGsAAOhEuAYAgE6EawAA6ES4BgCAToRrAADoRLgGAIBOhGsAAOhEuAYAgE6EawAA6ES4BgCATrZZ6wawZVq3z2dWfZ1nveHhq75OAIBJjlwDAEAnwjUAAHQiXAMAQCfCNQAAdCJcAwBAJ8I1AAB0IlwDAEAnwjUAAHQiXAMAQCfCNQAAdOLy51eRy3sDALCYI9cAANCJcA0AAJ0I1wAA0IlwDQAAnQjXAADQiXANAACdCNcAANCJcA0AAJ0I1wAA0IlwDQAAnbj8OQAAm2zdPp9Z9XWe9YaHr/o6N5Uj1wAA0IlwDQAAnQjXAADQiXANAACdCNcAANCJcA0AAJ04FR+sEacwAoAtjyPXAADQiXANAACdCNcAANCJcA0AAJ0I1wAA0IlwDQAAnQjXAADQiXANAACdCNcAANCJcA0AAJ0I1wAA0IlwDQAAnQjXAADQiXANAACdCNcAANCJcA0AAJ0I1wAA0IlwDQAAnQjXAADQiXANAACdCNcAANCJcA0AAJ3MLFxX1c5VdWRVfaOqTquqF4zlN62qw6vqO+P9Tcbyqqp3VNUZVXVyVd19Vm0DAIBZmOWR60uSvKS19t+S3DvJc6rqTkn2SXJEa22XJEeMj5PkoUl2GW97J3nXDNsGAADdzSxct9bOa62dME5fmOQbSXZKsnuSA8ZqByR59Di9e5IPtMFXkmxXVTvOqn0AANDbqoy5rqp1Se6W5KtJbtFaOy8ZAniSm4/Vdkpy9sRs54xli5e1d1UdV1XHbdiwYZbNBgCATTLzcF1V2yb5eJIXttYuWKnqEmXtSgWt7ddaW99aW7/DDjv0aiYAAFxtMw3XVXWtDMH6n1trnxiLf7ww3GO8P38sPyfJzhOz3yrJubNsHwAA9DTLs4VUkvcl+UZr7a0TTx2SZK9xeq8kn5oo33M8a8i9k/xiYfgIAADMg21muOz7JHlaklOq6sSx7OVJ3pDkwKp6ZpIfJNljfO6wJA9LckaSXyZ5xgzbBgAA3c0sXLfWvpSlx1EnyYOWqN+SPGdW7QEAgFlzhUYAAOhEuAYAgE6EawAA6ES4BgCAToRrAADoRLgGAIBOhGsAAOhEuAYAgE6EawAA6ES4BgCAToRrAADoRLgGAIBOhGsAAOhEuAYAgE6EawAA6ES4BgCAToRrAADoRLgGAIBOhGsAAOhEuAYAgE6EawAA6ES4BgCAToRrAADoRLgGAIBOhGsAAOhEuAYAgE6EawAA6ES4BgCAToRrAADoRLgGAIBOhGsAAOhEuAYAgE6EawAA6ES4BgCAToRrAADoRLgGAIBOhGsAAOhEuAYAgE6EawAA6ES4BgCAToRrAADoRLgGAIBOhGsAAOhEuAYAgE6EawAA6ES4BgCAToRrAADoRLgGAIBOhGsAAOhEuAYAgE6EawAA6ES4BgCAToRrAADoRLgGAIBOhGsAAOhEuAYAgE6EawAA6ES4BgCAToRrAADoRLgGAIBOhGsAAOhEuAYAgE6EawAA6ES4BgCAToRrAADoRLgGAIBOhGsAAOhEuAYAgE6EawAA6ES4BgCAToRrAADoRLgGAIBOhGsAAOhEuAYAgE6EawAA6GSj4bqq9qiqG47Tr6iqT1TV3WffNAAAmC/THLl+ZWvtwqq6b5IHJzkgybtm2ywAAJg/04TrS8f7hyd5V2vtU0muPbsmAQDAfJomXP+wqt6d5AlJDquq60w5HwAAXKNME5KfkORzSR7SWvt5kpsm+auZtgoAAObQRsN1a+2XSc5Pct+x6JIk35llowAAYB5Nc7aQVyV5aZKXjUXXSvKhWTYKAADm0TTDQh6T5FFJLk6S1tq5SW44y0YBAMA8miZc/6a11pK0JKmqG0yz4Kp6f1WdX1WnTpS9uqp+WFUnjreHTTz3sqo6o6q+VVUP3tQXAgAAa22acH3geLaQ7arqWUm+kOQ9U8y3f5KHLFH+ttbaruPtsCSpqjsleVKSO4/zvLOqtp7mBQAAwOZim41VaK29uar+NMkFSX4vyb6ttcOnmO+Yqlo3ZTt2T/KR1tqvk3yvqs5Icq8k/zHl/AAAsOY2Gq6TZAzTGw3UU3puVe2Z5LgkL2mt/SzJTkm+MlHnnLEMAADmxjRnC7mwqi5YdDu7qj5ZVbfbxPW9K8ntk+ya5Lwkb1lYzRJ12zLt2buqjquq4zZs2LCJqwcAgNmZ5sj1W5Ocm+RfMoTgJyX5nSTfSvL+JLtNu7LW2o8XpqvqPUkOHR+ek2Tniaq3Gte51DL2S7Jfkqxfv37JAA4AAGthmh80PqS19u7W2oWttQvGcPuw1tpHk9xkU1ZWVTtOPHxMkoUziRyS5ElVdZ2qum2SXZJ8bVOWDQAAa22aI9eXVdUTknxsfPz4ieeWPXJcVR/OcFR7+6o6J8mrkuxWVbuO852V5NlJ0lo7raoOTHJ6hitAPqe1dummvRQAAFhb04TrpyR5e5J3ZgjFX0ny1Kq6XpLnLjdTa+3JSxS/b4X6r0/y+inaAwAAm6VpTsV3ZpJHLvP0l/o2BwAA5tdGw3VVXTfJMzNc4OW6C+Wttf8xw3YBAMDcmeYHjR/McHaQByc5OsOZPC6cZaMAAGAeTROuf7e19sokF7fWDkjy8CR3nW2zAABg/kwTrv9rvP95Vd0lyY2TrJtZiwAAYE5Nc7aQ/arqJklemeF81Nsm2XemrQIAgDk0zdlC3jtOHp1kUy93DgAA1xjTnC1kuyR7ZhgK8tv6rbXnz65ZAAAwf6YZFnJYhgvHnJLkstk2BwAA5tc04fq6rbUXz7wlAAAw56Y6z3VVPauqdqyqmy7cZt4yAACYM9Mcuf5Nkjcl+eskbSxr8eNGAAC4gmnC9YszXEjmJ7NuDAAAzLNphoWcluSXs24IAADMu2mOXF+a5MSqOjLJrxcKnYoPAACuaJpwffB4AwAAVjDNFRoPWI2GAADAvFs2XFfVga21J1TVKbn8LCG/1Vr7/Zm2DAAA5sxKR65fMN4/YjUaAgAA827ZcN1aO2+8//7qNQcAAObXNKfiAwAApiBcAwBAJ8uG66o6Yrx/4+o1BwAA5tdKP2jcsar+JMmjquojSWryydbaCTNtGQAAzJmVwvW+SfZJcqskb130XEvywFk1CgAA5tFKZwv5WJKPVdUrW2uvW8U2AQDAXJrmCo2vq6pHJbn/WHRUa+3Q2TYLAADmz0bPFlJVf5vhgjKnj7cXjGUAAMCEjR65TvLwJLu21i5Lkqo6IMnXk7xslg0DAIB5M+15rrebmL7xLBoCAADzbpoj13+b5OtVdWSG0/HdP45aAwDAlUzzg8YPV9VRSe6ZIVy/tLX2o1k3DAAA5s00R67TWjsvySEzbgsAAMy1acdcAwAAGyFcAwBAJyuG66raqqpOXa3GAADAPFsxXI/ntj6pqm69Su0BAIC5Nc0PGndMclpVfS3JxQuFrbVHzaxVAAAwh6YJ16+ZeSsAAGALMM15ro+uqtsk2aW19oWqun6SrWffNAAAmC8bPVtIVT0ryceSvHss2inJwbNsFAAAzKNpTsX3nCT3SXJBkrTWvpPk5rNsFAAAzKNpwvWvW2u/WXhQVdskabNrEgAAzKdpwvXRVfXyJNerqj9NclCST8+2WQAAMH+mCdf7JNmQ5JQkz05yWJJXzLJRAAAwj6Y5W8hlVXVAkq9mGA7yrdaaYSEAALDIRsN1VT08yT8m+W6SSnLbqnp2a+1fZ904AACYJ9NcROYtSR7QWjsjSarq9kk+k0S4BgCACdOMuT5/IViPzkxy/ozaAwAAc2vZI9dV9dhx8rSqOizJgRnGXO+R5NhVaBsAAMyVlYaFPHJi+sdJ/mSc3pDkJjNrEQAAzKllw3Vr7Rmr2RAAAJh305wt5LZJnpdk3WT91tqjZtcsAACYP9OcLeTgJO/LcFXGy2bbHAAAmF/ThOtftdbeMfOWAADAnJsmXL+9ql6V5PNJfr1Q2Fo7YWatAgCAOTRNuL5rkqcleWAuHxbSxscAAMBomnD9mCS3a639ZtaNAQCAeTbNFRpPSrLdrBsCAADzbpoj17dI8s2qOjZXHHPtVHwAADBhmnD9qpm3AgAAtgAbDdettaNXoyEAADDvprlC44UZzg6SJNdOcq0kF7fWbjTLhgEAwLyZ5sj1DScfV9Wjk9xrZi0CAIA5Nc3ZQq6gtXZwnOMaAACuZJphIY+deLhVkvW5fJgIAAAwmuZsIY+cmL4kyVlJdp9JawAAYI5NM+b6GavREAAAmHfLhuuq2neF+Vpr7XUzaA8AAMytlY5cX7xE2Q2SPDPJzZII1wAAMGHZcN1ae8vCdFXdMMkLkjwjyUeSvGW5+QAA4JpqxTHXVXXTJC9O8pQkByS5e2vtZ6vRMAAAmDcrjbl+U5LHJtkvyV1baxetWqsAAGAOrXQRmZckuWWSVyQ5t6ouGG8XVtUFq9M8AACYHyuNud7kqzcCAMA1mQANAACdCNcAANCJcA0AAJ0I1wAA0IlwDQAAnQjXAADQiXANAACdCNcAANCJcA0AAJ3MLFxX1fur6vyqOnWi7KZVdXhVfWe8v8lYXlX1jqo6o6pOrqq7z6pdAAAwK7M8cr1/kocsKtsnyRGttV2SHDE+TpKHJtllvO2d5F0zbBcAAMzEzMJ1a+2YJP+5qHj3JAeM0wckefRE+Qfa4CtJtquqHWfVNgAAmIXVHnN9i9baeUky3t98LN8pydkT9c4Zy66kqvauquOq6rgNGzbMtLEAALApNpcfNNYSZW2piq21/Vpr61tr63fYYYcZNwsAAKa32uH6xwvDPcb788fyc5LsPFHvVknOXeW2AQDA1bLa4fqQJHuN03sl+dRE+Z7jWUPuneQXC8NHAABgXmwzqwVX1YeT7JZk+6o6J8mrkrwhyYFV9cwkP0iyx1j9sCQPS3JGkl8mecas2gUAALMys3DdWnvyMk89aIm6LclzZtUWAABYDZvLDxoBAGDuCdcAANCJcA0AAJ0I1wAA0IlwDQAAnQjXAADQiXANAACdCNcAANCJcA0AAJ0I1wAA0IlwDQAAnQjXAADQiXANAACdCNcAANCJcA0AAJ0I1wAA0IlwDQAAnQjXAADQiXANAACdCNcAANCJcA0AAJ0I1wAA0IlwDQAAnQjXAADQiXANAACdCNcAANCJcA0AAJ0I1wAA0IlwDQAAnQjXAADQiXANAACdCNcAANCJcA0AAJ0I1wAA0IlwDQAAnQjXAADQiXANAACdCNcAANCJcA0AAJ0I1wAA0IlwDQAAnQjXAADQiXANAACdCNcAANCJcA0AAJ0I1wAA0IlwDQAAnQjXAADQiXANAACdCNcAANCJcA0AAJ0I1wAA0IlwDQAAnQjXAADQiXANAACdCNcAANCJcA0AAJ0I1wAA0IlwDQAAnQjXAADQiXANAACdCNcAANCJcA0AAJ0I1wAA0IlwDQAAnQjXAADQiXANAACdCNcAANCJcA0AAJ0I1wAA0IlwDQAAnQjXAADQiXANAACdCNcAANCJcA0AAJ0I1wAA0IlwDQAAnQjXAADQiXANAACdCNcAANCJcA0AAJ0I1wAA0IlwDQAAnWyzFiutqrOSXJjk0iSXtNbWV9VNk3w0ybokZyV5QmvtZ2vRPgAAuCrW8sj1A1pru7bW1o+P90lyRGttlyRHjI8BAGBubE7DQnZPcsA4fUCSR69hWwAAYJOtVbhuST5fVcdX1d5j2S1aa+clyXh/86VmrKq9q+q4qjpuw4YNq9RcAADYuDUZc53kPq21c6vq5kkOr6pvTjtja22/JPslyfr169usGggAAJtqTY5ct9bOHe/PT/LJJPdK8uOq2jFJxvvz16JtAABwVa16uK6qG1TVDRemk/xZklOTHJJkr7HaXkk+tdptAwCAq2MthoXcIsknq2ph/f/SWvtsVR2b5MCqemaSHyTZYw3aBgAAV9mqh+vW2plJ/mCJ8p8medBqtwcAAHrZnE7FBwAAc024BgCAToRrAADoRLgGAIBOhGsAAOhEuAYAgE6EawAA6ES4BgCAToRrAADoRLgGAIBOhGsAAOhEuAYAgE6EawAA6ES4BgCAToRrAADoRLgGAIBOhGsAAOhEuAYAgE6EawAA6ES4BgCAToRrAADoRLgGAIBOhGsAAOhEuAYAgE6EawAA6ES4BgCAToRrAADoRLgGAIBOhGsAAOhEuAYAgE6EawAA6ES4BgCAToRrAADoRLgGAIBOhGsAAOhEuAYAgE6EawAA6ES4BgCAToRrAADoRLgGAIBOhGsAAOhEuAYAgE6EawAA6ES4BgCAToRrAADoRLgGAIBOhGsAAOhEuAYAgE6EawAA6ES4BgCAToRrAADoRLgGAIBOhGsAAOhEuAYAgE6EawAA6ES4BgCAToRrAADoRLgGAIBOhGsAAOhEuAYAgE6EawAA6ES4BgCAToRrAADoRLgGAIBOhGsAAOhEuAYAgE6EawAA6ES4BgCAToRrAADoRLgGAIBOhGsAAOhEuAYAgE6EawAA6ES4BgCAToRrAADoRLgGAIBOhGsAAOhEuAYAgE6EawAA6ES4BgCAToRrAADoRLgGAIBOhGsAAOhkswvXVfWQqvpWVZ1RVfusdXsAAGBam1W4rqqtk/xDkocmuVOSJ1fVnda2VQAAMJ3NKlwnuVeSM1prZ7bWfpPkI0l2X+M2AQDAVDa3cL1TkrMnHp8zlgEAwGavWmtr3Ybfqqo9kjy4tfY/x8dPS3Kv1trzJursnWTv8eHvJfnWqjf06tk+yU/WuhGbOX20Mv2zcfpoZfpnZfpn4/TRyvTPxs1jH92mtbbDxiptsxot2QTnJNl54vGtkpw7WaG1tl+S/VazUT1V1XGttfVr3Y7NmT5amf7ZOH20Mv2zMv2zcfpoZfpn47bkPtrchoUcm2SXqrptVV07yZOSHLLGbQIAgKlsVkeuW2uXVNVzk3wuydZJ3t9aO22NmwUAAFPZrMJ1krTWDkty2Fq3Y4bmdkjLKtJHK9M/G6ePVqZ/VqZ/Nk4frUz/bNwW20eb1Q8aAQBgnm1uY64BAGBuCddLqKp1VXXqJtR/elXdcuLxWVW1/Wxat/nY1H7qNe+WrKpeXVV/2XF5u1bVw3otbx5U1fqqescyz10jts1rsqX2LZPviararar+eFOXMS+q6qLx/pZV9bGN1H1UVe2zOi275tpS9sNV9cKquv4U9d57Tb+69mY35npOPT3JqVl02sCVVNU2rbVLZtaiOaVfuts1yfpsob9jWPx+GR8fl+S4DsuuDEPnLru6y9qEdb46yUVJbpTkmNbaF1ao+6gkd2qtvWGVmje3Fr0ndsvQx/++Zg1aBa21c5M8fiN1DkmnM3JV1dattUt7LGsLtOx+eM4+816Y5ENJfrlSpYVrlSx2TXqPOHK9vG2q6oCqOrmqPlZV16+qfavq2Ko6tar2q8HjM2w0/1xVJ1bV9cb5n1dVJ1TVKVV1x+S3RyX3q6rPJ/lAVV23qv5prPP1qnrAWG+58qdX1cFV9emq+l5VPbeqXjzW+UpV3XQz6ad7VNXRVXV8VX2uqnYc23+Pqjqpqv4jyXMWFjC+roOq6tNJPj/265vGfj6lqp441luufLdxfQdW1ber6g1V9ZSq+tpY7/Zr0C9Tqao9x747qao+uOi5Xce/68lV9cmquslY/vyqOn0s/8hYdoOqev/4/vx6Ve1ew+ksX5vkieN784mr/wqnt7gvquo2VXXEWHZEVd16rLd/Vb21qo5M8sYltqvdqurQse7NqurzY5+8O0lNrO/F43vp1Kp64Vi2rqq+UVXvTHJCrnje/VXTWtt3pWA91jlklsG6qrae1bJXS1Xdbvzb/1VVHVpV65L8RZIXjdvE/arqFuP2ddJ4WziqvXVVvaeqThvfQ9cbl3n7qvrsuH/7Yl2+f9+/qt5RVf9eVWfW8NmwZmri6HtVfbWq7jzx3FHj/vjpVfX3Y9mS7a+qrarqnWM/HFpVh008d1YNn4tfSrLHCvus5cqPqqq3VdUx43Z3z6r6RFV9p6r+ZpW77ErGPvxmTZEFJl7PG2v47Pn2+P660n54iX3WF6tq14n1frmqfn+NXvZCG25QVZ8Zt4lTq+pVSW6Z5Mhx35uqeldVHTe+N14zMe9RVbV+nL6oql5bVV9N8kc1fD4vfH69eayz5DZYQ945flz+3mPZ1uN7dSEHvGgsX3K7XDOtNbdFtyTrkrQk9xkfvz/JXya56USdDyZ55Dh9VJL1E8+dleR54/T/k+S94/Srkxyf5Hrj45ck+adx+o5JfpDkuiuUPz3JGUlumGSHJL9I8hdjvbcleeFm0E9/leGI0A5j2RMznFIxSU5O8ifj9JuSnDpOPz3DBYRuOj5+XJLDM5yO8Rbj699xhfLdkvx8nL5Okh8mec24rBck+b9r/Z5apv/unOEKo9uPj286vkf+con+eu3C68jwDcl1xuntxvv/k+SpC2VJvp3kBmPf/v1av9ar2BefTrLX+Ph/JDl4nN4/yaFJtm5Lb1e7JTl0nH5Hkn3H6YeP79ftk9wjySljH22b5LQkdxvf05clufcqvva/Hl/7F5J8OMO+Zv8kjx+fPyvJazKE/VOS3HFiu/n7iT7lzyO7AAALLElEQVR5R4Zt78yJebdK8s7x9R2a4cjZ41doy1lJ9k3ypQzXGdg1yVfG9+Ink9xkrLdc+VEZ9kXHJPlGknsm+USS7yT5m1Xqz3UZvkn8vSRfH9s6+Z54dcZtbHz80Yz7zgz7lhuPy7gkya5j+YG5fPs6Isku4/QfJvm3ib/BQWOf3ynJGWu0LV002Q/j9Ity+T5xxyTfXuY9dKX2Zzj6fdhY/jtJfrbovfm/J9a93D5rufKjkrxxnH5Bhn3bwn78nCQ3W4s+XPRe2tQs8JZx+mFJvrC4nyfeg5P7rL0m+uQOSY5by9c9tuNxSd4z8fjG4997+4myhc/srcfX/vsT/bB+nG5JnrBQP8O+buFkGgufX1faBhct/3oZtumbZdh3Hz7RhoVlLLldrtXNkevlnd1a+/I4/aEk903ygPEIwClJHpghECznE+P98Rk20AWHtNb+v3H6vhk2zLTWvpnk+xk2rOXKk+TI1tqFrbUNGcL1p8fyUxatZ7Us7qcHJ7lLksOr6sQkr0hyq6q6cYaN4Oix7gcXLefw1tp/jtP3TfLh1tqlrbUfJzk6w4f0cuVJcmxr7bzW2q+TfDfJ58fyteqXaTwwycdaaz9JkonXnyX664Ak9x+nT87wTclTMwSAJPmzJPuMfX5Uhn/Gbj3zV9DPUn3xR0n+ZXz+gxn+/gsOalf8enFyu5p0/wzvy7TWPpMhGGRc1idbaxe31i7KsL3eb3zu+621r3R4TRtVVffIEGLvluSxufz9vNhPWmt3T/KuDB/uS9kxw+t6RJKFI9qPzfD+v2uS/5mhTzfmV621+7bWPpLkA0le2lr7/Qzb0qvGOsuVJ8lvWmv3T/KPST6V4VuquyR5elXdbIr197DDuO6nttZO3EjdB2bo14z7ll+M5d+bmPf4JOuqatskf5zkoHFbe3eGfl9wcGvtstba6RkOAGwuDkyyxzj9hAwheilLtf++Gba3y1prP0py5KJ5Pposv8/ayL4suXxYyilJTpvYj5+ZNfrmaJFNzQLLffYvNrnPOijJI6rqWhkOJOzfqe1XxylJ/vt4JP5+E9vFpCdU1QkZ/om9c4Z/yha7NMnHx+kLkvwqyXur6rG5fHjJctvg86vqpAz/yO+cZJcM74vbVdXfVdVDklwwxXa56oy5Xt7icxS2DEeA1rfWzq5hbOR1V5j/1+P9pbliP188MV1Z2nLlk8tNhiNsv56YXou/5+J+ujDDDvIKH+JVtd0SdSdtaf0yjcrKfbKch2f4cHpUklfW8HVvJXlca+1bV1hB1R9e7Vaujmn6YvL5ixc9t/jxcvNNrm85Ky2rt/tlCPm/TJKqWm786+QH9mOXqXNwG8aHn15VVwpGSX608HXuRqwUlg5arnxi/iuFpXF5C2Hpp1O04er6RZKzk9wnw1H7q2Jyn3JphqNnWyX5eWtt16VnucI8K73HVlVr7YdV9dNxqMETkzx7mapLtX9jr+Pqbi+T++rF+/HNYd+9qVlguc/+xX7bb621X1bV4Ul2z/DPz5pfEry19u3xn/+HJfnbcQjLb1XVbTP8o3/P1trPqmr/LJ2JfrVwIKQNFwq8V5IHZTio8NwMwfpKqmq3JP89yR+N/XNUkuuO6/qDDAfynpOhv16YlbfLVefI9fJuXVULAfHJGb4mTZKfjP8lTY6nuzDDUI1NdUySpyRJVd0hw5HGb61Qvjla3E9fSbLDQllVXauq7txa+3mSX1TVwtHHp6ywzGMyjE/buqp2yBAkv7ZC+bw6IsN//jdLkpoYMz/+5/6zqlo4mvq0JEdX1VZJdm6tHZnkf2cYArJthquaPm9i7N/dxvmu6ntztS3VF/+eYQecDO+XLy0z70omt6WHJrnJRPmjaxg/eYMkj0nyxave/Ktlmn+wpvnAvirBaClbQlj6TZJHJ9mzqv580XOLt4kjkvyv5LfjOW+03EJbaxck+V5V7THWr/GDfh58JMM+48attVM2Yb4vJXlcDWOvb5FhiM2VLLfPWq78qryANbIpWWA50+yH35thaNexk99irpUazoD2y9bah5K8Ocndc8XXcaMM+4pfjO+Lh06xzG0zvP8OyxCIF8LwUtvgjZP8bAzWd0xy7/H57ZNs1Vr7eJJXJrn75rhdCtfL+0aSvarq5AzjhN6V5D0ZjsYcnOTYibr7J/nHuuIPGqfxzgw/mjklw9Gip49fhy1Xvjla3E9/l2Fn88bx65wTM3xdkyTPSPIPNfygcamv8Bd8MsPQh5OS/FuGMX0/WqF8LrXWTkvy+gyh+aQkb11UZa8kbxr7dtcMYxW3TvKh8b3x9SRvG/9xeV2SayU5uYYfMb1uXMaRSe5Um/kPGpfpi+cnecb4+p+WYUzmpnpNhq+mT8gwdOYH4/pOyLDdfi3JVzP8LuLrV/d1XAXHJHlMVV2vqm6Y5JGdlz9VMFrKvIel1trFGYbIvCjDB/WCT2fo8xPH1/CCDF/zn5Lhm4GVhvslwz9rzxzfp6dlONo4Dz6W4Z/VAzdxvo9nGP98aoav27+a4ZuBpSy1z1qpfB5sShZYzkb3w6214zMMm/inLq2++u6a5GvjMIu/TvI3Ga6o+K9VdWRr7aQMn0GnZRiL/uVll3S5GyY5dOzLozNsm8nS2+BnM5ww4eQMn2cLQ/V2SnLU2K79k7xsLN+stktXaARYQ1X110n2zPDbinOSnJ5hjPKhrbWPVdVZGb6C/kkNv8B/c2ttt6p6+lj+3PEr2UNbax8bl3lRa23b8ZuOd2b4lufbGX4o9tbW2uHLtOW36xof75ph7PT1M4x1fMb4texy5Udl+LHgcePXun/ZWnvEuKzfPter71gdVbVta+2i8Zulr2X4gd/cHtiYVg1nlzm0tXaXVVjXLTP8XuaObRVP/8lsCNcAW7BrajCin/Efo+2SXDvJ/9ta239NG7RKVitcV9WeGb65e3FrbbkfmzJHhGuALdg1NRgBrBXhGuAapqo+meS2i4pf2lr73Fq0B2BLIlwDAEAnzhYCAACdCNcAANCJcA0wR6rqd6rqI1X13ao6vaoOq6o7jOc3B2CNbQ6XFgVgCuMVOD+Z5IDW2pPGsl2T3GLFGQFYNY5cA8yPByT5r9baPy4UtNZOTHL2wuOqWldVX6yqE8bbH4/lO1bVMeNV4k6tqvuNlxref3x8SlW9aKx7+6r6bFUdPy7rjmP5HmPdk6rqmNV96QDzwZFrgPlxlwyXB17J+Un+tLX2q6raJcmHk6xP8udJPtdae31VbZ3h6oq7Jtlp4SIZVbXduIz9kvxFa+07VfWHGa7y+MAk+yZ5cGvthxN1AZggXANsWa6V5O/H4SKXJrnDWH5skvdX1bWSHNxaO7Gqzkxyu6r6uySfSfL5qto2yR8nOWgYhZJkuGx6knw5yf5VdWCST6zOywGYL4aFAMyP05LcYyN1XpTkx0n+IMMR62snSWvtmCT3T/LDJB+sqj1baz8b6x2V5DlJ3pvhc+HnrbVdJ27/bVzGXyR5RZKdk5w4XlIdgAnCNcD8+Lck16mqZy0UVNU9k9xmos6Nk5zXWrssydOSbD3Wu02S81tr70nyviR3r6rtk2zVWvt4klcmuXtr7YIk36uqPcb5qqr+YJy+fWvtq621fZP8JEPIBmCCcA0wJ9pwSd3HJPnT8VR8pyV5dZJzJ6q9M8leVfWVDENCLh7Ld8twtPnrSR6X5O1JdkpyVFWdmGT/JC8b6z4lyTOr6qQMR8t3H8vfNP7w8dQkxyQ5aRavE2Ceufw5AAB04sg1AAB0IlwDAEAnwjUAAHQiXAMAQCfCNQAAdCJcAwBAJ8I1AAB0IlwDAEAn/z8amusOentx3wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ploting the number of all the image in each class\n",
    "\n",
    "all_num=[]\n",
    "for i in range(0,9):\n",
    "    all_num.append(testing_num[i]+training_num[i]+validation_num[i])\n",
    "plt.bar(y_pos,all_num ,label='All dataset',width=2)\n",
    "plt.xticks(y_pos, classes_name)\n",
    "\n",
    "plt.xlabel(\"Classes\")\n",
    "plt.ylabel(\"Number of images\")\n",
    "plt.savefig('all_dataset.png')\n",
    "plt.title(\"all_dataset\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of a random model=9.192200557103064%\n"
     ]
    }
   ],
   "source": [
    "### RANDOM MODEL CLASSIFIER \n",
    "\n",
    "counter=0\n",
    "for true_value in data_testing['target']:\n",
    "    if(true_value==randint(0,9)):\n",
    "        counter=counter+1\n",
    "        \n",
    "accuracy=(counter/data_testing['target'].shape[0])   \n",
    "print(\"The accuracy of a random model={}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the dataset into 4D tensor\n",
    "train_tensor=paths_to_tensor(x_train)\n",
    "valid_tensor=paths_to_tensor(x_valid)\n",
    "test_tensor=paths_to_tensor(x_test)\n",
    "train_tensor_aug=paths_to_tensor(x_train_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# extract bottleneck feature of Resnet50 model\n",
    "\n",
    "valid_resnet=ResNet50(weights='imagenet', include_top=False).predict(preprocess_input(valid_tensor))\n",
    "print(\"done\")\n",
    "\n",
    "test_resnet=ResNet50(weights='imagenet', include_top=False).predict(preprocess_input(test_tensor))\n",
    "print(\"done\")\n",
    "\n",
    "train_resnet=ResNet50(weights='imagenet', include_top=False).predict(preprocess_input(train_tensor))\n",
    "print (\"done\")\n",
    "\n",
    "# save the bottleneck feature\n",
    "np.save(\"train_resnet\", train_resnet)\n",
    "np.save(\"valid_resnet\", valid_resnet)\n",
    "np.save(\"test_resnet\", test_resnet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'valid_resnet.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-67bf4e64ffff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# load the bottleneck feature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mvalid_resnet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'valid_resnet.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtest_resnet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test_resnet.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrain_resnet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train_resnet.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'valid_resnet.npy'"
     ]
    }
   ],
   "source": [
    "# load the bottleneck feature\n",
    "valid_resnet=np.load('valid_resnet.npy')\n",
    "test_resnet=np.load('test_resnet.npy')\n",
    "train_resnet=np.load('train_resnet.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d_2 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 9)                 18441     \n",
      "=================================================================\n",
      "Total params: 18,441\n",
      "Trainable params: 18,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create a convolutional model with a pooling layer that accept input with dimension (1,1,2048) and a dense layer for classification \n",
    "Resnet50_model = Sequential()\n",
    "Resnet50_model.add(GlobalAveragePooling2D(input_shape=(None,None,2048)))\n",
    "Resnet50_model.add(Dense(9, activation='softmax'))\n",
    "\n",
    "Resnet50_model.summary()\n",
    "Resnet50_model.compile(optimizer='adagrad', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 1.0180 - acc: 0.7099 - val_loss: 0.4204 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.42042, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/50\n",
      " - 1s - loss: 0.3663 - acc: 0.8750 - val_loss: 0.2455 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.42042 to 0.24554, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/50\n",
      " - 1s - loss: 0.2703 - acc: 0.9230 - val_loss: 0.1853 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.24554 to 0.18534, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/50\n",
      " - 1s - loss: 0.2227 - acc: 0.9474 - val_loss: 0.1688 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.18534 to 0.16884, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/50\n",
      " - 1s - loss: 0.1882 - acc: 0.9559 - val_loss: 0.1406 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.16884 to 0.14059, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/50\n",
      " - 1s - loss: 0.1637 - acc: 0.9664 - val_loss: 0.1198 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.14059 to 0.11975, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/50\n",
      " - 1s - loss: 0.1468 - acc: 0.9743 - val_loss: 0.1089 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.11975 to 0.10889, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/50\n",
      " - 1s - loss: 0.1316 - acc: 0.9822 - val_loss: 0.1009 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.10889 to 0.10088, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/50\n",
      " - 1s - loss: 0.1184 - acc: 0.9822 - val_loss: 0.0946 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.10088 to 0.09462, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/50\n",
      " - 1s - loss: 0.1096 - acc: 0.9849 - val_loss: 0.0846 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.09462 to 0.08464, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/50\n",
      " - 1s - loss: 0.1011 - acc: 0.9882 - val_loss: 0.0795 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.08464 to 0.07953, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/50\n",
      " - 1s - loss: 0.0946 - acc: 0.9882 - val_loss: 0.0744 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.07953 to 0.07445, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/50\n",
      " - 1s - loss: 0.0879 - acc: 0.9921 - val_loss: 0.0736 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.07445 to 0.07361, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/50\n",
      " - 1s - loss: 0.0825 - acc: 0.9928 - val_loss: 0.0703 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.07361 to 0.07032, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/50\n",
      " - 1s - loss: 0.0784 - acc: 0.9934 - val_loss: 0.0613 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.07032 to 0.06134, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/50\n",
      " - 1s - loss: 0.0737 - acc: 0.9934 - val_loss: 0.0587 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.06134 to 0.05866, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/50\n",
      " - 1s - loss: 0.0703 - acc: 0.9947 - val_loss: 0.0571 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.05866 to 0.05712, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/50\n",
      " - 1s - loss: 0.0667 - acc: 0.9947 - val_loss: 0.0544 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.05712 to 0.05444, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/50\n",
      " - 1s - loss: 0.0638 - acc: 0.9947 - val_loss: 0.0528 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.05444 to 0.05279, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/50\n",
      " - 1s - loss: 0.0611 - acc: 0.9961 - val_loss: 0.0502 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.05279 to 0.05019, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 21/50\n",
      " - 1s - loss: 0.0588 - acc: 0.9967 - val_loss: 0.0491 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.05019 to 0.04913, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/50\n",
      " - 1s - loss: 0.0558 - acc: 0.9961 - val_loss: 0.0475 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.04913 to 0.04754, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/50\n",
      " - 1s - loss: 0.0542 - acc: 0.9974 - val_loss: 0.0437 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.04754 to 0.04373, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 24/50\n",
      " - 1s - loss: 0.0525 - acc: 0.9967 - val_loss: 0.0434 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.04373 to 0.04337, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 25/50\n",
      " - 1s - loss: 0.0506 - acc: 0.9974 - val_loss: 0.0411 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.04337 to 0.04112, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 26/50\n",
      " - 1s - loss: 0.0488 - acc: 0.9967 - val_loss: 0.0403 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.04112 to 0.04032, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 27/50\n",
      " - 1s - loss: 0.0470 - acc: 0.9980 - val_loss: 0.0402 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.04032 to 0.04015, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 28/50\n",
      " - 1s - loss: 0.0460 - acc: 0.9974 - val_loss: 0.0388 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.04015 to 0.03881, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 29/50\n",
      " - 1s - loss: 0.0445 - acc: 0.9974 - val_loss: 0.0387 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.03881 to 0.03873, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 30/50\n",
      " - 1s - loss: 0.0434 - acc: 0.9967 - val_loss: 0.0359 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.03873 to 0.03588, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 31/50\n",
      " - 1s - loss: 0.0421 - acc: 0.9974 - val_loss: 0.0354 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.03588 to 0.03540, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 32/50\n",
      " - 1s - loss: 0.0406 - acc: 0.9980 - val_loss: 0.0348 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.03540 to 0.03478, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 33/50\n",
      " - 1s - loss: 0.0397 - acc: 0.9980 - val_loss: 0.0337 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.03478 to 0.03369, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 34/50\n",
      " - 1s - loss: 0.0387 - acc: 0.9974 - val_loss: 0.0329 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.03369 to 0.03285, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 35/50\n",
      " - 1s - loss: 0.0378 - acc: 0.9967 - val_loss: 0.0332 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.03285\n",
      "Epoch 36/50\n",
      " - 1s - loss: 0.0368 - acc: 0.9980 - val_loss: 0.0305 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.03285 to 0.03045, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 37/50\n",
      " - 1s - loss: 0.0362 - acc: 0.9974 - val_loss: 0.0302 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.03045 to 0.03022, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 38/50\n",
      " - 1s - loss: 0.0351 - acc: 0.9980 - val_loss: 0.0297 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.03022 to 0.02973, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 39/50\n",
      " - 1s - loss: 0.0347 - acc: 0.9967 - val_loss: 0.0293 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.02973 to 0.02926, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 40/50\n",
      " - 1s - loss: 0.0338 - acc: 0.9961 - val_loss: 0.0289 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.02926 to 0.02886, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 41/50\n",
      " - 1s - loss: 0.0332 - acc: 0.9967 - val_loss: 0.0282 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.02886 to 0.02815, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 42/50\n",
      " - 1s - loss: 0.0323 - acc: 0.9967 - val_loss: 0.0269 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.02815 to 0.02695, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 43/50\n",
      " - 1s - loss: 0.0318 - acc: 0.9974 - val_loss: 0.0275 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.02695\n",
      "Epoch 44/50\n",
      " - 1s - loss: 0.0312 - acc: 0.9967 - val_loss: 0.0261 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.02695 to 0.02610, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 45/50\n",
      " - 1s - loss: 0.0307 - acc: 0.9967 - val_loss: 0.0259 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.02610 to 0.02593, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 46/50\n",
      " - 1s - loss: 0.0300 - acc: 0.9974 - val_loss: 0.0256 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.02593 to 0.02556, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 47/50\n",
      " - 1s - loss: 0.0292 - acc: 0.9980 - val_loss: 0.0248 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.02556 to 0.02485, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 48/50\n",
      " - 1s - loss: 0.0289 - acc: 0.9980 - val_loss: 0.0250 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.02485\n",
      "Epoch 49/50\n",
      " - 1s - loss: 0.0284 - acc: 0.9974 - val_loss: 0.0244 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.02485 to 0.02444, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 50/50\n",
      " - 1s - loss: 0.0278 - acc: 0.9980 - val_loss: 0.0241 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.02444 to 0.02412, saving model to weights.best.Resnet50.hdf5\n"
     ]
    }
   ],
   "source": [
    "### TODO: Train the model.\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='weights.best.Resnet50.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "history=Resnet50_model.fit(train_resnet, y_train, \n",
    "          validation_data=(valid_resnet, y_valid),\n",
    "          epochs=50, batch_size=20, callbacks=[checkpointer], verbose=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Valid'], loc='upper left')\n",
    "plt.savefig('resnet50_accuracy.png')\n",
    "\n",
    "plt.show()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Valid'], loc='upper left')\n",
    "plt.savefig('resnet50_loss.png')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 84.4011%\n"
     ]
    }
   ],
   "source": [
    "Resnet50_model.load_weights('weights.best.Resnet50.hdf5')\n",
    "Resnet50_predictions = [np.argmax(Resnet50_model.predict(np.expand_dims(feature, axis=0))) for feature in test_resnet]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(Resnet50_predictions)==np.argmax(y_test, axis=1))/len(Resnet50_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_name=['bathroom','bedroom','closet','corridor','dining_room','kitchen','livingroom','pantry','stairscase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that accept the predicted output and pronouce the object loud\n",
    "\n",
    "def voice_assist(num):\n",
    "    \n",
    "    \n",
    "        if (num==0):\n",
    "            speaker.Speak(\"It's a bathroom!\")\n",
    "\n",
    "        elif (num==1):\n",
    "            speaker.Speak(\"It's a bedroom!\")  \n",
    "        elif (num==2):\n",
    "            speaker.Speak(\"It's a children room ! \")  \n",
    "        elif (num==3):\n",
    "            speaker.Speak(\"It's a closet!\")  \n",
    "        elif (num==4):\n",
    "            speaker.Speak(\"It's a corridor!\")  \n",
    "        elif (num==5):\n",
    "            speaker.Speak(\"It's a dining room!\")  \n",
    "        elif (num==6):\n",
    "            speaker.Speak(\"It's a kitchen!\")  \n",
    "        elif (num==7):\n",
    "            speaker.Speak(\"It's a living room!\")  \n",
    "        elif (num==8):\n",
    "            speaker.Speak(\"It's a pantry!\")  \n",
    "        elif (num==9):\n",
    "            speaker.Speak(\"It's a staircase!\") \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time taken to process one frame is =16.583635807037354\n"
     ]
    }
   ],
   "source": [
    "   # a function that thakes frames from the camera and preprocess \n",
    "   #the frame and the predict the class of the image and then pass the parameter to voice_assist function\n",
    "    prev_class_num=20 # random class number\n",
    "    accuracy=0.6 # determine how sure the model of the classified object\n",
    "    \n",
    "    cap = cv2.VideoCapture(0) # select the camera you choose if you have multiple camera devices\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX # font type\n",
    "\n",
    "\n",
    "    while 1:\n",
    "        start=time.time() # start the timer\n",
    "        ret, img = cap.read() # read a frame \n",
    "        # preprocess the frame\n",
    "        frame=cv2.resize(img, (224, 224))\n",
    "        frame = image.img_to_array(frame)\n",
    "        frame=np.expand_dims(frame,axis=0)\n",
    "        #predict the frame using the model created and classify the frame\n",
    "        prediction=Resnet50_model.predict(ResNet50(weights='imagenet', include_top=False).predict(preprocess_input(frame)))\n",
    "        \n",
    "        class_num=np.argmax(prediction) # return the number of the class that have the maximum class accuracy\n",
    "        if(prediction[0][class_num]>accuracy):\n",
    "            cv2.putText(img,classes_name[class_num],(10,224), font, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            if( (class_num != prev_class_num)):\n",
    "\n",
    "                prev_class_num=class_num\n",
    "                voice_assist(class_num)\n",
    "        cv2.imshow('img',img) # show the image ,this line can be deleted to decrease the time processing\n",
    "        end=time.time() # end the timer \n",
    "        \n",
    "        k = cv2.waitKey(30) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    print(\"The time taken to process one frame is ={}\".format(end-start)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\blackice\\Anaconda3\\envs\\test\\lib\\site-packages\\keras_applications\\mobilenet_v2.py:315: UserWarning: MobileNet shape is undefined. Weights for input shape(224, 224) will be loaded.\n",
      "  warnings.warn('MobileNet shape is undefined.'\n"
     ]
    }
   ],
   "source": [
    "# loading mobilenetv2 model trained on imagenet dataset\n",
    "model=MobileNetV2(weights='imagenet', include_top=False,pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "valid_mobile=model.predict(preprocess_input(valid_tensor))\n",
    "print(\"done\")\n",
    "\n",
    "test_mobile=model.predict(preprocess_input(test_tensor))\n",
    "print(\"done\")\n",
    "\n",
    "train_mobile=model.predict(preprocess_input(train_tensor))\n",
    "print (\"done\")\n",
    "\n",
    "train_tensor_aug=model.predict(preprocess_input(train_tensor_aug))\n",
    "print (\"done\")\n",
    "\n",
    "\n",
    "np.save(\"train_mobile\", train_mobile)\n",
    "np.save(\"valid_mobile\", valid_mobile)\n",
    "np.save(\"test_mobile\", test_mobile)\n",
    "np.save(\"train_tensor_aug\", train_tensor_aug)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_mobile=np.load('valid_mobile.npy')\n",
    "test_mobile=np.load('test_mobile.npy')\n",
    "train_mobile=np.load('train_mobile.npy')\n",
    "train_tensor_aug=np.load('train_tensor_aug.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_model = Sequential()\n",
    "\n",
    "my_model.add(Dense(9, activation='softmax',input_shape=train_mobile.shape[1:]))\n",
    "\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_model = Sequential()\n",
    "\n",
    "\n",
    "my_model.add(Dense(9, activation='softmax',input_shape=train_mobile.shape[1:]))\n",
    "\n",
    "\n",
    "my_model.summary()\n",
    "        \n",
    "my_model.compile(optimizer=\"RMSprop\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "checkpointer = ModelCheckpoint(filepath='weights.best.Resnet50.hdf5', \n",
    "                               verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 2s - loss: 1.7435 - acc: 0.3776 - val_loss: 1.3227 - val_acc: 0.5144\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.32274, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 1s - loss: 1.1993 - acc: 0.5803 - val_loss: 1.1787 - val_acc: 0.5514\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.32274 to 1.17874, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 1s - loss: 1.0179 - acc: 0.6572 - val_loss: 0.9290 - val_acc: 0.6790\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.17874 to 0.92904, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 1s - loss: 0.9051 - acc: 0.7053 - val_loss: 0.8787 - val_acc: 0.6790\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.92904 to 0.87871, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 1s - loss: 0.8463 - acc: 0.7197 - val_loss: 0.8098 - val_acc: 0.7160\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.87871 to 0.80983, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 1s - loss: 0.7753 - acc: 0.7395 - val_loss: 0.7898 - val_acc: 0.7243\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.80983 to 0.78976, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 1s - loss: 0.7223 - acc: 0.7605 - val_loss: 0.6618 - val_acc: 0.7860\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.78976 to 0.66182, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 1s - loss: 0.6859 - acc: 0.7822 - val_loss: 0.6878 - val_acc: 0.7737\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.66182\n",
      "Epoch 9/200\n",
      " - 1s - loss: 0.6502 - acc: 0.7783 - val_loss: 0.6770 - val_acc: 0.7449\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.66182\n",
      "Epoch 10/200\n",
      " - 1s - loss: 0.6189 - acc: 0.7987 - val_loss: 0.5878 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.66182 to 0.58779, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 1s - loss: 0.5810 - acc: 0.8151 - val_loss: 0.6111 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.58779\n",
      "Epoch 12/200\n",
      " - 1s - loss: 0.5619 - acc: 0.8204 - val_loss: 0.5243 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.58779 to 0.52427, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 1s - loss: 0.5409 - acc: 0.8349 - val_loss: 0.5082 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.52427 to 0.50817, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 1s - loss: 0.5164 - acc: 0.8355 - val_loss: 0.5175 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.50817\n",
      "Epoch 15/200\n",
      " - 1s - loss: 0.4971 - acc: 0.8520 - val_loss: 0.5003 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.50817 to 0.50035, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 1s - loss: 0.4803 - acc: 0.8559 - val_loss: 0.4522 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.50035 to 0.45220, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 1s - loss: 0.4605 - acc: 0.8645 - val_loss: 0.4626 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.45220\n",
      "Epoch 18/200\n",
      " - 1s - loss: 0.4398 - acc: 0.8809 - val_loss: 0.4740 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.45220\n",
      "Epoch 19/200\n",
      " - 1s - loss: 0.4279 - acc: 0.8730 - val_loss: 0.4624 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.45220\n",
      "Epoch 20/200\n",
      " - 1s - loss: 0.4157 - acc: 0.8908 - val_loss: 0.4182 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.45220 to 0.41815, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 21/200\n",
      " - 1s - loss: 0.4052 - acc: 0.8895 - val_loss: 0.3817 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.41815 to 0.38172, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 1s - loss: 0.3877 - acc: 0.9072 - val_loss: 0.3717 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.38172 to 0.37175, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 1s - loss: 0.3763 - acc: 0.9033 - val_loss: 0.3760 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.37175\n",
      "Epoch 24/200\n",
      " - 1s - loss: 0.3612 - acc: 0.9118 - val_loss: 0.3619 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.37175 to 0.36187, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 25/200\n",
      " - 1s - loss: 0.3563 - acc: 0.9033 - val_loss: 0.3517 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.36187 to 0.35171, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 26/200\n",
      " - 1s - loss: 0.3488 - acc: 0.9145 - val_loss: 0.3307 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.35171 to 0.33066, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 27/200\n",
      " - 1s - loss: 0.3335 - acc: 0.9237 - val_loss: 0.3393 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.33066\n",
      "Epoch 28/200\n",
      " - 1s - loss: 0.3293 - acc: 0.9224 - val_loss: 0.3314 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.33066\n",
      "Epoch 29/200\n",
      " - 1s - loss: 0.3146 - acc: 0.9270 - val_loss: 0.3187 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.33066 to 0.31874, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 30/200\n",
      " - 1s - loss: 0.3031 - acc: 0.9355 - val_loss: 0.3027 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.31874 to 0.30267, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 31/200\n",
      " - 1s - loss: 0.2962 - acc: 0.9368 - val_loss: 0.3106 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.30267\n",
      "Epoch 32/200\n",
      " - 1s - loss: 0.2886 - acc: 0.9467 - val_loss: 0.2896 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.30267 to 0.28956, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 33/200\n",
      " - 1s - loss: 0.2842 - acc: 0.9414 - val_loss: 0.3126 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.28956\n",
      "Epoch 34/200\n",
      " - 1s - loss: 0.2787 - acc: 0.9461 - val_loss: 0.2756 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.28956 to 0.27562, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 35/200\n",
      " - 1s - loss: 0.2705 - acc: 0.9434 - val_loss: 0.2891 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.27562\n",
      "Epoch 36/200\n",
      " - 1s - loss: 0.2625 - acc: 0.9467 - val_loss: 0.2725 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.27562 to 0.27254, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 37/200\n",
      " - 1s - loss: 0.2591 - acc: 0.9559 - val_loss: 0.2858 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.27254\n",
      "Epoch 38/200\n",
      " - 1s - loss: 0.2502 - acc: 0.9592 - val_loss: 0.2736 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.27254\n",
      "Epoch 39/200\n",
      " - 1s - loss: 0.2445 - acc: 0.9605 - val_loss: 0.2538 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.27254 to 0.25384, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 40/200\n",
      " - 1s - loss: 0.2440 - acc: 0.9553 - val_loss: 0.2678 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.25384\n",
      "Epoch 41/200\n",
      " - 1s - loss: 0.2381 - acc: 0.9632 - val_loss: 0.2761 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.25384\n",
      "Epoch 42/200\n",
      " - 1s - loss: 0.2341 - acc: 0.9605 - val_loss: 0.2639 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.25384\n",
      "Epoch 43/200\n",
      " - 1s - loss: 0.2269 - acc: 0.9658 - val_loss: 0.2299 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.25384 to 0.22986, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 44/200\n",
      " - 1s - loss: 0.2228 - acc: 0.9638 - val_loss: 0.2367 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.22986\n",
      "Epoch 45/200\n",
      " - 1s - loss: 0.2176 - acc: 0.9697 - val_loss: 0.2314 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.22986\n",
      "Epoch 46/200\n",
      " - 1s - loss: 0.2131 - acc: 0.9671 - val_loss: 0.2328 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.22986\n",
      "Epoch 47/200\n",
      " - 1s - loss: 0.2082 - acc: 0.9724 - val_loss: 0.2221 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.22986 to 0.22210, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 48/200\n",
      " - 1s - loss: 0.2068 - acc: 0.9737 - val_loss: 0.2320 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.22210\n",
      "Epoch 49/200\n",
      " - 1s - loss: 0.2001 - acc: 0.9697 - val_loss: 0.2162 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.22210 to 0.21619, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 50/200\n",
      " - 1s - loss: 0.1976 - acc: 0.9776 - val_loss: 0.2344 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.21619\n",
      "Epoch 51/200\n",
      " - 1s - loss: 0.1932 - acc: 0.9809 - val_loss: 0.2059 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.21619 to 0.20585, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 52/200\n",
      " - 1s - loss: 0.1867 - acc: 0.9809 - val_loss: 0.2037 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.20585 to 0.20371, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 53/200\n",
      " - 1s - loss: 0.1863 - acc: 0.9796 - val_loss: 0.1905 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.20371 to 0.19051, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 54/200\n",
      " - 1s - loss: 0.1843 - acc: 0.9816 - val_loss: 0.1848 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.19051 to 0.18481, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 55/200\n",
      " - 1s - loss: 0.1797 - acc: 0.9842 - val_loss: 0.2047 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.18481\n",
      "Epoch 56/200\n",
      " - 1s - loss: 0.1769 - acc: 0.9783 - val_loss: 0.1988 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.18481\n",
      "Epoch 57/200\n",
      " - 1s - loss: 0.1719 - acc: 0.9822 - val_loss: 0.2048 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.18481\n",
      "Epoch 58/200\n",
      " - 1s - loss: 0.1707 - acc: 0.9836 - val_loss: 0.1789 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.18481 to 0.17894, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 59/200\n",
      " - 1s - loss: 0.1668 - acc: 0.9849 - val_loss: 0.1845 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.17894\n",
      "Epoch 60/200\n",
      " - 1s - loss: 0.1660 - acc: 0.9855 - val_loss: 0.1771 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.17894 to 0.17708, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 61/200\n",
      " - 1s - loss: 0.1622 - acc: 0.9862 - val_loss: 0.1717 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.17708 to 0.17174, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 62/200\n",
      " - 1s - loss: 0.1602 - acc: 0.9862 - val_loss: 0.1644 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.17174 to 0.16443, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 63/200\n",
      " - 1s - loss: 0.1582 - acc: 0.9882 - val_loss: 0.1685 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.16443\n",
      "Epoch 64/200\n",
      " - 1s - loss: 0.1551 - acc: 0.9895 - val_loss: 0.1715 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.16443\n",
      "Epoch 65/200\n",
      " - 1s - loss: 0.1500 - acc: 0.9908 - val_loss: 0.1621 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.16443 to 0.16212, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 66/200\n",
      " - 1s - loss: 0.1504 - acc: 0.9901 - val_loss: 0.1557 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.16212 to 0.15575, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 67/200\n",
      " - 1s - loss: 0.1475 - acc: 0.9914 - val_loss: 0.1630 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.15575\n",
      "Epoch 68/200\n",
      " - 1s - loss: 0.1442 - acc: 0.9882 - val_loss: 0.1638 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.15575\n",
      "Epoch 69/200\n",
      " - 1s - loss: 0.1421 - acc: 0.9908 - val_loss: 0.1610 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.15575\n",
      "Epoch 70/200\n",
      " - 1s - loss: 0.1388 - acc: 0.9914 - val_loss: 0.1520 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.15575 to 0.15196, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 71/200\n",
      " - 1s - loss: 0.1394 - acc: 0.9921 - val_loss: 0.1451 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.15196 to 0.14508, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 72/200\n",
      " - 1s - loss: 0.1377 - acc: 0.9921 - val_loss: 0.1478 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.14508\n",
      "Epoch 73/200\n",
      " - 1s - loss: 0.1346 - acc: 0.9928 - val_loss: 0.1479 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.14508\n",
      "Epoch 74/200\n",
      " - 1s - loss: 0.1322 - acc: 0.9941 - val_loss: 0.1544 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.14508\n",
      "Epoch 75/200\n",
      " - 1s - loss: 0.1314 - acc: 0.9934 - val_loss: 0.1408 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.14508 to 0.14079, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 76/200\n",
      " - 1s - loss: 0.1295 - acc: 0.9954 - val_loss: 0.1386 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.14079 to 0.13857, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 77/200\n",
      " - 1s - loss: 0.1265 - acc: 0.9954 - val_loss: 0.1394 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.13857\n",
      "Epoch 78/200\n",
      " - 1s - loss: 0.1261 - acc: 0.9928 - val_loss: 0.1502 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.13857\n",
      "Epoch 79/200\n",
      " - 1s - loss: 0.1236 - acc: 0.9934 - val_loss: 0.1457 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.13857\n",
      "Epoch 80/200\n",
      " - 1s - loss: 0.1226 - acc: 0.9914 - val_loss: 0.1426 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.13857\n",
      "Epoch 81/200\n",
      " - 1s - loss: 0.1209 - acc: 0.9961 - val_loss: 0.1363 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.13857 to 0.13630, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 82/200\n",
      " - 1s - loss: 0.1194 - acc: 0.9967 - val_loss: 0.1369 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.13630\n",
      "Epoch 83/200\n",
      " - 1s - loss: 0.1171 - acc: 0.9967 - val_loss: 0.1342 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.13630 to 0.13417, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 84/200\n",
      " - 1s - loss: 0.1157 - acc: 0.9947 - val_loss: 0.1345 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.13417\n",
      "Epoch 85/200\n",
      " - 1s - loss: 0.1149 - acc: 0.9954 - val_loss: 0.1271 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.13417 to 0.12711, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 86/200\n",
      " - 1s - loss: 0.1144 - acc: 0.9934 - val_loss: 0.1242 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.12711 to 0.12418, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 87/200\n",
      " - 1s - loss: 0.1121 - acc: 0.9974 - val_loss: 0.1236 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.12418 to 0.12360, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 88/200\n",
      " - 1s - loss: 0.1098 - acc: 0.9967 - val_loss: 0.1203 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.12360 to 0.12027, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 89/200\n",
      " - 1s - loss: 0.1092 - acc: 0.9961 - val_loss: 0.1225 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.12027\n",
      "Epoch 90/200\n",
      " - 1s - loss: 0.1077 - acc: 0.9974 - val_loss: 0.1207 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.12027\n",
      "Epoch 91/200\n",
      " - 1s - loss: 0.1074 - acc: 0.9961 - val_loss: 0.1219 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.12027\n",
      "Epoch 92/200\n",
      " - 1s - loss: 0.1042 - acc: 0.9947 - val_loss: 0.1299 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.12027\n",
      "Epoch 93/200\n",
      " - 1s - loss: 0.1038 - acc: 0.9987 - val_loss: 0.1201 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.12027 to 0.12008, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 94/200\n",
      " - 1s - loss: 0.1031 - acc: 0.9967 - val_loss: 0.1189 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.12008 to 0.11888, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 95/200\n",
      " - 1s - loss: 0.1024 - acc: 0.9961 - val_loss: 0.1198 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.11888\n",
      "Epoch 96/200\n",
      " - 1s - loss: 0.1010 - acc: 0.9967 - val_loss: 0.1159 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.11888 to 0.11594, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 97/200\n",
      " - 1s - loss: 0.1003 - acc: 0.9967 - val_loss: 0.1201 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.11594\n",
      "Epoch 98/200\n",
      " - 1s - loss: 0.0991 - acc: 0.9987 - val_loss: 0.1205 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.11594\n",
      "Epoch 99/200\n",
      " - 1s - loss: 0.0984 - acc: 0.9961 - val_loss: 0.1143 - val_acc: 0.9959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00099: val_loss improved from 0.11594 to 0.11426, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 100/200\n",
      " - 1s - loss: 0.0965 - acc: 0.9980 - val_loss: 0.1124 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.11426 to 0.11240, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 101/200\n",
      " - 1s - loss: 0.0959 - acc: 0.9967 - val_loss: 0.1088 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.11240 to 0.10879, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 102/200\n",
      " - 1s - loss: 0.0944 - acc: 0.9954 - val_loss: 0.1077 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.10879 to 0.10765, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 103/200\n",
      " - 1s - loss: 0.0934 - acc: 0.9967 - val_loss: 0.1161 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.10765\n",
      "Epoch 104/200\n",
      " - 1s - loss: 0.0927 - acc: 0.9967 - val_loss: 0.1096 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.10765\n",
      "Epoch 105/200\n",
      " - 1s - loss: 0.0914 - acc: 0.9974 - val_loss: 0.1096 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.10765\n",
      "Epoch 106/200\n",
      " - 1s - loss: 0.0909 - acc: 0.9961 - val_loss: 0.1066 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.10765 to 0.10656, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 107/200\n",
      " - 1s - loss: 0.0893 - acc: 0.9987 - val_loss: 0.1097 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.10656\n",
      "Epoch 108/200\n",
      " - 1s - loss: 0.0894 - acc: 0.9967 - val_loss: 0.0990 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.10656 to 0.09904, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 109/200\n",
      " - 1s - loss: 0.0880 - acc: 0.9974 - val_loss: 0.1024 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.09904\n",
      "Epoch 110/200\n",
      " - 1s - loss: 0.0873 - acc: 0.9980 - val_loss: 0.0988 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.09904 to 0.09881, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 111/200\n",
      " - 1s - loss: 0.0863 - acc: 0.9974 - val_loss: 0.1033 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.09881\n",
      "Epoch 112/200\n",
      " - 1s - loss: 0.0858 - acc: 0.9967 - val_loss: 0.0988 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.09881 to 0.09876, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 113/200\n",
      " - 1s - loss: 0.0839 - acc: 0.9974 - val_loss: 0.1009 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.09876\n",
      "Epoch 114/200\n",
      " - 1s - loss: 0.0836 - acc: 0.9974 - val_loss: 0.1000 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.09876\n",
      "Epoch 115/200\n",
      " - 1s - loss: 0.0839 - acc: 0.9974 - val_loss: 0.1051 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.09876\n",
      "Epoch 116/200\n",
      " - 1s - loss: 0.0819 - acc: 0.9974 - val_loss: 0.1006 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.09876\n",
      "Epoch 117/200\n",
      " - 1s - loss: 0.0817 - acc: 0.9967 - val_loss: 0.0939 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.09876 to 0.09391, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 118/200\n",
      " - 1s - loss: 0.0817 - acc: 0.9974 - val_loss: 0.0954 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.09391\n",
      "Epoch 119/200\n",
      " - 1s - loss: 0.0803 - acc: 0.9987 - val_loss: 0.0976 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.09391\n",
      "Epoch 120/200\n",
      " - 1s - loss: 0.0796 - acc: 0.9967 - val_loss: 0.0985 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.09391\n",
      "Epoch 121/200\n",
      " - 1s - loss: 0.0796 - acc: 0.9961 - val_loss: 0.0935 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.09391 to 0.09349, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 122/200\n",
      " - 1s - loss: 0.0780 - acc: 0.9980 - val_loss: 0.1020 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.09349\n",
      "Epoch 123/200\n",
      " - 1s - loss: 0.0778 - acc: 0.9967 - val_loss: 0.0918 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.09349 to 0.09175, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 124/200\n",
      " - 1s - loss: 0.0778 - acc: 0.9954 - val_loss: 0.0921 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.09175\n",
      "Epoch 125/200\n",
      " - 1s - loss: 0.0760 - acc: 0.9967 - val_loss: 0.0978 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.09175\n",
      "Epoch 126/200\n",
      " - 1s - loss: 0.0755 - acc: 0.9974 - val_loss: 0.0896 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.09175 to 0.08964, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 127/200\n",
      " - 1s - loss: 0.0755 - acc: 0.9961 - val_loss: 0.0944 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.08964\n",
      "Epoch 128/200\n",
      " - 1s - loss: 0.0746 - acc: 0.9974 - val_loss: 0.0913 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.08964\n",
      "Epoch 129/200\n",
      " - 1s - loss: 0.0740 - acc: 0.9967 - val_loss: 0.0992 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.08964\n",
      "Epoch 130/200\n",
      " - 1s - loss: 0.0732 - acc: 0.9980 - val_loss: 0.0929 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.08964\n",
      "Epoch 131/200\n",
      " - 1s - loss: 0.0729 - acc: 0.9980 - val_loss: 0.0873 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.08964 to 0.08729, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 132/200\n",
      " - 1s - loss: 0.0725 - acc: 0.9967 - val_loss: 0.0876 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.08729\n",
      "Epoch 133/200\n",
      " - 1s - loss: 0.0720 - acc: 0.9987 - val_loss: 0.0872 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.08729 to 0.08725, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 134/200\n",
      " - 1s - loss: 0.0710 - acc: 0.9967 - val_loss: 0.0889 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.08725\n",
      "Epoch 135/200\n",
      " - 1s - loss: 0.0697 - acc: 0.9974 - val_loss: 0.0871 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.08725 to 0.08709, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 136/200\n",
      " - 1s - loss: 0.0700 - acc: 0.9967 - val_loss: 0.0875 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.08709\n",
      "Epoch 137/200\n",
      " - 1s - loss: 0.0687 - acc: 0.9980 - val_loss: 0.0880 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.08709\n",
      "Epoch 138/200\n",
      " - 1s - loss: 0.0688 - acc: 0.9980 - val_loss: 0.0847 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.08709 to 0.08472, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 139/200\n",
      " - 1s - loss: 0.0686 - acc: 0.9967 - val_loss: 0.0850 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.08472\n",
      "Epoch 140/200\n",
      " - 1s - loss: 0.0679 - acc: 0.9974 - val_loss: 0.0848 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.08472\n",
      "Epoch 141/200\n",
      " - 1s - loss: 0.0669 - acc: 0.9974 - val_loss: 0.0858 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.08472\n",
      "Epoch 142/200\n",
      " - 1s - loss: 0.0667 - acc: 0.9980 - val_loss: 0.0851 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.08472\n",
      "Epoch 143/200\n",
      " - 1s - loss: 0.0662 - acc: 0.9980 - val_loss: 0.0807 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.08472 to 0.08070, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 144/200\n",
      " - 1s - loss: 0.0663 - acc: 0.9974 - val_loss: 0.0837 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.08070\n",
      "Epoch 145/200\n",
      " - 1s - loss: 0.0657 - acc: 0.9980 - val_loss: 0.0784 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.08070 to 0.07837, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 146/200\n",
      " - 1s - loss: 0.0654 - acc: 0.9974 - val_loss: 0.0866 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.07837\n",
      "Epoch 147/200\n",
      " - 1s - loss: 0.0640 - acc: 0.9967 - val_loss: 0.0787 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.07837\n",
      "Epoch 148/200\n",
      " - 1s - loss: 0.0638 - acc: 0.9993 - val_loss: 0.0811 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.07837\n",
      "Epoch 149/200\n",
      " - 1s - loss: 0.0632 - acc: 0.9974 - val_loss: 0.0778 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.07837 to 0.07781, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 150/200\n",
      " - 1s - loss: 0.0630 - acc: 0.9974 - val_loss: 0.0807 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.07781\n",
      "Epoch 151/200\n",
      " - 1s - loss: 0.0624 - acc: 0.9980 - val_loss: 0.0821 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.07781\n",
      "Epoch 152/200\n",
      " - 1s - loss: 0.0623 - acc: 0.9967 - val_loss: 0.0794 - val_acc: 0.9959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00152: val_loss did not improve from 0.07781\n",
      "Epoch 153/200\n",
      " - 1s - loss: 0.0617 - acc: 0.9980 - val_loss: 0.0812 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.07781\n",
      "Epoch 154/200\n",
      " - 1s - loss: 0.0617 - acc: 0.9967 - val_loss: 0.0768 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.07781 to 0.07678, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 155/200\n",
      " - 1s - loss: 0.0615 - acc: 0.9967 - val_loss: 0.0824 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.07678\n",
      "Epoch 156/200\n",
      " - 1s - loss: 0.0603 - acc: 0.9980 - val_loss: 0.0747 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.07678 to 0.07469, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 157/200\n",
      " - 1s - loss: 0.0597 - acc: 0.9980 - val_loss: 0.0782 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.07469\n",
      "Epoch 158/200\n",
      " - 1s - loss: 0.0604 - acc: 0.9974 - val_loss: 0.0754 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.07469\n",
      "Epoch 159/200\n",
      " - 1s - loss: 0.0594 - acc: 0.9980 - val_loss: 0.0785 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.07469\n",
      "Epoch 160/200\n",
      " - 1s - loss: 0.0592 - acc: 0.9980 - val_loss: 0.0745 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.07469 to 0.07446, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 161/200\n",
      " - 1s - loss: 0.0588 - acc: 0.9967 - val_loss: 0.0793 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.07446\n",
      "Epoch 162/200\n",
      " - 1s - loss: 0.0582 - acc: 0.9980 - val_loss: 0.0756 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.07446\n",
      "Epoch 163/200\n",
      " - 1s - loss: 0.0582 - acc: 0.9967 - val_loss: 0.0713 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00163: val_loss improved from 0.07446 to 0.07128, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 164/200\n",
      " - 1s - loss: 0.0575 - acc: 0.9974 - val_loss: 0.0790 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.07128\n",
      "Epoch 165/200\n",
      " - 1s - loss: 0.0573 - acc: 0.9961 - val_loss: 0.0787 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.07128\n",
      "Epoch 166/200\n",
      " - 1s - loss: 0.0571 - acc: 0.9980 - val_loss: 0.0751 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.07128\n",
      "Epoch 167/200\n",
      " - 1s - loss: 0.0564 - acc: 0.9980 - val_loss: 0.0725 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.07128\n",
      "Epoch 168/200\n",
      " - 1s - loss: 0.0560 - acc: 0.9967 - val_loss: 0.0730 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.07128\n",
      "Epoch 169/200\n",
      " - 1s - loss: 0.0558 - acc: 0.9974 - val_loss: 0.0739 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.07128\n",
      "Epoch 170/200\n",
      " - 1s - loss: 0.0553 - acc: 0.9980 - val_loss: 0.0727 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.07128\n",
      "Epoch 171/200\n",
      " - 1s - loss: 0.0551 - acc: 0.9961 - val_loss: 0.0746 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.07128\n",
      "Epoch 172/200\n",
      " - 1s - loss: 0.0544 - acc: 0.9974 - val_loss: 0.0730 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.07128\n",
      "Epoch 173/200\n",
      " - 1s - loss: 0.0551 - acc: 0.9961 - val_loss: 0.0698 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.07128 to 0.06983, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 174/200\n",
      " - 1s - loss: 0.0542 - acc: 0.9974 - val_loss: 0.0740 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.06983\n",
      "Epoch 175/200\n",
      " - 1s - loss: 0.0540 - acc: 0.9974 - val_loss: 0.0728 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.06983\n",
      "Epoch 176/200\n",
      " - 1s - loss: 0.0536 - acc: 0.9974 - val_loss: 0.0738 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.06983\n",
      "Epoch 177/200\n",
      " - 1s - loss: 0.0531 - acc: 0.9967 - val_loss: 0.0693 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00177: val_loss improved from 0.06983 to 0.06929, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 178/200\n",
      " - 1s - loss: 0.0529 - acc: 0.9967 - val_loss: 0.0708 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.06929\n",
      "Epoch 179/200\n",
      " - 1s - loss: 0.0528 - acc: 0.9974 - val_loss: 0.0710 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.06929\n",
      "Epoch 180/200\n",
      " - 1s - loss: 0.0521 - acc: 0.9987 - val_loss: 0.0694 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.06929\n",
      "Epoch 181/200\n",
      " - 1s - loss: 0.0521 - acc: 0.9980 - val_loss: 0.0669 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00181: val_loss improved from 0.06929 to 0.06687, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 182/200\n",
      " - 1s - loss: 0.0518 - acc: 0.9980 - val_loss: 0.0680 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.06687\n",
      "Epoch 183/200\n",
      " - 1s - loss: 0.0515 - acc: 0.9974 - val_loss: 0.0715 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.06687\n",
      "Epoch 184/200\n",
      " - 1s - loss: 0.0512 - acc: 0.9974 - val_loss: 0.0678 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.06687\n",
      "Epoch 185/200\n",
      " - 1s - loss: 0.0505 - acc: 0.9980 - val_loss: 0.0660 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00185: val_loss improved from 0.06687 to 0.06600, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 186/200\n",
      " - 1s - loss: 0.0502 - acc: 0.9980 - val_loss: 0.0689 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.06600\n",
      "Epoch 187/200\n",
      " - 1s - loss: 0.0506 - acc: 0.9980 - val_loss: 0.0679 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.06600\n",
      "Epoch 188/200\n",
      " - 1s - loss: 0.0502 - acc: 0.9980 - val_loss: 0.0663 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.06600\n",
      "Epoch 189/200\n",
      " - 1s - loss: 0.0502 - acc: 0.9974 - val_loss: 0.0697 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.06600\n",
      "Epoch 190/200\n",
      " - 1s - loss: 0.0494 - acc: 0.9967 - val_loss: 0.0705 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.06600\n",
      "Epoch 191/200\n",
      " - 1s - loss: 0.0498 - acc: 0.9967 - val_loss: 0.0690 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.06600\n",
      "Epoch 192/200\n",
      " - 1s - loss: 0.0490 - acc: 0.9974 - val_loss: 0.0663 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.06600\n",
      "Epoch 193/200\n",
      " - 1s - loss: 0.0487 - acc: 0.9980 - val_loss: 0.0682 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.06600\n",
      "Epoch 194/200\n",
      " - 1s - loss: 0.0483 - acc: 0.9974 - val_loss: 0.0650 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00194: val_loss improved from 0.06600 to 0.06501, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 195/200\n",
      " - 1s - loss: 0.0481 - acc: 0.9974 - val_loss: 0.0683 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.06501\n",
      "Epoch 196/200\n",
      " - 1s - loss: 0.0480 - acc: 0.9980 - val_loss: 0.0644 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00196: val_loss improved from 0.06501 to 0.06437, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 197/200\n",
      " - 1s - loss: 0.0482 - acc: 0.9974 - val_loss: 0.0634 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00197: val_loss improved from 0.06437 to 0.06335, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 198/200\n",
      " - 1s - loss: 0.0473 - acc: 0.9967 - val_loss: 0.0663 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.06335\n",
      "Epoch 199/200\n",
      " - 1s - loss: 0.0474 - acc: 0.9974 - val_loss: 0.0662 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.06335\n",
      "Epoch 200/200\n",
      " - 1s - loss: 0.0468 - acc: 0.9987 - val_loss: 0.0635 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.06335\n",
      "batch_size=10   optimizer=SGD\n",
      "Test accuracy: 64.9025%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 1.8870 - acc: 0.3342 - val_loss: 1.4545 - val_acc: 0.5226\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.45447, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.3575 - acc: 0.5375 - val_loss: 1.2031 - val_acc: 0.5885\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.45447 to 1.20309, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 1.1749 - acc: 0.6099 - val_loss: 1.0384 - val_acc: 0.6502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: val_loss improved from 1.20309 to 1.03838, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 1.0629 - acc: 0.6526 - val_loss: 0.9624 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.03838 to 0.96239, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.9838 - acc: 0.6651 - val_loss: 0.9435 - val_acc: 0.6626\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.96239 to 0.94346, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.9244 - acc: 0.7000 - val_loss: 0.8795 - val_acc: 0.7243\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.94346 to 0.87945, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.8822 - acc: 0.7059 - val_loss: 0.8434 - val_acc: 0.7119\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.87945 to 0.84337, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.8334 - acc: 0.7368 - val_loss: 0.8129 - val_acc: 0.7284\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.84337 to 0.81290, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.8000 - acc: 0.7461 - val_loss: 0.7728 - val_acc: 0.7695\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.81290 to 0.77277, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.7709 - acc: 0.7599 - val_loss: 0.7294 - val_acc: 0.7737\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.77277 to 0.72936, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.7437 - acc: 0.7539 - val_loss: 0.7236 - val_acc: 0.7695\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.72936 to 0.72357, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.7138 - acc: 0.7750 - val_loss: 0.7538 - val_acc: 0.7366\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.72357\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.6891 - acc: 0.7908 - val_loss: 0.6888 - val_acc: 0.7654\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.72357 to 0.68877, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.6662 - acc: 0.7895 - val_loss: 0.6528 - val_acc: 0.7942\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.68877 to 0.65280, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.6561 - acc: 0.7941 - val_loss: 0.6402 - val_acc: 0.7901\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.65280 to 0.64016, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.6372 - acc: 0.8033 - val_loss: 0.5914 - val_acc: 0.8354\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.64016 to 0.59138, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.6119 - acc: 0.8118 - val_loss: 0.6016 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.59138\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.5977 - acc: 0.8276 - val_loss: 0.5743 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.59138 to 0.57426, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.5772 - acc: 0.8257 - val_loss: 0.5707 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.57426 to 0.57073, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.5736 - acc: 0.8270 - val_loss: 0.5663 - val_acc: 0.8148\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.57073 to 0.56632, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.5637 - acc: 0.8303 - val_loss: 0.5290 - val_acc: 0.8354\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.56632 to 0.52902, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.5463 - acc: 0.8349 - val_loss: 0.5129 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.52902 to 0.51291, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.5342 - acc: 0.8434 - val_loss: 0.5326 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.51291\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.5222 - acc: 0.8493 - val_loss: 0.5367 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.51291\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.5140 - acc: 0.8507 - val_loss: 0.5008 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.51291 to 0.50076, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.4968 - acc: 0.8559 - val_loss: 0.4996 - val_acc: 0.8765\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.50076 to 0.49956, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.4882 - acc: 0.8645 - val_loss: 0.4762 - val_acc: 0.8765\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.49956 to 0.47615, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.4813 - acc: 0.8645 - val_loss: 0.4633 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.47615 to 0.46334, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.4685 - acc: 0.8737 - val_loss: 0.4796 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.46334\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.4636 - acc: 0.8737 - val_loss: 0.4597 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.46334 to 0.45968, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.4530 - acc: 0.8783 - val_loss: 0.4348 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.45968 to 0.43484, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.4479 - acc: 0.8809 - val_loss: 0.4199 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.43484 to 0.41990, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.4405 - acc: 0.8875 - val_loss: 0.4204 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.41990\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.4291 - acc: 0.8954 - val_loss: 0.4227 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.41990\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.4214 - acc: 0.8921 - val_loss: 0.4053 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.41990 to 0.40532, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.4161 - acc: 0.8882 - val_loss: 0.4108 - val_acc: 0.9012\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.40532\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.4097 - acc: 0.8908 - val_loss: 0.4005 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.40532 to 0.40046, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.4039 - acc: 0.8974 - val_loss: 0.4227 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.40046\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.3941 - acc: 0.9013 - val_loss: 0.3900 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.40046 to 0.38997, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.3889 - acc: 0.9039 - val_loss: 0.3822 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.38997 to 0.38221, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.3845 - acc: 0.9046 - val_loss: 0.3726 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.38221 to 0.37263, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.3747 - acc: 0.9145 - val_loss: 0.3614 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.37263 to 0.36144, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.3741 - acc: 0.9112 - val_loss: 0.3646 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.36144\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.3672 - acc: 0.9191 - val_loss: 0.3406 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.36144 to 0.34055, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.3608 - acc: 0.9204 - val_loss: 0.3499 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.34055\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.3523 - acc: 0.9217 - val_loss: 0.3539 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.34055\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.3506 - acc: 0.9191 - val_loss: 0.3703 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.34055\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.3469 - acc: 0.9263 - val_loss: 0.3406 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.34055\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.3393 - acc: 0.9276 - val_loss: 0.3481 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.34055\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.3362 - acc: 0.9237 - val_loss: 0.3317 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.34055 to 0.33169, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.3318 - acc: 0.9237 - val_loss: 0.3221 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.33169 to 0.32210, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.3267 - acc: 0.9316 - val_loss: 0.3231 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.32210\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.3188 - acc: 0.9355 - val_loss: 0.3246 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.32210\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.3170 - acc: 0.9342 - val_loss: 0.3199 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.32210 to 0.31987, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.3138 - acc: 0.9329 - val_loss: 0.3269 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.31987\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.3102 - acc: 0.9362 - val_loss: 0.3246 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.31987\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.3046 - acc: 0.9355 - val_loss: 0.2949 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.31987 to 0.29485, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.3051 - acc: 0.9368 - val_loss: 0.2980 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.29485\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.2963 - acc: 0.9375 - val_loss: 0.3049 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.29485\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.2941 - acc: 0.9480 - val_loss: 0.3044 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.29485\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.2892 - acc: 0.9487 - val_loss: 0.2967 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.29485\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.2867 - acc: 0.9500 - val_loss: 0.2795 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.29485 to 0.27950, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.2822 - acc: 0.9467 - val_loss: 0.3184 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.27950\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.2790 - acc: 0.9480 - val_loss: 0.2937 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.27950\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.2754 - acc: 0.9454 - val_loss: 0.2984 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.27950\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.2708 - acc: 0.9526 - val_loss: 0.2804 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.27950\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.2713 - acc: 0.9520 - val_loss: 0.2676 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.27950 to 0.26762, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.2652 - acc: 0.9572 - val_loss: 0.2758 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.26762\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.2607 - acc: 0.9546 - val_loss: 0.2702 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.26762\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.2614 - acc: 0.9546 - val_loss: 0.2659 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.26762 to 0.26593, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.2577 - acc: 0.9559 - val_loss: 0.2654 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.26593 to 0.26541, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.2553 - acc: 0.9546 - val_loss: 0.2554 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.26541 to 0.25536, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.2472 - acc: 0.9605 - val_loss: 0.2711 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.25536\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.2487 - acc: 0.9612 - val_loss: 0.2548 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.25536 to 0.25483, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.2464 - acc: 0.9605 - val_loss: 0.2487 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.25483 to 0.24866, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.2435 - acc: 0.9664 - val_loss: 0.2459 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.24866 to 0.24586, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.2416 - acc: 0.9599 - val_loss: 0.2436 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.24586 to 0.24355, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.2368 - acc: 0.9651 - val_loss: 0.2397 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.24355 to 0.23972, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.2324 - acc: 0.9697 - val_loss: 0.2402 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.23972\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.2324 - acc: 0.9684 - val_loss: 0.2349 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.23972 to 0.23494, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.2305 - acc: 0.9658 - val_loss: 0.2431 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.23494\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.2273 - acc: 0.9697 - val_loss: 0.2348 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.23494 to 0.23481, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.2239 - acc: 0.9691 - val_loss: 0.2317 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.23481 to 0.23174, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.2229 - acc: 0.9717 - val_loss: 0.2532 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.23174\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.2196 - acc: 0.9704 - val_loss: 0.2245 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.23174 to 0.22446, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.2194 - acc: 0.9691 - val_loss: 0.2316 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.22446\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.2176 - acc: 0.9704 - val_loss: 0.2272 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.22446\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.2154 - acc: 0.9724 - val_loss: 0.2300 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.22446\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.2124 - acc: 0.9717 - val_loss: 0.2351 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.22446\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.2092 - acc: 0.9763 - val_loss: 0.2259 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.22446\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.2092 - acc: 0.9743 - val_loss: 0.2147 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.22446 to 0.21468, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.2069 - acc: 0.9750 - val_loss: 0.2240 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.21468\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.2044 - acc: 0.9730 - val_loss: 0.2120 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.21468 to 0.21205, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.2019 - acc: 0.9763 - val_loss: 0.2115 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.21205 to 0.21148, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.2006 - acc: 0.9816 - val_loss: 0.2098 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.21148 to 0.20981, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.1988 - acc: 0.9803 - val_loss: 0.2034 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.20981 to 0.20339, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.1971 - acc: 0.9783 - val_loss: 0.2084 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.20339\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.1939 - acc: 0.9789 - val_loss: 0.2286 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.20339\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.1936 - acc: 0.9796 - val_loss: 0.2029 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.20339 to 0.20291, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.1899 - acc: 0.9829 - val_loss: 0.2084 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.20291\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.1903 - acc: 0.9836 - val_loss: 0.2010 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.20291 to 0.20101, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.1878 - acc: 0.9796 - val_loss: 0.1973 - val_acc: 0.9794\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00102: val_loss improved from 0.20101 to 0.19733, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.1871 - acc: 0.9809 - val_loss: 0.1953 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.19733 to 0.19527, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.1843 - acc: 0.9836 - val_loss: 0.2020 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.19527\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.1823 - acc: 0.9842 - val_loss: 0.1897 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.19527 to 0.18968, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.1826 - acc: 0.9842 - val_loss: 0.1960 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.18968\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.1798 - acc: 0.9868 - val_loss: 0.1919 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.18968\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.1769 - acc: 0.9875 - val_loss: 0.1889 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.18968 to 0.18885, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.1764 - acc: 0.9829 - val_loss: 0.1973 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.18885\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.1742 - acc: 0.9868 - val_loss: 0.1949 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.18885\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.1726 - acc: 0.9855 - val_loss: 0.1872 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.18885 to 0.18717, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.1719 - acc: 0.9862 - val_loss: 0.1857 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.18717 to 0.18570, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.1693 - acc: 0.9882 - val_loss: 0.1848 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.18570 to 0.18478, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.1688 - acc: 0.9862 - val_loss: 0.1981 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.18478\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.1688 - acc: 0.9842 - val_loss: 0.1822 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.18478 to 0.18223, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.1664 - acc: 0.9862 - val_loss: 0.1758 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.18223 to 0.17584, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.1644 - acc: 0.9888 - val_loss: 0.1794 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.17584\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.1633 - acc: 0.9862 - val_loss: 0.1707 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.17584 to 0.17071, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.1621 - acc: 0.9908 - val_loss: 0.1745 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.17071\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.1602 - acc: 0.9895 - val_loss: 0.1739 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.17071\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.1593 - acc: 0.9895 - val_loss: 0.1794 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.17071\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.1593 - acc: 0.9901 - val_loss: 0.1679 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.17071 to 0.16792, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.1572 - acc: 0.9914 - val_loss: 0.1723 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.16792\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.1558 - acc: 0.9914 - val_loss: 0.1627 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.16792 to 0.16270, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.1550 - acc: 0.9888 - val_loss: 0.1672 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.16270\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.1534 - acc: 0.9928 - val_loss: 0.1661 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.16270\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.1522 - acc: 0.9908 - val_loss: 0.1677 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.16270\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.1498 - acc: 0.9934 - val_loss: 0.1667 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.16270\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.1503 - acc: 0.9928 - val_loss: 0.1664 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.16270\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.1478 - acc: 0.9914 - val_loss: 0.1612 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.16270 to 0.16118, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.1478 - acc: 0.9914 - val_loss: 0.1595 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.16118 to 0.15951, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.1471 - acc: 0.9928 - val_loss: 0.1584 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.15951 to 0.15837, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.1456 - acc: 0.9928 - val_loss: 0.1563 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.15837 to 0.15633, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.1441 - acc: 0.9941 - val_loss: 0.1567 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.15633\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.1433 - acc: 0.9921 - val_loss: 0.1555 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.15633 to 0.15548, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.1422 - acc: 0.9961 - val_loss: 0.1510 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.15548 to 0.15097, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.1412 - acc: 0.9921 - val_loss: 0.1553 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.15097\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.1399 - acc: 0.9941 - val_loss: 0.1615 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.15097\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.1391 - acc: 0.9947 - val_loss: 0.1504 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.15097 to 0.15037, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.1379 - acc: 0.9934 - val_loss: 0.1488 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.15037 to 0.14878, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.1364 - acc: 0.9941 - val_loss: 0.1509 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.14878\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.1361 - acc: 0.9947 - val_loss: 0.1541 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.14878\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.1358 - acc: 0.9947 - val_loss: 0.1547 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.14878\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.1333 - acc: 0.9941 - val_loss: 0.1435 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.14878 to 0.14354, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.1341 - acc: 0.9941 - val_loss: 0.1514 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.14354\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.1317 - acc: 0.9934 - val_loss: 0.1469 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.14354\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.1318 - acc: 0.9954 - val_loss: 0.1468 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.14354\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.1306 - acc: 0.9961 - val_loss: 0.1427 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.14354 to 0.14267, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.1298 - acc: 0.9954 - val_loss: 0.1488 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.14267\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.1286 - acc: 0.9954 - val_loss: 0.1403 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.14267 to 0.14030, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.1282 - acc: 0.9954 - val_loss: 0.1397 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.14030 to 0.13970, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.1269 - acc: 0.9954 - val_loss: 0.1379 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.13970 to 0.13792, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.1266 - acc: 0.9934 - val_loss: 0.1405 - val_acc: 0.9918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00153: val_loss did not improve from 0.13792\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.1247 - acc: 0.9961 - val_loss: 0.1378 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.13792 to 0.13782, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.1244 - acc: 0.9954 - val_loss: 0.1403 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.13782\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.1235 - acc: 0.9961 - val_loss: 0.1483 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.13782\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.1236 - acc: 0.9961 - val_loss: 0.1390 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.13782\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.1214 - acc: 0.9954 - val_loss: 0.1422 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.13782\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.1214 - acc: 0.9974 - val_loss: 0.1362 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.13782 to 0.13617, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.1207 - acc: 0.9954 - val_loss: 0.1365 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.13617\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.1198 - acc: 0.9961 - val_loss: 0.1320 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.13617 to 0.13199, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.1188 - acc: 0.9961 - val_loss: 0.1358 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.13199\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.1184 - acc: 0.9954 - val_loss: 0.1335 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.13199\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.1182 - acc: 0.9954 - val_loss: 0.1346 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.13199\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.1170 - acc: 0.9947 - val_loss: 0.1314 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.13199 to 0.13138, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.1166 - acc: 0.9967 - val_loss: 0.1334 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.13138\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.1154 - acc: 0.9961 - val_loss: 0.1286 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.13138 to 0.12857, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.1146 - acc: 0.9961 - val_loss: 0.1297 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.12857\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.1135 - acc: 0.9961 - val_loss: 0.1264 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.12857 to 0.12643, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.1125 - acc: 0.9967 - val_loss: 0.1309 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.12643\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.1125 - acc: 0.9967 - val_loss: 0.1302 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.12643\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.1126 - acc: 0.9967 - val_loss: 0.1272 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.12643\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.1111 - acc: 0.9974 - val_loss: 0.1247 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.12643 to 0.12467, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.1114 - acc: 0.9961 - val_loss: 0.1266 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.12467\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.1099 - acc: 0.9974 - val_loss: 0.1275 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.12467\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.1093 - acc: 0.9967 - val_loss: 0.1296 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.12467\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.1099 - acc: 0.9974 - val_loss: 0.1249 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.12467\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.1083 - acc: 0.9961 - val_loss: 0.1255 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.12467\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.1080 - acc: 0.9967 - val_loss: 0.1230 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00179: val_loss improved from 0.12467 to 0.12300, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.1070 - acc: 0.9961 - val_loss: 0.1192 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00180: val_loss improved from 0.12300 to 0.11917, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.1065 - acc: 0.9967 - val_loss: 0.1224 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.11917\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.1066 - acc: 0.9954 - val_loss: 0.1212 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.11917\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.1055 - acc: 0.9954 - val_loss: 0.1200 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.11917\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.1050 - acc: 0.9961 - val_loss: 0.1208 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.11917\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.1038 - acc: 0.9967 - val_loss: 0.1203 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.11917\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.1034 - acc: 0.9954 - val_loss: 0.1201 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.11917\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.1032 - acc: 0.9967 - val_loss: 0.1220 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.11917\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.1024 - acc: 0.9954 - val_loss: 0.1146 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00188: val_loss improved from 0.11917 to 0.11463, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.1018 - acc: 0.9967 - val_loss: 0.1169 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.11463\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.1012 - acc: 0.9967 - val_loss: 0.1174 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.11463\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.1007 - acc: 0.9967 - val_loss: 0.1199 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.11463\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.1002 - acc: 0.9980 - val_loss: 0.1140 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.11463 to 0.11402, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.0994 - acc: 0.9974 - val_loss: 0.1182 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.11402\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.0992 - acc: 0.9967 - val_loss: 0.1156 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.11402\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.0985 - acc: 0.9967 - val_loss: 0.1142 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.11402\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.0985 - acc: 0.9961 - val_loss: 0.1144 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.11402\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.0978 - acc: 0.9967 - val_loss: 0.1127 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00197: val_loss improved from 0.11402 to 0.11268, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.0968 - acc: 0.9974 - val_loss: 0.1169 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.11268\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.0969 - acc: 0.9980 - val_loss: 0.1155 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.11268\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.0960 - acc: 0.9967 - val_loss: 0.1156 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.11268\n",
      "batch_size=20   optimizer=SGD\n",
      "Test accuracy: 66.5738%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 2.1419 - acc: 0.2217 - val_loss: 1.7798 - val_acc: 0.3621\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.77984, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.6112 - acc: 0.4388 - val_loss: 1.5278 - val_acc: 0.4609\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.77984 to 1.52783, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 1.3919 - acc: 0.5368 - val_loss: 1.3347 - val_acc: 0.5144\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.52783 to 1.33467, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 1.2595 - acc: 0.5816 - val_loss: 1.2170 - val_acc: 0.5638\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.33467 to 1.21699, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 1.1673 - acc: 0.6184 - val_loss: 1.1315 - val_acc: 0.6214\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.21699 to 1.13154, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 1.1025 - acc: 0.6296 - val_loss: 1.0748 - val_acc: 0.6584\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.13154 to 1.07484, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 1.0507 - acc: 0.6664 - val_loss: 1.0322 - val_acc: 0.6790\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.07484 to 1.03221, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 0s - loss: 1.0121 - acc: 0.6803 - val_loss: 0.9859 - val_acc: 0.6831\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.03221 to 0.98594, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.9693 - acc: 0.6967 - val_loss: 0.9614 - val_acc: 0.6790\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.98594 to 0.96144, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.9399 - acc: 0.7007 - val_loss: 0.9313 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.96144 to 0.93127, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.9103 - acc: 0.7072 - val_loss: 0.9017 - val_acc: 0.7119\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.93127 to 0.90171, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.8783 - acc: 0.7224 - val_loss: 0.8873 - val_acc: 0.7407\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.90171 to 0.88731, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.8575 - acc: 0.7362 - val_loss: 0.8772 - val_acc: 0.7284\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.88731 to 0.87718, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.8328 - acc: 0.7454 - val_loss: 0.8401 - val_acc: 0.7160\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.87718 to 0.84007, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.8204 - acc: 0.7408 - val_loss: 0.8182 - val_acc: 0.7572\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.84007 to 0.81816, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.7979 - acc: 0.7480 - val_loss: 0.8316 - val_acc: 0.7325\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.81816\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.7830 - acc: 0.7625 - val_loss: 0.7963 - val_acc: 0.7613\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.81816 to 0.79625, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.7673 - acc: 0.7658 - val_loss: 0.7668 - val_acc: 0.7613\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.79625 to 0.76675, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.7490 - acc: 0.7678 - val_loss: 0.7640 - val_acc: 0.7819\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.76675 to 0.76403, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.7391 - acc: 0.7658 - val_loss: 0.7384 - val_acc: 0.7860\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.76403 to 0.73844, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.7240 - acc: 0.7711 - val_loss: 0.7274 - val_acc: 0.7860\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.73844 to 0.72739, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.7092 - acc: 0.7803 - val_loss: 0.7171 - val_acc: 0.7737\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.72739 to 0.71714, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.6975 - acc: 0.7842 - val_loss: 0.7070 - val_acc: 0.7860\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.71714 to 0.70704, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.6870 - acc: 0.7862 - val_loss: 0.6942 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.70704 to 0.69422, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.6765 - acc: 0.7941 - val_loss: 0.6798 - val_acc: 0.7819\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.69422 to 0.67977, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.6667 - acc: 0.7993 - val_loss: 0.6612 - val_acc: 0.8107\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.67977 to 0.66119, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.6511 - acc: 0.8020 - val_loss: 0.6944 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.66119\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.6423 - acc: 0.8086 - val_loss: 0.6494 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.66119 to 0.64939, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.6365 - acc: 0.8132 - val_loss: 0.6384 - val_acc: 0.8148\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.64939 to 0.63838, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.6249 - acc: 0.8158 - val_loss: 0.6359 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.63838 to 0.63591, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.6163 - acc: 0.8125 - val_loss: 0.6470 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.63591\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.6083 - acc: 0.8257 - val_loss: 0.6119 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.63591 to 0.61192, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.6007 - acc: 0.8250 - val_loss: 0.6311 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.61192\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.5945 - acc: 0.8283 - val_loss: 0.5960 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.61192 to 0.59603, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.5878 - acc: 0.8283 - val_loss: 0.6057 - val_acc: 0.8354\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.59603\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.5785 - acc: 0.8270 - val_loss: 0.5814 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.59603 to 0.58137, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.5698 - acc: 0.8316 - val_loss: 0.5717 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.58137 to 0.57171, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.5649 - acc: 0.8362 - val_loss: 0.5783 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.57171\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.5569 - acc: 0.8322 - val_loss: 0.5683 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.57171 to 0.56833, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.5524 - acc: 0.8368 - val_loss: 0.5691 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.56833\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.5465 - acc: 0.8467 - val_loss: 0.5553 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.56833 to 0.55531, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.5381 - acc: 0.8441 - val_loss: 0.5690 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.55531\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.5303 - acc: 0.8533 - val_loss: 0.5498 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.55531 to 0.54985, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.5226 - acc: 0.8520 - val_loss: 0.5280 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.54985 to 0.52800, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.5179 - acc: 0.8539 - val_loss: 0.5497 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.52800\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.5131 - acc: 0.8546 - val_loss: 0.5145 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.52800 to 0.51445, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.5083 - acc: 0.8513 - val_loss: 0.5165 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.51445\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.5011 - acc: 0.8592 - val_loss: 0.5219 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.51445\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.4978 - acc: 0.8638 - val_loss: 0.5210 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.51445\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.4928 - acc: 0.8586 - val_loss: 0.5359 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.51445\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.4852 - acc: 0.8678 - val_loss: 0.5105 - val_acc: 0.8436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00051: val_loss improved from 0.51445 to 0.51050, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.4835 - acc: 0.8697 - val_loss: 0.4928 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.51050 to 0.49277, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.4788 - acc: 0.8638 - val_loss: 0.4814 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.49277 to 0.48142, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.4761 - acc: 0.8770 - val_loss: 0.4876 - val_acc: 0.8765\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.48142\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.4681 - acc: 0.8783 - val_loss: 0.4832 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.48142\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.4626 - acc: 0.8849 - val_loss: 0.4741 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.48142 to 0.47412, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.4583 - acc: 0.8763 - val_loss: 0.4756 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.47412\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.4564 - acc: 0.8855 - val_loss: 0.4681 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.47412 to 0.46813, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.4480 - acc: 0.8855 - val_loss: 0.4798 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.46813\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.4465 - acc: 0.8849 - val_loss: 0.4486 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.46813 to 0.44862, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.4427 - acc: 0.8875 - val_loss: 0.4493 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.44862\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.4400 - acc: 0.8914 - val_loss: 0.4504 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.44862\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.4333 - acc: 0.8954 - val_loss: 0.4435 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.44862 to 0.44353, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.4287 - acc: 0.8987 - val_loss: 0.4450 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.44353\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.4262 - acc: 0.8974 - val_loss: 0.4372 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.44353 to 0.43725, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.4210 - acc: 0.9026 - val_loss: 0.4371 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.43725 to 0.43714, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.4177 - acc: 0.9000 - val_loss: 0.4283 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.43714 to 0.42832, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.4158 - acc: 0.9020 - val_loss: 0.4322 - val_acc: 0.9012\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.42832\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.4100 - acc: 0.9026 - val_loss: 0.4206 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.42832 to 0.42060, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.4081 - acc: 0.9013 - val_loss: 0.4258 - val_acc: 0.9012\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.42060\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.4035 - acc: 0.9066 - val_loss: 0.4133 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.42060 to 0.41335, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.3985 - acc: 0.9092 - val_loss: 0.4068 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.41335 to 0.40677, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.3951 - acc: 0.9079 - val_loss: 0.4232 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.40677\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.3951 - acc: 0.9059 - val_loss: 0.4139 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.40677\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.3906 - acc: 0.9145 - val_loss: 0.4025 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.40677 to 0.40255, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.3900 - acc: 0.9118 - val_loss: 0.4001 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.40255 to 0.40008, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.3852 - acc: 0.9151 - val_loss: 0.3969 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.40008 to 0.39695, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.3811 - acc: 0.9178 - val_loss: 0.3931 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.39695 to 0.39310, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.3800 - acc: 0.9164 - val_loss: 0.3962 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.39310\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.3773 - acc: 0.9164 - val_loss: 0.3876 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.39310 to 0.38758, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.3762 - acc: 0.9224 - val_loss: 0.3926 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.38758\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.3719 - acc: 0.9197 - val_loss: 0.3873 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.38758 to 0.38734, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.3677 - acc: 0.9171 - val_loss: 0.3818 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.38734 to 0.38185, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.3607 - acc: 0.9270 - val_loss: 0.3880 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.38185\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.3636 - acc: 0.9237 - val_loss: 0.3751 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.38185 to 0.37515, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.3595 - acc: 0.9283 - val_loss: 0.3668 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.37515 to 0.36682, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.3576 - acc: 0.9230 - val_loss: 0.3730 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.36682\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.3548 - acc: 0.9296 - val_loss: 0.3786 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.36682\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.3537 - acc: 0.9243 - val_loss: 0.3620 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.36682 to 0.36199, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.3509 - acc: 0.9263 - val_loss: 0.3596 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.36199 to 0.35957, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.3454 - acc: 0.9283 - val_loss: 0.3571 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.35957 to 0.35706, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.3416 - acc: 0.9329 - val_loss: 0.3634 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.35706\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.3408 - acc: 0.9303 - val_loss: 0.3683 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.35706\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.3377 - acc: 0.9309 - val_loss: 0.3477 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.35706 to 0.34767, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.3384 - acc: 0.9336 - val_loss: 0.3491 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.34767\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.3339 - acc: 0.9336 - val_loss: 0.3562 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.34767\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.3314 - acc: 0.9342 - val_loss: 0.3472 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.34767 to 0.34725, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.3274 - acc: 0.9309 - val_loss: 0.3561 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.34725\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.3282 - acc: 0.9336 - val_loss: 0.3445 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.34725 to 0.34450, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.3216 - acc: 0.9414 - val_loss: 0.3446 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.34450\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.3237 - acc: 0.9382 - val_loss: 0.3387 - val_acc: 0.9424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00101: val_loss improved from 0.34450 to 0.33871, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.3199 - acc: 0.9362 - val_loss: 0.3384 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.33871 to 0.33843, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.3194 - acc: 0.9368 - val_loss: 0.3361 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.33843 to 0.33608, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.3153 - acc: 0.9395 - val_loss: 0.3354 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.33608 to 0.33541, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.3139 - acc: 0.9395 - val_loss: 0.3279 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.33541 to 0.32794, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.3116 - acc: 0.9441 - val_loss: 0.3268 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.32794 to 0.32682, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.3108 - acc: 0.9388 - val_loss: 0.3265 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.32682 to 0.32654, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.3076 - acc: 0.9421 - val_loss: 0.3185 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.32654 to 0.31848, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.3040 - acc: 0.9434 - val_loss: 0.3184 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.31848 to 0.31842, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.3024 - acc: 0.9487 - val_loss: 0.3264 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.31842\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.3027 - acc: 0.9447 - val_loss: 0.3169 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.31842 to 0.31692, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.3017 - acc: 0.9421 - val_loss: 0.3178 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.31692\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.2979 - acc: 0.9454 - val_loss: 0.3139 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.31692 to 0.31385, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.2962 - acc: 0.9461 - val_loss: 0.3182 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.31385\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.2954 - acc: 0.9500 - val_loss: 0.3067 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.31385 to 0.30666, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.2931 - acc: 0.9428 - val_loss: 0.3069 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.30666\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.2898 - acc: 0.9500 - val_loss: 0.3020 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.30666 to 0.30202, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.2881 - acc: 0.9507 - val_loss: 0.2988 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.30202 to 0.29884, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.2876 - acc: 0.9539 - val_loss: 0.3003 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.29884\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.2847 - acc: 0.9533 - val_loss: 0.3008 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.29884\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.2847 - acc: 0.9520 - val_loss: 0.2963 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.29884 to 0.29634, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.2834 - acc: 0.9539 - val_loss: 0.2947 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.29634 to 0.29473, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.2807 - acc: 0.9513 - val_loss: 0.2955 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.29473\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.2776 - acc: 0.9546 - val_loss: 0.3014 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.29473\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.2783 - acc: 0.9507 - val_loss: 0.2954 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.29473\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.2744 - acc: 0.9592 - val_loss: 0.2895 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.29473 to 0.28946, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.2728 - acc: 0.9586 - val_loss: 0.2874 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.28946 to 0.28744, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.2708 - acc: 0.9586 - val_loss: 0.2898 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.28744\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.2685 - acc: 0.9618 - val_loss: 0.2915 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.28744\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.2692 - acc: 0.9572 - val_loss: 0.2797 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.28744 to 0.27973, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.2676 - acc: 0.9586 - val_loss: 0.2810 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.27973\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.2653 - acc: 0.9566 - val_loss: 0.2885 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.27973\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.2631 - acc: 0.9605 - val_loss: 0.2825 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.27973\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.2621 - acc: 0.9592 - val_loss: 0.2747 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.27973 to 0.27470, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.2612 - acc: 0.9599 - val_loss: 0.2745 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.27470 to 0.27450, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.2585 - acc: 0.9618 - val_loss: 0.2853 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.27450\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.2576 - acc: 0.9592 - val_loss: 0.2741 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.27450 to 0.27415, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.2563 - acc: 0.9618 - val_loss: 0.2722 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.27415 to 0.27215, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.2547 - acc: 0.9632 - val_loss: 0.2737 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.27215\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.2532 - acc: 0.9645 - val_loss: 0.2684 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.27215 to 0.26838, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.2502 - acc: 0.9651 - val_loss: 0.2748 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.26838\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.2501 - acc: 0.9625 - val_loss: 0.2706 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.26838\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.2490 - acc: 0.9632 - val_loss: 0.2709 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.26838\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.2479 - acc: 0.9632 - val_loss: 0.2635 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.26838 to 0.26349, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.2454 - acc: 0.9658 - val_loss: 0.2585 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.26349 to 0.25855, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.2446 - acc: 0.9678 - val_loss: 0.2594 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.25855\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.2434 - acc: 0.9671 - val_loss: 0.2602 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.25855\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.2403 - acc: 0.9691 - val_loss: 0.2689 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.25855\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.2413 - acc: 0.9684 - val_loss: 0.2656 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.25855\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.2407 - acc: 0.9671 - val_loss: 0.2519 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.25855 to 0.25188, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.2390 - acc: 0.9678 - val_loss: 0.2518 - val_acc: 0.9712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00151: val_loss improved from 0.25188 to 0.25178, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.2376 - acc: 0.9697 - val_loss: 0.2575 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.25178\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.2359 - acc: 0.9671 - val_loss: 0.2568 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.25178\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.2347 - acc: 0.9671 - val_loss: 0.2474 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.25178 to 0.24745, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.2341 - acc: 0.9671 - val_loss: 0.2531 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.24745\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.2305 - acc: 0.9737 - val_loss: 0.2475 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.24745\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.2306 - acc: 0.9691 - val_loss: 0.2468 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.24745 to 0.24679, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.2298 - acc: 0.9684 - val_loss: 0.2419 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.24679 to 0.24188, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.2282 - acc: 0.9743 - val_loss: 0.2410 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.24188 to 0.24096, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.2278 - acc: 0.9737 - val_loss: 0.2433 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.24096\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.2259 - acc: 0.9724 - val_loss: 0.2448 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.24096\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.2253 - acc: 0.9684 - val_loss: 0.2442 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.24096\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.2230 - acc: 0.9757 - val_loss: 0.2445 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.24096\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.2223 - acc: 0.9750 - val_loss: 0.2414 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.24096\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.2202 - acc: 0.9743 - val_loss: 0.2412 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.24096\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.2192 - acc: 0.9783 - val_loss: 0.2405 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00166: val_loss improved from 0.24096 to 0.24046, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.2198 - acc: 0.9770 - val_loss: 0.2372 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.24046 to 0.23717, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.2180 - acc: 0.9757 - val_loss: 0.2342 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.23717 to 0.23417, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.2165 - acc: 0.9776 - val_loss: 0.2317 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.23417 to 0.23173, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.2168 - acc: 0.9763 - val_loss: 0.2327 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.23173\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.2139 - acc: 0.9763 - val_loss: 0.2390 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.23173\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.2136 - acc: 0.9750 - val_loss: 0.2317 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.23173\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.2119 - acc: 0.9743 - val_loss: 0.2325 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.23173\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.2124 - acc: 0.9763 - val_loss: 0.2301 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.23173 to 0.23008, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.2092 - acc: 0.9796 - val_loss: 0.2413 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.23008\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.2094 - acc: 0.9783 - val_loss: 0.2283 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00176: val_loss improved from 0.23008 to 0.22832, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.2073 - acc: 0.9770 - val_loss: 0.2252 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00177: val_loss improved from 0.22832 to 0.22521, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.2065 - acc: 0.9757 - val_loss: 0.2201 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00178: val_loss improved from 0.22521 to 0.22014, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.2059 - acc: 0.9776 - val_loss: 0.2276 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.22014\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.2050 - acc: 0.9796 - val_loss: 0.2246 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.22014\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.2041 - acc: 0.9803 - val_loss: 0.2268 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.22014\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.2035 - acc: 0.9796 - val_loss: 0.2244 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.22014\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.2027 - acc: 0.9822 - val_loss: 0.2206 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.22014\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.2011 - acc: 0.9809 - val_loss: 0.2188 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00184: val_loss improved from 0.22014 to 0.21884, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.2003 - acc: 0.9809 - val_loss: 0.2148 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00185: val_loss improved from 0.21884 to 0.21480, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.1981 - acc: 0.9783 - val_loss: 0.2221 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.21480\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.1994 - acc: 0.9809 - val_loss: 0.2198 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.21480\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.1969 - acc: 0.9803 - val_loss: 0.2138 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00188: val_loss improved from 0.21480 to 0.21375, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.1969 - acc: 0.9822 - val_loss: 0.2163 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.21375\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.1958 - acc: 0.9803 - val_loss: 0.2121 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00190: val_loss improved from 0.21375 to 0.21211, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.1953 - acc: 0.9803 - val_loss: 0.2133 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.21211\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.1935 - acc: 0.9816 - val_loss: 0.2108 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.21211 to 0.21078, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.1936 - acc: 0.9829 - val_loss: 0.2113 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.21078\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.1928 - acc: 0.9849 - val_loss: 0.2149 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.21078\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.1914 - acc: 0.9822 - val_loss: 0.2132 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.21078\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.1907 - acc: 0.9816 - val_loss: 0.2073 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00196: val_loss improved from 0.21078 to 0.20727, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.1893 - acc: 0.9836 - val_loss: 0.2096 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.20727\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.1888 - acc: 0.9842 - val_loss: 0.2048 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.20727 to 0.20476, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.1880 - acc: 0.9842 - val_loss: 0.2118 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.20476\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.1885 - acc: 0.9842 - val_loss: 0.2028 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00200: val_loss improved from 0.20476 to 0.20276, saving model to weights.best.Resnet50.hdf5\n",
      "batch_size=40   optimizer=SGD\n",
      "Test accuracy: 66.8524%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 2.1927 - acc: 0.2039 - val_loss: 1.9061 - val_acc: 0.3292\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.90609, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.8362 - acc: 0.3507 - val_loss: 1.6741 - val_acc: 0.3868\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.90609 to 1.67413, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 1.6253 - acc: 0.4480 - val_loss: 1.5178 - val_acc: 0.5021\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.67413 to 1.51783, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 1.4898 - acc: 0.5020 - val_loss: 1.4137 - val_acc: 0.5103\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.51783 to 1.41375, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 1.3873 - acc: 0.5395 - val_loss: 1.3398 - val_acc: 0.5597\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.41375 to 1.33983, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 1.3153 - acc: 0.5757 - val_loss: 1.2700 - val_acc: 0.5679\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.33983 to 1.26998, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 1.2571 - acc: 0.5954 - val_loss: 1.2288 - val_acc: 0.5885\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.26998 to 1.22877, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 0s - loss: 1.2027 - acc: 0.6184 - val_loss: 1.1848 - val_acc: 0.6008\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.22877 to 1.18476, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 0s - loss: 1.1588 - acc: 0.6342 - val_loss: 1.1377 - val_acc: 0.6049\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.18476 to 1.13770, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 0s - loss: 1.1224 - acc: 0.6428 - val_loss: 1.1125 - val_acc: 0.6461\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.13770 to 1.11252, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 0s - loss: 1.0967 - acc: 0.6533 - val_loss: 1.0872 - val_acc: 0.6132\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.11252 to 1.08723, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 0s - loss: 1.0641 - acc: 0.6691 - val_loss: 1.0582 - val_acc: 0.6214\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.08723 to 1.05824, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 0s - loss: 1.0378 - acc: 0.6724 - val_loss: 1.0330 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.05824 to 1.03300, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 0s - loss: 1.0220 - acc: 0.6697 - val_loss: 1.0122 - val_acc: 0.6543\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.03300 to 1.01222, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.9994 - acc: 0.6822 - val_loss: 1.0105 - val_acc: 0.6626\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.01222 to 1.01047, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.9751 - acc: 0.6908 - val_loss: 0.9747 - val_acc: 0.6584\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.01047 to 0.97472, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.9585 - acc: 0.6974 - val_loss: 0.9599 - val_acc: 0.6831\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.97472 to 0.95989, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.9468 - acc: 0.7099 - val_loss: 0.9383 - val_acc: 0.6749\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.95989 to 0.93831, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.9242 - acc: 0.7092 - val_loss: 0.9267 - val_acc: 0.6955\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.93831 to 0.92669, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.9116 - acc: 0.7158 - val_loss: 0.9206 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.92669 to 0.92064, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.8955 - acc: 0.7197 - val_loss: 0.9069 - val_acc: 0.7119\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.92064 to 0.90686, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.8855 - acc: 0.7283 - val_loss: 0.8986 - val_acc: 0.6955\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.90686 to 0.89864, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.8680 - acc: 0.7349 - val_loss: 0.8933 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.89864 to 0.89334, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.8603 - acc: 0.7329 - val_loss: 0.8685 - val_acc: 0.7119\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.89334 to 0.86855, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.8470 - acc: 0.7414 - val_loss: 0.8615 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.86855 to 0.86154, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.8341 - acc: 0.7414 - val_loss: 0.8528 - val_acc: 0.7202\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.86154 to 0.85281, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.8278 - acc: 0.7421 - val_loss: 0.8407 - val_acc: 0.7284\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.85281 to 0.84066, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.8173 - acc: 0.7480 - val_loss: 0.8328 - val_acc: 0.7366\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.84066 to 0.83284, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.8080 - acc: 0.7526 - val_loss: 0.8193 - val_acc: 0.7366\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.83284 to 0.81925, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.7976 - acc: 0.7566 - val_loss: 0.8078 - val_acc: 0.7366\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.81925 to 0.80777, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.7869 - acc: 0.7605 - val_loss: 0.8072 - val_acc: 0.7325\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.80777 to 0.80721, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.7768 - acc: 0.7605 - val_loss: 0.8100 - val_acc: 0.7202\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.80721\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.7722 - acc: 0.7605 - val_loss: 0.7885 - val_acc: 0.7366\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.80721 to 0.78854, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.7604 - acc: 0.7664 - val_loss: 0.7936 - val_acc: 0.7366\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.78854\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.7596 - acc: 0.7671 - val_loss: 0.7678 - val_acc: 0.7449\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.78854 to 0.76783, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.7475 - acc: 0.7704 - val_loss: 0.7689 - val_acc: 0.7284\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.76783\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.7388 - acc: 0.7803 - val_loss: 0.7671 - val_acc: 0.7531\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.76783 to 0.76710, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.7320 - acc: 0.7770 - val_loss: 0.7435 - val_acc: 0.7531\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.76710 to 0.74346, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.7293 - acc: 0.7717 - val_loss: 0.7460 - val_acc: 0.7613\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.74346\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.7224 - acc: 0.7776 - val_loss: 0.7460 - val_acc: 0.7407\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.74346\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.7110 - acc: 0.7882 - val_loss: 0.7440 - val_acc: 0.7449\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.74346\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.7070 - acc: 0.7829 - val_loss: 0.7269 - val_acc: 0.7654\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.74346 to 0.72686, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.7040 - acc: 0.7829 - val_loss: 0.7104 - val_acc: 0.7819\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.72686 to 0.71040, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.6932 - acc: 0.7914 - val_loss: 0.7115 - val_acc: 0.7737\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.71040\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.6881 - acc: 0.7947 - val_loss: 0.7034 - val_acc: 0.7778\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00045: val_loss improved from 0.71040 to 0.70337, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.6853 - acc: 0.7901 - val_loss: 0.6890 - val_acc: 0.7819\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.70337 to 0.68895, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.6759 - acc: 0.8000 - val_loss: 0.6949 - val_acc: 0.7654\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.68895\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.6714 - acc: 0.7967 - val_loss: 0.6906 - val_acc: 0.7860\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.68895\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.6673 - acc: 0.8026 - val_loss: 0.6806 - val_acc: 0.7737\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.68895 to 0.68058, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.6651 - acc: 0.8013 - val_loss: 0.6761 - val_acc: 0.7860\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.68058 to 0.67612, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.6540 - acc: 0.7980 - val_loss: 0.6877 - val_acc: 0.7654\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.67612\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.6496 - acc: 0.8092 - val_loss: 0.6722 - val_acc: 0.7737\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.67612 to 0.67222, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.6454 - acc: 0.8125 - val_loss: 0.6695 - val_acc: 0.7942\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.67222 to 0.66952, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.6431 - acc: 0.8046 - val_loss: 0.6539 - val_acc: 0.7819\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.66952 to 0.65387, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.6347 - acc: 0.8138 - val_loss: 0.6564 - val_acc: 0.7819\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.65387\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.6315 - acc: 0.8112 - val_loss: 0.6378 - val_acc: 0.8107\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.65387 to 0.63778, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.6284 - acc: 0.8072 - val_loss: 0.6485 - val_acc: 0.7819\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.63778\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.6208 - acc: 0.8145 - val_loss: 0.6491 - val_acc: 0.7860\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.63778\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.6189 - acc: 0.8171 - val_loss: 0.6292 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.63778 to 0.62916, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.6135 - acc: 0.8158 - val_loss: 0.6205 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.62916 to 0.62052, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.6077 - acc: 0.8145 - val_loss: 0.6318 - val_acc: 0.7860\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.62052\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.6054 - acc: 0.8243 - val_loss: 0.6222 - val_acc: 0.8107\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.62052\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.5999 - acc: 0.8250 - val_loss: 0.6220 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.62052\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.5969 - acc: 0.8224 - val_loss: 0.6071 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.62052 to 0.60714, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.5924 - acc: 0.8289 - val_loss: 0.6201 - val_acc: 0.7942\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.60714\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.5916 - acc: 0.8283 - val_loss: 0.6077 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.60714\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.5860 - acc: 0.8336 - val_loss: 0.6030 - val_acc: 0.8148\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.60714 to 0.60300, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.5869 - acc: 0.8250 - val_loss: 0.5943 - val_acc: 0.8354\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.60300 to 0.59428, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.5785 - acc: 0.8309 - val_loss: 0.5923 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.59428 to 0.59228, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.5765 - acc: 0.8309 - val_loss: 0.5892 - val_acc: 0.8107\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.59228 to 0.58919, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.5734 - acc: 0.8316 - val_loss: 0.5891 - val_acc: 0.8107\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.58919 to 0.58909, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.5694 - acc: 0.8329 - val_loss: 0.5823 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.58909 to 0.58230, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.5655 - acc: 0.8362 - val_loss: 0.5788 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.58230 to 0.57884, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.5607 - acc: 0.8355 - val_loss: 0.5729 - val_acc: 0.8148\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.57884 to 0.57291, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.5567 - acc: 0.8336 - val_loss: 0.5756 - val_acc: 0.8107\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.57291\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.5565 - acc: 0.8349 - val_loss: 0.5652 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.57291 to 0.56520, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.5507 - acc: 0.8461 - val_loss: 0.5699 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.56520\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.5486 - acc: 0.8408 - val_loss: 0.5601 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.56520 to 0.56010, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.5466 - acc: 0.8428 - val_loss: 0.5570 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.56010 to 0.55699, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.5410 - acc: 0.8447 - val_loss: 0.5590 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.55699\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.5388 - acc: 0.8414 - val_loss: 0.5602 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.55699\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.5359 - acc: 0.8461 - val_loss: 0.5448 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.55699 to 0.54477, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.5338 - acc: 0.8520 - val_loss: 0.5406 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.54477 to 0.54062, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.5282 - acc: 0.8500 - val_loss: 0.5428 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.54062\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.5281 - acc: 0.8539 - val_loss: 0.5409 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.54062\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.5221 - acc: 0.8559 - val_loss: 0.5411 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.54062\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.5207 - acc: 0.8533 - val_loss: 0.5326 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.54062 to 0.53263, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.5194 - acc: 0.8507 - val_loss: 0.5305 - val_acc: 0.8354\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.53263 to 0.53046, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.5138 - acc: 0.8507 - val_loss: 0.5273 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.53046 to 0.52732, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.5153 - acc: 0.8526 - val_loss: 0.5365 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.52732\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.5100 - acc: 0.8579 - val_loss: 0.5295 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.52732\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.5063 - acc: 0.8539 - val_loss: 0.5157 - val_acc: 0.8765\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.52732 to 0.51574, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.5027 - acc: 0.8592 - val_loss: 0.5135 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.51574 to 0.51355, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.4993 - acc: 0.8572 - val_loss: 0.5187 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.51355\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.4998 - acc: 0.8625 - val_loss: 0.5117 - val_acc: 0.8560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00095: val_loss improved from 0.51355 to 0.51175, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.4962 - acc: 0.8586 - val_loss: 0.5071 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.51175 to 0.50707, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.4923 - acc: 0.8618 - val_loss: 0.5217 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.50707\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.4907 - acc: 0.8592 - val_loss: 0.4966 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.50707 to 0.49657, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.4905 - acc: 0.8632 - val_loss: 0.4965 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.49657 to 0.49650, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.4893 - acc: 0.8579 - val_loss: 0.4969 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.49650\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.4836 - acc: 0.8664 - val_loss: 0.4949 - val_acc: 0.8765\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.49650 to 0.49487, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.4825 - acc: 0.8658 - val_loss: 0.4884 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.49487 to 0.48840, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.4805 - acc: 0.8684 - val_loss: 0.4975 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.48840\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.4769 - acc: 0.8730 - val_loss: 0.4860 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.48840 to 0.48599, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.4743 - acc: 0.8724 - val_loss: 0.4939 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.48599\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.4742 - acc: 0.8757 - val_loss: 0.4849 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.48599 to 0.48486, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.4691 - acc: 0.8724 - val_loss: 0.4906 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.48486\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.4681 - acc: 0.8704 - val_loss: 0.4769 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.48486 to 0.47692, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.4643 - acc: 0.8750 - val_loss: 0.4868 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.47692\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.4626 - acc: 0.8763 - val_loss: 0.4706 - val_acc: 0.8765\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.47692 to 0.47057, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.4593 - acc: 0.8743 - val_loss: 0.4770 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.47057\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.4591 - acc: 0.8809 - val_loss: 0.4736 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.47057\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.4582 - acc: 0.8796 - val_loss: 0.4665 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.47057 to 0.46651, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.4564 - acc: 0.8796 - val_loss: 0.4684 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.46651\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.4536 - acc: 0.8796 - val_loss: 0.4612 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.46651 to 0.46118, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.4494 - acc: 0.8822 - val_loss: 0.4634 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.46118\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.4479 - acc: 0.8803 - val_loss: 0.4560 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.46118 to 0.45601, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.4481 - acc: 0.8822 - val_loss: 0.4591 - val_acc: 0.8765\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.45601\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.4450 - acc: 0.8862 - val_loss: 0.4577 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.45601\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.4411 - acc: 0.8868 - val_loss: 0.4555 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.45601 to 0.45553, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.4409 - acc: 0.8816 - val_loss: 0.4579 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.45553\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.4395 - acc: 0.8882 - val_loss: 0.4498 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.45553 to 0.44977, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.4362 - acc: 0.8901 - val_loss: 0.4544 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.44977\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.4353 - acc: 0.8862 - val_loss: 0.4480 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.44977 to 0.44804, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.4315 - acc: 0.8888 - val_loss: 0.4482 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.44804\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.4307 - acc: 0.8882 - val_loss: 0.4464 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.44804 to 0.44642, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.4274 - acc: 0.8941 - val_loss: 0.4411 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.44642 to 0.44108, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.4259 - acc: 0.8928 - val_loss: 0.4359 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.44108 to 0.43587, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.4246 - acc: 0.8941 - val_loss: 0.4388 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.43587\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.4234 - acc: 0.8921 - val_loss: 0.4342 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.43587 to 0.43418, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.4205 - acc: 0.8901 - val_loss: 0.4302 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.43418 to 0.43018, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.4192 - acc: 0.8941 - val_loss: 0.4306 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.43018\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.4154 - acc: 0.8974 - val_loss: 0.4356 - val_acc: 0.9012\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.43018\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.4148 - acc: 0.9007 - val_loss: 0.4309 - val_acc: 0.9012\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.43018\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.4139 - acc: 0.9053 - val_loss: 0.4273 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.43018 to 0.42729, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.4128 - acc: 0.8974 - val_loss: 0.4266 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.42729 to 0.42658, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.4095 - acc: 0.8993 - val_loss: 0.4233 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.42658 to 0.42329, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.4083 - acc: 0.9033 - val_loss: 0.4213 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.42329 to 0.42130, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.4077 - acc: 0.9020 - val_loss: 0.4159 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.42130 to 0.41589, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.4056 - acc: 0.9020 - val_loss: 0.4299 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.41589\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.4028 - acc: 0.9026 - val_loss: 0.4121 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.41589 to 0.41208, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.4023 - acc: 0.9053 - val_loss: 0.4167 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.41208\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.3995 - acc: 0.9059 - val_loss: 0.4201 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.41208\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.3980 - acc: 0.9046 - val_loss: 0.4140 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.41208\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.3955 - acc: 0.9105 - val_loss: 0.4072 - val_acc: 0.9218\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00145: val_loss improved from 0.41208 to 0.40722, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.3950 - acc: 0.9072 - val_loss: 0.4049 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.40722 to 0.40495, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.3951 - acc: 0.9099 - val_loss: 0.4056 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.40495\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.3918 - acc: 0.9118 - val_loss: 0.4083 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.40495\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.3909 - acc: 0.9092 - val_loss: 0.3992 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.40495 to 0.39916, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.3892 - acc: 0.9092 - val_loss: 0.4028 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.39916\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.3865 - acc: 0.9158 - val_loss: 0.4045 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.39916\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.3866 - acc: 0.9138 - val_loss: 0.4014 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.39916\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.3849 - acc: 0.9112 - val_loss: 0.3998 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.39916\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.3827 - acc: 0.9158 - val_loss: 0.4003 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.39916\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.3810 - acc: 0.9099 - val_loss: 0.3927 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.39916 to 0.39270, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.3792 - acc: 0.9092 - val_loss: 0.3948 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.39270\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.3780 - acc: 0.9099 - val_loss: 0.3922 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.39270 to 0.39225, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.3755 - acc: 0.9145 - val_loss: 0.3912 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.39225 to 0.39125, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.3751 - acc: 0.9184 - val_loss: 0.3908 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.39125 to 0.39081, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.3748 - acc: 0.9138 - val_loss: 0.3871 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.39081 to 0.38709, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.3719 - acc: 0.9184 - val_loss: 0.3817 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.38709 to 0.38167, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.3701 - acc: 0.9178 - val_loss: 0.3828 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.38167\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.3694 - acc: 0.9217 - val_loss: 0.3836 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.38167\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.3678 - acc: 0.9211 - val_loss: 0.3775 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.38167 to 0.37752, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.3666 - acc: 0.9217 - val_loss: 0.3835 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.37752\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.3652 - acc: 0.9197 - val_loss: 0.3888 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.37752\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.3651 - acc: 0.9178 - val_loss: 0.3758 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.37752 to 0.37583, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.3624 - acc: 0.9243 - val_loss: 0.3800 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.37583\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.3622 - acc: 0.9211 - val_loss: 0.3736 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.37583 to 0.37357, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.3610 - acc: 0.9263 - val_loss: 0.3721 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.37357 to 0.37213, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.3595 - acc: 0.9230 - val_loss: 0.3831 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.37213\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.3576 - acc: 0.9237 - val_loss: 0.3742 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.37213\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.3582 - acc: 0.9276 - val_loss: 0.3714 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.37213 to 0.37141, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.3553 - acc: 0.9257 - val_loss: 0.3655 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.37141 to 0.36550, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.3533 - acc: 0.9303 - val_loss: 0.3713 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.36550\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.3511 - acc: 0.9316 - val_loss: 0.3659 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.36550\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.3506 - acc: 0.9283 - val_loss: 0.3631 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00177: val_loss improved from 0.36550 to 0.36311, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.3492 - acc: 0.9289 - val_loss: 0.3640 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.36311\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.3489 - acc: 0.9276 - val_loss: 0.3624 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00179: val_loss improved from 0.36311 to 0.36240, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.3472 - acc: 0.9289 - val_loss: 0.3639 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.36240\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.3462 - acc: 0.9303 - val_loss: 0.3566 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00181: val_loss improved from 0.36240 to 0.35661, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.3450 - acc: 0.9309 - val_loss: 0.3622 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.35661\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.3439 - acc: 0.9276 - val_loss: 0.3553 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00183: val_loss improved from 0.35661 to 0.35533, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.3414 - acc: 0.9296 - val_loss: 0.3593 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.35533\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.3402 - acc: 0.9303 - val_loss: 0.3597 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.35533\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.3399 - acc: 0.9303 - val_loss: 0.3565 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.35533\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.3381 - acc: 0.9329 - val_loss: 0.3581 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.35533\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.3368 - acc: 0.9336 - val_loss: 0.3542 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00188: val_loss improved from 0.35533 to 0.35420, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.3367 - acc: 0.9322 - val_loss: 0.3520 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.35420 to 0.35197, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.3356 - acc: 0.9303 - val_loss: 0.3529 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.35197\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.3333 - acc: 0.9368 - val_loss: 0.3467 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00191: val_loss improved from 0.35197 to 0.34669, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.3329 - acc: 0.9375 - val_loss: 0.3485 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.34669\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.3309 - acc: 0.9368 - val_loss: 0.3442 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00193: val_loss improved from 0.34669 to 0.34419, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.3295 - acc: 0.9368 - val_loss: 0.3497 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.34419\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.3304 - acc: 0.9316 - val_loss: 0.3395 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00195: val_loss improved from 0.34419 to 0.33954, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.3284 - acc: 0.9395 - val_loss: 0.3438 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.33954\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.3255 - acc: 0.9362 - val_loss: 0.3374 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00197: val_loss improved from 0.33954 to 0.33738, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.3248 - acc: 0.9382 - val_loss: 0.3426 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.33738\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.3237 - acc: 0.9382 - val_loss: 0.3400 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.33738\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.3235 - acc: 0.9355 - val_loss: 0.3394 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.33738\n",
      "batch_size=80   optimizer=SGD\n",
      "Test accuracy: 65.1811%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 2.3009 - acc: 0.1526 - val_loss: 2.1175 - val_acc: 0.2016\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.11752, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.9740 - acc: 0.2888 - val_loss: 1.9102 - val_acc: 0.3251\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.11752 to 1.91017, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 1.7758 - acc: 0.3770 - val_loss: 1.7268 - val_acc: 0.3992\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.91017 to 1.72681, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 1.6271 - acc: 0.4533 - val_loss: 1.6166 - val_acc: 0.4444\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.72681 to 1.61663, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 1.5215 - acc: 0.5026 - val_loss: 1.5302 - val_acc: 0.4856\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.61663 to 1.53016, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 1.4359 - acc: 0.5401 - val_loss: 1.4424 - val_acc: 0.4856\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.53016 to 1.44240, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 1.3713 - acc: 0.5520 - val_loss: 1.3995 - val_acc: 0.4979\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.44240 to 1.39946, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 0s - loss: 1.3143 - acc: 0.5855 - val_loss: 1.3395 - val_acc: 0.5267\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.39946 to 1.33953, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 0s - loss: 1.2693 - acc: 0.5934 - val_loss: 1.3200 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.33953 to 1.32000, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 0s - loss: 1.2328 - acc: 0.6092 - val_loss: 1.2710 - val_acc: 0.5473\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.32000 to 1.27104, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 0s - loss: 1.1945 - acc: 0.6263 - val_loss: 1.2429 - val_acc: 0.5761\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.27104 to 1.24289, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 0s - loss: 1.1629 - acc: 0.6316 - val_loss: 1.2221 - val_acc: 0.5597\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.24289 to 1.22206, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 0s - loss: 1.1387 - acc: 0.6447 - val_loss: 1.1886 - val_acc: 0.6132\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.22206 to 1.18864, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 0s - loss: 1.1116 - acc: 0.6612 - val_loss: 1.1546 - val_acc: 0.6049\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.18864 to 1.15457, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 0s - loss: 1.0904 - acc: 0.6632 - val_loss: 1.1348 - val_acc: 0.6255\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.15457 to 1.13480, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 0s - loss: 1.0715 - acc: 0.6651 - val_loss: 1.1170 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.13480 to 1.11696, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 0s - loss: 1.0507 - acc: 0.6776 - val_loss: 1.0927 - val_acc: 0.6502\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.11696 to 1.09268, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/200\n",
      " - 0s - loss: 1.0324 - acc: 0.6895 - val_loss: 1.0814 - val_acc: 0.6337\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.09268 to 1.08144, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 0s - loss: 1.0201 - acc: 0.6816 - val_loss: 1.0562 - val_acc: 0.6584\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.08144 to 1.05616, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 0s - loss: 1.0012 - acc: 0.6980 - val_loss: 1.0550 - val_acc: 0.6461\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.05616 to 1.05502, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.9868 - acc: 0.7007 - val_loss: 1.0286 - val_acc: 0.6543\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.05502 to 1.02856, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.9755 - acc: 0.7066 - val_loss: 1.0117 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.02856 to 1.01168, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.9603 - acc: 0.7118 - val_loss: 0.9983 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.01168 to 0.99832, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.9526 - acc: 0.7000 - val_loss: 1.0057 - val_acc: 0.6626\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.99832\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.9403 - acc: 0.7217 - val_loss: 0.9926 - val_acc: 0.6831\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.99832 to 0.99256, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.9297 - acc: 0.7204 - val_loss: 0.9710 - val_acc: 0.6831\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.99256 to 0.97101, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.9176 - acc: 0.7178 - val_loss: 0.9508 - val_acc: 0.6790\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.97101 to 0.95078, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.9062 - acc: 0.7250 - val_loss: 0.9482 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.95078 to 0.94820, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.8976 - acc: 0.7276 - val_loss: 0.9368 - val_acc: 0.6955\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.94820 to 0.93681, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.8888 - acc: 0.7368 - val_loss: 0.9373 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.93681\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.8789 - acc: 0.7362 - val_loss: 0.9147 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.93681 to 0.91474, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.8709 - acc: 0.7362 - val_loss: 0.9110 - val_acc: 0.7078\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.91474 to 0.91101, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.8636 - acc: 0.7368 - val_loss: 0.9065 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.91101 to 0.90645, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.8543 - acc: 0.7447 - val_loss: 0.9030 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.90645 to 0.90296, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.8467 - acc: 0.7401 - val_loss: 0.8987 - val_acc: 0.7119\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.90296 to 0.89868, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.8388 - acc: 0.7441 - val_loss: 0.8716 - val_acc: 0.7325\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.89868 to 0.87164, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.8297 - acc: 0.7507 - val_loss: 0.8641 - val_acc: 0.7284\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.87164 to 0.86412, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.8239 - acc: 0.7559 - val_loss: 0.8611 - val_acc: 0.7119\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.86412 to 0.86112, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.8157 - acc: 0.7520 - val_loss: 0.8616 - val_acc: 0.7325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00039: val_loss did not improve from 0.86112\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.8100 - acc: 0.7507 - val_loss: 0.8518 - val_acc: 0.7284\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.86112 to 0.85181, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.8016 - acc: 0.7599 - val_loss: 0.8369 - val_acc: 0.7449\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.85181 to 0.83693, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.7962 - acc: 0.7572 - val_loss: 0.8460 - val_acc: 0.7243\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.83693\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.7917 - acc: 0.7651 - val_loss: 0.8283 - val_acc: 0.7366\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.83693 to 0.82835, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.7857 - acc: 0.7651 - val_loss: 0.8232 - val_acc: 0.7366\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.82835 to 0.82320, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.7811 - acc: 0.7658 - val_loss: 0.8218 - val_acc: 0.7366\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.82320 to 0.82179, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.7717 - acc: 0.7717 - val_loss: 0.8152 - val_acc: 0.7407\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.82179 to 0.81523, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.7679 - acc: 0.7645 - val_loss: 0.8012 - val_acc: 0.7531\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.81523 to 0.80121, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.7645 - acc: 0.7645 - val_loss: 0.8003 - val_acc: 0.7490\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.80121 to 0.80030, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.7538 - acc: 0.7684 - val_loss: 0.7971 - val_acc: 0.7449\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.80030 to 0.79712, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.7540 - acc: 0.7684 - val_loss: 0.7993 - val_acc: 0.7407\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.79712\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.7469 - acc: 0.7816 - val_loss: 0.7973 - val_acc: 0.7284\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.79712\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.7427 - acc: 0.7816 - val_loss: 0.7724 - val_acc: 0.7531\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.79712 to 0.77241, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.7372 - acc: 0.7829 - val_loss: 0.7810 - val_acc: 0.7613\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.77241\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.7315 - acc: 0.7796 - val_loss: 0.7747 - val_acc: 0.7531\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.77241\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.7274 - acc: 0.7803 - val_loss: 0.7825 - val_acc: 0.7531\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.77241\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.7234 - acc: 0.7875 - val_loss: 0.7601 - val_acc: 0.7613\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.77241 to 0.76010, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.7185 - acc: 0.7862 - val_loss: 0.7547 - val_acc: 0.7695\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.76010 to 0.75471, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.7152 - acc: 0.7836 - val_loss: 0.7590 - val_acc: 0.7490\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.75471\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.7098 - acc: 0.7921 - val_loss: 0.7451 - val_acc: 0.7572\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.75471 to 0.74515, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.7024 - acc: 0.7928 - val_loss: 0.7416 - val_acc: 0.7531\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.74515 to 0.74160, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.6989 - acc: 0.7842 - val_loss: 0.7311 - val_acc: 0.7654\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.74160 to 0.73106, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.6961 - acc: 0.7888 - val_loss: 0.7277 - val_acc: 0.7819\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.73106 to 0.72766, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.6931 - acc: 0.7921 - val_loss: 0.7274 - val_acc: 0.7613\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.72766 to 0.72740, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.6895 - acc: 0.7928 - val_loss: 0.7255 - val_acc: 0.7695\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.72740 to 0.72547, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.6822 - acc: 0.7974 - val_loss: 0.7283 - val_acc: 0.7654\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.72547\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.6813 - acc: 0.7954 - val_loss: 0.7141 - val_acc: 0.7819\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.72547 to 0.71415, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.6758 - acc: 0.7967 - val_loss: 0.7172 - val_acc: 0.7737\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.71415\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.6711 - acc: 0.7980 - val_loss: 0.7079 - val_acc: 0.7613\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.71415 to 0.70791, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.6701 - acc: 0.8053 - val_loss: 0.7054 - val_acc: 0.7901\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.70791 to 0.70545, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.6642 - acc: 0.8000 - val_loss: 0.7050 - val_acc: 0.7819\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.70545 to 0.70504, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.6605 - acc: 0.8046 - val_loss: 0.7057 - val_acc: 0.7860\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.70504\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.6566 - acc: 0.8033 - val_loss: 0.6904 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.70504 to 0.69042, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.6534 - acc: 0.8039 - val_loss: 0.6824 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.69042 to 0.68236, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.6509 - acc: 0.8066 - val_loss: 0.6824 - val_acc: 0.7737\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.68236\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.6467 - acc: 0.8086 - val_loss: 0.6904 - val_acc: 0.7860\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.68236\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.6426 - acc: 0.8086 - val_loss: 0.6859 - val_acc: 0.7942\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.68236\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.6402 - acc: 0.8092 - val_loss: 0.6724 - val_acc: 0.7860\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.68236 to 0.67236, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.6381 - acc: 0.8053 - val_loss: 0.6697 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.67236 to 0.66970, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.6341 - acc: 0.8164 - val_loss: 0.6704 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.66970\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.6329 - acc: 0.8132 - val_loss: 0.6623 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.66970 to 0.66228, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.6289 - acc: 0.8132 - val_loss: 0.6606 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.66228 to 0.66062, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.6237 - acc: 0.8125 - val_loss: 0.6651 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.66062\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.6225 - acc: 0.8158 - val_loss: 0.6574 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.66062 to 0.65744, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.6189 - acc: 0.8158 - val_loss: 0.6557 - val_acc: 0.7942\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.65744 to 0.65574, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.6154 - acc: 0.8197 - val_loss: 0.6495 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.65574 to 0.64950, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.6115 - acc: 0.8178 - val_loss: 0.6413 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.64950 to 0.64129, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.6095 - acc: 0.8145 - val_loss: 0.6444 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.64129\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.6091 - acc: 0.8184 - val_loss: 0.6398 - val_acc: 0.7984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00088: val_loss improved from 0.64129 to 0.63984, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.6050 - acc: 0.8178 - val_loss: 0.6362 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.63984 to 0.63616, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.6012 - acc: 0.8211 - val_loss: 0.6420 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.63616\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.5990 - acc: 0.8237 - val_loss: 0.6343 - val_acc: 0.8107\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.63616 to 0.63431, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.5950 - acc: 0.8283 - val_loss: 0.6395 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.63431\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.5945 - acc: 0.8276 - val_loss: 0.6369 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.63431\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.5902 - acc: 0.8289 - val_loss: 0.6275 - val_acc: 0.8107\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.63431 to 0.62747, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.5868 - acc: 0.8283 - val_loss: 0.6184 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.62747 to 0.61840, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.5832 - acc: 0.8309 - val_loss: 0.6232 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.61840\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.5843 - acc: 0.8257 - val_loss: 0.6201 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.61840\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.5807 - acc: 0.8296 - val_loss: 0.6181 - val_acc: 0.8148\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.61840 to 0.61814, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.5791 - acc: 0.8263 - val_loss: 0.6136 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.61814 to 0.61362, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.5746 - acc: 0.8296 - val_loss: 0.6096 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.61362 to 0.60964, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.5721 - acc: 0.8336 - val_loss: 0.6097 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.60964\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.5693 - acc: 0.8296 - val_loss: 0.6089 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.60964 to 0.60894, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.5670 - acc: 0.8395 - val_loss: 0.6089 - val_acc: 0.8148\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.60894 to 0.60891, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.5650 - acc: 0.8362 - val_loss: 0.5972 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.60891 to 0.59720, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.5626 - acc: 0.8375 - val_loss: 0.6060 - val_acc: 0.8107\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.59720\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.5627 - acc: 0.8375 - val_loss: 0.6011 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.59720\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.5588 - acc: 0.8368 - val_loss: 0.5967 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.59720 to 0.59669, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.5561 - acc: 0.8408 - val_loss: 0.5859 - val_acc: 0.8354\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.59669 to 0.58593, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.5541 - acc: 0.8408 - val_loss: 0.5890 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.58593\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.5502 - acc: 0.8428 - val_loss: 0.5839 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.58593 to 0.58388, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.5495 - acc: 0.8408 - val_loss: 0.5792 - val_acc: 0.8354\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.58388 to 0.57921, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.5463 - acc: 0.8474 - val_loss: 0.5981 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.57921\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.5467 - acc: 0.8395 - val_loss: 0.5840 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.57921\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.5437 - acc: 0.8382 - val_loss: 0.5810 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.57921\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.5419 - acc: 0.8447 - val_loss: 0.5782 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.57921 to 0.57820, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.5379 - acc: 0.8434 - val_loss: 0.5739 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.57820 to 0.57387, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.5358 - acc: 0.8441 - val_loss: 0.5773 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.57387\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.5349 - acc: 0.8493 - val_loss: 0.5637 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.57387 to 0.56374, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.5321 - acc: 0.8493 - val_loss: 0.5688 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.56374\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.5295 - acc: 0.8480 - val_loss: 0.5663 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.56374\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.5266 - acc: 0.8533 - val_loss: 0.5638 - val_acc: 0.8354\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.56374\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.5260 - acc: 0.8447 - val_loss: 0.5634 - val_acc: 0.8354\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.56374 to 0.56342, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.5269 - acc: 0.8480 - val_loss: 0.5635 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.56342\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.5204 - acc: 0.8500 - val_loss: 0.5532 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.56342 to 0.55318, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.5192 - acc: 0.8493 - val_loss: 0.5617 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.55318\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.5183 - acc: 0.8507 - val_loss: 0.5570 - val_acc: 0.8354\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.55318\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.5169 - acc: 0.8553 - val_loss: 0.5495 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.55318 to 0.54952, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.5130 - acc: 0.8553 - val_loss: 0.5521 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.54952\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.5108 - acc: 0.8579 - val_loss: 0.5572 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.54952\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.5096 - acc: 0.8539 - val_loss: 0.5497 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.54952\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.5099 - acc: 0.8559 - val_loss: 0.5468 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.54952 to 0.54683, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.5063 - acc: 0.8559 - val_loss: 0.5450 - val_acc: 0.8354\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.54683 to 0.54501, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.5048 - acc: 0.8605 - val_loss: 0.5338 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.54501 to 0.53381, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.5025 - acc: 0.8572 - val_loss: 0.5371 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.53381\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.5016 - acc: 0.8599 - val_loss: 0.5420 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.53381\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.4995 - acc: 0.8625 - val_loss: 0.5329 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.53381 to 0.53288, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.4968 - acc: 0.8605 - val_loss: 0.5381 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.53288\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.4965 - acc: 0.8632 - val_loss: 0.5303 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.53288 to 0.53028, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.4945 - acc: 0.8671 - val_loss: 0.5238 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.53028 to 0.52382, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.4921 - acc: 0.8691 - val_loss: 0.5409 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.52382\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.4899 - acc: 0.8658 - val_loss: 0.5318 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.52382\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.4890 - acc: 0.8605 - val_loss: 0.5193 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.52382 to 0.51932, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.4865 - acc: 0.8697 - val_loss: 0.5183 - val_acc: 0.8765\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.51932 to 0.51831, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.4877 - acc: 0.8612 - val_loss: 0.5205 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.51831\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.4833 - acc: 0.8711 - val_loss: 0.5218 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.51831\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.4829 - acc: 0.8625 - val_loss: 0.5162 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.51831 to 0.51616, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.4826 - acc: 0.8671 - val_loss: 0.5147 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.51616 to 0.51474, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.4786 - acc: 0.8750 - val_loss: 0.5276 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.51474\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.4782 - acc: 0.8697 - val_loss: 0.5169 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.51474\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.4754 - acc: 0.8704 - val_loss: 0.5098 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.51474 to 0.50985, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.4749 - acc: 0.8750 - val_loss: 0.5065 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.50985 to 0.50647, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.4732 - acc: 0.8789 - val_loss: 0.5078 - val_acc: 0.8765\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.50647\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.4709 - acc: 0.8789 - val_loss: 0.5023 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.50647 to 0.50228, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.4707 - acc: 0.8757 - val_loss: 0.5056 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.50228\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.4685 - acc: 0.8783 - val_loss: 0.5096 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.50228\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.4669 - acc: 0.8737 - val_loss: 0.5030 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.50228\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.4657 - acc: 0.8763 - val_loss: 0.4929 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.50228 to 0.49287, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.4643 - acc: 0.8803 - val_loss: 0.5019 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.49287\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.4620 - acc: 0.8776 - val_loss: 0.5014 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.49287\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.4589 - acc: 0.8836 - val_loss: 0.4994 - val_acc: 0.8765\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.49287\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.4585 - acc: 0.8809 - val_loss: 0.4983 - val_acc: 0.8765\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.49287\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.4573 - acc: 0.8809 - val_loss: 0.4910 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.49287 to 0.49103, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.4547 - acc: 0.8809 - val_loss: 0.4852 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00163: val_loss improved from 0.49103 to 0.48524, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.4545 - acc: 0.8855 - val_loss: 0.4877 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.48524\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.4516 - acc: 0.8842 - val_loss: 0.4890 - val_acc: 0.8765\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.48524\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.4505 - acc: 0.8855 - val_loss: 0.4875 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.48524\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.4504 - acc: 0.8849 - val_loss: 0.4835 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.48524 to 0.48354, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.4489 - acc: 0.8868 - val_loss: 0.4818 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.48354 to 0.48182, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.4481 - acc: 0.8855 - val_loss: 0.4769 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.48182 to 0.47692, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.4454 - acc: 0.8882 - val_loss: 0.4772 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.47692\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.4453 - acc: 0.8862 - val_loss: 0.4742 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00171: val_loss improved from 0.47692 to 0.47417, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.4425 - acc: 0.8842 - val_loss: 0.4754 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.47417\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.4411 - acc: 0.8914 - val_loss: 0.4722 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.47417 to 0.47219, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.4401 - acc: 0.8941 - val_loss: 0.4799 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.47219\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.4394 - acc: 0.8875 - val_loss: 0.4780 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.47219\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.4386 - acc: 0.8888 - val_loss: 0.4677 - val_acc: 0.9012\n",
      "\n",
      "Epoch 00176: val_loss improved from 0.47219 to 0.46773, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.4361 - acc: 0.8888 - val_loss: 0.4682 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.46773\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.4348 - acc: 0.8934 - val_loss: 0.4679 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.46773\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.4348 - acc: 0.8921 - val_loss: 0.4719 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.46773\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.4311 - acc: 0.8882 - val_loss: 0.4603 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00180: val_loss improved from 0.46773 to 0.46027, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.4315 - acc: 0.8888 - val_loss: 0.4610 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.46027\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.4303 - acc: 0.8954 - val_loss: 0.4627 - val_acc: 0.9012\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.46027\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.4278 - acc: 0.8921 - val_loss: 0.4641 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.46027\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.4265 - acc: 0.8961 - val_loss: 0.4616 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.46027\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.4268 - acc: 0.8921 - val_loss: 0.4588 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00185: val_loss improved from 0.46027 to 0.45883, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.4239 - acc: 0.8974 - val_loss: 0.4552 - val_acc: 0.9012\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.45883 to 0.45520, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.4221 - acc: 0.8993 - val_loss: 0.4577 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.45520\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.4235 - acc: 0.8974 - val_loss: 0.4637 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.45520\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.4212 - acc: 0.8961 - val_loss: 0.4578 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.45520\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.4197 - acc: 0.8980 - val_loss: 0.4571 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.45520\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.4178 - acc: 0.8987 - val_loss: 0.4542 - val_acc: 0.8930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00191: val_loss improved from 0.45520 to 0.45416, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.4172 - acc: 0.9000 - val_loss: 0.4496 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.45416 to 0.44956, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.4145 - acc: 0.9007 - val_loss: 0.4550 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.44956\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.4132 - acc: 0.8967 - val_loss: 0.4479 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00194: val_loss improved from 0.44956 to 0.44789, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.4134 - acc: 0.8993 - val_loss: 0.4495 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.44789\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.4128 - acc: 0.9066 - val_loss: 0.4448 - val_acc: 0.9012\n",
      "\n",
      "Epoch 00196: val_loss improved from 0.44789 to 0.44483, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.4113 - acc: 0.9020 - val_loss: 0.4461 - val_acc: 0.9012\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.44483\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.4102 - acc: 0.9046 - val_loss: 0.4465 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.44483\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.4078 - acc: 0.9020 - val_loss: 0.4467 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.44483\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.4074 - acc: 0.9020 - val_loss: 0.4403 - val_acc: 0.9012\n",
      "\n",
      "Epoch 00200: val_loss improved from 0.44483 to 0.44033, saving model to weights.best.Resnet50.hdf5\n",
      "batch_size=120   optimizer=SGD\n",
      "Test accuracy: 67.4095%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 2.3909 - acc: 0.1401 - val_loss: 2.1578 - val_acc: 0.1934\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.15782, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 2.0834 - acc: 0.2395 - val_loss: 1.9505 - val_acc: 0.3251\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.15782 to 1.95048, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 1.8988 - acc: 0.3072 - val_loss: 1.8002 - val_acc: 0.3498\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.95048 to 1.80020, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 1.7599 - acc: 0.3855 - val_loss: 1.6689 - val_acc: 0.3992\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.80020 to 1.66892, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 1.6459 - acc: 0.4309 - val_loss: 1.5809 - val_acc: 0.4444\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.66892 to 1.58087, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 1.5603 - acc: 0.4829 - val_loss: 1.5047 - val_acc: 0.4856\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.58087 to 1.50467, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 1.4820 - acc: 0.5099 - val_loss: 1.4359 - val_acc: 0.5103\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.50467 to 1.43595, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 0s - loss: 1.4238 - acc: 0.5382 - val_loss: 1.3887 - val_acc: 0.5226\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.43595 to 1.38868, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 0s - loss: 1.3727 - acc: 0.5572 - val_loss: 1.3327 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.38868 to 1.33273, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 0s - loss: 1.3232 - acc: 0.5849 - val_loss: 1.2938 - val_acc: 0.5720\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.33273 to 1.29378, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 0s - loss: 1.2873 - acc: 0.5934 - val_loss: 1.2636 - val_acc: 0.5967\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.29378 to 1.26361, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 0s - loss: 1.2515 - acc: 0.6033 - val_loss: 1.2403 - val_acc: 0.6049\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.26361 to 1.24031, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 0s - loss: 1.2268 - acc: 0.6125 - val_loss: 1.2130 - val_acc: 0.6091\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.24031 to 1.21302, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 0s - loss: 1.2003 - acc: 0.6237 - val_loss: 1.1776 - val_acc: 0.6255\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.21302 to 1.17757, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 0s - loss: 1.1732 - acc: 0.6289 - val_loss: 1.1703 - val_acc: 0.6173\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.17757 to 1.17026, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 0s - loss: 1.1516 - acc: 0.6414 - val_loss: 1.1405 - val_acc: 0.6461\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.17026 to 1.14051, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 0s - loss: 1.1288 - acc: 0.6500 - val_loss: 1.1300 - val_acc: 0.6091\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.14051 to 1.13003, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/200\n",
      " - 0s - loss: 1.1101 - acc: 0.6638 - val_loss: 1.1100 - val_acc: 0.6502\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.13003 to 1.10996, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 0s - loss: 1.0923 - acc: 0.6691 - val_loss: 1.0845 - val_acc: 0.6543\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.10996 to 1.08446, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 0s - loss: 1.0743 - acc: 0.6645 - val_loss: 1.0764 - val_acc: 0.6626\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.08446 to 1.07636, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 21/200\n",
      " - 0s - loss: 1.0624 - acc: 0.6750 - val_loss: 1.0657 - val_acc: 0.6461\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.07636 to 1.06565, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 0s - loss: 1.0471 - acc: 0.6763 - val_loss: 1.0567 - val_acc: 0.6708\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.06565 to 1.05670, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 0s - loss: 1.0351 - acc: 0.6829 - val_loss: 1.0328 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.05670 to 1.03276, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 24/200\n",
      " - 0s - loss: 1.0210 - acc: 0.6829 - val_loss: 1.0335 - val_acc: 0.6502\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.03276\n",
      "Epoch 25/200\n",
      " - 0s - loss: 1.0080 - acc: 0.6829 - val_loss: 1.0090 - val_acc: 0.6626\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.03276 to 1.00903, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.9969 - acc: 0.6862 - val_loss: 0.9985 - val_acc: 0.6831\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.00903 to 0.99855, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.9875 - acc: 0.6961 - val_loss: 0.9921 - val_acc: 0.6626\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.99855 to 0.99210, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.9809 - acc: 0.6967 - val_loss: 0.9805 - val_acc: 0.6708\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.99210 to 0.98054, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.9642 - acc: 0.7046 - val_loss: 0.9860 - val_acc: 0.6749\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.98054\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.9564 - acc: 0.7000 - val_loss: 0.9526 - val_acc: 0.6831\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.98054 to 0.95260, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.9472 - acc: 0.7105 - val_loss: 0.9663 - val_acc: 0.6914\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.95260\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.9371 - acc: 0.7151 - val_loss: 0.9375 - val_acc: 0.6831\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.95260 to 0.93750, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.9298 - acc: 0.7125 - val_loss: 0.9377 - val_acc: 0.6790\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.93750\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.9194 - acc: 0.7204 - val_loss: 0.9241 - val_acc: 0.6955\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.93750 to 0.92409, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.9154 - acc: 0.7204 - val_loss: 0.9205 - val_acc: 0.6914\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.92409 to 0.92050, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.9069 - acc: 0.7224 - val_loss: 0.9153 - val_acc: 0.6831\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.92050 to 0.91528, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.8965 - acc: 0.7329 - val_loss: 0.9004 - val_acc: 0.7078\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.91528 to 0.90042, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.8904 - acc: 0.7309 - val_loss: 0.8992 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.90042 to 0.89920, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.8853 - acc: 0.7237 - val_loss: 0.8940 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.89920 to 0.89404, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.8765 - acc: 0.7336 - val_loss: 0.8888 - val_acc: 0.7119\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.89404 to 0.88884, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.8696 - acc: 0.7336 - val_loss: 0.8860 - val_acc: 0.7078\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.88884 to 0.88598, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.8617 - acc: 0.7421 - val_loss: 0.8658 - val_acc: 0.7160\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.88598 to 0.86580, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.8579 - acc: 0.7355 - val_loss: 0.8738 - val_acc: 0.7119\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.86580\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.8506 - acc: 0.7395 - val_loss: 0.8576 - val_acc: 0.7243\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.86580 to 0.85756, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.8446 - acc: 0.7461 - val_loss: 0.8521 - val_acc: 0.7325\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.85756 to 0.85211, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.8378 - acc: 0.7487 - val_loss: 0.8522 - val_acc: 0.7202\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.85211\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.8313 - acc: 0.7507 - val_loss: 0.8363 - val_acc: 0.7202\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.85211 to 0.83632, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.8278 - acc: 0.7454 - val_loss: 0.8471 - val_acc: 0.7202\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.83632\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.8200 - acc: 0.7526 - val_loss: 0.8267 - val_acc: 0.7407\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.83632 to 0.82674, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.8171 - acc: 0.7493 - val_loss: 0.8346 - val_acc: 0.7243\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.82674\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.8086 - acc: 0.7533 - val_loss: 0.8225 - val_acc: 0.7449\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.82674 to 0.82252, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.8080 - acc: 0.7592 - val_loss: 0.8222 - val_acc: 0.7284\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.82252 to 0.82224, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.8024 - acc: 0.7658 - val_loss: 0.8177 - val_acc: 0.7284\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.82224 to 0.81772, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.7974 - acc: 0.7539 - val_loss: 0.8132 - val_acc: 0.7407\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.81772 to 0.81323, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.7893 - acc: 0.7638 - val_loss: 0.8071 - val_acc: 0.7325\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.81323 to 0.80714, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.7872 - acc: 0.7645 - val_loss: 0.8013 - val_acc: 0.7407\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.80714 to 0.80129, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.7812 - acc: 0.7651 - val_loss: 0.8019 - val_acc: 0.7366\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.80129\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.7778 - acc: 0.7645 - val_loss: 0.7993 - val_acc: 0.7407\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.80129 to 0.79925, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.7714 - acc: 0.7691 - val_loss: 0.7828 - val_acc: 0.7407\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.79925 to 0.78282, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.7695 - acc: 0.7730 - val_loss: 0.7838 - val_acc: 0.7407\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.78282\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.7640 - acc: 0.7684 - val_loss: 0.7844 - val_acc: 0.7407\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.78282\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.7617 - acc: 0.7704 - val_loss: 0.7770 - val_acc: 0.7572\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.78282 to 0.77697, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.7548 - acc: 0.7763 - val_loss: 0.7836 - val_acc: 0.7325\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.77697\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.7529 - acc: 0.7789 - val_loss: 0.7708 - val_acc: 0.7572\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.77697 to 0.77080, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.7497 - acc: 0.7737 - val_loss: 0.7664 - val_acc: 0.7490\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.77080 to 0.76638, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.7431 - acc: 0.7822 - val_loss: 0.7605 - val_acc: 0.7613\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.76638 to 0.76050, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.7388 - acc: 0.7776 - val_loss: 0.7588 - val_acc: 0.7449\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.76050 to 0.75882, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.7354 - acc: 0.7862 - val_loss: 0.7649 - val_acc: 0.7490\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.75882\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.7311 - acc: 0.7822 - val_loss: 0.7430 - val_acc: 0.7654\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.75882 to 0.74304, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.7307 - acc: 0.7855 - val_loss: 0.7547 - val_acc: 0.7572\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.74304\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.7266 - acc: 0.7868 - val_loss: 0.7461 - val_acc: 0.7490\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.74304\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.7222 - acc: 0.7829 - val_loss: 0.7459 - val_acc: 0.7695\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.74304\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.7184 - acc: 0.7862 - val_loss: 0.7361 - val_acc: 0.7654\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.74304 to 0.73613, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.7154 - acc: 0.7842 - val_loss: 0.7346 - val_acc: 0.7613\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.73613 to 0.73462, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.7122 - acc: 0.7882 - val_loss: 0.7290 - val_acc: 0.7613\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.73462 to 0.72898, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.7090 - acc: 0.7895 - val_loss: 0.7229 - val_acc: 0.7654\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.72898 to 0.72289, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.7033 - acc: 0.7868 - val_loss: 0.7185 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.72289 to 0.71851, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.6999 - acc: 0.7921 - val_loss: 0.7116 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.71851 to 0.71159, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.6974 - acc: 0.7967 - val_loss: 0.7183 - val_acc: 0.7737\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.71159\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.6951 - acc: 0.7947 - val_loss: 0.7185 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.71159\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.6923 - acc: 0.7961 - val_loss: 0.7182 - val_acc: 0.7737\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.71159\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.6880 - acc: 0.7934 - val_loss: 0.7097 - val_acc: 0.7860\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.71159 to 0.70972, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.6864 - acc: 0.7980 - val_loss: 0.6995 - val_acc: 0.7695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00083: val_loss improved from 0.70972 to 0.69951, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.6825 - acc: 0.7941 - val_loss: 0.6941 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.69951 to 0.69406, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.6788 - acc: 0.8000 - val_loss: 0.6912 - val_acc: 0.7819\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.69406 to 0.69120, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.6765 - acc: 0.7993 - val_loss: 0.6935 - val_acc: 0.7819\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.69120\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.6733 - acc: 0.8013 - val_loss: 0.6856 - val_acc: 0.7860\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.69120 to 0.68558, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.6718 - acc: 0.8013 - val_loss: 0.7008 - val_acc: 0.7860\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.68558\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.6684 - acc: 0.7987 - val_loss: 0.6926 - val_acc: 0.7901\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.68558\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.6645 - acc: 0.8046 - val_loss: 0.6790 - val_acc: 0.7860\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.68558 to 0.67899, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.6630 - acc: 0.8079 - val_loss: 0.6700 - val_acc: 0.7901\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.67899 to 0.67000, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.6592 - acc: 0.8059 - val_loss: 0.6728 - val_acc: 0.7819\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.67000\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.6556 - acc: 0.8066 - val_loss: 0.6822 - val_acc: 0.7942\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.67000\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.6547 - acc: 0.8086 - val_loss: 0.6744 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.67000\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.6510 - acc: 0.8046 - val_loss: 0.6681 - val_acc: 0.7942\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.67000 to 0.66812, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.6476 - acc: 0.8079 - val_loss: 0.6577 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.66812 to 0.65769, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.6467 - acc: 0.8105 - val_loss: 0.6646 - val_acc: 0.7901\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.65769\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.6437 - acc: 0.8112 - val_loss: 0.6629 - val_acc: 0.7737\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.65769\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.6399 - acc: 0.8105 - val_loss: 0.6601 - val_acc: 0.7942\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.65769\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.6379 - acc: 0.8079 - val_loss: 0.6461 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.65769 to 0.64613, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.6359 - acc: 0.8164 - val_loss: 0.6509 - val_acc: 0.7901\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.64613\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.6326 - acc: 0.8105 - val_loss: 0.6527 - val_acc: 0.7901\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.64613\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.6319 - acc: 0.8092 - val_loss: 0.6442 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.64613 to 0.64422, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.6308 - acc: 0.8171 - val_loss: 0.6437 - val_acc: 0.7942\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.64422 to 0.64373, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.6267 - acc: 0.8158 - val_loss: 0.6432 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.64373 to 0.64319, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.6246 - acc: 0.8145 - val_loss: 0.6447 - val_acc: 0.8107\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.64319\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.6216 - acc: 0.8158 - val_loss: 0.6408 - val_acc: 0.7901\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.64319 to 0.64082, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.6188 - acc: 0.8151 - val_loss: 0.6393 - val_acc: 0.7942\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.64082 to 0.63926, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.6172 - acc: 0.8191 - val_loss: 0.6434 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.63926\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.6155 - acc: 0.8178 - val_loss: 0.6352 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.63926 to 0.63520, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.6120 - acc: 0.8145 - val_loss: 0.6348 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.63520 to 0.63475, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.6100 - acc: 0.8184 - val_loss: 0.6240 - val_acc: 0.8148\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.63475 to 0.62404, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.6082 - acc: 0.8217 - val_loss: 0.6294 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.62404\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.6051 - acc: 0.8237 - val_loss: 0.6225 - val_acc: 0.8107\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.62404 to 0.62249, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.6033 - acc: 0.8204 - val_loss: 0.6218 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.62249 to 0.62178, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.6002 - acc: 0.8257 - val_loss: 0.6354 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.62178\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.6005 - acc: 0.8237 - val_loss: 0.6241 - val_acc: 0.8148\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.62178\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.6001 - acc: 0.8230 - val_loss: 0.6111 - val_acc: 0.8148\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.62178 to 0.61106, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.5940 - acc: 0.8362 - val_loss: 0.6127 - val_acc: 0.8148\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.61106\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.5925 - acc: 0.8250 - val_loss: 0.6076 - val_acc: 0.8148\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.61106 to 0.60758, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.5911 - acc: 0.8224 - val_loss: 0.6057 - val_acc: 0.8148\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.60758 to 0.60575, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.5888 - acc: 0.8276 - val_loss: 0.6071 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.60575\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.5857 - acc: 0.8276 - val_loss: 0.6045 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.60575 to 0.60453, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.5856 - acc: 0.8309 - val_loss: 0.6028 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.60453 to 0.60279, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.5827 - acc: 0.8283 - val_loss: 0.6079 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.60279\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.5832 - acc: 0.8303 - val_loss: 0.5983 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.60279 to 0.59828, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.5786 - acc: 0.8316 - val_loss: 0.5924 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.59828 to 0.59238, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.5784 - acc: 0.8316 - val_loss: 0.5949 - val_acc: 0.8107\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.59238\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.5738 - acc: 0.8309 - val_loss: 0.5929 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.59238\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.5726 - acc: 0.8303 - val_loss: 0.5923 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.59238 to 0.59229, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.5704 - acc: 0.8362 - val_loss: 0.5869 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.59229 to 0.58686, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.5690 - acc: 0.8349 - val_loss: 0.5826 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.58686 to 0.58257, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.5680 - acc: 0.8296 - val_loss: 0.5881 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.58257\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.5655 - acc: 0.8368 - val_loss: 0.5835 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.58257\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.5630 - acc: 0.8388 - val_loss: 0.5791 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.58257 to 0.57913, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.5618 - acc: 0.8382 - val_loss: 0.5803 - val_acc: 0.8354\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.57913\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.5603 - acc: 0.8375 - val_loss: 0.5822 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.57913\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.5585 - acc: 0.8421 - val_loss: 0.5819 - val_acc: 0.8354\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.57913\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.5568 - acc: 0.8434 - val_loss: 0.5711 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.57913 to 0.57107, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.5536 - acc: 0.8388 - val_loss: 0.5728 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.57107\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.5511 - acc: 0.8414 - val_loss: 0.5727 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.57107\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.5505 - acc: 0.8428 - val_loss: 0.5661 - val_acc: 0.8354\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.57107 to 0.56607, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.5497 - acc: 0.8401 - val_loss: 0.5648 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.56607 to 0.56477, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.5474 - acc: 0.8434 - val_loss: 0.5665 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.56477\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.5459 - acc: 0.8434 - val_loss: 0.5656 - val_acc: 0.8354\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.56477\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.5448 - acc: 0.8408 - val_loss: 0.5653 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.56477\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.5429 - acc: 0.8480 - val_loss: 0.5622 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.56477 to 0.56225, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.5406 - acc: 0.8421 - val_loss: 0.5579 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.56225 to 0.55786, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.5392 - acc: 0.8500 - val_loss: 0.5519 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.55786 to 0.55189, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.5376 - acc: 0.8487 - val_loss: 0.5508 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.55189 to 0.55084, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.5373 - acc: 0.8487 - val_loss: 0.5566 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.55084\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.5336 - acc: 0.8507 - val_loss: 0.5527 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.55084\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.5328 - acc: 0.8461 - val_loss: 0.5457 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.55084 to 0.54574, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.5311 - acc: 0.8553 - val_loss: 0.5567 - val_acc: 0.8354\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.54574\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.5295 - acc: 0.8474 - val_loss: 0.5583 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.54574\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.5293 - acc: 0.8507 - val_loss: 0.5442 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.54574 to 0.54422, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.5257 - acc: 0.8572 - val_loss: 0.5446 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.54422\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.5241 - acc: 0.8572 - val_loss: 0.5351 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.54422 to 0.53511, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.5250 - acc: 0.8546 - val_loss: 0.5436 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.53511\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.5223 - acc: 0.8520 - val_loss: 0.5406 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.53511\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.5194 - acc: 0.8579 - val_loss: 0.5378 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.53511\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.5202 - acc: 0.8553 - val_loss: 0.5329 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.53511 to 0.53287, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.5161 - acc: 0.8559 - val_loss: 0.5290 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00163: val_loss improved from 0.53287 to 0.52897, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.5156 - acc: 0.8579 - val_loss: 0.5316 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.52897\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.5129 - acc: 0.8566 - val_loss: 0.5273 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.52897 to 0.52729, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.5121 - acc: 0.8572 - val_loss: 0.5282 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.52729\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.5114 - acc: 0.8572 - val_loss: 0.5264 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.52729 to 0.52639, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.5113 - acc: 0.8579 - val_loss: 0.5362 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.52639\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.5076 - acc: 0.8664 - val_loss: 0.5242 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.52639 to 0.52421, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.5072 - acc: 0.8599 - val_loss: 0.5279 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.52421\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.5053 - acc: 0.8625 - val_loss: 0.5164 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00171: val_loss improved from 0.52421 to 0.51637, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.5049 - acc: 0.8618 - val_loss: 0.5240 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.51637\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.5017 - acc: 0.8645 - val_loss: 0.5277 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.51637\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.5018 - acc: 0.8632 - val_loss: 0.5209 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.51637\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.5015 - acc: 0.8651 - val_loss: 0.5144 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00175: val_loss improved from 0.51637 to 0.51442, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.4981 - acc: 0.8638 - val_loss: 0.5136 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00176: val_loss improved from 0.51442 to 0.51357, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.4966 - acc: 0.8632 - val_loss: 0.5062 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00177: val_loss improved from 0.51357 to 0.50619, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.4959 - acc: 0.8664 - val_loss: 0.5109 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.50619\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.4952 - acc: 0.8632 - val_loss: 0.5193 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.50619\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.4933 - acc: 0.8671 - val_loss: 0.5156 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.50619\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.4915 - acc: 0.8645 - val_loss: 0.5056 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00181: val_loss improved from 0.50619 to 0.50562, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.4911 - acc: 0.8664 - val_loss: 0.5099 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.50562\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.4878 - acc: 0.8691 - val_loss: 0.5060 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.50562\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.4883 - acc: 0.8743 - val_loss: 0.5029 - val_acc: 0.8642\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00184: val_loss improved from 0.50562 to 0.50287, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.4864 - acc: 0.8658 - val_loss: 0.4990 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00185: val_loss improved from 0.50287 to 0.49901, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.4850 - acc: 0.8724 - val_loss: 0.5031 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.49901\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.4846 - acc: 0.8678 - val_loss: 0.5022 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.49901\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.4823 - acc: 0.8664 - val_loss: 0.5011 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.49901\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.4807 - acc: 0.8704 - val_loss: 0.4988 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.49901 to 0.49884, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.4801 - acc: 0.8711 - val_loss: 0.4994 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.49884\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.4800 - acc: 0.8730 - val_loss: 0.5020 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.49884\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.4769 - acc: 0.8757 - val_loss: 0.4937 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.49884 to 0.49372, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.4759 - acc: 0.8730 - val_loss: 0.5112 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.49372\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.4755 - acc: 0.8757 - val_loss: 0.4910 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00194: val_loss improved from 0.49372 to 0.49104, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.4734 - acc: 0.8750 - val_loss: 0.4916 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.49104\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.4719 - acc: 0.8770 - val_loss: 0.4937 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.49104\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.4707 - acc: 0.8770 - val_loss: 0.4851 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00197: val_loss improved from 0.49104 to 0.48515, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.4694 - acc: 0.8750 - val_loss: 0.4859 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.48515\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.4688 - acc: 0.8783 - val_loss: 0.4881 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.48515\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.4677 - acc: 0.8783 - val_loss: 0.4866 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.48515\n",
      "batch_size=160   optimizer=SGD\n",
      "Test accuracy: 66.2953%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 2.4701 - acc: 0.1211 - val_loss: 2.3162 - val_acc: 0.1523\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.31616, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 2.1801 - acc: 0.1921 - val_loss: 2.1394 - val_acc: 0.2181\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.31616 to 2.13940, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 2.0138 - acc: 0.2770 - val_loss: 1.9789 - val_acc: 0.2881\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.13940 to 1.97892, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 1.8758 - acc: 0.3461 - val_loss: 1.8600 - val_acc: 0.3251\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.97892 to 1.85996, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 1.7639 - acc: 0.3961 - val_loss: 1.7634 - val_acc: 0.3868\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.85996 to 1.76342, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 1.6739 - acc: 0.4355 - val_loss: 1.6798 - val_acc: 0.4156\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.76342 to 1.67977, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 1.5960 - acc: 0.4737 - val_loss: 1.6018 - val_acc: 0.4362\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.67977 to 1.60177, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 0s - loss: 1.5281 - acc: 0.5020 - val_loss: 1.5489 - val_acc: 0.4815\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.60177 to 1.54895, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 0s - loss: 1.4760 - acc: 0.5171 - val_loss: 1.5001 - val_acc: 0.5103\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.54895 to 1.50013, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 0s - loss: 1.4262 - acc: 0.5461 - val_loss: 1.4437 - val_acc: 0.5144\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.50013 to 1.44374, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 0s - loss: 1.3836 - acc: 0.5592 - val_loss: 1.4067 - val_acc: 0.5391\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.44374 to 1.40668, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 0s - loss: 1.3506 - acc: 0.5704 - val_loss: 1.3713 - val_acc: 0.5679\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.40668 to 1.37133, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 0s - loss: 1.3144 - acc: 0.5855 - val_loss: 1.3495 - val_acc: 0.5514\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.37133 to 1.34954, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 0s - loss: 1.2865 - acc: 0.5961 - val_loss: 1.3195 - val_acc: 0.5844\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.34954 to 1.31953, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 0s - loss: 1.2579 - acc: 0.6013 - val_loss: 1.2952 - val_acc: 0.5802\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.31953 to 1.29522, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 0s - loss: 1.2361 - acc: 0.6046 - val_loss: 1.2649 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.29522 to 1.26493, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 0s - loss: 1.2138 - acc: 0.6211 - val_loss: 1.2519 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.26493 to 1.25189, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/200\n",
      " - 0s - loss: 1.1914 - acc: 0.6316 - val_loss: 1.2304 - val_acc: 0.6132\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.25189 to 1.23041, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 0s - loss: 1.1700 - acc: 0.6401 - val_loss: 1.2046 - val_acc: 0.6091\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.23041 to 1.20458, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 0s - loss: 1.1556 - acc: 0.6395 - val_loss: 1.1961 - val_acc: 0.6132\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.20458 to 1.19612, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 21/200\n",
      " - 0s - loss: 1.1396 - acc: 0.6454 - val_loss: 1.1801 - val_acc: 0.6214\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.19612 to 1.18013, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 0s - loss: 1.1236 - acc: 0.6467 - val_loss: 1.1594 - val_acc: 0.6214\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.18013 to 1.15938, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 0s - loss: 1.1082 - acc: 0.6507 - val_loss: 1.1530 - val_acc: 0.6049\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.15938 to 1.15299, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 24/200\n",
      " - 0s - loss: 1.0951 - acc: 0.6572 - val_loss: 1.1284 - val_acc: 0.6255\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.15299 to 1.12843, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 25/200\n",
      " - 0s - loss: 1.0814 - acc: 0.6664 - val_loss: 1.1195 - val_acc: 0.6337\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.12843 to 1.11953, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 26/200\n",
      " - 0s - loss: 1.0699 - acc: 0.6664 - val_loss: 1.1063 - val_acc: 0.6461\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.11953 to 1.10635, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 27/200\n",
      " - 0s - loss: 1.0595 - acc: 0.6651 - val_loss: 1.0926 - val_acc: 0.6502\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.10635 to 1.09258, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 28/200\n",
      " - 0s - loss: 1.0470 - acc: 0.6664 - val_loss: 1.0842 - val_acc: 0.6379\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.09258 to 1.08420, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 29/200\n",
      " - 0s - loss: 1.0387 - acc: 0.6789 - val_loss: 1.0701 - val_acc: 0.6461\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.08420 to 1.07005, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 30/200\n",
      " - 0s - loss: 1.0269 - acc: 0.6789 - val_loss: 1.0577 - val_acc: 0.6543\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.07005 to 1.05766, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 31/200\n",
      " - 0s - loss: 1.0147 - acc: 0.6783 - val_loss: 1.0571 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.05766 to 1.05715, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 32/200\n",
      " - 0s - loss: 1.0077 - acc: 0.6862 - val_loss: 1.0437 - val_acc: 0.6708\n",
      "\n",
      "Epoch 00032: val_loss improved from 1.05715 to 1.04369, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.9971 - acc: 0.6901 - val_loss: 1.0359 - val_acc: 0.6584\n",
      "\n",
      "Epoch 00033: val_loss improved from 1.04369 to 1.03589, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.9906 - acc: 0.6934 - val_loss: 1.0312 - val_acc: 0.6831\n",
      "\n",
      "Epoch 00034: val_loss improved from 1.03589 to 1.03123, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.9799 - acc: 0.6934 - val_loss: 1.0135 - val_acc: 0.6749\n",
      "\n",
      "Epoch 00035: val_loss improved from 1.03123 to 1.01355, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.9706 - acc: 0.7033 - val_loss: 1.0100 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00036: val_loss improved from 1.01355 to 1.01005, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.9631 - acc: 0.7026 - val_loss: 1.0019 - val_acc: 0.6749\n",
      "\n",
      "Epoch 00037: val_loss improved from 1.01005 to 1.00189, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.9571 - acc: 0.7033 - val_loss: 1.0035 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.00189\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.9509 - acc: 0.7033 - val_loss: 0.9859 - val_acc: 0.6584\n",
      "\n",
      "Epoch 00039: val_loss improved from 1.00189 to 0.98588, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.9402 - acc: 0.7164 - val_loss: 0.9820 - val_acc: 0.6749\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.98588 to 0.98201, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.9342 - acc: 0.7138 - val_loss: 0.9723 - val_acc: 0.6790\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.98201 to 0.97232, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.9264 - acc: 0.7125 - val_loss: 0.9691 - val_acc: 0.6790\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.97232 to 0.96907, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.9244 - acc: 0.7197 - val_loss: 0.9550 - val_acc: 0.6831\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.96907 to 0.95497, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.9156 - acc: 0.7197 - val_loss: 0.9514 - val_acc: 0.6749\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.95497 to 0.95136, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.9088 - acc: 0.7243 - val_loss: 0.9478 - val_acc: 0.6872\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.95136 to 0.94779, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.9060 - acc: 0.7270 - val_loss: 0.9443 - val_acc: 0.6955\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.94779 to 0.94428, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.8980 - acc: 0.7257 - val_loss: 0.9406 - val_acc: 0.6872\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.94428 to 0.94060, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.8886 - acc: 0.7329 - val_loss: 0.9240 - val_acc: 0.6872\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.94060 to 0.92403, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.8856 - acc: 0.7283 - val_loss: 0.9228 - val_acc: 0.6831\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.92403 to 0.92282, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.8798 - acc: 0.7309 - val_loss: 0.9255 - val_acc: 0.6914\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.92282\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.8752 - acc: 0.7296 - val_loss: 0.9153 - val_acc: 0.6872\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.92282 to 0.91531, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.8692 - acc: 0.7349 - val_loss: 0.9047 - val_acc: 0.6872\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.91531 to 0.90466, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.8652 - acc: 0.7336 - val_loss: 0.9024 - val_acc: 0.6914\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.90466 to 0.90243, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.8595 - acc: 0.7342 - val_loss: 0.9008 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.90243 to 0.90077, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.8524 - acc: 0.7428 - val_loss: 0.8952 - val_acc: 0.7078\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.90077 to 0.89517, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.8499 - acc: 0.7395 - val_loss: 0.8948 - val_acc: 0.7119\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.89517 to 0.89477, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.8460 - acc: 0.7401 - val_loss: 0.8805 - val_acc: 0.7078\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.89477 to 0.88055, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.8405 - acc: 0.7388 - val_loss: 0.8746 - val_acc: 0.7119\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.88055 to 0.87462, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.8361 - acc: 0.7447 - val_loss: 0.8668 - val_acc: 0.6955\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.87462 to 0.86684, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.8326 - acc: 0.7500 - val_loss: 0.8647 - val_acc: 0.7078\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.86684 to 0.86469, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.8247 - acc: 0.7507 - val_loss: 0.8593 - val_acc: 0.7119\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.86469 to 0.85927, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.8204 - acc: 0.7520 - val_loss: 0.8602 - val_acc: 0.7243\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.85927\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.8184 - acc: 0.7500 - val_loss: 0.8581 - val_acc: 0.7243\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.85927 to 0.85807, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.8128 - acc: 0.7487 - val_loss: 0.8481 - val_acc: 0.7078\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.85807 to 0.84814, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.8098 - acc: 0.7539 - val_loss: 0.8439 - val_acc: 0.7284\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.84814 to 0.84387, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.8065 - acc: 0.7533 - val_loss: 0.8467 - val_acc: 0.7243\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.84387\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.8045 - acc: 0.7546 - val_loss: 0.8369 - val_acc: 0.7160\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.84387 to 0.83689, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.7977 - acc: 0.7500 - val_loss: 0.8354 - val_acc: 0.7325\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.83689 to 0.83539, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.7953 - acc: 0.7572 - val_loss: 0.8275 - val_acc: 0.7160\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.83539 to 0.82748, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.7905 - acc: 0.7566 - val_loss: 0.8221 - val_acc: 0.7243\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.82748 to 0.82206, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.7858 - acc: 0.7605 - val_loss: 0.8186 - val_acc: 0.7202\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.82206 to 0.81861, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.7830 - acc: 0.7559 - val_loss: 0.8227 - val_acc: 0.7325\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.81861\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.7782 - acc: 0.7651 - val_loss: 0.8142 - val_acc: 0.7243\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.81861 to 0.81420, saving model to weights.best.Resnet50.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/200\n",
      " - 0s - loss: 0.7754 - acc: 0.7599 - val_loss: 0.8109 - val_acc: 0.7243\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.81420 to 0.81088, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.7713 - acc: 0.7592 - val_loss: 0.8071 - val_acc: 0.7243\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.81088 to 0.80711, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.7685 - acc: 0.7645 - val_loss: 0.8047 - val_acc: 0.7449\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.80711 to 0.80474, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.7651 - acc: 0.7612 - val_loss: 0.8031 - val_acc: 0.7284\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.80474 to 0.80306, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.7612 - acc: 0.7645 - val_loss: 0.7995 - val_acc: 0.7366\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.80306 to 0.79954, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.7580 - acc: 0.7658 - val_loss: 0.7946 - val_acc: 0.7325\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.79954 to 0.79465, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.7538 - acc: 0.7678 - val_loss: 0.8016 - val_acc: 0.7449\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.79465\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.7522 - acc: 0.7724 - val_loss: 0.7866 - val_acc: 0.7366\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.79465 to 0.78657, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.7472 - acc: 0.7717 - val_loss: 0.7907 - val_acc: 0.7490\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.78657\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.7464 - acc: 0.7770 - val_loss: 0.7792 - val_acc: 0.7366\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.78657 to 0.77917, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.7436 - acc: 0.7704 - val_loss: 0.7768 - val_acc: 0.7449\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.77917 to 0.77678, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.7380 - acc: 0.7730 - val_loss: 0.7788 - val_acc: 0.7449\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.77678\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.7368 - acc: 0.7789 - val_loss: 0.7793 - val_acc: 0.7407\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.77678\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.7350 - acc: 0.7757 - val_loss: 0.7686 - val_acc: 0.7531\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.77678 to 0.76862, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.7316 - acc: 0.7724 - val_loss: 0.7663 - val_acc: 0.7572\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.76862 to 0.76632, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.7261 - acc: 0.7776 - val_loss: 0.7751 - val_acc: 0.7407\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.76632\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.7237 - acc: 0.7796 - val_loss: 0.7616 - val_acc: 0.7449\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.76632 to 0.76165, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.7223 - acc: 0.7789 - val_loss: 0.7607 - val_acc: 0.7490\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.76165 to 0.76069, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.7210 - acc: 0.7829 - val_loss: 0.7552 - val_acc: 0.7654\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.76069 to 0.75520, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.7173 - acc: 0.7868 - val_loss: 0.7647 - val_acc: 0.7490\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.75520\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.7159 - acc: 0.7829 - val_loss: 0.7491 - val_acc: 0.7407\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.75520 to 0.74911, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.7108 - acc: 0.7862 - val_loss: 0.7496 - val_acc: 0.7531\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.74911\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.7090 - acc: 0.7862 - val_loss: 0.7483 - val_acc: 0.7490\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.74911 to 0.74834, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.7052 - acc: 0.7868 - val_loss: 0.7420 - val_acc: 0.7613\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.74834 to 0.74202, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.7038 - acc: 0.7895 - val_loss: 0.7367 - val_acc: 0.7572\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.74202 to 0.73673, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.7000 - acc: 0.7875 - val_loss: 0.7414 - val_acc: 0.7572\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.73673\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.6989 - acc: 0.7829 - val_loss: 0.7360 - val_acc: 0.7490\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.73673 to 0.73597, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.6936 - acc: 0.7934 - val_loss: 0.7365 - val_acc: 0.7531\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.73597\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.6945 - acc: 0.7888 - val_loss: 0.7298 - val_acc: 0.7613\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.73597 to 0.72982, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.6889 - acc: 0.7914 - val_loss: 0.7321 - val_acc: 0.7695\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.72982\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.6874 - acc: 0.7954 - val_loss: 0.7253 - val_acc: 0.7695\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.72982 to 0.72529, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.6855 - acc: 0.7921 - val_loss: 0.7210 - val_acc: 0.7531\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.72529 to 0.72101, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.6825 - acc: 0.7921 - val_loss: 0.7201 - val_acc: 0.7654\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.72101 to 0.72012, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.6810 - acc: 0.7987 - val_loss: 0.7141 - val_acc: 0.7695\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.72012 to 0.71411, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.6802 - acc: 0.7928 - val_loss: 0.7089 - val_acc: 0.7737\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.71411 to 0.70888, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.6747 - acc: 0.8026 - val_loss: 0.7112 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.70888\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.6720 - acc: 0.8026 - val_loss: 0.7079 - val_acc: 0.7695\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.70888 to 0.70785, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.6715 - acc: 0.7974 - val_loss: 0.7102 - val_acc: 0.7654\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.70785\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.6695 - acc: 0.8026 - val_loss: 0.7038 - val_acc: 0.7695\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.70785 to 0.70381, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.6670 - acc: 0.7993 - val_loss: 0.7056 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.70381\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.6640 - acc: 0.8033 - val_loss: 0.6979 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.70381 to 0.69787, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.6624 - acc: 0.8007 - val_loss: 0.6982 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.69787\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.6605 - acc: 0.7980 - val_loss: 0.6901 - val_acc: 0.7860\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.69787 to 0.69011, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.6568 - acc: 0.8033 - val_loss: 0.6895 - val_acc: 0.7695\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.69011 to 0.68954, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.6565 - acc: 0.8026 - val_loss: 0.6927 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.68954\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.6527 - acc: 0.8099 - val_loss: 0.6848 - val_acc: 0.7737\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.68954 to 0.68479, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.6509 - acc: 0.8072 - val_loss: 0.6830 - val_acc: 0.7737\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.68479 to 0.68296, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.6484 - acc: 0.8086 - val_loss: 0.6819 - val_acc: 0.7901\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.68296 to 0.68189, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.6483 - acc: 0.8066 - val_loss: 0.6788 - val_acc: 0.7860\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.68189 to 0.67880, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.6467 - acc: 0.8046 - val_loss: 0.6814 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.67880\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.6437 - acc: 0.8092 - val_loss: 0.6810 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.67880\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.6417 - acc: 0.8112 - val_loss: 0.6740 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.67880 to 0.67396, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.6385 - acc: 0.8151 - val_loss: 0.6727 - val_acc: 0.7819\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.67396 to 0.67273, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.6375 - acc: 0.8145 - val_loss: 0.6687 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.67273 to 0.66872, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.6363 - acc: 0.8125 - val_loss: 0.6652 - val_acc: 0.7942\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.66872 to 0.66517, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.6323 - acc: 0.8138 - val_loss: 0.6723 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.66517\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.6324 - acc: 0.8099 - val_loss: 0.6659 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.66517\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.6290 - acc: 0.8197 - val_loss: 0.6610 - val_acc: 0.7942\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.66517 to 0.66103, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.6275 - acc: 0.8151 - val_loss: 0.6599 - val_acc: 0.7860\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.66103 to 0.65986, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.6262 - acc: 0.8178 - val_loss: 0.6603 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.65986\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.6241 - acc: 0.8171 - val_loss: 0.6508 - val_acc: 0.7901\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.65986 to 0.65079, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.6232 - acc: 0.8164 - val_loss: 0.6562 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.65079\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.6189 - acc: 0.8171 - val_loss: 0.6578 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.65079\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.6177 - acc: 0.8211 - val_loss: 0.6622 - val_acc: 0.8107\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.65079\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.6167 - acc: 0.8217 - val_loss: 0.6505 - val_acc: 0.8107\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.65079 to 0.65052, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.6145 - acc: 0.8237 - val_loss: 0.6515 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.65052\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.6127 - acc: 0.8217 - val_loss: 0.6404 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.65052 to 0.64035, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.6104 - acc: 0.8250 - val_loss: 0.6490 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.64035\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.6097 - acc: 0.8230 - val_loss: 0.6426 - val_acc: 0.8148\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.64035\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.6072 - acc: 0.8296 - val_loss: 0.6436 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.64035\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.6061 - acc: 0.8276 - val_loss: 0.6431 - val_acc: 0.8148\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.64035\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.6045 - acc: 0.8276 - val_loss: 0.6371 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.64035 to 0.63708, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.6021 - acc: 0.8257 - val_loss: 0.6367 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.63708 to 0.63666, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.6003 - acc: 0.8303 - val_loss: 0.6389 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.63666\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.5983 - acc: 0.8289 - val_loss: 0.6332 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.63666 to 0.63316, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.5961 - acc: 0.8243 - val_loss: 0.6335 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.63316\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.5960 - acc: 0.8283 - val_loss: 0.6283 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.63316 to 0.62832, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.5939 - acc: 0.8283 - val_loss: 0.6319 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.62832\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.5921 - acc: 0.8283 - val_loss: 0.6247 - val_acc: 0.8107\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.62832 to 0.62466, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.5912 - acc: 0.8322 - val_loss: 0.6239 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.62466 to 0.62391, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.5898 - acc: 0.8329 - val_loss: 0.6212 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.62391 to 0.62116, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.5877 - acc: 0.8336 - val_loss: 0.6239 - val_acc: 0.8148\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.62116\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.5864 - acc: 0.8342 - val_loss: 0.6214 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.62116\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.5846 - acc: 0.8329 - val_loss: 0.6172 - val_acc: 0.8148\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.62116 to 0.61722, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.5824 - acc: 0.8349 - val_loss: 0.6182 - val_acc: 0.8148\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.61722\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.5805 - acc: 0.8336 - val_loss: 0.6157 - val_acc: 0.8107\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.61722 to 0.61572, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.5803 - acc: 0.8336 - val_loss: 0.6107 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.61572 to 0.61074, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.5781 - acc: 0.8349 - val_loss: 0.6138 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.61074\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.5757 - acc: 0.8362 - val_loss: 0.6134 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.61074\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.5747 - acc: 0.8375 - val_loss: 0.6066 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00163: val_loss improved from 0.61074 to 0.60657, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.5727 - acc: 0.8401 - val_loss: 0.6028 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.60657 to 0.60283, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.5709 - acc: 0.8375 - val_loss: 0.6059 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.60283\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.5703 - acc: 0.8336 - val_loss: 0.6027 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00166: val_loss improved from 0.60283 to 0.60272, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.5695 - acc: 0.8395 - val_loss: 0.6010 - val_acc: 0.8148\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.60272 to 0.60101, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.5670 - acc: 0.8388 - val_loss: 0.5988 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.60101 to 0.59878, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.5647 - acc: 0.8434 - val_loss: 0.5998 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.59878\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.5645 - acc: 0.8414 - val_loss: 0.5960 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.59878 to 0.59605, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.5616 - acc: 0.8421 - val_loss: 0.5935 - val_acc: 0.8313\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00171: val_loss improved from 0.59605 to 0.59351, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.5615 - acc: 0.8388 - val_loss: 0.5936 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.59351\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.5595 - acc: 0.8447 - val_loss: 0.5887 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.59351 to 0.58875, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.5591 - acc: 0.8414 - val_loss: 0.5894 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.58875\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.5566 - acc: 0.8447 - val_loss: 0.5897 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.58875\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.5560 - acc: 0.8414 - val_loss: 0.5876 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00176: val_loss improved from 0.58875 to 0.58757, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.5536 - acc: 0.8441 - val_loss: 0.5808 - val_acc: 0.8148\n",
      "\n",
      "Epoch 00177: val_loss improved from 0.58757 to 0.58076, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.5530 - acc: 0.8421 - val_loss: 0.5830 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.58076\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.5527 - acc: 0.8434 - val_loss: 0.5832 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.58076\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.5500 - acc: 0.8408 - val_loss: 0.5810 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.58076\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.5485 - acc: 0.8461 - val_loss: 0.5792 - val_acc: 0.8354\n",
      "\n",
      "Epoch 00181: val_loss improved from 0.58076 to 0.57923, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.5470 - acc: 0.8461 - val_loss: 0.5780 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00182: val_loss improved from 0.57923 to 0.57798, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.5462 - acc: 0.8461 - val_loss: 0.5794 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.57798\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.5436 - acc: 0.8421 - val_loss: 0.5787 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.57798\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.5415 - acc: 0.8461 - val_loss: 0.5792 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.57798\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.5435 - acc: 0.8428 - val_loss: 0.5773 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.57798 to 0.57729, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.5406 - acc: 0.8434 - val_loss: 0.5710 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.57729 to 0.57098, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.5394 - acc: 0.8454 - val_loss: 0.5712 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.57098\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.5377 - acc: 0.8467 - val_loss: 0.5686 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.57098 to 0.56863, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.5355 - acc: 0.8474 - val_loss: 0.5663 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00190: val_loss improved from 0.56863 to 0.56630, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.5357 - acc: 0.8500 - val_loss: 0.5690 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.56630\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.5337 - acc: 0.8461 - val_loss: 0.5633 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.56630 to 0.56327, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.5319 - acc: 0.8493 - val_loss: 0.5613 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00193: val_loss improved from 0.56327 to 0.56132, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.5323 - acc: 0.8487 - val_loss: 0.5671 - val_acc: 0.8354\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.56132\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.5297 - acc: 0.8533 - val_loss: 0.5604 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00195: val_loss improved from 0.56132 to 0.56043, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.5294 - acc: 0.8500 - val_loss: 0.5604 - val_acc: 0.8354\n",
      "\n",
      "Epoch 00196: val_loss improved from 0.56043 to 0.56041, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.5274 - acc: 0.8520 - val_loss: 0.5570 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00197: val_loss improved from 0.56041 to 0.55703, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.5273 - acc: 0.8546 - val_loss: 0.5562 - val_acc: 0.8354\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.55703 to 0.55622, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.5250 - acc: 0.8533 - val_loss: 0.5572 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.55622\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.5238 - acc: 0.8480 - val_loss: 0.5571 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.55622\n",
      "batch_size=200   optimizer=SGD\n",
      "Test accuracy: 66.0167%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 1.6993 - acc: 0.4138 - val_loss: 1.1173 - val_acc: 0.6337\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.11727, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 1s - loss: 1.0974 - acc: 0.6184 - val_loss: 1.0863 - val_acc: 0.6091\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.11727 to 1.08626, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 1s - loss: 0.9118 - acc: 0.6888 - val_loss: 0.7643 - val_acc: 0.7613\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.08626 to 0.76432, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 1s - loss: 0.7751 - acc: 0.7362 - val_loss: 0.7064 - val_acc: 0.7490\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.76432 to 0.70635, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 1s - loss: 0.6847 - acc: 0.7651 - val_loss: 0.6703 - val_acc: 0.7490\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.70635 to 0.67032, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 1s - loss: 0.6198 - acc: 0.7987 - val_loss: 0.6110 - val_acc: 0.7531\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.67032 to 0.61101, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 1s - loss: 0.5522 - acc: 0.8132 - val_loss: 0.4954 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.61101 to 0.49536, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 1s - loss: 0.5009 - acc: 0.8474 - val_loss: 0.4092 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.49536 to 0.40915, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 1s - loss: 0.4536 - acc: 0.8579 - val_loss: 0.4102 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.40915\n",
      "Epoch 10/200\n",
      " - 1s - loss: 0.4232 - acc: 0.8691 - val_loss: 0.4268 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.40915\n",
      "Epoch 11/200\n",
      " - 1s - loss: 0.3832 - acc: 0.8829 - val_loss: 0.4275 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.40915\n",
      "Epoch 12/200\n",
      " - 1s - loss: 0.3448 - acc: 0.9059 - val_loss: 0.3293 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.40915 to 0.32932, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 1s - loss: 0.3232 - acc: 0.9066 - val_loss: 0.2861 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.32932 to 0.28610, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 1s - loss: 0.3009 - acc: 0.9217 - val_loss: 0.2668 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.28610 to 0.26676, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 1s - loss: 0.2763 - acc: 0.9382 - val_loss: 0.2464 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.26676 to 0.24641, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 1s - loss: 0.2537 - acc: 0.9342 - val_loss: 0.3093 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.24641\n",
      "Epoch 17/200\n",
      " - 1s - loss: 0.2396 - acc: 0.9408 - val_loss: 0.2216 - val_acc: 0.9671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00017: val_loss improved from 0.24641 to 0.22162, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/200\n",
      " - 1s - loss: 0.2138 - acc: 0.9572 - val_loss: 0.2109 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.22162 to 0.21090, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 1s - loss: 0.2019 - acc: 0.9612 - val_loss: 0.1717 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.21090 to 0.17169, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 1s - loss: 0.1866 - acc: 0.9618 - val_loss: 0.1732 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.17169\n",
      "Epoch 21/200\n",
      " - 1s - loss: 0.1708 - acc: 0.9697 - val_loss: 0.1682 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.17169 to 0.16819, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 1s - loss: 0.1610 - acc: 0.9724 - val_loss: 0.1535 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.16819 to 0.15353, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 1s - loss: 0.1483 - acc: 0.9763 - val_loss: 0.1467 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.15353 to 0.14668, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 24/200\n",
      " - 1s - loss: 0.1388 - acc: 0.9757 - val_loss: 0.1276 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.14668 to 0.12759, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 25/200\n",
      " - 1s - loss: 0.1266 - acc: 0.9829 - val_loss: 0.1264 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.12759 to 0.12644, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 26/200\n",
      " - 1s - loss: 0.1196 - acc: 0.9783 - val_loss: 0.1013 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.12644 to 0.10127, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 27/200\n",
      " - 1s - loss: 0.1092 - acc: 0.9842 - val_loss: 0.1212 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.10127\n",
      "Epoch 28/200\n",
      " - 1s - loss: 0.1024 - acc: 0.9862 - val_loss: 0.0978 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.10127 to 0.09778, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 29/200\n",
      " - 1s - loss: 0.0959 - acc: 0.9836 - val_loss: 0.1029 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.09778\n",
      "Epoch 30/200\n",
      " - 1s - loss: 0.0884 - acc: 0.9882 - val_loss: 0.0973 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.09778 to 0.09729, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 31/200\n",
      " - 1s - loss: 0.0836 - acc: 0.9875 - val_loss: 0.0806 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.09729 to 0.08058, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 32/200\n",
      " - 1s - loss: 0.0782 - acc: 0.9901 - val_loss: 0.0868 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.08058\n",
      "Epoch 33/200\n",
      " - 1s - loss: 0.0725 - acc: 0.9914 - val_loss: 0.0801 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.08058 to 0.08010, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 34/200\n",
      " - 1s - loss: 0.0669 - acc: 0.9934 - val_loss: 0.0869 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.08010\n",
      "Epoch 35/200\n",
      " - 1s - loss: 0.0646 - acc: 0.9921 - val_loss: 0.0663 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.08010 to 0.06627, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 36/200\n",
      " - 1s - loss: 0.0586 - acc: 0.9928 - val_loss: 0.0629 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.06627 to 0.06286, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 37/200\n",
      " - 1s - loss: 0.0567 - acc: 0.9954 - val_loss: 0.0594 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.06286 to 0.05943, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 38/200\n",
      " - 1s - loss: 0.0474 - acc: 0.9974 - val_loss: 0.0681 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.05943\n",
      "Epoch 39/200\n",
      " - 1s - loss: 0.0494 - acc: 0.9934 - val_loss: 0.0560 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.05943 to 0.05600, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 40/200\n",
      " - 1s - loss: 0.0444 - acc: 0.9967 - val_loss: 0.0544 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.05600 to 0.05436, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 41/200\n",
      " - 1s - loss: 0.0421 - acc: 0.9954 - val_loss: 0.0604 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.05436\n",
      "Epoch 42/200\n",
      " - 1s - loss: 0.0381 - acc: 0.9961 - val_loss: 0.0693 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.05436\n",
      "Epoch 43/200\n",
      " - 1s - loss: 0.0374 - acc: 0.9961 - val_loss: 0.0594 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.05436\n",
      "Epoch 44/200\n",
      " - 1s - loss: 0.0354 - acc: 0.9967 - val_loss: 0.0507 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.05436 to 0.05067, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 45/200\n",
      " - 1s - loss: 0.0317 - acc: 0.9980 - val_loss: 0.0514 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.05067\n",
      "Epoch 46/200\n",
      " - 1s - loss: 0.0307 - acc: 0.9967 - val_loss: 0.0398 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.05067 to 0.03982, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 47/200\n",
      " - 1s - loss: 0.0286 - acc: 0.9954 - val_loss: 0.0615 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.03982\n",
      "Epoch 48/200\n",
      " - 1s - loss: 0.0279 - acc: 0.9974 - val_loss: 0.0574 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.03982\n",
      "Epoch 49/200\n",
      " - 1s - loss: 0.0267 - acc: 0.9954 - val_loss: 0.0409 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.03982\n",
      "Epoch 50/200\n",
      " - 1s - loss: 0.0246 - acc: 0.9974 - val_loss: 0.0449 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.03982\n",
      "Epoch 51/200\n",
      " - 1s - loss: 0.0243 - acc: 0.9954 - val_loss: 0.0369 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.03982 to 0.03690, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 52/200\n",
      " - 1s - loss: 0.0226 - acc: 0.9954 - val_loss: 0.0374 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.03690\n",
      "Epoch 53/200\n",
      " - 1s - loss: 0.0220 - acc: 0.9967 - val_loss: 0.0387 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.03690\n",
      "Epoch 54/200\n",
      " - 1s - loss: 0.0213 - acc: 0.9967 - val_loss: 0.0490 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.03690\n",
      "Epoch 55/200\n",
      " - 1s - loss: 0.0209 - acc: 0.9974 - val_loss: 0.0367 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.03690 to 0.03669, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 56/200\n",
      " - 1s - loss: 0.0187 - acc: 0.9961 - val_loss: 0.0660 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.03669\n",
      "Epoch 57/200\n",
      " - 1s - loss: 0.0182 - acc: 0.9967 - val_loss: 0.0505 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.03669\n",
      "Epoch 58/200\n",
      " - 1s - loss: 0.0178 - acc: 0.9967 - val_loss: 0.0393 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.03669\n",
      "Epoch 59/200\n",
      " - 1s - loss: 0.0155 - acc: 0.9974 - val_loss: 0.0337 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.03669 to 0.03372, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 60/200\n",
      " - 1s - loss: 0.0152 - acc: 0.9974 - val_loss: 0.0362 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.03372\n",
      "Epoch 61/200\n",
      " - 1s - loss: 0.0141 - acc: 0.9974 - val_loss: 0.0410 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.03372\n",
      "Epoch 62/200\n",
      " - 1s - loss: 0.0144 - acc: 0.9961 - val_loss: 0.0391 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.03372\n",
      "Epoch 63/200\n",
      " - 1s - loss: 0.0146 - acc: 0.9974 - val_loss: 0.0421 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.03372\n",
      "Epoch 64/200\n",
      " - 1s - loss: 0.0131 - acc: 0.9980 - val_loss: 0.0282 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.03372 to 0.02823, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 65/200\n",
      " - 1s - loss: 0.0123 - acc: 0.9967 - val_loss: 0.0348 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.02823\n",
      "Epoch 66/200\n",
      " - 1s - loss: 0.0121 - acc: 0.9974 - val_loss: 0.0284 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.02823\n",
      "Epoch 67/200\n",
      " - 1s - loss: 0.0116 - acc: 0.9967 - val_loss: 0.0366 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.02823\n",
      "Epoch 68/200\n",
      " - 1s - loss: 0.0112 - acc: 0.9967 - val_loss: 0.0229 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.02823 to 0.02287, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 69/200\n",
      " - 1s - loss: 0.0117 - acc: 0.9967 - val_loss: 0.0275 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.02287\n",
      "Epoch 70/200\n",
      " - 1s - loss: 0.0117 - acc: 0.9961 - val_loss: 0.0269 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.02287\n",
      "Epoch 71/200\n",
      " - 1s - loss: 0.0109 - acc: 0.9980 - val_loss: 0.0304 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.02287\n",
      "Epoch 72/200\n",
      " - 1s - loss: 0.0107 - acc: 0.9980 - val_loss: 0.0283 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.02287\n",
      "Epoch 73/200\n",
      " - 1s - loss: 0.0105 - acc: 0.9974 - val_loss: 0.0272 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.02287\n",
      "Epoch 74/200\n",
      " - 1s - loss: 0.0094 - acc: 0.9974 - val_loss: 0.0282 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.02287\n",
      "Epoch 75/200\n",
      " - 1s - loss: 0.0099 - acc: 0.9974 - val_loss: 0.0206 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.02287 to 0.02062, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 76/200\n",
      " - 1s - loss: 0.0091 - acc: 0.9980 - val_loss: 0.0292 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.02062\n",
      "Epoch 77/200\n",
      " - 1s - loss: 0.0080 - acc: 0.9974 - val_loss: 0.0326 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.02062\n",
      "Epoch 78/200\n",
      " - 1s - loss: 0.0085 - acc: 0.9974 - val_loss: 0.0342 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.02062\n",
      "Epoch 79/200\n",
      " - 1s - loss: 0.0087 - acc: 0.9967 - val_loss: 0.0191 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.02062 to 0.01912, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 80/200\n",
      " - 1s - loss: 0.0080 - acc: 0.9974 - val_loss: 0.0382 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.01912\n",
      "Epoch 81/200\n",
      " - 1s - loss: 0.0076 - acc: 0.9980 - val_loss: 0.0419 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.01912\n",
      "Epoch 82/200\n",
      " - 1s - loss: 0.0083 - acc: 0.9974 - val_loss: 0.0452 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.01912\n",
      "Epoch 83/200\n",
      " - 1s - loss: 0.0084 - acc: 0.9961 - val_loss: 0.0258 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.01912\n",
      "Epoch 84/200\n",
      " - 1s - loss: 0.0076 - acc: 0.9980 - val_loss: 0.0203 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.01912\n",
      "Epoch 85/200\n",
      " - 1s - loss: 0.0083 - acc: 0.9980 - val_loss: 0.0399 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.01912\n",
      "Epoch 86/200\n",
      " - 1s - loss: 0.0075 - acc: 0.9967 - val_loss: 0.0168 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.01912 to 0.01676, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 87/200\n",
      " - 1s - loss: 0.0081 - acc: 0.9961 - val_loss: 0.0281 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.01676\n",
      "Epoch 88/200\n",
      " - 1s - loss: 0.0081 - acc: 0.9974 - val_loss: 0.0289 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.01676\n",
      "Epoch 89/200\n",
      " - 1s - loss: 0.0078 - acc: 0.9974 - val_loss: 0.0408 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.01676\n",
      "Epoch 90/200\n",
      " - 1s - loss: 0.0067 - acc: 0.9974 - val_loss: 0.0263 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.01676\n",
      "Epoch 91/200\n",
      " - 1s - loss: 0.0076 - acc: 0.9974 - val_loss: 0.0256 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.01676\n",
      "Epoch 92/200\n",
      " - 1s - loss: 0.0077 - acc: 0.9967 - val_loss: 0.0281 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.01676\n",
      "Epoch 93/200\n",
      " - 1s - loss: 0.0070 - acc: 0.9967 - val_loss: 0.0313 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.01676\n",
      "Epoch 94/200\n",
      " - 1s - loss: 0.0078 - acc: 0.9967 - val_loss: 0.0489 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.01676\n",
      "Epoch 95/200\n",
      " - 1s - loss: 0.0082 - acc: 0.9967 - val_loss: 0.0354 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.01676\n",
      "Epoch 96/200\n",
      " - 1s - loss: 0.0070 - acc: 0.9974 - val_loss: 0.0214 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.01676\n",
      "Epoch 97/200\n",
      " - 1s - loss: 0.0077 - acc: 0.9980 - val_loss: 0.0182 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.01676\n",
      "Epoch 98/200\n",
      " - 1s - loss: 0.0074 - acc: 0.9967 - val_loss: 0.0266 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.01676\n",
      "Epoch 99/200\n",
      " - 1s - loss: 0.0070 - acc: 0.9974 - val_loss: 0.0168 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.01676\n",
      "Epoch 100/200\n",
      " - 1s - loss: 0.0058 - acc: 0.9967 - val_loss: 0.0324 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.01676\n",
      "Epoch 101/200\n",
      " - 1s - loss: 0.0078 - acc: 0.9974 - val_loss: 0.0193 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.01676\n",
      "Epoch 102/200\n",
      " - 1s - loss: 0.0054 - acc: 0.9974 - val_loss: 0.0131 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.01676 to 0.01315, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 103/200\n",
      " - 1s - loss: 0.0055 - acc: 0.9980 - val_loss: 0.0315 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.01315\n",
      "Epoch 104/200\n",
      " - 1s - loss: 0.0054 - acc: 0.9980 - val_loss: 0.0399 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.01315\n",
      "Epoch 105/200\n",
      " - 1s - loss: 0.0070 - acc: 0.9967 - val_loss: 0.0242 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.01315\n",
      "Epoch 106/200\n",
      " - 1s - loss: 0.0074 - acc: 0.9961 - val_loss: 0.0377 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.01315\n",
      "Epoch 107/200\n",
      " - 1s - loss: 0.0056 - acc: 0.9980 - val_loss: 0.0312 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.01315\n",
      "Epoch 108/200\n",
      " - 1s - loss: 0.0073 - acc: 0.9980 - val_loss: 0.0304 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.01315\n",
      "Epoch 109/200\n",
      " - 1s - loss: 0.0062 - acc: 0.9974 - val_loss: 0.0184 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.01315\n",
      "Epoch 110/200\n",
      " - 1s - loss: 0.0065 - acc: 0.9974 - val_loss: 0.0242 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.01315\n",
      "Epoch 111/200\n",
      " - 1s - loss: 0.0066 - acc: 0.9967 - val_loss: 0.0343 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.01315\n",
      "Epoch 112/200\n",
      " - 1s - loss: 0.0063 - acc: 0.9974 - val_loss: 0.0258 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.01315\n",
      "Epoch 113/200\n",
      " - 1s - loss: 0.0070 - acc: 0.9961 - val_loss: 0.0320 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.01315\n",
      "Epoch 114/200\n",
      " - 1s - loss: 0.0066 - acc: 0.9974 - val_loss: 0.0291 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.01315\n",
      "Epoch 115/200\n",
      " - 1s - loss: 0.0057 - acc: 0.9974 - val_loss: 0.0315 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.01315\n",
      "Epoch 116/200\n",
      " - 1s - loss: 0.0068 - acc: 0.9961 - val_loss: 0.0228 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.01315\n",
      "Epoch 117/200\n",
      " - 1s - loss: 0.0063 - acc: 0.9974 - val_loss: 0.0195 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.01315\n",
      "Epoch 118/200\n",
      " - 1s - loss: 0.0050 - acc: 0.9974 - val_loss: 0.0244 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.01315\n",
      "Epoch 119/200\n",
      " - 1s - loss: 0.0056 - acc: 0.9967 - val_loss: 0.0321 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.01315\n",
      "Epoch 120/200\n",
      " - 1s - loss: 0.0060 - acc: 0.9974 - val_loss: 0.0469 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.01315\n",
      "Epoch 121/200\n",
      " - 1s - loss: 0.0058 - acc: 0.9974 - val_loss: 0.0246 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.01315\n",
      "Epoch 122/200\n",
      " - 1s - loss: 0.0059 - acc: 0.9967 - val_loss: 0.0301 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.01315\n",
      "Epoch 123/200\n",
      " - 1s - loss: 0.0053 - acc: 0.9980 - val_loss: 0.0393 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.01315\n",
      "Epoch 124/200\n",
      " - 1s - loss: 0.0060 - acc: 0.9967 - val_loss: 0.0282 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.01315\n",
      "Epoch 125/200\n",
      " - 1s - loss: 0.0057 - acc: 0.9967 - val_loss: 0.0182 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.01315\n",
      "Epoch 126/200\n",
      " - 1s - loss: 0.0067 - acc: 0.9980 - val_loss: 0.0142 - val_acc: 0.9959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00126: val_loss did not improve from 0.01315\n",
      "Epoch 127/200\n",
      " - 1s - loss: 0.0062 - acc: 0.9974 - val_loss: 0.0278 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.01315\n",
      "Epoch 128/200\n",
      " - 1s - loss: 0.0047 - acc: 0.9974 - val_loss: 0.0156 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.01315\n",
      "Epoch 129/200\n",
      " - 1s - loss: 0.0065 - acc: 0.9967 - val_loss: 0.0264 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.01315\n",
      "Epoch 130/200\n",
      " - 1s - loss: 0.0072 - acc: 0.9974 - val_loss: 0.0294 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.01315\n",
      "Epoch 131/200\n",
      " - 1s - loss: 0.0069 - acc: 0.9980 - val_loss: 0.0224 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.01315\n",
      "Epoch 132/200\n",
      " - 1s - loss: 0.0053 - acc: 0.9974 - val_loss: 0.0258 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.01315\n",
      "Epoch 133/200\n",
      " - 1s - loss: 0.0063 - acc: 0.9974 - val_loss: 0.0265 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.01315\n",
      "Epoch 134/200\n",
      " - 1s - loss: 0.0069 - acc: 0.9961 - val_loss: 0.0340 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.01315\n",
      "Epoch 135/200\n",
      " - 1s - loss: 0.0065 - acc: 0.9967 - val_loss: 0.0205 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.01315\n",
      "Epoch 136/200\n",
      " - 1s - loss: 0.0054 - acc: 0.9980 - val_loss: 0.0252 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.01315\n",
      "Epoch 137/200\n",
      " - 1s - loss: 0.0060 - acc: 0.9980 - val_loss: 0.0185 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.01315\n",
      "Epoch 138/200\n",
      " - 1s - loss: 0.0072 - acc: 0.9967 - val_loss: 0.0308 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.01315\n",
      "Epoch 139/200\n",
      " - 1s - loss: 0.0051 - acc: 0.9974 - val_loss: 0.0282 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.01315\n",
      "Epoch 140/200\n",
      " - 1s - loss: 0.0057 - acc: 0.9974 - val_loss: 0.0210 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.01315\n",
      "Epoch 141/200\n",
      " - 1s - loss: 0.0064 - acc: 0.9974 - val_loss: 0.0254 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.01315\n",
      "Epoch 142/200\n",
      " - 1s - loss: 0.0064 - acc: 0.9967 - val_loss: 0.0382 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.01315\n",
      "Epoch 143/200\n",
      " - 1s - loss: 0.0050 - acc: 0.9987 - val_loss: 0.0334 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.01315\n",
      "Epoch 144/200\n",
      " - 1s - loss: 0.0070 - acc: 0.9967 - val_loss: 0.0256 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.01315\n",
      "Epoch 145/200\n",
      " - 1s - loss: 0.0066 - acc: 0.9980 - val_loss: 0.0309 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.01315\n",
      "Epoch 146/200\n",
      " - 1s - loss: 0.0070 - acc: 0.9967 - val_loss: 0.0404 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.01315\n",
      "Epoch 147/200\n",
      " - 1s - loss: 0.0058 - acc: 0.9967 - val_loss: 0.0257 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.01315\n",
      "Epoch 148/200\n",
      " - 1s - loss: 0.0072 - acc: 0.9980 - val_loss: 0.0337 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.01315\n",
      "Epoch 149/200\n",
      " - 1s - loss: 0.0073 - acc: 0.9980 - val_loss: 0.0250 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.01315\n",
      "Epoch 150/200\n",
      " - 1s - loss: 0.0074 - acc: 0.9974 - val_loss: 0.0299 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.01315\n",
      "Epoch 151/200\n",
      " - 1s - loss: 0.0068 - acc: 0.9974 - val_loss: 0.0276 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.01315\n",
      "Epoch 152/200\n",
      " - 1s - loss: 0.0064 - acc: 0.9961 - val_loss: 0.0348 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.01315\n",
      "Epoch 153/200\n",
      " - 1s - loss: 0.0069 - acc: 0.9967 - val_loss: 0.0298 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.01315\n",
      "Epoch 154/200\n",
      " - 1s - loss: 0.0070 - acc: 0.9961 - val_loss: 0.0419 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.01315\n",
      "Epoch 155/200\n",
      " - 1s - loss: 0.0061 - acc: 0.9980 - val_loss: 0.0387 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.01315\n",
      "Epoch 156/200\n",
      " - 1s - loss: 0.0066 - acc: 0.9974 - val_loss: 0.0387 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.01315\n",
      "Epoch 157/200\n",
      " - 1s - loss: 0.0067 - acc: 0.9974 - val_loss: 0.0228 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.01315\n",
      "Epoch 158/200\n",
      " - 1s - loss: 0.0064 - acc: 0.9974 - val_loss: 0.0290 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.01315\n",
      "Epoch 159/200\n",
      " - 1s - loss: 0.0067 - acc: 0.9961 - val_loss: 0.0230 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.01315\n",
      "Epoch 160/200\n",
      " - 1s - loss: 0.0062 - acc: 0.9967 - val_loss: 0.0354 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.01315\n",
      "Epoch 161/200\n",
      " - 1s - loss: 0.0075 - acc: 0.9980 - val_loss: 0.0189 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.01315\n",
      "Epoch 162/200\n",
      " - 1s - loss: 0.0076 - acc: 0.9980 - val_loss: 0.0289 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.01315\n",
      "Epoch 163/200\n",
      " - 1s - loss: 0.0068 - acc: 0.9961 - val_loss: 0.0283 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.01315\n",
      "Epoch 164/200\n",
      " - 1s - loss: 0.0050 - acc: 0.9967 - val_loss: 0.0274 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.01315\n",
      "Epoch 165/200\n",
      " - 1s - loss: 0.0067 - acc: 0.9967 - val_loss: 0.0270 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.01315\n",
      "Epoch 166/200\n",
      " - 1s - loss: 0.0065 - acc: 0.9961 - val_loss: 0.0199 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.01315\n",
      "Epoch 167/200\n",
      " - 1s - loss: 0.0073 - acc: 0.9980 - val_loss: 0.0220 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.01315\n",
      "Epoch 168/200\n",
      " - 1s - loss: 0.0067 - acc: 0.9974 - val_loss: 0.0403 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.01315\n",
      "Epoch 169/200\n",
      " - 1s - loss: 0.0076 - acc: 0.9980 - val_loss: 0.0326 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.01315\n",
      "Epoch 170/200\n",
      " - 1s - loss: 0.0079 - acc: 0.9974 - val_loss: 0.0244 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.01315\n",
      "Epoch 171/200\n",
      " - 1s - loss: 0.0057 - acc: 0.9967 - val_loss: 0.0238 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.01315\n",
      "Epoch 172/200\n",
      " - 1s - loss: 0.0054 - acc: 0.9987 - val_loss: 0.0304 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.01315\n",
      "Epoch 173/200\n",
      " - 1s - loss: 0.0070 - acc: 0.9967 - val_loss: 0.0284 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.01315\n",
      "Epoch 174/200\n",
      " - 1s - loss: 0.0065 - acc: 0.9967 - val_loss: 0.0249 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.01315\n",
      "Epoch 175/200\n",
      " - 1s - loss: 0.0066 - acc: 0.9967 - val_loss: 0.0186 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.01315\n",
      "Epoch 176/200\n",
      " - 1s - loss: 0.0064 - acc: 0.9967 - val_loss: 0.0334 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.01315\n",
      "Epoch 177/200\n",
      " - 1s - loss: 0.0074 - acc: 0.9974 - val_loss: 0.0271 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.01315\n",
      "Epoch 178/200\n",
      " - 1s - loss: 0.0076 - acc: 0.9974 - val_loss: 0.0272 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.01315\n",
      "Epoch 179/200\n",
      " - 1s - loss: 0.0067 - acc: 0.9961 - val_loss: 0.0501 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.01315\n",
      "Epoch 180/200\n",
      " - 1s - loss: 0.0061 - acc: 0.9967 - val_loss: 0.0306 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.01315\n",
      "Epoch 181/200\n",
      " - 1s - loss: 0.0058 - acc: 0.9967 - val_loss: 0.0462 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.01315\n",
      "Epoch 182/200\n",
      " - 1s - loss: 0.0061 - acc: 0.9974 - val_loss: 0.0360 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.01315\n",
      "Epoch 183/200\n",
      " - 1s - loss: 0.0061 - acc: 0.9967 - val_loss: 0.0348 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.01315\n",
      "Epoch 184/200\n",
      " - 1s - loss: 0.0065 - acc: 0.9974 - val_loss: 0.0376 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.01315\n",
      "Epoch 185/200\n",
      " - 1s - loss: 0.0067 - acc: 0.9967 - val_loss: 0.0434 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.01315\n",
      "Epoch 186/200\n",
      " - 1s - loss: 0.0074 - acc: 0.9967 - val_loss: 0.0275 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.01315\n",
      "Epoch 187/200\n",
      " - 1s - loss: 0.0067 - acc: 0.9967 - val_loss: 0.0166 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.01315\n",
      "Epoch 188/200\n",
      " - 1s - loss: 0.0068 - acc: 0.9967 - val_loss: 0.0421 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.01315\n",
      "Epoch 189/200\n",
      " - 1s - loss: 0.0055 - acc: 0.9974 - val_loss: 0.0466 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.01315\n",
      "Epoch 190/200\n",
      " - 1s - loss: 0.0056 - acc: 0.9980 - val_loss: 0.0406 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.01315\n",
      "Epoch 191/200\n",
      " - 1s - loss: 0.0077 - acc: 0.9967 - val_loss: 0.0233 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.01315\n",
      "Epoch 192/200\n",
      " - 1s - loss: 0.0064 - acc: 0.9974 - val_loss: 0.0454 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.01315\n",
      "Epoch 193/200\n",
      " - 1s - loss: 0.0055 - acc: 0.9974 - val_loss: 0.0383 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.01315\n",
      "Epoch 194/200\n",
      " - 1s - loss: 0.0067 - acc: 0.9967 - val_loss: 0.0300 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.01315\n",
      "Epoch 195/200\n",
      " - 1s - loss: 0.0077 - acc: 0.9974 - val_loss: 0.0296 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.01315\n",
      "Epoch 196/200\n",
      " - 1s - loss: 0.0070 - acc: 0.9974 - val_loss: 0.0404 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.01315\n",
      "Epoch 197/200\n",
      " - 1s - loss: 0.0041 - acc: 0.9967 - val_loss: 0.0417 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.01315\n",
      "Epoch 198/200\n",
      " - 1s - loss: 0.0063 - acc: 0.9974 - val_loss: 0.0396 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.01315\n",
      "Epoch 199/200\n",
      " - 1s - loss: 0.0062 - acc: 0.9974 - val_loss: 0.0349 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.01315\n",
      "Epoch 200/200\n",
      " - 1s - loss: 0.0058 - acc: 0.9967 - val_loss: 0.0488 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.01315\n",
      "batch_size=10   optimizer=RMSprop\n",
      "Test accuracy: 66.5738%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 1.7494 - acc: 0.3895 - val_loss: 1.2152 - val_acc: 0.6214\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.21519, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.1614 - acc: 0.6118 - val_loss: 1.1032 - val_acc: 0.6543\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.21519 to 1.10318, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.9714 - acc: 0.6684 - val_loss: 0.8713 - val_acc: 0.7325\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.10318 to 0.87134, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.8603 - acc: 0.7191 - val_loss: 0.7940 - val_acc: 0.7119\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.87134 to 0.79395, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.7646 - acc: 0.7493 - val_loss: 0.7125 - val_acc: 0.7860\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.79395 to 0.71245, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.6897 - acc: 0.7776 - val_loss: 0.6563 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.71245 to 0.65634, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.6356 - acc: 0.8039 - val_loss: 0.5913 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.65634 to 0.59128, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.5796 - acc: 0.8138 - val_loss: 0.5300 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.59128 to 0.52999, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.5384 - acc: 0.8263 - val_loss: 0.5073 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.52999 to 0.50728, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.5003 - acc: 0.8507 - val_loss: 0.5021 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.50728 to 0.50207, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.4644 - acc: 0.8566 - val_loss: 0.4488 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.50207 to 0.44877, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.4308 - acc: 0.8724 - val_loss: 0.3992 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.44877 to 0.39920, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.4003 - acc: 0.8868 - val_loss: 0.3806 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.39920 to 0.38057, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3711 - acc: 0.9046 - val_loss: 0.3693 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.38057 to 0.36930, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3485 - acc: 0.9099 - val_loss: 0.3174 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.36930 to 0.31741, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.3293 - acc: 0.9112 - val_loss: 0.3179 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.31741\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.3098 - acc: 0.9296 - val_loss: 0.2918 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.31741 to 0.29181, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.2864 - acc: 0.9342 - val_loss: 0.2739 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.29181 to 0.27390, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2694 - acc: 0.9368 - val_loss: 0.2568 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.27390 to 0.25685, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2489 - acc: 0.9553 - val_loss: 0.2598 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.25685\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2352 - acc: 0.9559 - val_loss: 0.2222 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.25685 to 0.22222, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2180 - acc: 0.9625 - val_loss: 0.2095 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.22222 to 0.20951, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2059 - acc: 0.9651 - val_loss: 0.1958 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.20951 to 0.19584, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.1944 - acc: 0.9717 - val_loss: 0.1902 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.19584 to 0.19021, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.1843 - acc: 0.9724 - val_loss: 0.1917 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.19021\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.1712 - acc: 0.9750 - val_loss: 0.1808 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.19021 to 0.18081, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.1617 - acc: 0.9757 - val_loss: 0.1517 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.18081 to 0.15173, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.1515 - acc: 0.9822 - val_loss: 0.1366 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.15173 to 0.13664, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.1431 - acc: 0.9836 - val_loss: 0.1305 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.13664 to 0.13052, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.1330 - acc: 0.9842 - val_loss: 0.1597 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.13052\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.1270 - acc: 0.9868 - val_loss: 0.1273 - val_acc: 0.9918\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00031: val_loss improved from 0.13052 to 0.12731, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.1191 - acc: 0.9842 - val_loss: 0.1258 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.12731 to 0.12583, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.1093 - acc: 0.9908 - val_loss: 0.1226 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.12583 to 0.12261, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.1064 - acc: 0.9888 - val_loss: 0.1336 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.12261\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.0991 - acc: 0.9901 - val_loss: 0.0966 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.12261 to 0.09664, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.0928 - acc: 0.9941 - val_loss: 0.0991 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.09664\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.0865 - acc: 0.9934 - val_loss: 0.0952 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.09664 to 0.09519, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.0820 - acc: 0.9954 - val_loss: 0.0987 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.09519\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.0767 - acc: 0.9967 - val_loss: 0.1094 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.09519\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.0738 - acc: 0.9941 - val_loss: 0.0786 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.09519 to 0.07862, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.0697 - acc: 0.9974 - val_loss: 0.0788 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.07862\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.0651 - acc: 0.9961 - val_loss: 0.0840 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.07862\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.0619 - acc: 0.9954 - val_loss: 0.0960 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.07862\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.0600 - acc: 0.9961 - val_loss: 0.0733 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.07862 to 0.07327, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.0539 - acc: 0.9967 - val_loss: 0.0617 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.07327 to 0.06173, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.0521 - acc: 0.9961 - val_loss: 0.0735 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.06173\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.0500 - acc: 0.9974 - val_loss: 0.0600 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.06173 to 0.05995, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.0463 - acc: 0.9974 - val_loss: 0.0612 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.05995\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.0450 - acc: 0.9967 - val_loss: 0.0744 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.05995\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.0419 - acc: 0.9980 - val_loss: 0.0816 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.05995\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.0401 - acc: 0.9974 - val_loss: 0.0643 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.05995\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.0392 - acc: 0.9974 - val_loss: 0.0566 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.05995 to 0.05658, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.0379 - acc: 0.9967 - val_loss: 0.0464 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.05658 to 0.04644, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.0363 - acc: 0.9967 - val_loss: 0.0497 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.04644\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.0339 - acc: 0.9967 - val_loss: 0.0522 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.04644\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.0328 - acc: 0.9961 - val_loss: 0.0550 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.04644\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.0314 - acc: 0.9967 - val_loss: 0.0442 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.04644 to 0.04419, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.0296 - acc: 0.9974 - val_loss: 0.0433 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.04419 to 0.04329, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.0289 - acc: 0.9961 - val_loss: 0.0555 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.04329\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.0265 - acc: 0.9967 - val_loss: 0.0391 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.04329 to 0.03905, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.0256 - acc: 0.9980 - val_loss: 0.0538 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.03905\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.0240 - acc: 0.9967 - val_loss: 0.0808 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.03905\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.0238 - acc: 0.9974 - val_loss: 0.0346 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.03905 to 0.03459, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.0226 - acc: 0.9974 - val_loss: 0.0305 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.03459 to 0.03052, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.0224 - acc: 0.9967 - val_loss: 0.0444 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.03052\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.0204 - acc: 0.9974 - val_loss: 0.0456 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.03052\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.0196 - acc: 0.9967 - val_loss: 0.0405 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.03052\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.0197 - acc: 0.9967 - val_loss: 0.0354 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.03052\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.0185 - acc: 0.9974 - val_loss: 0.0336 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.03052\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.0178 - acc: 0.9961 - val_loss: 0.0392 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.03052\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.0173 - acc: 0.9974 - val_loss: 0.0279 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.03052 to 0.02790, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.0173 - acc: 0.9967 - val_loss: 0.0310 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.02790\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.0163 - acc: 0.9974 - val_loss: 0.0403 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.02790\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.0165 - acc: 0.9980 - val_loss: 0.0261 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.02790 to 0.02609, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.0149 - acc: 0.9974 - val_loss: 0.0338 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.02609\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.0150 - acc: 0.9980 - val_loss: 0.0369 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.02609\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.0139 - acc: 0.9974 - val_loss: 0.0417 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.02609\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.0137 - acc: 0.9974 - val_loss: 0.0276 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.02609\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.0125 - acc: 0.9974 - val_loss: 0.0242 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.02609 to 0.02419, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0132 - acc: 0.9974 - val_loss: 0.0366 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.02419\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0119 - acc: 0.9974 - val_loss: 0.0298 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.02419\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0121 - acc: 0.9980 - val_loss: 0.0359 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.02419\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0111 - acc: 0.9974 - val_loss: 0.0233 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.02419 to 0.02334, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0115 - acc: 0.9974 - val_loss: 0.0294 - val_acc: 0.9918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00084: val_loss did not improve from 0.02334\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0117 - acc: 0.9967 - val_loss: 0.0314 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.02334\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0113 - acc: 0.9980 - val_loss: 0.0292 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.02334\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0109 - acc: 0.9967 - val_loss: 0.0320 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.02334\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0090 - acc: 0.9974 - val_loss: 0.0339 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.02334\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0102 - acc: 0.9980 - val_loss: 0.0328 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.02334\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0105 - acc: 0.9974 - val_loss: 0.0278 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.02334\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0096 - acc: 0.9967 - val_loss: 0.0263 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.02334\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0097 - acc: 0.9974 - val_loss: 0.0325 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.02334\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0099 - acc: 0.9967 - val_loss: 0.0231 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.02334 to 0.02314, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0091 - acc: 0.9967 - val_loss: 0.0312 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.02314\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0093 - acc: 0.9974 - val_loss: 0.0252 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.02314\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0095 - acc: 0.9974 - val_loss: 0.0309 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.02314\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0102 - acc: 0.9967 - val_loss: 0.0267 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.02314\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0090 - acc: 0.9974 - val_loss: 0.0267 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.02314\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0086 - acc: 0.9967 - val_loss: 0.0423 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.02314\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0091 - acc: 0.9967 - val_loss: 0.0233 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.02314\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0085 - acc: 0.9974 - val_loss: 0.0317 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.02314\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0089 - acc: 0.9961 - val_loss: 0.0320 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.02314\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0086 - acc: 0.9974 - val_loss: 0.0259 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.02314\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0077 - acc: 0.9967 - val_loss: 0.0435 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.02314\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0088 - acc: 0.9961 - val_loss: 0.0248 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.02314\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0085 - acc: 0.9967 - val_loss: 0.0226 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.02314 to 0.02262, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0078 - acc: 0.9967 - val_loss: 0.0371 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.02262\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0073 - acc: 0.9980 - val_loss: 0.0298 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.02262\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0072 - acc: 0.9974 - val_loss: 0.0216 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.02262 to 0.02164, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0081 - acc: 0.9967 - val_loss: 0.0250 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.02164\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0080 - acc: 0.9980 - val_loss: 0.0281 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.02164\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0071 - acc: 0.9974 - val_loss: 0.0347 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.02164\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0075 - acc: 0.9967 - val_loss: 0.0260 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.02164\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0080 - acc: 0.9974 - val_loss: 0.0320 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.02164\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0077 - acc: 0.9967 - val_loss: 0.0281 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.02164\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0077 - acc: 0.9974 - val_loss: 0.0294 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.02164\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0066 - acc: 0.9980 - val_loss: 0.0256 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.02164\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0079 - acc: 0.9974 - val_loss: 0.0160 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.02164 to 0.01597, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0072 - acc: 0.9967 - val_loss: 0.0294 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.01597\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0077 - acc: 0.9967 - val_loss: 0.0248 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.01597\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0070 - acc: 0.9974 - val_loss: 0.0258 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.01597\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0075 - acc: 0.9961 - val_loss: 0.0266 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.01597\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0062 - acc: 0.9974 - val_loss: 0.0255 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.01597\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0073 - acc: 0.9980 - val_loss: 0.0285 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.01597\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0067 - acc: 0.9974 - val_loss: 0.0273 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.01597\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0070 - acc: 0.9974 - val_loss: 0.0218 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.01597\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0071 - acc: 0.9967 - val_loss: 0.0224 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.01597\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0072 - acc: 0.9967 - val_loss: 0.0215 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.01597\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0073 - acc: 0.9974 - val_loss: 0.0230 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.01597\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0070 - acc: 0.9974 - val_loss: 0.0277 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.01597\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0060 - acc: 0.9980 - val_loss: 0.0261 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.01597\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0066 - acc: 0.9967 - val_loss: 0.0307 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.01597\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0070 - acc: 0.9967 - val_loss: 0.0220 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.01597\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0072 - acc: 0.9961 - val_loss: 0.0205 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.01597\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0066 - acc: 0.9974 - val_loss: 0.0231 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.01597\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0062 - acc: 0.9967 - val_loss: 0.0262 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.01597\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0061 - acc: 0.9974 - val_loss: 0.0318 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.01597\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0069 - acc: 0.9961 - val_loss: 0.0252 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.01597\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0066 - acc: 0.9974 - val_loss: 0.0399 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.01597\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0076 - acc: 0.9967 - val_loss: 0.0209 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.01597\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0058 - acc: 0.9974 - val_loss: 0.0158 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.01597 to 0.01577, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0070 - acc: 0.9961 - val_loss: 0.0210 - val_acc: 0.9918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00142: val_loss did not improve from 0.01577\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0069 - acc: 0.9961 - val_loss: 0.0318 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.01577\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0048 - acc: 0.9974 - val_loss: 0.0188 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.01577\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0064 - acc: 0.9967 - val_loss: 0.0314 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.01577\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0070 - acc: 0.9967 - val_loss: 0.0177 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.01577\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0071 - acc: 0.9961 - val_loss: 0.0169 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.01577\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0061 - acc: 0.9967 - val_loss: 0.0188 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.01577\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0063 - acc: 0.9967 - val_loss: 0.0195 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.01577\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0038 - acc: 0.9980 - val_loss: 0.0189 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.01577\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0055 - acc: 0.9974 - val_loss: 0.0343 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.01577\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0063 - acc: 0.9980 - val_loss: 0.0159 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.01577\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0060 - acc: 0.9974 - val_loss: 0.0259 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.01577\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0062 - acc: 0.9980 - val_loss: 0.0312 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.01577\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.0065 - acc: 0.9961 - val_loss: 0.0262 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.01577\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.0050 - acc: 0.9974 - val_loss: 0.0343 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.01577\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0072 - acc: 0.9961 - val_loss: 0.0207 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.01577\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.0066 - acc: 0.9974 - val_loss: 0.0239 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.01577\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.0061 - acc: 0.9961 - val_loss: 0.0300 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.01577\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.0068 - acc: 0.9974 - val_loss: 0.0258 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.01577\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.0066 - acc: 0.9980 - val_loss: 0.0280 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.01577\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.0068 - acc: 0.9967 - val_loss: 0.0316 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.01577\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.0062 - acc: 0.9967 - val_loss: 0.0207 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.01577\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.0065 - acc: 0.9980 - val_loss: 0.0248 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.01577\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.0070 - acc: 0.9967 - val_loss: 0.0270 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.01577\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.0054 - acc: 0.9967 - val_loss: 0.0314 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.01577\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.0067 - acc: 0.9967 - val_loss: 0.0267 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.01577\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.0059 - acc: 0.9967 - val_loss: 0.0279 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.01577\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.0059 - acc: 0.9980 - val_loss: 0.0260 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.01577\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.0069 - acc: 0.9980 - val_loss: 0.0323 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.01577\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.0060 - acc: 0.9980 - val_loss: 0.0216 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.01577\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.0057 - acc: 0.9961 - val_loss: 0.0261 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.01577\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.0061 - acc: 0.9974 - val_loss: 0.0298 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.01577\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.0064 - acc: 0.9961 - val_loss: 0.0269 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.01577\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.0047 - acc: 0.9980 - val_loss: 0.0215 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.01577\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.0061 - acc: 0.9980 - val_loss: 0.0256 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.01577\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.0063 - acc: 0.9961 - val_loss: 0.0226 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.01577\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.0063 - acc: 0.9967 - val_loss: 0.0327 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.01577\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.0068 - acc: 0.9961 - val_loss: 0.0258 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.01577\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.0070 - acc: 0.9967 - val_loss: 0.0225 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.01577\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.0057 - acc: 0.9974 - val_loss: 0.0311 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.01577\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.0038 - acc: 0.9980 - val_loss: 0.0321 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.01577\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.0068 - acc: 0.9980 - val_loss: 0.0227 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.01577\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.0053 - acc: 0.9987 - val_loss: 0.0253 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.01577\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.0053 - acc: 0.9967 - val_loss: 0.0346 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.01577\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.0050 - acc: 0.9980 - val_loss: 0.0253 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.01577\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.0044 - acc: 0.9980 - val_loss: 0.0277 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.01577\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.0074 - acc: 0.9974 - val_loss: 0.0271 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.01577\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.0073 - acc: 0.9967 - val_loss: 0.0291 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.01577\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.0064 - acc: 0.9974 - val_loss: 0.0284 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.01577\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.0070 - acc: 0.9980 - val_loss: 0.0280 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.01577\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.0069 - acc: 0.9967 - val_loss: 0.0245 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.01577\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.0056 - acc: 0.9974 - val_loss: 0.0275 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.01577\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.0051 - acc: 0.9980 - val_loss: 0.0197 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.01577\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.0064 - acc: 0.9974 - val_loss: 0.0186 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.01577\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.0070 - acc: 0.9974 - val_loss: 0.0216 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.01577\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.0066 - acc: 0.9967 - val_loss: 0.0205 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.01577\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.0065 - acc: 0.9974 - val_loss: 0.0354 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.01577\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.0058 - acc: 0.9980 - val_loss: 0.0264 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.01577\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.0066 - acc: 0.9967 - val_loss: 0.0292 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.01577\n",
      "batch_size=20   optimizer=RMSprop\n",
      "Test accuracy: 67.1309%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 1.8403 - acc: 0.3487 - val_loss: 1.4939 - val_acc: 0.4897\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.49392, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.3199 - acc: 0.5559 - val_loss: 1.2435 - val_acc: 0.5720\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.49392 to 1.24351, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 1.1100 - acc: 0.6454 - val_loss: 1.0601 - val_acc: 0.6790\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.24351 to 1.06013, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.9798 - acc: 0.6829 - val_loss: 0.9372 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.06013 to 0.93717, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.8940 - acc: 0.6941 - val_loss: 0.8282 - val_acc: 0.7407\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.93717 to 0.82818, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.8247 - acc: 0.7349 - val_loss: 0.7712 - val_acc: 0.7407\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.82818 to 0.77122, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.7519 - acc: 0.7618 - val_loss: 0.7204 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.77122 to 0.72040, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.7085 - acc: 0.7757 - val_loss: 0.6776 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.72040 to 0.67762, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.6544 - acc: 0.7961 - val_loss: 0.6322 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.67762 to 0.63219, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.6177 - acc: 0.8138 - val_loss: 0.6130 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.63219 to 0.61295, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.5791 - acc: 0.8211 - val_loss: 0.5568 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.61295 to 0.55685, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.5435 - acc: 0.8276 - val_loss: 0.5232 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.55685 to 0.52325, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.5259 - acc: 0.8454 - val_loss: 0.5003 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.52325 to 0.50029, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.4806 - acc: 0.8618 - val_loss: 0.4882 - val_acc: 0.8765\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.50029 to 0.48822, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.4649 - acc: 0.8645 - val_loss: 0.4686 - val_acc: 0.8765\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.48822 to 0.46862, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.4437 - acc: 0.8691 - val_loss: 0.4388 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.46862 to 0.43878, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.4229 - acc: 0.8822 - val_loss: 0.4090 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.43878 to 0.40902, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.3947 - acc: 0.8980 - val_loss: 0.4080 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.40902 to 0.40797, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.3753 - acc: 0.9118 - val_loss: 0.3670 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.40797 to 0.36701, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.3581 - acc: 0.9118 - val_loss: 0.3488 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.36701 to 0.34884, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.3426 - acc: 0.9184 - val_loss: 0.3275 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.34884 to 0.32749, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.3248 - acc: 0.9257 - val_loss: 0.3467 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.32749\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.3044 - acc: 0.9349 - val_loss: 0.3367 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.32749\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2939 - acc: 0.9303 - val_loss: 0.2960 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.32749 to 0.29599, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2814 - acc: 0.9408 - val_loss: 0.2987 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.29599\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2633 - acc: 0.9487 - val_loss: 0.2754 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.29599 to 0.27535, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2527 - acc: 0.9605 - val_loss: 0.2718 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.27535 to 0.27184, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2434 - acc: 0.9566 - val_loss: 0.2337 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.27184 to 0.23370, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2284 - acc: 0.9605 - val_loss: 0.2298 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.23370 to 0.22979, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2191 - acc: 0.9645 - val_loss: 0.2298 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.22979 to 0.22975, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2098 - acc: 0.9658 - val_loss: 0.1989 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.22975 to 0.19892, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.1986 - acc: 0.9704 - val_loss: 0.1977 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.19892 to 0.19769, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.1905 - acc: 0.9750 - val_loss: 0.1992 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.19769\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.1814 - acc: 0.9763 - val_loss: 0.2011 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.19769\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.1723 - acc: 0.9776 - val_loss: 0.2029 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.19769\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.1643 - acc: 0.9803 - val_loss: 0.1720 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.19769 to 0.17203, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.1600 - acc: 0.9816 - val_loss: 0.1725 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.17203\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.1495 - acc: 0.9822 - val_loss: 0.1675 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.17203 to 0.16749, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.1432 - acc: 0.9842 - val_loss: 0.1555 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.16749 to 0.15547, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.1385 - acc: 0.9862 - val_loss: 0.1349 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.15547 to 0.13490, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.1310 - acc: 0.9888 - val_loss: 0.1390 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.13490\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.1232 - acc: 0.9908 - val_loss: 0.1477 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.13490\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1212 - acc: 0.9895 - val_loss: 0.1243 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.13490 to 0.12429, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1127 - acc: 0.9941 - val_loss: 0.1580 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.12429\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1125 - acc: 0.9901 - val_loss: 0.1095 - val_acc: 0.9959\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00045: val_loss improved from 0.12429 to 0.10953, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1041 - acc: 0.9921 - val_loss: 0.1174 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.10953\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1012 - acc: 0.9934 - val_loss: 0.1162 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.10953\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.0943 - acc: 0.9934 - val_loss: 0.1044 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.10953 to 0.10440, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.0919 - acc: 0.9947 - val_loss: 0.1137 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.10440\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.0878 - acc: 0.9961 - val_loss: 0.0948 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.10440 to 0.09481, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.0834 - acc: 0.9954 - val_loss: 0.1074 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.09481\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.0782 - acc: 0.9974 - val_loss: 0.0909 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.09481 to 0.09089, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.0748 - acc: 0.9974 - val_loss: 0.0925 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.09089\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.0735 - acc: 0.9954 - val_loss: 0.0863 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.09089 to 0.08628, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.0699 - acc: 0.9974 - val_loss: 0.0867 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.08628\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.0677 - acc: 0.9954 - val_loss: 0.0857 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.08628 to 0.08571, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.0647 - acc: 0.9967 - val_loss: 0.0855 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.08571 to 0.08550, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.0616 - acc: 0.9967 - val_loss: 0.0784 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.08550 to 0.07843, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.0589 - acc: 0.9961 - val_loss: 0.0800 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.07843\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.0574 - acc: 0.9974 - val_loss: 0.0682 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.07843 to 0.06822, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.0540 - acc: 0.9967 - val_loss: 0.0825 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.06822\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.0533 - acc: 0.9974 - val_loss: 0.0690 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.06822\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.0507 - acc: 0.9980 - val_loss: 0.0630 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.06822 to 0.06304, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.0486 - acc: 0.9967 - val_loss: 0.0732 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.06304\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.0467 - acc: 0.9974 - val_loss: 0.0658 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.06304\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.0445 - acc: 0.9967 - val_loss: 0.0549 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.06304 to 0.05490, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.0424 - acc: 0.9980 - val_loss: 0.0702 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.05490\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.0429 - acc: 0.9974 - val_loss: 0.0694 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.05490\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.0399 - acc: 0.9961 - val_loss: 0.0528 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.05490 to 0.05281, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.0388 - acc: 0.9974 - val_loss: 0.0693 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.05281\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.0358 - acc: 0.9967 - val_loss: 0.0520 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.05281 to 0.05198, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.0357 - acc: 0.9974 - val_loss: 0.0542 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.05198\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.0347 - acc: 0.9961 - val_loss: 0.0642 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.05198\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.0332 - acc: 0.9974 - val_loss: 0.0502 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.05198 to 0.05023, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.0315 - acc: 0.9980 - val_loss: 0.0645 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.05023\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.0307 - acc: 0.9967 - val_loss: 0.0528 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.05023\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.0309 - acc: 0.9961 - val_loss: 0.0467 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.05023 to 0.04672, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.0296 - acc: 0.9974 - val_loss: 0.0491 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.04672\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.0281 - acc: 0.9967 - val_loss: 0.0502 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.04672\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0269 - acc: 0.9967 - val_loss: 0.0446 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.04672 to 0.04463, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0256 - acc: 0.9980 - val_loss: 0.0550 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.04463\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0258 - acc: 0.9974 - val_loss: 0.0497 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.04463\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0248 - acc: 0.9974 - val_loss: 0.0387 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.04463 to 0.03868, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0242 - acc: 0.9974 - val_loss: 0.0433 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.03868\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0233 - acc: 0.9974 - val_loss: 0.0414 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.03868\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0227 - acc: 0.9974 - val_loss: 0.0369 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.03868 to 0.03686, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0223 - acc: 0.9961 - val_loss: 0.0449 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.03686\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0211 - acc: 0.9974 - val_loss: 0.0349 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.03686 to 0.03494, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0211 - acc: 0.9974 - val_loss: 0.0327 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.03494 to 0.03273, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0201 - acc: 0.9980 - val_loss: 0.0322 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.03273 to 0.03216, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0203 - acc: 0.9967 - val_loss: 0.0405 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.03216\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0190 - acc: 0.9967 - val_loss: 0.0534 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.03216\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0181 - acc: 0.9961 - val_loss: 0.0485 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.03216\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0171 - acc: 0.9980 - val_loss: 0.0471 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.03216\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0184 - acc: 0.9967 - val_loss: 0.0363 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.03216\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0169 - acc: 0.9967 - val_loss: 0.0560 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.03216\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0173 - acc: 0.9967 - val_loss: 0.0404 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.03216\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0165 - acc: 0.9961 - val_loss: 0.0436 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.03216\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0162 - acc: 0.9961 - val_loss: 0.0357 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.03216\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0161 - acc: 0.9967 - val_loss: 0.0332 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.03216\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0149 - acc: 0.9961 - val_loss: 0.0332 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.03216\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0158 - acc: 0.9967 - val_loss: 0.0363 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.03216\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0136 - acc: 0.9980 - val_loss: 0.0395 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.03216\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0140 - acc: 0.9974 - val_loss: 0.0357 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.03216\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0138 - acc: 0.9974 - val_loss: 0.0370 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.03216\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0131 - acc: 0.9974 - val_loss: 0.0379 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.03216\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0129 - acc: 0.9974 - val_loss: 0.0323 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.03216\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0133 - acc: 0.9974 - val_loss: 0.0344 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.03216\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0121 - acc: 0.9980 - val_loss: 0.0360 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.03216\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0122 - acc: 0.9974 - val_loss: 0.0364 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.03216\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0126 - acc: 0.9974 - val_loss: 0.0323 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.03216\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0111 - acc: 0.9967 - val_loss: 0.0389 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.03216\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0114 - acc: 0.9974 - val_loss: 0.0381 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.03216\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0111 - acc: 0.9967 - val_loss: 0.0323 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.03216\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0104 - acc: 0.9974 - val_loss: 0.0285 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.03216 to 0.02852, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0119 - acc: 0.9961 - val_loss: 0.0379 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.02852\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0111 - acc: 0.9967 - val_loss: 0.0379 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.02852\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0108 - acc: 0.9967 - val_loss: 0.0355 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.02852\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0106 - acc: 0.9974 - val_loss: 0.0365 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.02852\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0101 - acc: 0.9974 - val_loss: 0.0359 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.02852\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0107 - acc: 0.9980 - val_loss: 0.0264 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.02852 to 0.02638, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0100 - acc: 0.9974 - val_loss: 0.0331 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.02638\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0103 - acc: 0.9967 - val_loss: 0.0389 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.02638\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0103 - acc: 0.9961 - val_loss: 0.0356 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.02638\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0102 - acc: 0.9980 - val_loss: 0.0323 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.02638\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0093 - acc: 0.9980 - val_loss: 0.0312 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.02638\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0094 - acc: 0.9974 - val_loss: 0.0269 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.02638\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0091 - acc: 0.9967 - val_loss: 0.0407 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.02638\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0086 - acc: 0.9967 - val_loss: 0.0431 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.02638\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0091 - acc: 0.9961 - val_loss: 0.0256 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.02638 to 0.02561, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0094 - acc: 0.9967 - val_loss: 0.0300 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.02561\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0092 - acc: 0.9974 - val_loss: 0.0417 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.02561\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0087 - acc: 0.9974 - val_loss: 0.0298 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.02561\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0090 - acc: 0.9974 - val_loss: 0.0296 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.02561\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0082 - acc: 0.9974 - val_loss: 0.0241 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.02561 to 0.02410, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0086 - acc: 0.9967 - val_loss: 0.0406 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.02410\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0087 - acc: 0.9974 - val_loss: 0.0322 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.02410\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0081 - acc: 0.9974 - val_loss: 0.0314 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.02410\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0079 - acc: 0.9980 - val_loss: 0.0292 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.02410\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0079 - acc: 0.9967 - val_loss: 0.0293 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.02410\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0086 - acc: 0.9974 - val_loss: 0.0353 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.02410\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0076 - acc: 0.9974 - val_loss: 0.0320 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.02410\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0068 - acc: 0.9974 - val_loss: 0.0359 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.02410\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0068 - acc: 0.9967 - val_loss: 0.0375 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.02410\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0083 - acc: 0.9967 - val_loss: 0.0318 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.02410\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0072 - acc: 0.9980 - val_loss: 0.0253 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.02410\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0071 - acc: 0.9967 - val_loss: 0.0256 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.02410\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0077 - acc: 0.9967 - val_loss: 0.0229 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.02410 to 0.02288, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0069 - acc: 0.9967 - val_loss: 0.0270 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.02288\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0085 - acc: 0.9974 - val_loss: 0.0255 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.02288\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0073 - acc: 0.9974 - val_loss: 0.0352 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.02288\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0066 - acc: 0.9974 - val_loss: 0.0266 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.02288\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0061 - acc: 0.9980 - val_loss: 0.0319 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.02288\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0082 - acc: 0.9974 - val_loss: 0.0247 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.02288\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.0064 - acc: 0.9974 - val_loss: 0.0405 - val_acc: 0.9877\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00155: val_loss did not improve from 0.02288\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.0076 - acc: 0.9967 - val_loss: 0.0246 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.02288\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0076 - acc: 0.9967 - val_loss: 0.0406 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.02288\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.0067 - acc: 0.9967 - val_loss: 0.0247 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.02288\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.0070 - acc: 0.9980 - val_loss: 0.0301 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.02288\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.0072 - acc: 0.9980 - val_loss: 0.0278 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.02288\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.0068 - acc: 0.9961 - val_loss: 0.0266 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.02288\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.0072 - acc: 0.9974 - val_loss: 0.0258 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.02288\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.0071 - acc: 0.9967 - val_loss: 0.0356 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.02288\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.0059 - acc: 0.9987 - val_loss: 0.0264 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.02288\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.0065 - acc: 0.9974 - val_loss: 0.0249 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.02288\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.0073 - acc: 0.9967 - val_loss: 0.0308 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.02288\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.0067 - acc: 0.9974 - val_loss: 0.0345 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.02288\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.0073 - acc: 0.9967 - val_loss: 0.0314 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.02288\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.0060 - acc: 0.9967 - val_loss: 0.0346 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.02288\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.0062 - acc: 0.9980 - val_loss: 0.0285 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.02288\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.0071 - acc: 0.9974 - val_loss: 0.0283 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.02288\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.0064 - acc: 0.9974 - val_loss: 0.0329 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.02288\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.0076 - acc: 0.9974 - val_loss: 0.0246 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.02288\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.0060 - acc: 0.9974 - val_loss: 0.0265 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.02288\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.0070 - acc: 0.9967 - val_loss: 0.0275 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.02288\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.0067 - acc: 0.9967 - val_loss: 0.0282 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.02288\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.0062 - acc: 0.9974 - val_loss: 0.0250 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.02288\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.0070 - acc: 0.9967 - val_loss: 0.0340 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.02288\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.0075 - acc: 0.9967 - val_loss: 0.0306 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.02288\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.0063 - acc: 0.9967 - val_loss: 0.0379 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.02288\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.0061 - acc: 0.9967 - val_loss: 0.0294 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.02288\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.0061 - acc: 0.9967 - val_loss: 0.0326 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.02288\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.0064 - acc: 0.9961 - val_loss: 0.0285 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.02288\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.0057 - acc: 0.9974 - val_loss: 0.0299 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.02288\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.0061 - acc: 0.9967 - val_loss: 0.0233 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.02288\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.0054 - acc: 0.9980 - val_loss: 0.0430 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.02288\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.0064 - acc: 0.9967 - val_loss: 0.0285 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.02288\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.0067 - acc: 0.9967 - val_loss: 0.0322 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.02288\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.0056 - acc: 0.9974 - val_loss: 0.0293 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.02288\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.0071 - acc: 0.9974 - val_loss: 0.0359 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.02288\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.0058 - acc: 0.9974 - val_loss: 0.0227 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00191: val_loss improved from 0.02288 to 0.02268, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.0071 - acc: 0.9974 - val_loss: 0.0347 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.02268\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.0065 - acc: 0.9961 - val_loss: 0.0300 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.02268\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.0070 - acc: 0.9967 - val_loss: 0.0309 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.02268\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.0056 - acc: 0.9967 - val_loss: 0.0250 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.02268\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.0067 - acc: 0.9961 - val_loss: 0.0293 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.02268\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.0060 - acc: 0.9974 - val_loss: 0.0319 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.02268\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.0073 - acc: 0.9974 - val_loss: 0.0341 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.02268\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.0049 - acc: 0.9980 - val_loss: 0.0292 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.02268\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.0044 - acc: 0.9980 - val_loss: 0.0275 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.02268\n",
      "batch_size=40   optimizer=RMSprop\n",
      "Test accuracy: 68.8022%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_23 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 1.9871 - acc: 0.3066 - val_loss: 1.6103 - val_acc: 0.4444\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.61035, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.4569 - acc: 0.5197 - val_loss: 1.3496 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.61035 to 1.34956, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 1.2357 - acc: 0.5908 - val_loss: 1.1872 - val_acc: 0.6049\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.34956 to 1.18721, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 1.1171 - acc: 0.6270 - val_loss: 1.0455 - val_acc: 0.6626\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.18721 to 1.04555, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 1.0127 - acc: 0.6770 - val_loss: 0.9705 - val_acc: 0.6790\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.04555 to 0.97048, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.9426 - acc: 0.6967 - val_loss: 0.9540 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.97048 to 0.95395, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.8803 - acc: 0.7283 - val_loss: 0.8530 - val_acc: 0.7284\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.95395 to 0.85304, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.8368 - acc: 0.7368 - val_loss: 0.8270 - val_acc: 0.7284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00008: val_loss improved from 0.85304 to 0.82700, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.7730 - acc: 0.7632 - val_loss: 0.8320 - val_acc: 0.7078\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.82700\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.7418 - acc: 0.7671 - val_loss: 0.7583 - val_acc: 0.7284\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.82700 to 0.75835, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.7192 - acc: 0.7691 - val_loss: 0.6950 - val_acc: 0.7737\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.75835 to 0.69501, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.6617 - acc: 0.8000 - val_loss: 0.6831 - val_acc: 0.7531\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.69501 to 0.68307, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.6352 - acc: 0.8072 - val_loss: 0.6395 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.68307 to 0.63953, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.6118 - acc: 0.8151 - val_loss: 0.6112 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.63953 to 0.61121, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.5818 - acc: 0.8191 - val_loss: 0.5672 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.61121 to 0.56719, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.5565 - acc: 0.8316 - val_loss: 0.5634 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.56719 to 0.56337, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.5311 - acc: 0.8441 - val_loss: 0.5416 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.56337 to 0.54160, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.5192 - acc: 0.8408 - val_loss: 0.5372 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.54160 to 0.53719, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.4853 - acc: 0.8553 - val_loss: 0.5060 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.53719 to 0.50596, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.4772 - acc: 0.8684 - val_loss: 0.4786 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.50596 to 0.47858, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.4458 - acc: 0.8809 - val_loss: 0.4685 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.47858 to 0.46852, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.4370 - acc: 0.8829 - val_loss: 0.4512 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.46852 to 0.45115, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.4228 - acc: 0.8941 - val_loss: 0.4356 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.45115 to 0.43564, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.4084 - acc: 0.8914 - val_loss: 0.3931 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.43564 to 0.39312, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.3944 - acc: 0.9039 - val_loss: 0.3886 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.39312 to 0.38857, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.3734 - acc: 0.9125 - val_loss: 0.3818 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.38857 to 0.38183, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.3637 - acc: 0.9112 - val_loss: 0.3985 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.38183\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.3459 - acc: 0.9257 - val_loss: 0.4206 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.38183\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.3373 - acc: 0.9217 - val_loss: 0.3483 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.38183 to 0.34826, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.3252 - acc: 0.9257 - val_loss: 0.3755 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.34826\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.3095 - acc: 0.9388 - val_loss: 0.3387 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.34826 to 0.33870, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.3054 - acc: 0.9414 - val_loss: 0.3209 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.33870 to 0.32090, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2943 - acc: 0.9375 - val_loss: 0.2963 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.32090 to 0.29629, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2811 - acc: 0.9487 - val_loss: 0.3001 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.29629\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2700 - acc: 0.9533 - val_loss: 0.2767 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.29629 to 0.27669, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2621 - acc: 0.9566 - val_loss: 0.2676 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.27669 to 0.26756, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2508 - acc: 0.9566 - val_loss: 0.3033 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.26756\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2483 - acc: 0.9553 - val_loss: 0.2642 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.26756 to 0.26416, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.2368 - acc: 0.9625 - val_loss: 0.2417 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.26416 to 0.24168, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.2306 - acc: 0.9632 - val_loss: 0.2441 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.24168\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.2215 - acc: 0.9664 - val_loss: 0.2380 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.24168 to 0.23795, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.2134 - acc: 0.9730 - val_loss: 0.2404 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.23795\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.2051 - acc: 0.9737 - val_loss: 0.2183 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.23795 to 0.21829, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.2030 - acc: 0.9724 - val_loss: 0.2422 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.21829\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1921 - acc: 0.9717 - val_loss: 0.1977 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.21829 to 0.19774, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1876 - acc: 0.9776 - val_loss: 0.2042 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.19774\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1769 - acc: 0.9816 - val_loss: 0.2318 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.19774\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1758 - acc: 0.9862 - val_loss: 0.2052 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.19774\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1682 - acc: 0.9829 - val_loss: 0.1996 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.19774\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1636 - acc: 0.9862 - val_loss: 0.1730 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.19774 to 0.17302, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1569 - acc: 0.9842 - val_loss: 0.1872 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.17302\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1519 - acc: 0.9882 - val_loss: 0.1695 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.17302 to 0.16946, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1462 - acc: 0.9895 - val_loss: 0.1504 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.16946 to 0.15045, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1441 - acc: 0.9882 - val_loss: 0.1489 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.15045 to 0.14891, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1356 - acc: 0.9901 - val_loss: 0.1533 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.14891\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1327 - acc: 0.9901 - val_loss: 0.1498 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.14891\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1340 - acc: 0.9901 - val_loss: 0.1537 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.14891\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1219 - acc: 0.9901 - val_loss: 0.1312 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.14891 to 0.13124, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1211 - acc: 0.9941 - val_loss: 0.1448 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.13124\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1153 - acc: 0.9941 - val_loss: 0.1256 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.13124 to 0.12560, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1146 - acc: 0.9947 - val_loss: 0.1571 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.12560\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1119 - acc: 0.9934 - val_loss: 0.1366 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.12560\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1071 - acc: 0.9928 - val_loss: 0.1183 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.12560 to 0.11832, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1014 - acc: 0.9961 - val_loss: 0.1144 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.11832 to 0.11442, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1023 - acc: 0.9934 - val_loss: 0.1236 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.11442\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.0933 - acc: 0.9967 - val_loss: 0.1309 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.11442\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.0932 - acc: 0.9934 - val_loss: 0.1168 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.11442\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.0903 - acc: 0.9947 - val_loss: 0.1184 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.11442\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.0883 - acc: 0.9954 - val_loss: 0.1031 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.11442 to 0.10308, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.0844 - acc: 0.9961 - val_loss: 0.1066 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.10308\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.0826 - acc: 0.9967 - val_loss: 0.0907 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.10308 to 0.09073, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.0796 - acc: 0.9967 - val_loss: 0.1055 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.09073\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.0763 - acc: 0.9961 - val_loss: 0.1095 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.09073\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.0761 - acc: 0.9974 - val_loss: 0.0928 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.09073\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.0737 - acc: 0.9974 - val_loss: 0.1025 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.09073\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.0724 - acc: 0.9974 - val_loss: 0.0914 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.09073\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.0671 - acc: 0.9967 - val_loss: 0.0968 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.09073\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.0662 - acc: 0.9980 - val_loss: 0.0848 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.09073 to 0.08479, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.0643 - acc: 0.9980 - val_loss: 0.0981 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.08479\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0608 - acc: 0.9980 - val_loss: 0.1020 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.08479\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0627 - acc: 0.9961 - val_loss: 0.0727 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.08479 to 0.07271, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0598 - acc: 0.9954 - val_loss: 0.0802 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.07271\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0576 - acc: 0.9967 - val_loss: 0.0781 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.07271\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0544 - acc: 0.9974 - val_loss: 0.0753 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.07271\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0543 - acc: 0.9974 - val_loss: 0.0739 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.07271\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0511 - acc: 0.9967 - val_loss: 0.0692 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.07271 to 0.06921, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0517 - acc: 0.9967 - val_loss: 0.0857 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.06921\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0503 - acc: 0.9967 - val_loss: 0.0749 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.06921\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0482 - acc: 0.9967 - val_loss: 0.0686 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.06921 to 0.06865, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0461 - acc: 0.9967 - val_loss: 0.0843 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.06865\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0461 - acc: 0.9967 - val_loss: 0.0777 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.06865\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0449 - acc: 0.9980 - val_loss: 0.0686 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.06865 to 0.06856, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0426 - acc: 0.9980 - val_loss: 0.0826 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.06856\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0414 - acc: 0.9967 - val_loss: 0.0676 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.06856 to 0.06758, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0410 - acc: 0.9967 - val_loss: 0.0561 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.06758 to 0.05608, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0407 - acc: 0.9974 - val_loss: 0.0565 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.05608\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0389 - acc: 0.9974 - val_loss: 0.0625 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.05608\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0389 - acc: 0.9967 - val_loss: 0.0524 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.05608 to 0.05235, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0358 - acc: 0.9987 - val_loss: 0.0749 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.05235\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0366 - acc: 0.9967 - val_loss: 0.0644 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.05235\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0358 - acc: 0.9967 - val_loss: 0.0587 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.05235\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0349 - acc: 0.9974 - val_loss: 0.0637 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.05235\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0328 - acc: 0.9974 - val_loss: 0.0475 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.05235 to 0.04747, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0321 - acc: 0.9980 - val_loss: 0.0506 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.04747\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0312 - acc: 0.9980 - val_loss: 0.0760 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.04747\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0310 - acc: 0.9974 - val_loss: 0.0582 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.04747\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0305 - acc: 0.9980 - val_loss: 0.0511 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.04747\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0290 - acc: 0.9974 - val_loss: 0.0535 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.04747\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0305 - acc: 0.9967 - val_loss: 0.0561 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.04747\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0276 - acc: 0.9974 - val_loss: 0.0593 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.04747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/200\n",
      " - 0s - loss: 0.0269 - acc: 0.9974 - val_loss: 0.0572 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.04747\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0270 - acc: 0.9980 - val_loss: 0.0504 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.04747\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0270 - acc: 0.9980 - val_loss: 0.0555 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.04747\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0263 - acc: 0.9967 - val_loss: 0.0433 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.04747 to 0.04332, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0246 - acc: 0.9974 - val_loss: 0.0541 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.04332\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0248 - acc: 0.9974 - val_loss: 0.0491 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.04332\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0236 - acc: 0.9980 - val_loss: 0.0443 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.04332\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0227 - acc: 0.9980 - val_loss: 0.0473 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.04332\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0232 - acc: 0.9967 - val_loss: 0.0549 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.04332\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0221 - acc: 0.9980 - val_loss: 0.0441 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.04332\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0217 - acc: 0.9974 - val_loss: 0.0531 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.04332\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0214 - acc: 0.9974 - val_loss: 0.0536 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.04332\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0216 - acc: 0.9974 - val_loss: 0.0516 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.04332\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0205 - acc: 0.9967 - val_loss: 0.0501 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.04332\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0204 - acc: 0.9961 - val_loss: 0.0473 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.04332\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0197 - acc: 0.9980 - val_loss: 0.0432 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.04332 to 0.04324, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0195 - acc: 0.9974 - val_loss: 0.0403 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.04324 to 0.04031, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0187 - acc: 0.9974 - val_loss: 0.0432 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.04031\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0191 - acc: 0.9980 - val_loss: 0.0391 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.04031 to 0.03912, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0188 - acc: 0.9967 - val_loss: 0.0485 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.03912\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0181 - acc: 0.9974 - val_loss: 0.0466 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.03912\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0172 - acc: 0.9980 - val_loss: 0.0433 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.03912\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0179 - acc: 0.9967 - val_loss: 0.0466 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.03912\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0171 - acc: 0.9974 - val_loss: 0.0428 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.03912\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0164 - acc: 0.9967 - val_loss: 0.0514 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.03912\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0167 - acc: 0.9967 - val_loss: 0.0367 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.03912 to 0.03674, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0158 - acc: 0.9974 - val_loss: 0.0438 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.03674\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0155 - acc: 0.9974 - val_loss: 0.0381 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.03674\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0158 - acc: 0.9967 - val_loss: 0.0386 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.03674\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0157 - acc: 0.9980 - val_loss: 0.0478 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.03674\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0156 - acc: 0.9961 - val_loss: 0.0353 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.03674 to 0.03532, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0143 - acc: 0.9974 - val_loss: 0.0443 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.03532\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0149 - acc: 0.9967 - val_loss: 0.0408 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.03532\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0144 - acc: 0.9967 - val_loss: 0.0570 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.03532\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0140 - acc: 0.9967 - val_loss: 0.0348 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.03532 to 0.03483, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0143 - acc: 0.9974 - val_loss: 0.0453 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.03483\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0139 - acc: 0.9967 - val_loss: 0.0335 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.03483 to 0.03346, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0131 - acc: 0.9967 - val_loss: 0.0368 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.03346\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0133 - acc: 0.9967 - val_loss: 0.0392 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.03346\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0137 - acc: 0.9961 - val_loss: 0.0400 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.03346\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0131 - acc: 0.9967 - val_loss: 0.0439 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.03346\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0117 - acc: 0.9980 - val_loss: 0.0374 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.03346\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0136 - acc: 0.9967 - val_loss: 0.0374 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.03346\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0124 - acc: 0.9961 - val_loss: 0.0335 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.03346\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.0119 - acc: 0.9980 - val_loss: 0.0412 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.03346\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.0108 - acc: 0.9974 - val_loss: 0.0340 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.03346\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0118 - acc: 0.9987 - val_loss: 0.0411 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.03346\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.0117 - acc: 0.9961 - val_loss: 0.0500 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.03346\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.0112 - acc: 0.9967 - val_loss: 0.0329 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.03346 to 0.03291, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.0117 - acc: 0.9974 - val_loss: 0.0342 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.03291\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.0125 - acc: 0.9967 - val_loss: 0.0473 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.03291\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.0113 - acc: 0.9967 - val_loss: 0.0300 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.03291 to 0.02999, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.0104 - acc: 0.9967 - val_loss: 0.0345 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.02999\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.0106 - acc: 0.9967 - val_loss: 0.0384 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.02999\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.0106 - acc: 0.9974 - val_loss: 0.0298 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.02999 to 0.02985, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.0106 - acc: 0.9974 - val_loss: 0.0391 - val_acc: 0.9877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00166: val_loss did not improve from 0.02985\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.0102 - acc: 0.9974 - val_loss: 0.0406 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.02985\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.0098 - acc: 0.9980 - val_loss: 0.0440 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.02985\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.0101 - acc: 0.9967 - val_loss: 0.0486 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.02985\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.0104 - acc: 0.9974 - val_loss: 0.0413 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.02985\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.0099 - acc: 0.9967 - val_loss: 0.0413 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.02985\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.0101 - acc: 0.9961 - val_loss: 0.0419 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.02985\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.0099 - acc: 0.9961 - val_loss: 0.0419 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.02985\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.0100 - acc: 0.9980 - val_loss: 0.0383 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.02985\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.0087 - acc: 0.9980 - val_loss: 0.0348 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.02985\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.0102 - acc: 0.9974 - val_loss: 0.0351 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.02985\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.0094 - acc: 0.9974 - val_loss: 0.0290 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00177: val_loss improved from 0.02985 to 0.02904, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.0091 - acc: 0.9974 - val_loss: 0.0381 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.02904\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.0089 - acc: 0.9974 - val_loss: 0.0376 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.02904\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.0091 - acc: 0.9961 - val_loss: 0.0359 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.02904\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.0098 - acc: 0.9974 - val_loss: 0.0383 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.02904\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.0086 - acc: 0.9974 - val_loss: 0.0395 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.02904\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.0090 - acc: 0.9961 - val_loss: 0.0437 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.02904\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.0087 - acc: 0.9967 - val_loss: 0.0392 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.02904\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.0083 - acc: 0.9967 - val_loss: 0.0359 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.02904\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.0090 - acc: 0.9967 - val_loss: 0.0360 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.02904\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.0080 - acc: 0.9974 - val_loss: 0.0421 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.02904\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.0091 - acc: 0.9961 - val_loss: 0.0368 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.02904\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.0078 - acc: 0.9974 - val_loss: 0.0347 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.02904\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.0082 - acc: 0.9967 - val_loss: 0.0334 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.02904\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.0077 - acc: 0.9967 - val_loss: 0.0396 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.02904\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.0086 - acc: 0.9967 - val_loss: 0.0328 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.02904\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.0079 - acc: 0.9974 - val_loss: 0.0445 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.02904\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.0084 - acc: 0.9974 - val_loss: 0.0349 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.02904\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.0077 - acc: 0.9967 - val_loss: 0.0407 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.02904\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.0089 - acc: 0.9974 - val_loss: 0.0438 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.02904\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.0084 - acc: 0.9961 - val_loss: 0.0294 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.02904\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.0082 - acc: 0.9967 - val_loss: 0.0428 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.02904\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.0072 - acc: 0.9980 - val_loss: 0.0360 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.02904\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.0081 - acc: 0.9961 - val_loss: 0.0293 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.02904\n",
      "batch_size=80   optimizer=RMSprop\n",
      "Test accuracy: 69.9164%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 2.1438 - acc: 0.2586 - val_loss: 1.7576 - val_acc: 0.3786\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.75757, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.6177 - acc: 0.4388 - val_loss: 1.4825 - val_acc: 0.5021\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.75757 to 1.48254, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 1.4006 - acc: 0.5211 - val_loss: 1.2934 - val_acc: 0.5844\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.48254 to 1.29342, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 1.2369 - acc: 0.5914 - val_loss: 1.1887 - val_acc: 0.5802\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.29342 to 1.18870, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 1.1330 - acc: 0.6342 - val_loss: 1.0978 - val_acc: 0.6461\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.18870 to 1.09782, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 1.0536 - acc: 0.6559 - val_loss: 1.0343 - val_acc: 0.6379\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.09782 to 1.03429, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.9869 - acc: 0.6770 - val_loss: 1.0041 - val_acc: 0.6502\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.03429 to 1.00414, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.9316 - acc: 0.7033 - val_loss: 0.9040 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.00414 to 0.90402, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.8709 - acc: 0.7296 - val_loss: 0.8864 - val_acc: 0.7243\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.90402 to 0.88637, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.8357 - acc: 0.7263 - val_loss: 0.8241 - val_acc: 0.7202\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.88637 to 0.82411, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.7880 - acc: 0.7487 - val_loss: 0.8190 - val_acc: 0.7243\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.82411 to 0.81898, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.7647 - acc: 0.7625 - val_loss: 0.8073 - val_acc: 0.7325\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.81898 to 0.80730, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.7184 - acc: 0.7750 - val_loss: 0.7758 - val_acc: 0.7407\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.80730 to 0.77577, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.6975 - acc: 0.7934 - val_loss: 0.6968 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.77577 to 0.69676, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.6685 - acc: 0.7967 - val_loss: 0.6670 - val_acc: 0.7942\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.69676 to 0.66697, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.6499 - acc: 0.8020 - val_loss: 0.6408 - val_acc: 0.8272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00016: val_loss improved from 0.66697 to 0.64080, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.6184 - acc: 0.8289 - val_loss: 0.6393 - val_acc: 0.7942\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.64080 to 0.63932, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.5946 - acc: 0.8237 - val_loss: 0.6510 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.63932\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.5801 - acc: 0.8276 - val_loss: 0.5947 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.63932 to 0.59466, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.5528 - acc: 0.8428 - val_loss: 0.5484 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.59466 to 0.54837, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.5386 - acc: 0.8447 - val_loss: 0.5445 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.54837 to 0.54447, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.5209 - acc: 0.8441 - val_loss: 0.5585 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.54447\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.4994 - acc: 0.8612 - val_loss: 0.5245 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.54447 to 0.52451, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.4864 - acc: 0.8651 - val_loss: 0.4924 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.52451 to 0.49242, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.4720 - acc: 0.8783 - val_loss: 0.4932 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.49242\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.4532 - acc: 0.8842 - val_loss: 0.4971 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.49242\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.4394 - acc: 0.8849 - val_loss: 0.4704 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.49242 to 0.47038, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.4269 - acc: 0.8947 - val_loss: 0.4361 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.47038 to 0.43607, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.4184 - acc: 0.9039 - val_loss: 0.4114 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.43607 to 0.41142, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.3965 - acc: 0.9053 - val_loss: 0.4290 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.41142\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.3951 - acc: 0.9033 - val_loss: 0.3885 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.41142 to 0.38846, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.3719 - acc: 0.9184 - val_loss: 0.3831 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.38846 to 0.38313, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.3653 - acc: 0.9217 - val_loss: 0.3851 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.38313\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.3576 - acc: 0.9237 - val_loss: 0.3801 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.38313 to 0.38010, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.3467 - acc: 0.9191 - val_loss: 0.3818 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.38010\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.3336 - acc: 0.9276 - val_loss: 0.3759 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.38010 to 0.37587, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.3269 - acc: 0.9382 - val_loss: 0.3217 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.37587 to 0.32169, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.3165 - acc: 0.9368 - val_loss: 0.3307 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.32169\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.3090 - acc: 0.9388 - val_loss: 0.3146 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.32169 to 0.31456, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.2962 - acc: 0.9421 - val_loss: 0.3006 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.31456 to 0.30058, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.2876 - acc: 0.9526 - val_loss: 0.3061 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.30058\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.2819 - acc: 0.9553 - val_loss: 0.2977 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.30058 to 0.29771, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.2780 - acc: 0.9493 - val_loss: 0.2928 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.29771 to 0.29278, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.2646 - acc: 0.9566 - val_loss: 0.2919 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.29278 to 0.29192, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.2642 - acc: 0.9546 - val_loss: 0.2912 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.29192 to 0.29115, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.2572 - acc: 0.9605 - val_loss: 0.2631 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.29115 to 0.26310, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.2413 - acc: 0.9645 - val_loss: 0.3128 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.26310\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.2378 - acc: 0.9664 - val_loss: 0.2463 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.26310 to 0.24631, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.2352 - acc: 0.9638 - val_loss: 0.2536 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.24631\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.2216 - acc: 0.9724 - val_loss: 0.2274 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.24631 to 0.22739, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.2148 - acc: 0.9763 - val_loss: 0.2261 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.22739 to 0.22611, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.2139 - acc: 0.9743 - val_loss: 0.2422 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.22611\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.2093 - acc: 0.9757 - val_loss: 0.2241 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.22611 to 0.22411, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1992 - acc: 0.9783 - val_loss: 0.2209 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.22411 to 0.22088, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1981 - acc: 0.9789 - val_loss: 0.2085 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.22088 to 0.20850, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1906 - acc: 0.9789 - val_loss: 0.2053 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.20850 to 0.20527, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1907 - acc: 0.9789 - val_loss: 0.2110 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.20527\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1778 - acc: 0.9783 - val_loss: 0.1985 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.20527 to 0.19849, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1777 - acc: 0.9829 - val_loss: 0.2083 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.19849\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1708 - acc: 0.9849 - val_loss: 0.1805 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.19849 to 0.18049, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1698 - acc: 0.9822 - val_loss: 0.1747 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.18049 to 0.17473, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1604 - acc: 0.9888 - val_loss: 0.2055 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.17473\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1576 - acc: 0.9868 - val_loss: 0.1791 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.17473\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1567 - acc: 0.9849 - val_loss: 0.1858 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.17473\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1455 - acc: 0.9908 - val_loss: 0.1660 - val_acc: 0.9835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00065: val_loss improved from 0.17473 to 0.16599, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1448 - acc: 0.9882 - val_loss: 0.1673 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.16599\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1433 - acc: 0.9888 - val_loss: 0.1711 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.16599\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1418 - acc: 0.9901 - val_loss: 0.1495 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.16599 to 0.14953, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1336 - acc: 0.9908 - val_loss: 0.1421 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.14953 to 0.14207, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1292 - acc: 0.9901 - val_loss: 0.1544 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.14207\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1303 - acc: 0.9908 - val_loss: 0.1384 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.14207 to 0.13840, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1252 - acc: 0.9921 - val_loss: 0.1515 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.13840\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1193 - acc: 0.9954 - val_loss: 0.1280 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.13840 to 0.12800, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1205 - acc: 0.9921 - val_loss: 0.1344 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.12800\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1160 - acc: 0.9934 - val_loss: 0.1460 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.12800\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1128 - acc: 0.9934 - val_loss: 0.1298 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.12800\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1072 - acc: 0.9954 - val_loss: 0.1233 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.12800 to 0.12330, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.1120 - acc: 0.9921 - val_loss: 0.1450 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.12330\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.1028 - acc: 0.9941 - val_loss: 0.1221 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.12330 to 0.12214, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.1015 - acc: 0.9934 - val_loss: 0.1094 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.12214 to 0.10942, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0998 - acc: 0.9947 - val_loss: 0.1212 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.10942\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0978 - acc: 0.9967 - val_loss: 0.1048 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.10942 to 0.10477, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0928 - acc: 0.9954 - val_loss: 0.1118 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.10477\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0923 - acc: 0.9961 - val_loss: 0.1151 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.10477\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0871 - acc: 0.9967 - val_loss: 0.1032 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.10477 to 0.10319, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0863 - acc: 0.9954 - val_loss: 0.1253 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.10319\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0829 - acc: 0.9961 - val_loss: 0.1039 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.10319\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0836 - acc: 0.9967 - val_loss: 0.1032 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.10319 to 0.10317, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0824 - acc: 0.9974 - val_loss: 0.0996 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.10317 to 0.09963, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0795 - acc: 0.9954 - val_loss: 0.1014 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.09963\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0766 - acc: 0.9961 - val_loss: 0.1030 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.09963\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0752 - acc: 0.9980 - val_loss: 0.0892 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.09963 to 0.08917, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0736 - acc: 0.9954 - val_loss: 0.0936 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.08917\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0728 - acc: 0.9980 - val_loss: 0.1020 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.08917\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0708 - acc: 0.9974 - val_loss: 0.1026 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.08917\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0676 - acc: 0.9974 - val_loss: 0.0945 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.08917\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0667 - acc: 0.9974 - val_loss: 0.0865 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.08917 to 0.08646, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0647 - acc: 0.9967 - val_loss: 0.0851 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.08646 to 0.08511, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0629 - acc: 0.9980 - val_loss: 0.0868 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.08511\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0618 - acc: 0.9974 - val_loss: 0.0907 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.08511\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0628 - acc: 0.9961 - val_loss: 0.0745 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.08511 to 0.07448, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0588 - acc: 0.9987 - val_loss: 0.0764 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.07448\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0589 - acc: 0.9967 - val_loss: 0.1066 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.07448\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0578 - acc: 0.9974 - val_loss: 0.0813 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.07448\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0534 - acc: 0.9980 - val_loss: 0.0654 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.07448 to 0.06538, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0548 - acc: 0.9980 - val_loss: 0.0708 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.06538\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0539 - acc: 0.9967 - val_loss: 0.0831 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.06538\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0511 - acc: 0.9974 - val_loss: 0.0649 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.06538 to 0.06489, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0506 - acc: 0.9967 - val_loss: 0.0914 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.06489\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0480 - acc: 0.9967 - val_loss: 0.0623 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.06489 to 0.06227, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0482 - acc: 0.9974 - val_loss: 0.0650 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.06227\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0478 - acc: 0.9967 - val_loss: 0.0812 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.06227\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0465 - acc: 0.9980 - val_loss: 0.0658 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.06227\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0442 - acc: 0.9980 - val_loss: 0.0669 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.06227\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0452 - acc: 0.9974 - val_loss: 0.0650 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.06227\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0427 - acc: 0.9961 - val_loss: 0.0634 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.06227\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0432 - acc: 0.9980 - val_loss: 0.0718 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.06227\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0417 - acc: 0.9967 - val_loss: 0.0586 - val_acc: 0.9959\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00118: val_loss improved from 0.06227 to 0.05864, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0407 - acc: 0.9980 - val_loss: 0.0589 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.05864\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0386 - acc: 0.9974 - val_loss: 0.0664 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.05864\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0386 - acc: 0.9974 - val_loss: 0.0636 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.05864\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0387 - acc: 0.9974 - val_loss: 0.0620 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.05864\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0367 - acc: 0.9961 - val_loss: 0.0685 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.05864\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0371 - acc: 0.9967 - val_loss: 0.0540 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.05864 to 0.05402, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0364 - acc: 0.9974 - val_loss: 0.0513 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.05402 to 0.05133, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0350 - acc: 0.9980 - val_loss: 0.0604 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.05133\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0346 - acc: 0.9980 - val_loss: 0.0539 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.05133\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0335 - acc: 0.9974 - val_loss: 0.0671 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.05133\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0326 - acc: 0.9967 - val_loss: 0.0608 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.05133\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0329 - acc: 0.9967 - val_loss: 0.0628 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.05133\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0324 - acc: 0.9974 - val_loss: 0.0580 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.05133\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0305 - acc: 0.9980 - val_loss: 0.0477 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.05133 to 0.04770, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0302 - acc: 0.9980 - val_loss: 0.0478 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.04770\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0287 - acc: 0.9967 - val_loss: 0.0493 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.04770\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0292 - acc: 0.9980 - val_loss: 0.0518 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.04770\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0283 - acc: 0.9974 - val_loss: 0.0510 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.04770\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0288 - acc: 0.9974 - val_loss: 0.0539 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.04770\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0273 - acc: 0.9961 - val_loss: 0.0472 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.04770 to 0.04722, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0277 - acc: 0.9967 - val_loss: 0.0434 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.04722 to 0.04338, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0264 - acc: 0.9967 - val_loss: 0.0507 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.04338\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0259 - acc: 0.9974 - val_loss: 0.0533 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.04338\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0270 - acc: 0.9967 - val_loss: 0.0399 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.04338 to 0.03991, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0251 - acc: 0.9974 - val_loss: 0.0463 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.03991\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0254 - acc: 0.9974 - val_loss: 0.0469 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.03991\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0247 - acc: 0.9967 - val_loss: 0.0646 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.03991\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0245 - acc: 0.9967 - val_loss: 0.0390 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.03991 to 0.03895, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0226 - acc: 0.9974 - val_loss: 0.0564 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.03895\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0240 - acc: 0.9974 - val_loss: 0.0470 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.03895\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0226 - acc: 0.9967 - val_loss: 0.0462 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.03895\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0217 - acc: 0.9974 - val_loss: 0.0444 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.03895\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0226 - acc: 0.9974 - val_loss: 0.0433 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.03895\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0219 - acc: 0.9974 - val_loss: 0.0487 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.03895\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0210 - acc: 0.9967 - val_loss: 0.0362 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.03895 to 0.03618, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0206 - acc: 0.9967 - val_loss: 0.0482 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.03618\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.0195 - acc: 0.9980 - val_loss: 0.0451 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.03618\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.0214 - acc: 0.9974 - val_loss: 0.0504 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.03618\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0195 - acc: 0.9967 - val_loss: 0.0446 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.03618\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.0207 - acc: 0.9967 - val_loss: 0.0353 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.03618 to 0.03532, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.0191 - acc: 0.9980 - val_loss: 0.0464 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.03532\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.0189 - acc: 0.9967 - val_loss: 0.0432 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.03532\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.0196 - acc: 0.9961 - val_loss: 0.0356 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.03532\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.0180 - acc: 0.9980 - val_loss: 0.0365 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.03532\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.0184 - acc: 0.9967 - val_loss: 0.0389 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.03532\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.0167 - acc: 0.9980 - val_loss: 0.0460 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.03532\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.0180 - acc: 0.9961 - val_loss: 0.0363 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.03532\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.0178 - acc: 0.9967 - val_loss: 0.0358 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.03532\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.0169 - acc: 0.9974 - val_loss: 0.0343 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.03532 to 0.03434, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.0172 - acc: 0.9974 - val_loss: 0.0438 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.03434\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.0158 - acc: 0.9974 - val_loss: 0.0399 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.03434\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.0162 - acc: 0.9967 - val_loss: 0.0368 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.03434\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.0164 - acc: 0.9961 - val_loss: 0.0322 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00171: val_loss improved from 0.03434 to 0.03222, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.0169 - acc: 0.9961 - val_loss: 0.0377 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.03222\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.0154 - acc: 0.9974 - val_loss: 0.0326 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.03222\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.0151 - acc: 0.9967 - val_loss: 0.0298 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.03222 to 0.02982, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.0151 - acc: 0.9974 - val_loss: 0.0384 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.02982\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.0143 - acc: 0.9974 - val_loss: 0.0369 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.02982\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.0148 - acc: 0.9987 - val_loss: 0.0420 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.02982\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.0145 - acc: 0.9974 - val_loss: 0.0379 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.02982\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.0140 - acc: 0.9974 - val_loss: 0.0441 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.02982\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.0143 - acc: 0.9967 - val_loss: 0.0354 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.02982\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.0140 - acc: 0.9967 - val_loss: 0.0342 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.02982\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.0142 - acc: 0.9961 - val_loss: 0.0305 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.02982\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.0134 - acc: 0.9961 - val_loss: 0.0379 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.02982\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.0129 - acc: 0.9974 - val_loss: 0.0325 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.02982\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.0134 - acc: 0.9980 - val_loss: 0.0371 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.02982\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.0123 - acc: 0.9980 - val_loss: 0.0318 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.02982\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.0131 - acc: 0.9974 - val_loss: 0.0438 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.02982\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.0127 - acc: 0.9974 - val_loss: 0.0272 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00188: val_loss improved from 0.02982 to 0.02717, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.0131 - acc: 0.9967 - val_loss: 0.0372 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.02717\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.0128 - acc: 0.9967 - val_loss: 0.0385 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.02717\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.0127 - acc: 0.9967 - val_loss: 0.0375 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.02717\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.0119 - acc: 0.9967 - val_loss: 0.0330 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.02717\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.0126 - acc: 0.9980 - val_loss: 0.0352 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.02717\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.0115 - acc: 0.9974 - val_loss: 0.0311 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.02717\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.0119 - acc: 0.9980 - val_loss: 0.0285 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.02717\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.0116 - acc: 0.9974 - val_loss: 0.0318 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.02717\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.0116 - acc: 0.9974 - val_loss: 0.0294 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.02717\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.0119 - acc: 0.9974 - val_loss: 0.0345 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.02717\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.0114 - acc: 0.9961 - val_loss: 0.0346 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.02717\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.0110 - acc: 0.9980 - val_loss: 0.0353 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.02717\n",
      "batch_size=120   optimizer=RMSprop\n",
      "Test accuracy: 68.8022%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 2.0334 - acc: 0.2737 - val_loss: 1.6942 - val_acc: 0.3909\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.69418, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.5774 - acc: 0.4684 - val_loss: 1.4646 - val_acc: 0.5103\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.69418 to 1.46462, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 1.3732 - acc: 0.5428 - val_loss: 1.2934 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.46462 to 1.29337, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 1.2358 - acc: 0.5987 - val_loss: 1.2451 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.29337 to 1.24511, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 1.1512 - acc: 0.6276 - val_loss: 1.1424 - val_acc: 0.6091\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.24511 to 1.14236, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 1.0772 - acc: 0.6447 - val_loss: 1.0469 - val_acc: 0.6543\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.14236 to 1.04690, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 1.0101 - acc: 0.6658 - val_loss: 1.0117 - val_acc: 0.6831\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.04690 to 1.01175, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.9550 - acc: 0.6921 - val_loss: 0.9759 - val_acc: 0.6584\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.01175 to 0.97585, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.9109 - acc: 0.6974 - val_loss: 0.9795 - val_acc: 0.6584\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.97585\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.8764 - acc: 0.7158 - val_loss: 0.8822 - val_acc: 0.6914\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.97585 to 0.88222, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.8461 - acc: 0.7230 - val_loss: 0.8662 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.88222 to 0.86617, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.7934 - acc: 0.7349 - val_loss: 0.8145 - val_acc: 0.7654\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.86617 to 0.81454, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.7739 - acc: 0.7559 - val_loss: 0.7891 - val_acc: 0.7449\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.81454 to 0.78909, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.7456 - acc: 0.7697 - val_loss: 0.7512 - val_acc: 0.7572\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.78909 to 0.75123, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.7204 - acc: 0.7743 - val_loss: 0.7938 - val_acc: 0.7160\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.75123\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.7044 - acc: 0.7750 - val_loss: 0.7055 - val_acc: 0.7737\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.75123 to 0.70546, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.6768 - acc: 0.7901 - val_loss: 0.7477 - val_acc: 0.7695\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.70546\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.6536 - acc: 0.8033 - val_loss: 0.7013 - val_acc: 0.7572\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.70546 to 0.70133, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.6412 - acc: 0.8046 - val_loss: 0.6601 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.70133 to 0.66008, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.6094 - acc: 0.8204 - val_loss: 0.6841 - val_acc: 0.7819\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.66008\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.5974 - acc: 0.8158 - val_loss: 0.6134 - val_acc: 0.8107\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.66008 to 0.61335, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.5837 - acc: 0.8283 - val_loss: 0.5916 - val_acc: 0.8436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00022: val_loss improved from 0.61335 to 0.59159, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.5665 - acc: 0.8289 - val_loss: 0.5741 - val_acc: 0.8354\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.59159 to 0.57411, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.5441 - acc: 0.8401 - val_loss: 0.6055 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.57411\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.5315 - acc: 0.8539 - val_loss: 0.6346 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.57411\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.5199 - acc: 0.8454 - val_loss: 0.5437 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.57411 to 0.54370, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.4957 - acc: 0.8625 - val_loss: 0.5202 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.54370 to 0.52016, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.4868 - acc: 0.8684 - val_loss: 0.5584 - val_acc: 0.8107\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.52016\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.4776 - acc: 0.8717 - val_loss: 0.4961 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.52016 to 0.49610, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.4575 - acc: 0.8776 - val_loss: 0.4805 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.49610 to 0.48047, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.4485 - acc: 0.8868 - val_loss: 0.5048 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.48047\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.4396 - acc: 0.8822 - val_loss: 0.4425 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.48047 to 0.44251, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.4225 - acc: 0.8934 - val_loss: 0.4389 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.44251 to 0.43889, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.4112 - acc: 0.8987 - val_loss: 0.4399 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.43889\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.3987 - acc: 0.9086 - val_loss: 0.4059 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.43889 to 0.40591, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.3959 - acc: 0.9000 - val_loss: 0.3840 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.40591 to 0.38403, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.3808 - acc: 0.9171 - val_loss: 0.3989 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.38403\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.3796 - acc: 0.9099 - val_loss: 0.4009 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.38403\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.3611 - acc: 0.9191 - val_loss: 0.3925 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.38403\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.3598 - acc: 0.9197 - val_loss: 0.4290 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.38403\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.3499 - acc: 0.9151 - val_loss: 0.3899 - val_acc: 0.9012\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.38403\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.3443 - acc: 0.9263 - val_loss: 0.3461 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.38403 to 0.34611, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.3282 - acc: 0.9368 - val_loss: 0.3701 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.34611\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.3241 - acc: 0.9355 - val_loss: 0.3344 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.34611 to 0.33441, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.3131 - acc: 0.9395 - val_loss: 0.3238 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.33441 to 0.32384, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.3010 - acc: 0.9447 - val_loss: 0.3187 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.32384 to 0.31869, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.3088 - acc: 0.9388 - val_loss: 0.3263 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.31869\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.2922 - acc: 0.9493 - val_loss: 0.3260 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.31869\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.2817 - acc: 0.9480 - val_loss: 0.3188 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.31869\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.2743 - acc: 0.9572 - val_loss: 0.3383 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.31869\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.2823 - acc: 0.9454 - val_loss: 0.2836 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.31869 to 0.28364, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.2666 - acc: 0.9553 - val_loss: 0.2933 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.28364\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.2541 - acc: 0.9625 - val_loss: 0.2861 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.28364\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.2542 - acc: 0.9671 - val_loss: 0.2671 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.28364 to 0.26713, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.2432 - acc: 0.9697 - val_loss: 0.2794 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.26713\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.2404 - acc: 0.9678 - val_loss: 0.2598 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.26713 to 0.25985, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.2417 - acc: 0.9612 - val_loss: 0.2534 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.25985 to 0.25340, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.2275 - acc: 0.9776 - val_loss: 0.2422 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.25340 to 0.24222, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.2214 - acc: 0.9730 - val_loss: 0.2577 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.24222\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.2180 - acc: 0.9678 - val_loss: 0.2665 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.24222\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.2149 - acc: 0.9750 - val_loss: 0.2357 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.24222 to 0.23571, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.2098 - acc: 0.9717 - val_loss: 0.2301 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.23571 to 0.23006, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.2037 - acc: 0.9783 - val_loss: 0.2590 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.23006\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.2027 - acc: 0.9717 - val_loss: 0.2264 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.23006 to 0.22639, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1937 - acc: 0.9803 - val_loss: 0.2054 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.22639 to 0.20542, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1882 - acc: 0.9796 - val_loss: 0.1988 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.20542 to 0.19884, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1903 - acc: 0.9776 - val_loss: 0.2078 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.19884\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1838 - acc: 0.9796 - val_loss: 0.1963 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.19884 to 0.19634, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1788 - acc: 0.9816 - val_loss: 0.1964 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.19634\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1711 - acc: 0.9836 - val_loss: 0.1877 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.19634 to 0.18772, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1721 - acc: 0.9868 - val_loss: 0.1889 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.18772\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1671 - acc: 0.9829 - val_loss: 0.1765 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.18772 to 0.17652, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1593 - acc: 0.9868 - val_loss: 0.1703 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.17652 to 0.17027, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1639 - acc: 0.9822 - val_loss: 0.1822 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.17027\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1550 - acc: 0.9901 - val_loss: 0.1654 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.17027 to 0.16542, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1512 - acc: 0.9868 - val_loss: 0.1666 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.16542\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1476 - acc: 0.9895 - val_loss: 0.1751 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.16542\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.1473 - acc: 0.9875 - val_loss: 0.1543 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.16542 to 0.15429, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.1392 - acc: 0.9934 - val_loss: 0.1688 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.15429\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.1473 - acc: 0.9875 - val_loss: 0.1550 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.15429\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.1341 - acc: 0.9934 - val_loss: 0.1718 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.15429\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.1310 - acc: 0.9908 - val_loss: 0.1494 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.15429 to 0.14941, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.1316 - acc: 0.9928 - val_loss: 0.1597 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.14941\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.1300 - acc: 0.9901 - val_loss: 0.1589 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.14941\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.1225 - acc: 0.9914 - val_loss: 0.1456 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.14941 to 0.14558, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.1252 - acc: 0.9888 - val_loss: 0.1509 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.14558\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.1180 - acc: 0.9914 - val_loss: 0.1440 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.14558 to 0.14398, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.1137 - acc: 0.9967 - val_loss: 0.1403 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.14398 to 0.14034, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.1175 - acc: 0.9947 - val_loss: 0.1245 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.14034 to 0.12447, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.1096 - acc: 0.9947 - val_loss: 0.1605 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.12447\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.1115 - acc: 0.9954 - val_loss: 0.1247 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.12447\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.1054 - acc: 0.9954 - val_loss: 0.1292 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.12447\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.1039 - acc: 0.9954 - val_loss: 0.1242 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.12447 to 0.12415, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.1079 - acc: 0.9934 - val_loss: 0.1439 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.12415\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.1006 - acc: 0.9947 - val_loss: 0.1201 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.12415 to 0.12009, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0972 - acc: 0.9961 - val_loss: 0.1249 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.12009\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0979 - acc: 0.9967 - val_loss: 0.1149 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.12009 to 0.11487, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0911 - acc: 0.9961 - val_loss: 0.1197 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.11487\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0919 - acc: 0.9974 - val_loss: 0.1081 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.11487 to 0.10809, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0907 - acc: 0.9954 - val_loss: 0.1228 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.10809\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0896 - acc: 0.9980 - val_loss: 0.1052 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.10809 to 0.10519, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0841 - acc: 0.9967 - val_loss: 0.1109 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.10519\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0870 - acc: 0.9954 - val_loss: 0.1108 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.10519\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0831 - acc: 0.9961 - val_loss: 0.1233 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.10519\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0826 - acc: 0.9954 - val_loss: 0.1002 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.10519 to 0.10016, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0780 - acc: 0.9974 - val_loss: 0.0964 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.10016 to 0.09644, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0801 - acc: 0.9961 - val_loss: 0.1060 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.09644\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0780 - acc: 0.9967 - val_loss: 0.1128 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.09644\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0774 - acc: 0.9947 - val_loss: 0.0910 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.09644 to 0.09096, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0708 - acc: 0.9987 - val_loss: 0.0924 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.09096\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0741 - acc: 0.9980 - val_loss: 0.1011 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.09096\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0719 - acc: 0.9967 - val_loss: 0.0904 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.09096 to 0.09039, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0693 - acc: 0.9967 - val_loss: 0.0868 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.09039 to 0.08679, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0671 - acc: 0.9974 - val_loss: 0.0867 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.08679 to 0.08669, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0693 - acc: 0.9967 - val_loss: 0.0946 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.08669\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0649 - acc: 0.9974 - val_loss: 0.0802 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.08669 to 0.08022, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0636 - acc: 0.9980 - val_loss: 0.0860 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.08022\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0640 - acc: 0.9980 - val_loss: 0.0831 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.08022\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0627 - acc: 0.9993 - val_loss: 0.0786 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.08022 to 0.07862, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0602 - acc: 0.9980 - val_loss: 0.0772 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.07862 to 0.07725, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0588 - acc: 0.9974 - val_loss: 0.0974 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.07725\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0568 - acc: 0.9980 - val_loss: 0.0783 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.07725\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0612 - acc: 0.9967 - val_loss: 0.0792 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.07725\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0555 - acc: 0.9980 - val_loss: 0.0825 - val_acc: 0.9918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00124: val_loss did not improve from 0.07725\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0527 - acc: 0.9974 - val_loss: 0.0804 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.07725\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0542 - acc: 0.9980 - val_loss: 0.0823 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.07725\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0533 - acc: 0.9980 - val_loss: 0.0882 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.07725\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0515 - acc: 0.9980 - val_loss: 0.0788 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.07725\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0500 - acc: 0.9980 - val_loss: 0.0732 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.07725 to 0.07317, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0494 - acc: 0.9980 - val_loss: 0.0665 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.07317 to 0.06652, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0492 - acc: 0.9974 - val_loss: 0.0726 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.06652\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0462 - acc: 0.9987 - val_loss: 0.0776 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.06652\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0487 - acc: 0.9974 - val_loss: 0.0795 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.06652\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0455 - acc: 0.9967 - val_loss: 0.0752 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.06652\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0449 - acc: 0.9987 - val_loss: 0.0805 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.06652\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0470 - acc: 0.9974 - val_loss: 0.0699 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.06652\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0434 - acc: 0.9967 - val_loss: 0.0661 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.06652 to 0.06613, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0412 - acc: 0.9974 - val_loss: 0.0662 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.06613\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0433 - acc: 0.9967 - val_loss: 0.0535 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.06613 to 0.05347, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0426 - acc: 0.9967 - val_loss: 0.0735 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.05347\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0409 - acc: 0.9987 - val_loss: 0.0755 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.05347\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0392 - acc: 0.9974 - val_loss: 0.0761 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.05347\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0415 - acc: 0.9967 - val_loss: 0.0578 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.05347\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0383 - acc: 0.9967 - val_loss: 0.0657 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.05347\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0376 - acc: 0.9980 - val_loss: 0.0639 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.05347\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0391 - acc: 0.9967 - val_loss: 0.0723 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.05347\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0376 - acc: 0.9974 - val_loss: 0.0569 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.05347\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0370 - acc: 0.9980 - val_loss: 0.0707 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.05347\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0339 - acc: 0.9980 - val_loss: 0.0703 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.05347\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0357 - acc: 0.9980 - val_loss: 0.0541 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.05347\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0352 - acc: 0.9980 - val_loss: 0.0606 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.05347\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0330 - acc: 0.9980 - val_loss: 0.0761 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.05347\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0344 - acc: 0.9974 - val_loss: 0.0527 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.05347 to 0.05269, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0310 - acc: 0.9980 - val_loss: 0.0570 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.05269\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.0318 - acc: 0.9974 - val_loss: 0.0535 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.05269\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.0314 - acc: 0.9967 - val_loss: 0.0680 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.05269\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0313 - acc: 0.9980 - val_loss: 0.0607 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.05269\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.0300 - acc: 0.9980 - val_loss: 0.0493 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.05269 to 0.04925, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.0304 - acc: 0.9974 - val_loss: 0.0645 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.04925\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.0286 - acc: 0.9974 - val_loss: 0.0638 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.04925\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.0283 - acc: 0.9980 - val_loss: 0.0630 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.04925\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.0316 - acc: 0.9974 - val_loss: 0.0638 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.04925\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.0274 - acc: 0.9980 - val_loss: 0.0613 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.04925\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.0278 - acc: 0.9974 - val_loss: 0.0475 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.04925 to 0.04753, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.0266 - acc: 0.9967 - val_loss: 0.0544 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.04753\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.0272 - acc: 0.9974 - val_loss: 0.0606 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.04753\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.0275 - acc: 0.9967 - val_loss: 0.0451 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.04753 to 0.04507, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.0253 - acc: 0.9974 - val_loss: 0.0516 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.04507\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.0255 - acc: 0.9974 - val_loss: 0.0527 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.04507\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.0249 - acc: 0.9974 - val_loss: 0.0606 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.04507\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.0254 - acc: 0.9967 - val_loss: 0.0456 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.04507\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.0239 - acc: 0.9974 - val_loss: 0.0453 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.04507\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.0235 - acc: 0.9974 - val_loss: 0.0487 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.04507\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.0240 - acc: 0.9967 - val_loss: 0.0456 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.04507\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.0227 - acc: 0.9974 - val_loss: 0.0455 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.04507\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.0232 - acc: 0.9967 - val_loss: 0.0453 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.04507\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.0224 - acc: 0.9967 - val_loss: 0.0376 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00177: val_loss improved from 0.04507 to 0.03757, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.0220 - acc: 0.9974 - val_loss: 0.0409 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.03757\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.0222 - acc: 0.9974 - val_loss: 0.0492 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.03757\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.0223 - acc: 0.9974 - val_loss: 0.0516 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.03757\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.0210 - acc: 0.9967 - val_loss: 0.0345 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00181: val_loss improved from 0.03757 to 0.03451, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.0212 - acc: 0.9980 - val_loss: 0.0418 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.03451\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.0199 - acc: 0.9974 - val_loss: 0.0442 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.03451\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.0201 - acc: 0.9974 - val_loss: 0.0484 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.03451\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.0201 - acc: 0.9980 - val_loss: 0.0408 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.03451\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.0202 - acc: 0.9967 - val_loss: 0.0442 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.03451\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.0192 - acc: 0.9974 - val_loss: 0.0416 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.03451\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.0194 - acc: 0.9967 - val_loss: 0.0377 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.03451\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.0187 - acc: 0.9980 - val_loss: 0.0509 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.03451\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.0190 - acc: 0.9967 - val_loss: 0.0418 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.03451\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.0184 - acc: 0.9967 - val_loss: 0.0487 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.03451\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.0185 - acc: 0.9980 - val_loss: 0.0522 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.03451\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.0176 - acc: 0.9974 - val_loss: 0.0416 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.03451\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.0171 - acc: 0.9974 - val_loss: 0.0532 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.03451\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.0178 - acc: 0.9967 - val_loss: 0.0572 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.03451\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.0181 - acc: 0.9980 - val_loss: 0.0480 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.03451\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.0173 - acc: 0.9974 - val_loss: 0.0421 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.03451\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.0162 - acc: 0.9980 - val_loss: 0.0391 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.03451\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.0180 - acc: 0.9974 - val_loss: 0.0435 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.03451\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.0163 - acc: 0.9967 - val_loss: 0.0431 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.03451\n",
      "batch_size=160   optimizer=RMSprop\n",
      "Test accuracy: 68.5237%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_26 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 2.2643 - acc: 0.1941 - val_loss: 1.9029 - val_acc: 0.3210\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.90294, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.7612 - acc: 0.3717 - val_loss: 1.6154 - val_acc: 0.4280\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.90294 to 1.61538, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 1.5345 - acc: 0.4750 - val_loss: 1.4425 - val_acc: 0.5473\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.61538 to 1.44250, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 1.3754 - acc: 0.5559 - val_loss: 1.3238 - val_acc: 0.5802\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.44250 to 1.32381, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 1.2548 - acc: 0.6026 - val_loss: 1.2214 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.32381 to 1.22144, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 1.1702 - acc: 0.6145 - val_loss: 1.2108 - val_acc: 0.5802\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.22144 to 1.21078, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 1.1046 - acc: 0.6526 - val_loss: 1.0787 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.21078 to 1.07869, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 0s - loss: 1.0361 - acc: 0.6737 - val_loss: 1.0774 - val_acc: 0.6420\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.07869 to 1.07745, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 0s - loss: 1.0083 - acc: 0.6776 - val_loss: 0.9951 - val_acc: 0.6749\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.07745 to 0.99512, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.9434 - acc: 0.7000 - val_loss: 0.9400 - val_acc: 0.7078\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.99512 to 0.94001, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.9048 - acc: 0.7178 - val_loss: 0.9436 - val_acc: 0.7119\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.94001\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.8813 - acc: 0.7296 - val_loss: 0.9089 - val_acc: 0.7119\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.94001 to 0.90894, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.8373 - acc: 0.7375 - val_loss: 0.8946 - val_acc: 0.6914\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.90894 to 0.89458, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.8180 - acc: 0.7414 - val_loss: 0.8332 - val_acc: 0.7160\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.89458 to 0.83324, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.7872 - acc: 0.7599 - val_loss: 0.8387 - val_acc: 0.7366\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.83324\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.7577 - acc: 0.7711 - val_loss: 0.7684 - val_acc: 0.7572\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.83324 to 0.76836, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.7338 - acc: 0.7697 - val_loss: 0.7812 - val_acc: 0.7572\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.76836\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.7025 - acc: 0.7862 - val_loss: 0.7170 - val_acc: 0.7942\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.76836 to 0.71700, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.7062 - acc: 0.7789 - val_loss: 0.7165 - val_acc: 0.7737\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.71700 to 0.71647, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.6739 - acc: 0.8007 - val_loss: 0.6821 - val_acc: 0.7860\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.71647 to 0.68212, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.6544 - acc: 0.8020 - val_loss: 0.7138 - val_acc: 0.7613\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.68212\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.6306 - acc: 0.8105 - val_loss: 0.6446 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.68212 to 0.64465, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.6172 - acc: 0.8092 - val_loss: 0.6293 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.64465 to 0.62932, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.6036 - acc: 0.8184 - val_loss: 0.6305 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.62932\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.5883 - acc: 0.8237 - val_loss: 0.5841 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.62932 to 0.58409, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.5646 - acc: 0.8289 - val_loss: 0.5871 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.58409\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.5600 - acc: 0.8447 - val_loss: 0.5994 - val_acc: 0.8107\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.58409\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.5389 - acc: 0.8480 - val_loss: 0.6321 - val_acc: 0.8025\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00028: val_loss did not improve from 0.58409\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.5314 - acc: 0.8474 - val_loss: 0.5271 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.58409 to 0.52712, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.5138 - acc: 0.8592 - val_loss: 0.5539 - val_acc: 0.8354\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.52712\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.5046 - acc: 0.8572 - val_loss: 0.5121 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.52712 to 0.51214, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.4929 - acc: 0.8592 - val_loss: 0.4993 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.51214 to 0.49929, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.4765 - acc: 0.8717 - val_loss: 0.4788 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.49929 to 0.47882, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.4643 - acc: 0.8763 - val_loss: 0.5205 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.47882\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.4595 - acc: 0.8803 - val_loss: 0.4709 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.47882 to 0.47089, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.4436 - acc: 0.8888 - val_loss: 0.4510 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.47089 to 0.45097, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.4312 - acc: 0.8895 - val_loss: 0.4518 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.45097\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.4311 - acc: 0.8967 - val_loss: 0.4478 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.45097 to 0.44780, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.4192 - acc: 0.8928 - val_loss: 0.4308 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.44780 to 0.43078, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.4033 - acc: 0.9046 - val_loss: 0.4388 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.43078\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.3946 - acc: 0.9033 - val_loss: 0.4518 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.43078\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.3933 - acc: 0.9066 - val_loss: 0.4278 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.43078 to 0.42780, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.3790 - acc: 0.9224 - val_loss: 0.4058 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.42780 to 0.40583, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.3738 - acc: 0.9125 - val_loss: 0.4010 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.40583 to 0.40103, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.3680 - acc: 0.9145 - val_loss: 0.3896 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.40103 to 0.38955, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.3567 - acc: 0.9224 - val_loss: 0.3728 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.38955 to 0.37278, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.3485 - acc: 0.9224 - val_loss: 0.3579 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.37278 to 0.35792, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.3419 - acc: 0.9257 - val_loss: 0.3693 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.35792\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.3365 - acc: 0.9316 - val_loss: 0.3603 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.35792\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.3264 - acc: 0.9296 - val_loss: 0.3364 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.35792 to 0.33636, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.3193 - acc: 0.9375 - val_loss: 0.3269 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.33636 to 0.32693, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.3130 - acc: 0.9349 - val_loss: 0.3163 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.32693 to 0.31634, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.3063 - acc: 0.9434 - val_loss: 0.3401 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.31634\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.2988 - acc: 0.9447 - val_loss: 0.3186 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.31634\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.2977 - acc: 0.9408 - val_loss: 0.3123 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.31634 to 0.31227, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.2928 - acc: 0.9454 - val_loss: 0.3279 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.31227\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.2768 - acc: 0.9533 - val_loss: 0.2923 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.31227 to 0.29228, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.2687 - acc: 0.9553 - val_loss: 0.3018 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.29228\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.2725 - acc: 0.9493 - val_loss: 0.2869 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.29228 to 0.28691, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.2614 - acc: 0.9605 - val_loss: 0.2816 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.28691 to 0.28161, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.2569 - acc: 0.9592 - val_loss: 0.2800 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.28161 to 0.28000, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.2483 - acc: 0.9658 - val_loss: 0.2875 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.28000\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.2519 - acc: 0.9612 - val_loss: 0.2659 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.28000 to 0.26591, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.2424 - acc: 0.9658 - val_loss: 0.2674 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.26591\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.2396 - acc: 0.9638 - val_loss: 0.2560 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.26591 to 0.25596, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.2288 - acc: 0.9743 - val_loss: 0.2602 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.25596\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.2279 - acc: 0.9704 - val_loss: 0.2376 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.25596 to 0.23763, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.2195 - acc: 0.9711 - val_loss: 0.2531 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.23763\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.2287 - acc: 0.9612 - val_loss: 0.2403 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.23763\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.2117 - acc: 0.9750 - val_loss: 0.2409 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.23763\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.2130 - acc: 0.9724 - val_loss: 0.2466 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.23763\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.2046 - acc: 0.9770 - val_loss: 0.2372 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.23763 to 0.23717, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1993 - acc: 0.9776 - val_loss: 0.2350 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.23717 to 0.23501, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.2025 - acc: 0.9737 - val_loss: 0.2149 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.23501 to 0.21488, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1976 - acc: 0.9789 - val_loss: 0.2068 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.21488 to 0.20681, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1843 - acc: 0.9849 - val_loss: 0.2081 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.20681\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1916 - acc: 0.9789 - val_loss: 0.2049 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.20681 to 0.20487, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.1813 - acc: 0.9803 - val_loss: 0.2005 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.20487 to 0.20047, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.1810 - acc: 0.9789 - val_loss: 0.2100 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.20047\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.1742 - acc: 0.9849 - val_loss: 0.1912 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.20047 to 0.19116, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.1734 - acc: 0.9829 - val_loss: 0.2037 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.19116\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.1700 - acc: 0.9862 - val_loss: 0.1807 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.19116 to 0.18074, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.1686 - acc: 0.9855 - val_loss: 0.1847 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.18074\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.1630 - acc: 0.9862 - val_loss: 0.1750 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.18074 to 0.17503, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.1542 - acc: 0.9895 - val_loss: 0.1766 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.17503\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.1599 - acc: 0.9842 - val_loss: 0.1833 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.17503\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.1518 - acc: 0.9882 - val_loss: 0.1777 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.17503\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.1519 - acc: 0.9829 - val_loss: 0.1661 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.17503 to 0.16610, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.1456 - acc: 0.9895 - val_loss: 0.1597 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.16610 to 0.15968, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.1428 - acc: 0.9862 - val_loss: 0.1729 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.15968\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.1400 - acc: 0.9882 - val_loss: 0.1589 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.15968 to 0.15888, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.1411 - acc: 0.9895 - val_loss: 0.1674 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.15888\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.1345 - acc: 0.9914 - val_loss: 0.1616 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.15888\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.1333 - acc: 0.9914 - val_loss: 0.1474 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.15888 to 0.14743, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.1334 - acc: 0.9888 - val_loss: 0.1623 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.14743\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.1287 - acc: 0.9901 - val_loss: 0.1525 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.14743\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.1271 - acc: 0.9934 - val_loss: 0.1629 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.14743\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.1219 - acc: 0.9941 - val_loss: 0.1483 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.14743\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.1211 - acc: 0.9934 - val_loss: 0.1406 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.14743 to 0.14063, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.1252 - acc: 0.9914 - val_loss: 0.1350 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.14063 to 0.13500, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.1123 - acc: 0.9954 - val_loss: 0.1449 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.13500\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.1155 - acc: 0.9921 - val_loss: 0.1350 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.13500\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.1141 - acc: 0.9934 - val_loss: 0.1763 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.13500\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.1078 - acc: 0.9954 - val_loss: 0.1439 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.13500\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.1090 - acc: 0.9947 - val_loss: 0.1280 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.13500 to 0.12796, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.1098 - acc: 0.9914 - val_loss: 0.1508 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.12796\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.1026 - acc: 0.9974 - val_loss: 0.1271 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.12796 to 0.12705, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.1033 - acc: 0.9954 - val_loss: 0.1294 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.12705\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0979 - acc: 0.9980 - val_loss: 0.1231 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.12705 to 0.12314, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0992 - acc: 0.9947 - val_loss: 0.1239 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.12314\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0971 - acc: 0.9974 - val_loss: 0.1229 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.12314 to 0.12291, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0965 - acc: 0.9934 - val_loss: 0.1089 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.12291 to 0.10895, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0909 - acc: 0.9967 - val_loss: 0.1060 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.10895 to 0.10601, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0938 - acc: 0.9954 - val_loss: 0.1218 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.10601\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0892 - acc: 0.9980 - val_loss: 0.1142 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.10601\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0902 - acc: 0.9961 - val_loss: 0.1014 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.10601 to 0.10136, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0880 - acc: 0.9974 - val_loss: 0.1194 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.10136\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0869 - acc: 0.9967 - val_loss: 0.1106 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.10136\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0845 - acc: 0.9967 - val_loss: 0.1185 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.10136\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0796 - acc: 0.9967 - val_loss: 0.1021 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.10136\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0795 - acc: 0.9961 - val_loss: 0.1271 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.10136\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0813 - acc: 0.9947 - val_loss: 0.1049 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.10136\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0782 - acc: 0.9993 - val_loss: 0.0934 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.10136 to 0.09344, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0755 - acc: 0.9967 - val_loss: 0.1064 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.09344\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0749 - acc: 0.9967 - val_loss: 0.0998 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.09344\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0741 - acc: 0.9980 - val_loss: 0.0958 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.09344\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0752 - acc: 0.9954 - val_loss: 0.1005 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.09344\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0726 - acc: 0.9961 - val_loss: 0.0895 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.09344 to 0.08952, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0713 - acc: 0.9974 - val_loss: 0.1029 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.08952\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0681 - acc: 0.9980 - val_loss: 0.0930 - val_acc: 0.9918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00130: val_loss did not improve from 0.08952\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0704 - acc: 0.9974 - val_loss: 0.0875 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.08952 to 0.08750, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0659 - acc: 0.9974 - val_loss: 0.1023 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.08750\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0701 - acc: 0.9967 - val_loss: 0.0900 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.08750\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0641 - acc: 0.9980 - val_loss: 0.0803 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.08750 to 0.08035, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0640 - acc: 0.9974 - val_loss: 0.1010 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.08035\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0643 - acc: 0.9967 - val_loss: 0.0838 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.08035\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0600 - acc: 0.9967 - val_loss: 0.0916 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.08035\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0631 - acc: 0.9961 - val_loss: 0.0843 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.08035\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0597 - acc: 0.9974 - val_loss: 0.0860 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.08035\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0597 - acc: 0.9974 - val_loss: 0.0742 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.08035 to 0.07416, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0566 - acc: 0.9974 - val_loss: 0.0763 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.07416\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0583 - acc: 0.9974 - val_loss: 0.0867 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.07416\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0556 - acc: 0.9980 - val_loss: 0.0734 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.07416 to 0.07343, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0542 - acc: 0.9980 - val_loss: 0.0758 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.07343\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0558 - acc: 0.9967 - val_loss: 0.0746 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.07343\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0537 - acc: 0.9980 - val_loss: 0.0716 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.07343 to 0.07156, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0535 - acc: 0.9993 - val_loss: 0.0721 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.07156\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0518 - acc: 0.9974 - val_loss: 0.0789 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.07156\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0514 - acc: 0.9980 - val_loss: 0.0672 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.07156 to 0.06721, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0496 - acc: 0.9987 - val_loss: 0.0848 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.06721\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0500 - acc: 0.9974 - val_loss: 0.0737 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.06721\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0481 - acc: 0.9974 - val_loss: 0.0656 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.06721 to 0.06561, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0475 - acc: 0.9967 - val_loss: 0.0652 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.06561 to 0.06517, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0450 - acc: 0.9974 - val_loss: 0.0859 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.06517\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.0446 - acc: 0.9980 - val_loss: 0.0675 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.06517\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.0465 - acc: 0.9974 - val_loss: 0.0709 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.06517\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0441 - acc: 0.9980 - val_loss: 0.0660 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.06517\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.0429 - acc: 0.9974 - val_loss: 0.0817 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.06517\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.0425 - acc: 0.9974 - val_loss: 0.0706 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.06517\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.0411 - acc: 0.9967 - val_loss: 0.0683 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.06517\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.0417 - acc: 0.9987 - val_loss: 0.0705 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.06517\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.0419 - acc: 0.9980 - val_loss: 0.0803 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.06517\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.0401 - acc: 0.9974 - val_loss: 0.0709 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.06517\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.0414 - acc: 0.9961 - val_loss: 0.0685 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.06517\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.0384 - acc: 0.9974 - val_loss: 0.0888 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.06517\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.0394 - acc: 0.9974 - val_loss: 0.0550 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00166: val_loss improved from 0.06517 to 0.05505, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.0373 - acc: 0.9974 - val_loss: 0.0634 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.05505\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.0391 - acc: 0.9980 - val_loss: 0.0624 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.05505\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.0359 - acc: 0.9980 - val_loss: 0.0592 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.05505\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.0360 - acc: 0.9974 - val_loss: 0.0745 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.05505\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.0365 - acc: 0.9980 - val_loss: 0.0621 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.05505\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.0349 - acc: 0.9974 - val_loss: 0.0582 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.05505\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.0353 - acc: 0.9980 - val_loss: 0.0710 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.05505\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.0351 - acc: 0.9980 - val_loss: 0.0610 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.05505\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.0335 - acc: 0.9980 - val_loss: 0.0586 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.05505\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.0334 - acc: 0.9980 - val_loss: 0.0501 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00176: val_loss improved from 0.05505 to 0.05007, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.0333 - acc: 0.9967 - val_loss: 0.0641 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.05007\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.0328 - acc: 0.9974 - val_loss: 0.0553 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.05007\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.0311 - acc: 0.9967 - val_loss: 0.0568 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.05007\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.0318 - acc: 0.9974 - val_loss: 0.0593 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.05007\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.0299 - acc: 0.9980 - val_loss: 0.0534 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.05007\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.0315 - acc: 0.9967 - val_loss: 0.0505 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.05007\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.0307 - acc: 0.9961 - val_loss: 0.0621 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.05007\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.0289 - acc: 0.9967 - val_loss: 0.0523 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.05007\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.0282 - acc: 0.9967 - val_loss: 0.0437 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00185: val_loss improved from 0.05007 to 0.04368, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.0280 - acc: 0.9987 - val_loss: 0.0444 - val_acc: 0.9959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00186: val_loss did not improve from 0.04368\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.0290 - acc: 0.9980 - val_loss: 0.0520 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.04368\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.0284 - acc: 0.9974 - val_loss: 0.0535 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.04368\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.0279 - acc: 0.9974 - val_loss: 0.0547 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.04368\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.0265 - acc: 0.9974 - val_loss: 0.0620 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.04368\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.0270 - acc: 0.9967 - val_loss: 0.0460 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.04368\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.0261 - acc: 0.9974 - val_loss: 0.0461 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.04368\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.0265 - acc: 0.9974 - val_loss: 0.0479 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.04368\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.0255 - acc: 0.9974 - val_loss: 0.0567 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.04368\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.0255 - acc: 0.9974 - val_loss: 0.0448 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.04368\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.0247 - acc: 0.9980 - val_loss: 0.0491 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.04368\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.0243 - acc: 0.9980 - val_loss: 0.0616 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.04368\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.0251 - acc: 0.9980 - val_loss: 0.0509 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.04368\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.0233 - acc: 0.9974 - val_loss: 0.0488 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.04368\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.0250 - acc: 0.9967 - val_loss: 0.0508 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.04368\n",
      "batch_size=200   optimizer=RMSprop\n",
      "Test accuracy: 68.5237%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 1.6403 - acc: 0.4559 - val_loss: 1.1013 - val_acc: 0.6420\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.10134, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 1s - loss: 1.0461 - acc: 0.6553 - val_loss: 0.9616 - val_acc: 0.6749\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.10134 to 0.96156, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 1s - loss: 0.9051 - acc: 0.7039 - val_loss: 0.8686 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.96156 to 0.86857, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 1s - loss: 0.8308 - acc: 0.7395 - val_loss: 0.8408 - val_acc: 0.7160\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.86857 to 0.84080, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 1s - loss: 0.7737 - acc: 0.7632 - val_loss: 0.7686 - val_acc: 0.7490\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.84080 to 0.76856, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 1s - loss: 0.7243 - acc: 0.7763 - val_loss: 0.7237 - val_acc: 0.7695\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.76856 to 0.72366, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 1s - loss: 0.6846 - acc: 0.7961 - val_loss: 0.6939 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.72366 to 0.69393, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 1s - loss: 0.6577 - acc: 0.8053 - val_loss: 0.6653 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.69393 to 0.66532, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 1s - loss: 0.6272 - acc: 0.8151 - val_loss: 0.6451 - val_acc: 0.8107\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.66532 to 0.64515, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 1s - loss: 0.6039 - acc: 0.8270 - val_loss: 0.6150 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.64515 to 0.61499, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 1s - loss: 0.5853 - acc: 0.8401 - val_loss: 0.5922 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.61499 to 0.59219, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 1s - loss: 0.5672 - acc: 0.8441 - val_loss: 0.6003 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.59219\n",
      "Epoch 13/200\n",
      " - 1s - loss: 0.5509 - acc: 0.8579 - val_loss: 0.5619 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.59219 to 0.56188, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 1s - loss: 0.5354 - acc: 0.8579 - val_loss: 0.5511 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.56188 to 0.55113, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 1s - loss: 0.5210 - acc: 0.8572 - val_loss: 0.5352 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.55113 to 0.53516, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 1s - loss: 0.5090 - acc: 0.8651 - val_loss: 0.5207 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.53516 to 0.52066, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 1s - loss: 0.4927 - acc: 0.8763 - val_loss: 0.5105 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.52066 to 0.51047, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/200\n",
      " - 1s - loss: 0.4846 - acc: 0.8809 - val_loss: 0.4961 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.51047 to 0.49614, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 1s - loss: 0.4716 - acc: 0.8875 - val_loss: 0.5020 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.49614\n",
      "Epoch 20/200\n",
      " - 1s - loss: 0.4646 - acc: 0.8829 - val_loss: 0.4810 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.49614 to 0.48101, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 21/200\n",
      " - 1s - loss: 0.4528 - acc: 0.8875 - val_loss: 0.4710 - val_acc: 0.9012\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.48101 to 0.47099, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 1s - loss: 0.4437 - acc: 0.8921 - val_loss: 0.4609 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.47099 to 0.46093, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 1s - loss: 0.4363 - acc: 0.8947 - val_loss: 0.4500 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.46093 to 0.44998, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 24/200\n",
      " - 1s - loss: 0.4277 - acc: 0.9046 - val_loss: 0.4433 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.44998 to 0.44331, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 25/200\n",
      " - 1s - loss: 0.4194 - acc: 0.9059 - val_loss: 0.4387 - val_acc: 0.9012\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.44331 to 0.43869, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 26/200\n",
      " - 1s - loss: 0.4126 - acc: 0.9053 - val_loss: 0.4378 - val_acc: 0.9012\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.43869 to 0.43777, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 27/200\n",
      " - 1s - loss: 0.4053 - acc: 0.9105 - val_loss: 0.4248 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.43777 to 0.42482, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 28/200\n",
      " - 1s - loss: 0.3983 - acc: 0.9112 - val_loss: 0.4149 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.42482 to 0.41490, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 29/200\n",
      " - 1s - loss: 0.3924 - acc: 0.9125 - val_loss: 0.4117 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.41490 to 0.41167, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 30/200\n",
      " - 1s - loss: 0.3860 - acc: 0.9151 - val_loss: 0.4045 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.41167 to 0.40452, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 31/200\n",
      " - 1s - loss: 0.3804 - acc: 0.9178 - val_loss: 0.4008 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.40452 to 0.40082, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 32/200\n",
      " - 1s - loss: 0.3741 - acc: 0.9197 - val_loss: 0.3914 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.40082 to 0.39136, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 33/200\n",
      " - 1s - loss: 0.3689 - acc: 0.9230 - val_loss: 0.3880 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.39136 to 0.38797, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 34/200\n",
      " - 1s - loss: 0.3643 - acc: 0.9230 - val_loss: 0.3879 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.38797 to 0.38795, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 35/200\n",
      " - 1s - loss: 0.3583 - acc: 0.9303 - val_loss: 0.3783 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.38795 to 0.37834, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 36/200\n",
      " - 1s - loss: 0.3531 - acc: 0.9270 - val_loss: 0.3748 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.37834 to 0.37476, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 37/200\n",
      " - 1s - loss: 0.3481 - acc: 0.9322 - val_loss: 0.3651 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.37476 to 0.36507, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 38/200\n",
      " - 1s - loss: 0.3427 - acc: 0.9316 - val_loss: 0.3585 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.36507 to 0.35854, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 39/200\n",
      " - 1s - loss: 0.3390 - acc: 0.9382 - val_loss: 0.3608 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.35854\n",
      "Epoch 40/200\n",
      " - 1s - loss: 0.3353 - acc: 0.9362 - val_loss: 0.3525 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.35854 to 0.35252, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 41/200\n",
      " - 1s - loss: 0.3290 - acc: 0.9421 - val_loss: 0.3484 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.35252 to 0.34837, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 42/200\n",
      " - 1s - loss: 0.3278 - acc: 0.9428 - val_loss: 0.3499 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.34837\n",
      "Epoch 43/200\n",
      " - 1s - loss: 0.3223 - acc: 0.9401 - val_loss: 0.3420 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.34837 to 0.34204, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 44/200\n",
      " - 1s - loss: 0.3184 - acc: 0.9480 - val_loss: 0.3378 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.34204 to 0.33777, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 45/200\n",
      " - 1s - loss: 0.3132 - acc: 0.9474 - val_loss: 0.3335 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.33777 to 0.33351, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 46/200\n",
      " - 1s - loss: 0.3114 - acc: 0.9526 - val_loss: 0.3340 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.33351\n",
      "Epoch 47/200\n",
      " - 1s - loss: 0.3073 - acc: 0.9447 - val_loss: 0.3241 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.33351 to 0.32408, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 48/200\n",
      " - 1s - loss: 0.3042 - acc: 0.9539 - val_loss: 0.3290 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.32408\n",
      "Epoch 49/200\n",
      " - 1s - loss: 0.3009 - acc: 0.9526 - val_loss: 0.3236 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.32408 to 0.32356, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 50/200\n",
      " - 1s - loss: 0.2977 - acc: 0.9526 - val_loss: 0.3148 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.32356 to 0.31477, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 51/200\n",
      " - 1s - loss: 0.2945 - acc: 0.9566 - val_loss: 0.3149 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.31477\n",
      "Epoch 52/200\n",
      " - 1s - loss: 0.2910 - acc: 0.9539 - val_loss: 0.3074 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.31477 to 0.30742, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 53/200\n",
      " - 1s - loss: 0.2878 - acc: 0.9599 - val_loss: 0.3098 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.30742\n",
      "Epoch 54/200\n",
      " - 1s - loss: 0.2850 - acc: 0.9566 - val_loss: 0.3081 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.30742\n",
      "Epoch 55/200\n",
      " - 1s - loss: 0.2811 - acc: 0.9592 - val_loss: 0.3014 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.30742 to 0.30141, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 56/200\n",
      " - 1s - loss: 0.2796 - acc: 0.9586 - val_loss: 0.3019 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.30141\n",
      "Epoch 57/200\n",
      " - 1s - loss: 0.2769 - acc: 0.9605 - val_loss: 0.2937 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.30141 to 0.29366, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 58/200\n",
      " - 1s - loss: 0.2739 - acc: 0.9632 - val_loss: 0.2962 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.29366\n",
      "Epoch 59/200\n",
      " - 1s - loss: 0.2703 - acc: 0.9625 - val_loss: 0.2932 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.29366 to 0.29323, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 60/200\n",
      " - 1s - loss: 0.2684 - acc: 0.9612 - val_loss: 0.2891 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.29323 to 0.28906, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 61/200\n",
      " - 1s - loss: 0.2657 - acc: 0.9658 - val_loss: 0.2922 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.28906\n",
      "Epoch 62/200\n",
      " - 1s - loss: 0.2625 - acc: 0.9645 - val_loss: 0.2885 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.28906 to 0.28845, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 63/200\n",
      " - 1s - loss: 0.2605 - acc: 0.9671 - val_loss: 0.2828 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.28845 to 0.28280, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 64/200\n",
      " - 1s - loss: 0.2593 - acc: 0.9691 - val_loss: 0.2809 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.28280 to 0.28091, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 65/200\n",
      " - 1s - loss: 0.2557 - acc: 0.9671 - val_loss: 0.2781 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.28091 to 0.27811, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 66/200\n",
      " - 1s - loss: 0.2538 - acc: 0.9664 - val_loss: 0.2756 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.27811 to 0.27565, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 67/200\n",
      " - 1s - loss: 0.2517 - acc: 0.9697 - val_loss: 0.2755 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.27565 to 0.27555, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 68/200\n",
      " - 1s - loss: 0.2494 - acc: 0.9691 - val_loss: 0.2719 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.27555 to 0.27192, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 69/200\n",
      " - 1s - loss: 0.2472 - acc: 0.9697 - val_loss: 0.2671 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.27192 to 0.26709, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 70/200\n",
      " - 1s - loss: 0.2450 - acc: 0.9717 - val_loss: 0.2654 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.26709 to 0.26543, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 71/200\n",
      " - 1s - loss: 0.2431 - acc: 0.9691 - val_loss: 0.2618 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.26543 to 0.26176, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 72/200\n",
      " - 1s - loss: 0.2402 - acc: 0.9697 - val_loss: 0.2652 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.26176\n",
      "Epoch 73/200\n",
      " - 1s - loss: 0.2386 - acc: 0.9711 - val_loss: 0.2616 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.26176 to 0.26159, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 74/200\n",
      " - 1s - loss: 0.2365 - acc: 0.9704 - val_loss: 0.2621 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.26159\n",
      "Epoch 75/200\n",
      " - 1s - loss: 0.2354 - acc: 0.9730 - val_loss: 0.2559 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.26159 to 0.25591, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 76/200\n",
      " - 1s - loss: 0.2326 - acc: 0.9743 - val_loss: 0.2539 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.25591 to 0.25393, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 77/200\n",
      " - 1s - loss: 0.2306 - acc: 0.9743 - val_loss: 0.2552 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.25393\n",
      "Epoch 78/200\n",
      " - 1s - loss: 0.2289 - acc: 0.9750 - val_loss: 0.2505 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.25393 to 0.25053, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 79/200\n",
      " - 1s - loss: 0.2273 - acc: 0.9743 - val_loss: 0.2480 - val_acc: 0.9712\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00079: val_loss improved from 0.25053 to 0.24796, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 80/200\n",
      " - 1s - loss: 0.2256 - acc: 0.9770 - val_loss: 0.2469 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.24796 to 0.24695, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 81/200\n",
      " - 1s - loss: 0.2241 - acc: 0.9737 - val_loss: 0.2430 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.24695 to 0.24298, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 82/200\n",
      " - 1s - loss: 0.2219 - acc: 0.9757 - val_loss: 0.2432 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.24298\n",
      "Epoch 83/200\n",
      " - 1s - loss: 0.2202 - acc: 0.9776 - val_loss: 0.2438 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.24298\n",
      "Epoch 84/200\n",
      " - 1s - loss: 0.2188 - acc: 0.9789 - val_loss: 0.2416 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.24298 to 0.24159, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 85/200\n",
      " - 1s - loss: 0.2170 - acc: 0.9763 - val_loss: 0.2386 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.24159 to 0.23859, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 86/200\n",
      " - 1s - loss: 0.2147 - acc: 0.9796 - val_loss: 0.2397 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.23859\n",
      "Epoch 87/200\n",
      " - 1s - loss: 0.2142 - acc: 0.9770 - val_loss: 0.2353 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.23859 to 0.23526, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 88/200\n",
      " - 1s - loss: 0.2123 - acc: 0.9816 - val_loss: 0.2359 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.23526\n",
      "Epoch 89/200\n",
      " - 1s - loss: 0.2103 - acc: 0.9783 - val_loss: 0.2327 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.23526 to 0.23270, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 90/200\n",
      " - 1s - loss: 0.2083 - acc: 0.9796 - val_loss: 0.2295 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.23270 to 0.22954, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 91/200\n",
      " - 1s - loss: 0.2081 - acc: 0.9829 - val_loss: 0.2287 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.22954 to 0.22865, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 92/200\n",
      " - 1s - loss: 0.2064 - acc: 0.9816 - val_loss: 0.2283 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.22865 to 0.22826, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 93/200\n",
      " - 1s - loss: 0.2045 - acc: 0.9829 - val_loss: 0.2305 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.22826\n",
      "Epoch 94/200\n",
      " - 1s - loss: 0.2030 - acc: 0.9809 - val_loss: 0.2266 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.22826 to 0.22656, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 95/200\n",
      " - 1s - loss: 0.2015 - acc: 0.9822 - val_loss: 0.2264 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.22656 to 0.22642, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 96/200\n",
      " - 1s - loss: 0.2003 - acc: 0.9816 - val_loss: 0.2237 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.22642 to 0.22373, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 97/200\n",
      " - 1s - loss: 0.1987 - acc: 0.9849 - val_loss: 0.2261 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.22373\n",
      "Epoch 98/200\n",
      " - 1s - loss: 0.1979 - acc: 0.9829 - val_loss: 0.2181 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.22373 to 0.21805, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 99/200\n",
      " - 1s - loss: 0.1961 - acc: 0.9829 - val_loss: 0.2216 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.21805\n",
      "Epoch 100/200\n",
      " - 1s - loss: 0.1950 - acc: 0.9809 - val_loss: 0.2183 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.21805\n",
      "Epoch 101/200\n",
      " - 1s - loss: 0.1940 - acc: 0.9836 - val_loss: 0.2169 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.21805 to 0.21689, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 102/200\n",
      " - 1s - loss: 0.1920 - acc: 0.9816 - val_loss: 0.2183 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.21689\n",
      "Epoch 103/200\n",
      " - 1s - loss: 0.1913 - acc: 0.9849 - val_loss: 0.2160 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.21689 to 0.21603, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 104/200\n",
      " - 1s - loss: 0.1903 - acc: 0.9875 - val_loss: 0.2142 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.21603 to 0.21420, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 105/200\n",
      " - 1s - loss: 0.1885 - acc: 0.9842 - val_loss: 0.2099 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.21420 to 0.20987, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 106/200\n",
      " - 1s - loss: 0.1873 - acc: 0.9875 - val_loss: 0.2113 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.20987\n",
      "Epoch 107/200\n",
      " - 1s - loss: 0.1860 - acc: 0.9868 - val_loss: 0.2147 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.20987\n",
      "Epoch 108/200\n",
      " - 1s - loss: 0.1851 - acc: 0.9862 - val_loss: 0.2096 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.20987 to 0.20957, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 109/200\n",
      " - 1s - loss: 0.1839 - acc: 0.9842 - val_loss: 0.2074 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.20957 to 0.20739, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 110/200\n",
      " - 1s - loss: 0.1828 - acc: 0.9868 - val_loss: 0.2089 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.20739\n",
      "Epoch 111/200\n",
      " - 1s - loss: 0.1815 - acc: 0.9882 - val_loss: 0.2056 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.20739 to 0.20557, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 112/200\n",
      " - 1s - loss: 0.1803 - acc: 0.9888 - val_loss: 0.2044 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.20557 to 0.20443, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 113/200\n",
      " - 1s - loss: 0.1796 - acc: 0.9882 - val_loss: 0.2010 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.20443 to 0.20097, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 114/200\n",
      " - 1s - loss: 0.1782 - acc: 0.9888 - val_loss: 0.2001 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.20097 to 0.20006, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 115/200\n",
      " - 1s - loss: 0.1774 - acc: 0.9895 - val_loss: 0.2045 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.20006\n",
      "Epoch 116/200\n",
      " - 1s - loss: 0.1763 - acc: 0.9882 - val_loss: 0.1984 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.20006 to 0.19843, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 117/200\n",
      " - 1s - loss: 0.1755 - acc: 0.9882 - val_loss: 0.1962 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.19843 to 0.19618, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 118/200\n",
      " - 1s - loss: 0.1739 - acc: 0.9895 - val_loss: 0.1993 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.19618\n",
      "Epoch 119/200\n",
      " - 1s - loss: 0.1730 - acc: 0.9908 - val_loss: 0.1969 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.19618\n",
      "Epoch 120/200\n",
      " - 1s - loss: 0.1721 - acc: 0.9908 - val_loss: 0.1937 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.19618 to 0.19369, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 121/200\n",
      " - 1s - loss: 0.1711 - acc: 0.9908 - val_loss: 0.1948 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.19369\n",
      "Epoch 122/200\n",
      " - 1s - loss: 0.1695 - acc: 0.9882 - val_loss: 0.1929 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.19369 to 0.19294, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 123/200\n",
      " - 1s - loss: 0.1693 - acc: 0.9908 - val_loss: 0.1942 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.19294\n",
      "Epoch 124/200\n",
      " - 1s - loss: 0.1679 - acc: 0.9914 - val_loss: 0.1918 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.19294 to 0.19183, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 125/200\n",
      " - 1s - loss: 0.1673 - acc: 0.9901 - val_loss: 0.1919 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.19183\n",
      "Epoch 126/200\n",
      " - 1s - loss: 0.1662 - acc: 0.9908 - val_loss: 0.1896 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.19183 to 0.18958, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 127/200\n",
      " - 1s - loss: 0.1655 - acc: 0.9908 - val_loss: 0.1874 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.18958 to 0.18735, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 128/200\n",
      " - 1s - loss: 0.1642 - acc: 0.9914 - val_loss: 0.1898 - val_acc: 0.9877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00128: val_loss did not improve from 0.18735\n",
      "Epoch 129/200\n",
      " - 1s - loss: 0.1639 - acc: 0.9914 - val_loss: 0.1872 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.18735 to 0.18720, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 130/200\n",
      " - 1s - loss: 0.1628 - acc: 0.9914 - val_loss: 0.1867 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.18720 to 0.18666, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 131/200\n",
      " - 1s - loss: 0.1617 - acc: 0.9921 - val_loss: 0.1855 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.18666 to 0.18552, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 132/200\n",
      " - 1s - loss: 0.1611 - acc: 0.9914 - val_loss: 0.1846 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.18552 to 0.18460, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 133/200\n",
      " - 1s - loss: 0.1601 - acc: 0.9921 - val_loss: 0.1843 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.18460 to 0.18426, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 134/200\n",
      " - 1s - loss: 0.1593 - acc: 0.9928 - val_loss: 0.1820 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.18426 to 0.18196, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 135/200\n",
      " - 1s - loss: 0.1583 - acc: 0.9914 - val_loss: 0.1811 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.18196 to 0.18114, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 136/200\n",
      " - 1s - loss: 0.1572 - acc: 0.9928 - val_loss: 0.1791 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.18114 to 0.17911, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 137/200\n",
      " - 1s - loss: 0.1569 - acc: 0.9934 - val_loss: 0.1816 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.17911\n",
      "Epoch 138/200\n",
      " - 1s - loss: 0.1557 - acc: 0.9934 - val_loss: 0.1781 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.17911 to 0.17811, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 139/200\n",
      " - 1s - loss: 0.1553 - acc: 0.9921 - val_loss: 0.1778 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.17811 to 0.17783, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 140/200\n",
      " - 1s - loss: 0.1541 - acc: 0.9914 - val_loss: 0.1770 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.17783 to 0.17702, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 141/200\n",
      " - 1s - loss: 0.1537 - acc: 0.9934 - val_loss: 0.1764 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.17702 to 0.17644, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 142/200\n",
      " - 1s - loss: 0.1525 - acc: 0.9941 - val_loss: 0.1759 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.17644 to 0.17588, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 143/200\n",
      " - 1s - loss: 0.1520 - acc: 0.9914 - val_loss: 0.1757 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.17588 to 0.17568, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 144/200\n",
      " - 1s - loss: 0.1511 - acc: 0.9928 - val_loss: 0.1737 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.17568 to 0.17366, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 145/200\n",
      " - 1s - loss: 0.1503 - acc: 0.9934 - val_loss: 0.1726 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.17366 to 0.17260, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 146/200\n",
      " - 1s - loss: 0.1497 - acc: 0.9928 - val_loss: 0.1712 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.17260 to 0.17116, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 147/200\n",
      " - 1s - loss: 0.1487 - acc: 0.9921 - val_loss: 0.1734 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.17116\n",
      "Epoch 148/200\n",
      " - 1s - loss: 0.1481 - acc: 0.9941 - val_loss: 0.1712 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.17116 to 0.17115, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 149/200\n",
      " - 1s - loss: 0.1475 - acc: 0.9928 - val_loss: 0.1705 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.17115 to 0.17054, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 150/200\n",
      " - 1s - loss: 0.1468 - acc: 0.9934 - val_loss: 0.1686 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.17054 to 0.16857, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 151/200\n",
      " - 1s - loss: 0.1458 - acc: 0.9934 - val_loss: 0.1709 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.16857\n",
      "Epoch 152/200\n",
      " - 1s - loss: 0.1451 - acc: 0.9934 - val_loss: 0.1690 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.16857\n",
      "Epoch 153/200\n",
      " - 1s - loss: 0.1449 - acc: 0.9941 - val_loss: 0.1678 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.16857 to 0.16783, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 154/200\n",
      " - 1s - loss: 0.1437 - acc: 0.9947 - val_loss: 0.1677 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.16783 to 0.16769, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 155/200\n",
      " - 1s - loss: 0.1432 - acc: 0.9941 - val_loss: 0.1658 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.16769 to 0.16580, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 156/200\n",
      " - 1s - loss: 0.1425 - acc: 0.9947 - val_loss: 0.1643 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.16580 to 0.16435, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 157/200\n",
      " - 1s - loss: 0.1419 - acc: 0.9941 - val_loss: 0.1654 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.16435\n",
      "Epoch 158/200\n",
      " - 1s - loss: 0.1412 - acc: 0.9947 - val_loss: 0.1629 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.16435 to 0.16292, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 159/200\n",
      " - 1s - loss: 0.1403 - acc: 0.9934 - val_loss: 0.1652 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.16292\n",
      "Epoch 160/200\n",
      " - 1s - loss: 0.1398 - acc: 0.9947 - val_loss: 0.1626 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.16292 to 0.16264, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 161/200\n",
      " - 1s - loss: 0.1392 - acc: 0.9941 - val_loss: 0.1619 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.16264 to 0.16189, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 162/200\n",
      " - 1s - loss: 0.1387 - acc: 0.9947 - val_loss: 0.1622 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.16189\n",
      "Epoch 163/200\n",
      " - 1s - loss: 0.1378 - acc: 0.9941 - val_loss: 0.1613 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00163: val_loss improved from 0.16189 to 0.16135, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 164/200\n",
      " - 1s - loss: 0.1372 - acc: 0.9947 - val_loss: 0.1604 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.16135 to 0.16045, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 165/200\n",
      " - 1s - loss: 0.1367 - acc: 0.9934 - val_loss: 0.1602 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.16045 to 0.16020, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 166/200\n",
      " - 1s - loss: 0.1363 - acc: 0.9954 - val_loss: 0.1590 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00166: val_loss improved from 0.16020 to 0.15904, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 167/200\n",
      " - 1s - loss: 0.1355 - acc: 0.9947 - val_loss: 0.1593 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.15904\n",
      "Epoch 168/200\n",
      " - 1s - loss: 0.1350 - acc: 0.9947 - val_loss: 0.1595 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.15904\n",
      "Epoch 169/200\n",
      " - 1s - loss: 0.1342 - acc: 0.9947 - val_loss: 0.1567 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.15904 to 0.15667, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 170/200\n",
      " - 1s - loss: 0.1338 - acc: 0.9947 - val_loss: 0.1560 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.15667 to 0.15598, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 171/200\n",
      " - 1s - loss: 0.1330 - acc: 0.9961 - val_loss: 0.1579 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.15598\n",
      "Epoch 172/200\n",
      " - 1s - loss: 0.1324 - acc: 0.9961 - val_loss: 0.1551 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00172: val_loss improved from 0.15598 to 0.15506, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 173/200\n",
      " - 1s - loss: 0.1319 - acc: 0.9947 - val_loss: 0.1538 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.15506 to 0.15384, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 174/200\n",
      " - 1s - loss: 0.1313 - acc: 0.9954 - val_loss: 0.1548 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.15384\n",
      "Epoch 175/200\n",
      " - 1s - loss: 0.1306 - acc: 0.9961 - val_loss: 0.1560 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.15384\n",
      "Epoch 176/200\n",
      " - 1s - loss: 0.1301 - acc: 0.9954 - val_loss: 0.1548 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.15384\n",
      "Epoch 177/200\n",
      " - 1s - loss: 0.1297 - acc: 0.9954 - val_loss: 0.1520 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00177: val_loss improved from 0.15384 to 0.15205, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 178/200\n",
      " - 1s - loss: 0.1290 - acc: 0.9967 - val_loss: 0.1537 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.15205\n",
      "Epoch 179/200\n",
      " - 1s - loss: 0.1285 - acc: 0.9961 - val_loss: 0.1503 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00179: val_loss improved from 0.15205 to 0.15035, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 180/200\n",
      " - 1s - loss: 0.1279 - acc: 0.9961 - val_loss: 0.1500 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00180: val_loss improved from 0.15035 to 0.15002, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 181/200\n",
      " - 1s - loss: 0.1275 - acc: 0.9947 - val_loss: 0.1506 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.15002\n",
      "Epoch 182/200\n",
      " - 1s - loss: 0.1269 - acc: 0.9961 - val_loss: 0.1501 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.15002\n",
      "Epoch 183/200\n",
      " - 1s - loss: 0.1264 - acc: 0.9967 - val_loss: 0.1498 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00183: val_loss improved from 0.15002 to 0.14980, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 184/200\n",
      " - 1s - loss: 0.1259 - acc: 0.9961 - val_loss: 0.1489 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00184: val_loss improved from 0.14980 to 0.14895, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 185/200\n",
      " - 1s - loss: 0.1249 - acc: 0.9961 - val_loss: 0.1494 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.14895\n",
      "Epoch 186/200\n",
      " - 1s - loss: 0.1250 - acc: 0.9967 - val_loss: 0.1494 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.14895\n",
      "Epoch 187/200\n",
      " - 1s - loss: 0.1242 - acc: 0.9967 - val_loss: 0.1482 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.14895 to 0.14816, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 188/200\n",
      " - 1s - loss: 0.1238 - acc: 0.9967 - val_loss: 0.1474 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00188: val_loss improved from 0.14816 to 0.14745, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 189/200\n",
      " - 1s - loss: 0.1233 - acc: 0.9967 - val_loss: 0.1473 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.14745 to 0.14728, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 190/200\n",
      " - 1s - loss: 0.1228 - acc: 0.9961 - val_loss: 0.1459 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00190: val_loss improved from 0.14728 to 0.14586, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 191/200\n",
      " - 1s - loss: 0.1224 - acc: 0.9967 - val_loss: 0.1459 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.14586\n",
      "Epoch 192/200\n",
      " - 1s - loss: 0.1218 - acc: 0.9967 - val_loss: 0.1457 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.14586 to 0.14575, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 193/200\n",
      " - 1s - loss: 0.1213 - acc: 0.9967 - val_loss: 0.1450 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00193: val_loss improved from 0.14575 to 0.14503, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 194/200\n",
      " - 1s - loss: 0.1207 - acc: 0.9961 - val_loss: 0.1440 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00194: val_loss improved from 0.14503 to 0.14404, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 195/200\n",
      " - 1s - loss: 0.1204 - acc: 0.9961 - val_loss: 0.1447 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.14404\n",
      "Epoch 196/200\n",
      " - 1s - loss: 0.1201 - acc: 0.9961 - val_loss: 0.1432 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00196: val_loss improved from 0.14404 to 0.14321, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 197/200\n",
      " - 1s - loss: 0.1192 - acc: 0.9961 - val_loss: 0.1448 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.14321\n",
      "Epoch 198/200\n",
      " - 1s - loss: 0.1190 - acc: 0.9967 - val_loss: 0.1436 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.14321\n",
      "Epoch 199/200\n",
      " - 1s - loss: 0.1185 - acc: 0.9967 - val_loss: 0.1421 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00199: val_loss improved from 0.14321 to 0.14207, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 200/200\n",
      " - 1s - loss: 0.1181 - acc: 0.9961 - val_loss: 0.1407 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00200: val_loss improved from 0.14207 to 0.14067, saving model to weights.best.Resnet50.hdf5\n",
      "batch_size=10   optimizer=Adagrad\n",
      "Test accuracy: 65.4596%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 1.7198 - acc: 0.4237 - val_loss: 1.2383 - val_acc: 0.5597\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.23825, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.0825 - acc: 0.6349 - val_loss: 0.9388 - val_acc: 0.6831\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.23825 to 0.93883, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.9395 - acc: 0.7039 - val_loss: 0.8703 - val_acc: 0.7078\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.93883 to 0.87027, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.8526 - acc: 0.7289 - val_loss: 0.8281 - val_acc: 0.7284\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.87027 to 0.82810, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.7878 - acc: 0.7500 - val_loss: 0.7611 - val_acc: 0.7695\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.82810 to 0.76111, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.7440 - acc: 0.7638 - val_loss: 0.7043 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.76111 to 0.70433, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.7063 - acc: 0.7862 - val_loss: 0.6742 - val_acc: 0.8107\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.70433 to 0.67419, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.6713 - acc: 0.7888 - val_loss: 0.6681 - val_acc: 0.7819\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.67419 to 0.66807, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.6455 - acc: 0.7987 - val_loss: 0.6219 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.66807 to 0.62195, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.6199 - acc: 0.8132 - val_loss: 0.6045 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.62195 to 0.60452, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.5981 - acc: 0.8243 - val_loss: 0.6033 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.60452 to 0.60328, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.5819 - acc: 0.8316 - val_loss: 0.5843 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.60328 to 0.58429, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.5646 - acc: 0.8362 - val_loss: 0.5567 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.58429 to 0.55672, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.5462 - acc: 0.8461 - val_loss: 0.5449 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.55672 to 0.54489, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.5322 - acc: 0.8539 - val_loss: 0.5253 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.54489 to 0.52526, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.5208 - acc: 0.8500 - val_loss: 0.5132 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.52526 to 0.51317, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.5038 - acc: 0.8599 - val_loss: 0.5069 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.51317 to 0.50692, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.4947 - acc: 0.8599 - val_loss: 0.4957 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.50692 to 0.49571, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.4846 - acc: 0.8691 - val_loss: 0.4770 - val_acc: 0.8848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00019: val_loss improved from 0.49571 to 0.47700, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.4734 - acc: 0.8664 - val_loss: 0.4777 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.47700\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.4632 - acc: 0.8816 - val_loss: 0.4715 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.47700 to 0.47154, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.4538 - acc: 0.8822 - val_loss: 0.4656 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.47154 to 0.46561, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.4456 - acc: 0.8868 - val_loss: 0.4588 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.46561 to 0.45884, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.4369 - acc: 0.8928 - val_loss: 0.4391 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.45884 to 0.43914, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.4288 - acc: 0.8928 - val_loss: 0.4318 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.43914 to 0.43181, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.4219 - acc: 0.8974 - val_loss: 0.4363 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.43181\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.4153 - acc: 0.8947 - val_loss: 0.4246 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.43181 to 0.42460, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.4081 - acc: 0.9066 - val_loss: 0.4138 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.42460 to 0.41380, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.4008 - acc: 0.9059 - val_loss: 0.4031 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.41380 to 0.40308, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.3951 - acc: 0.9118 - val_loss: 0.4015 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.40308 to 0.40153, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.3883 - acc: 0.9184 - val_loss: 0.3964 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.40153 to 0.39642, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.3824 - acc: 0.9184 - val_loss: 0.3952 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.39642 to 0.39521, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.3778 - acc: 0.9191 - val_loss: 0.3889 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.39521 to 0.38888, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.3717 - acc: 0.9224 - val_loss: 0.3840 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.38888 to 0.38404, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.3668 - acc: 0.9243 - val_loss: 0.3803 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.38404 to 0.38034, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.3618 - acc: 0.9237 - val_loss: 0.3687 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.38034 to 0.36867, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.3569 - acc: 0.9289 - val_loss: 0.3663 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.36867 to 0.36635, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.3516 - acc: 0.9329 - val_loss: 0.3634 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.36635 to 0.36344, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.3470 - acc: 0.9336 - val_loss: 0.3631 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.36344 to 0.36305, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.3427 - acc: 0.9355 - val_loss: 0.3518 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.36305 to 0.35183, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.3374 - acc: 0.9382 - val_loss: 0.3570 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.35183\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.3342 - acc: 0.9362 - val_loss: 0.3468 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.35183 to 0.34681, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.3303 - acc: 0.9388 - val_loss: 0.3482 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.34681\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.3259 - acc: 0.9414 - val_loss: 0.3390 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.34681 to 0.33901, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.3207 - acc: 0.9428 - val_loss: 0.3392 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.33901\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.3186 - acc: 0.9461 - val_loss: 0.3330 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.33901 to 0.33297, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.3156 - acc: 0.9526 - val_loss: 0.3280 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.33297 to 0.32804, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.3111 - acc: 0.9493 - val_loss: 0.3256 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.32804 to 0.32560, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.3061 - acc: 0.9513 - val_loss: 0.3272 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.32560\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.3045 - acc: 0.9513 - val_loss: 0.3171 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.32560 to 0.31712, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.3013 - acc: 0.9520 - val_loss: 0.3176 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.31712\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.2970 - acc: 0.9539 - val_loss: 0.3163 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.31712 to 0.31630, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.2943 - acc: 0.9539 - val_loss: 0.3066 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.31630 to 0.30656, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.2915 - acc: 0.9579 - val_loss: 0.3071 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.30656\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.2878 - acc: 0.9618 - val_loss: 0.3094 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.30656\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.2846 - acc: 0.9599 - val_loss: 0.3019 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.30656 to 0.30191, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.2821 - acc: 0.9612 - val_loss: 0.3044 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.30191\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.2795 - acc: 0.9658 - val_loss: 0.2941 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.30191 to 0.29412, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.2766 - acc: 0.9645 - val_loss: 0.2992 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.29412\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.2742 - acc: 0.9632 - val_loss: 0.2963 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.29412\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.2722 - acc: 0.9632 - val_loss: 0.2876 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.29412 to 0.28761, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.2691 - acc: 0.9671 - val_loss: 0.2896 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.28761\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.2665 - acc: 0.9678 - val_loss: 0.2902 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.28761\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.2647 - acc: 0.9664 - val_loss: 0.2808 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.28761 to 0.28084, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.2613 - acc: 0.9711 - val_loss: 0.2810 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.28084\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.2596 - acc: 0.9717 - val_loss: 0.2793 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.28084 to 0.27934, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.2560 - acc: 0.9711 - val_loss: 0.2800 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.27934\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.2553 - acc: 0.9704 - val_loss: 0.2735 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.27934 to 0.27351, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.2526 - acc: 0.9717 - val_loss: 0.2710 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.27351 to 0.27098, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.2504 - acc: 0.9730 - val_loss: 0.2671 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.27098 to 0.26709, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.2485 - acc: 0.9750 - val_loss: 0.2649 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.26709 to 0.26490, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.2463 - acc: 0.9724 - val_loss: 0.2635 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.26490 to 0.26355, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.2436 - acc: 0.9763 - val_loss: 0.2605 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.26355 to 0.26050, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.2421 - acc: 0.9750 - val_loss: 0.2605 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.26050\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.2396 - acc: 0.9737 - val_loss: 0.2598 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.26050 to 0.25980, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.2371 - acc: 0.9770 - val_loss: 0.2590 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.25980 to 0.25896, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.2364 - acc: 0.9763 - val_loss: 0.2569 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.25896 to 0.25693, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.2342 - acc: 0.9763 - val_loss: 0.2561 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.25693 to 0.25613, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.2325 - acc: 0.9783 - val_loss: 0.2549 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.25613 to 0.25488, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.2303 - acc: 0.9757 - val_loss: 0.2495 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.25488 to 0.24952, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.2283 - acc: 0.9783 - val_loss: 0.2541 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.24952\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.2274 - acc: 0.9783 - val_loss: 0.2450 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.24952 to 0.24502, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.2253 - acc: 0.9809 - val_loss: 0.2451 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.24502\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.2234 - acc: 0.9776 - val_loss: 0.2425 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.24502 to 0.24250, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.2220 - acc: 0.9829 - val_loss: 0.2437 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.24250\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.2200 - acc: 0.9809 - val_loss: 0.2411 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.24250 to 0.24114, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.2184 - acc: 0.9816 - val_loss: 0.2392 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.24114 to 0.23921, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.2173 - acc: 0.9816 - val_loss: 0.2375 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.23921 to 0.23755, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.2156 - acc: 0.9816 - val_loss: 0.2358 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.23755 to 0.23575, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.2137 - acc: 0.9829 - val_loss: 0.2354 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.23575 to 0.23542, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.2118 - acc: 0.9842 - val_loss: 0.2374 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.23542\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.2110 - acc: 0.9809 - val_loss: 0.2317 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.23542 to 0.23170, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.2092 - acc: 0.9842 - val_loss: 0.2324 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.23170\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.2079 - acc: 0.9822 - val_loss: 0.2284 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.23170 to 0.22840, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.2060 - acc: 0.9829 - val_loss: 0.2286 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.22840\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.2053 - acc: 0.9836 - val_loss: 0.2280 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.22840 to 0.22804, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.2035 - acc: 0.9829 - val_loss: 0.2270 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.22804 to 0.22696, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.2020 - acc: 0.9842 - val_loss: 0.2250 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.22696 to 0.22496, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.2008 - acc: 0.9862 - val_loss: 0.2235 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.22496 to 0.22353, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.1995 - acc: 0.9842 - val_loss: 0.2226 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.22353 to 0.22261, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.1983 - acc: 0.9875 - val_loss: 0.2215 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.22261 to 0.22146, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.1969 - acc: 0.9855 - val_loss: 0.2183 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.22146 to 0.21830, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.1953 - acc: 0.9862 - val_loss: 0.2211 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.21830\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.1940 - acc: 0.9862 - val_loss: 0.2166 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.21830 to 0.21659, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.1933 - acc: 0.9849 - val_loss: 0.2157 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.21659 to 0.21566, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.1914 - acc: 0.9868 - val_loss: 0.2141 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.21566 to 0.21407, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.1905 - acc: 0.9862 - val_loss: 0.2139 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.21407 to 0.21386, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.1891 - acc: 0.9855 - val_loss: 0.2098 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.21386 to 0.20980, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.1883 - acc: 0.9875 - val_loss: 0.2106 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.20980\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.1870 - acc: 0.9862 - val_loss: 0.2096 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.20980 to 0.20960, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.1860 - acc: 0.9862 - val_loss: 0.2069 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.20960 to 0.20686, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.1849 - acc: 0.9875 - val_loss: 0.2060 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.20686 to 0.20600, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.1837 - acc: 0.9875 - val_loss: 0.2056 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.20600 to 0.20558, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.1824 - acc: 0.9882 - val_loss: 0.2073 - val_acc: 0.9753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00114: val_loss did not improve from 0.20558\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.1814 - acc: 0.9875 - val_loss: 0.2039 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.20558 to 0.20390, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.1803 - acc: 0.9868 - val_loss: 0.2043 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.20390\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.1793 - acc: 0.9882 - val_loss: 0.2034 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.20390 to 0.20345, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.1780 - acc: 0.9895 - val_loss: 0.2034 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.20345 to 0.20335, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.1772 - acc: 0.9882 - val_loss: 0.1986 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.20335 to 0.19859, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.1763 - acc: 0.9875 - val_loss: 0.1998 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.19859\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.1748 - acc: 0.9882 - val_loss: 0.1965 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.19859 to 0.19646, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.1736 - acc: 0.9882 - val_loss: 0.1967 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.19646\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.1730 - acc: 0.9882 - val_loss: 0.1955 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.19646 to 0.19554, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.1721 - acc: 0.9895 - val_loss: 0.1959 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.19554\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.1710 - acc: 0.9888 - val_loss: 0.1952 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.19554 to 0.19515, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.1701 - acc: 0.9895 - val_loss: 0.1942 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.19515 to 0.19419, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.1693 - acc: 0.9895 - val_loss: 0.1923 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.19419 to 0.19231, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.1684 - acc: 0.9895 - val_loss: 0.1918 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.19231 to 0.19182, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.1670 - acc: 0.9888 - val_loss: 0.1914 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.19182 to 0.19145, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.1666 - acc: 0.9908 - val_loss: 0.1909 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.19145 to 0.19093, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.1654 - acc: 0.9914 - val_loss: 0.1880 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.19093 to 0.18800, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.1646 - acc: 0.9901 - val_loss: 0.1885 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.18800\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.1638 - acc: 0.9908 - val_loss: 0.1877 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.18800 to 0.18768, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.1626 - acc: 0.9901 - val_loss: 0.1891 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.18768\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.1621 - acc: 0.9921 - val_loss: 0.1863 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.18768 to 0.18630, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.1614 - acc: 0.9901 - val_loss: 0.1844 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.18630 to 0.18436, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.1601 - acc: 0.9914 - val_loss: 0.1847 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.18436\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.1595 - acc: 0.9928 - val_loss: 0.1827 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.18436 to 0.18270, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.1585 - acc: 0.9921 - val_loss: 0.1816 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.18270 to 0.18157, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.1576 - acc: 0.9914 - val_loss: 0.1814 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.18157 to 0.18139, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.1570 - acc: 0.9921 - val_loss: 0.1812 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.18139 to 0.18115, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.1561 - acc: 0.9928 - val_loss: 0.1802 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.18115 to 0.18018, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.1552 - acc: 0.9941 - val_loss: 0.1794 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.18018 to 0.17937, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.1546 - acc: 0.9928 - val_loss: 0.1786 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.17937 to 0.17865, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.1540 - acc: 0.9921 - val_loss: 0.1788 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.17865\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.1528 - acc: 0.9941 - val_loss: 0.1785 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.17865 to 0.17854, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.1522 - acc: 0.9928 - val_loss: 0.1762 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.17854 to 0.17623, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.1517 - acc: 0.9928 - val_loss: 0.1751 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.17623 to 0.17514, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.1508 - acc: 0.9928 - val_loss: 0.1754 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.17514\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.1500 - acc: 0.9934 - val_loss: 0.1737 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.17514 to 0.17370, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.1493 - acc: 0.9934 - val_loss: 0.1727 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.17370 to 0.17271, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.1486 - acc: 0.9934 - val_loss: 0.1732 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.17271\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.1479 - acc: 0.9934 - val_loss: 0.1719 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.17271 to 0.17192, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.1472 - acc: 0.9941 - val_loss: 0.1719 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.17192 to 0.17191, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.1464 - acc: 0.9947 - val_loss: 0.1715 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.17191 to 0.17147, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.1458 - acc: 0.9941 - val_loss: 0.1704 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.17147 to 0.17041, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.1451 - acc: 0.9941 - val_loss: 0.1703 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.17041 to 0.17026, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.1443 - acc: 0.9941 - val_loss: 0.1705 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.17026\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.1436 - acc: 0.9941 - val_loss: 0.1666 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.17026 to 0.16661, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.1429 - acc: 0.9947 - val_loss: 0.1677 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.16661\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.1426 - acc: 0.9934 - val_loss: 0.1669 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.16661\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.1418 - acc: 0.9941 - val_loss: 0.1662 - val_acc: 0.9918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00162: val_loss improved from 0.16661 to 0.16623, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.1412 - acc: 0.9934 - val_loss: 0.1670 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.16623\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.1407 - acc: 0.9954 - val_loss: 0.1659 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.16623 to 0.16594, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.1399 - acc: 0.9954 - val_loss: 0.1638 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.16594 to 0.16379, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.1393 - acc: 0.9941 - val_loss: 0.1654 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.16379\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.1386 - acc: 0.9934 - val_loss: 0.1631 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.16379 to 0.16312, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.1381 - acc: 0.9954 - val_loss: 0.1629 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.16312 to 0.16293, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.1374 - acc: 0.9947 - val_loss: 0.1626 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.16293 to 0.16262, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.1367 - acc: 0.9947 - val_loss: 0.1627 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.16262\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.1359 - acc: 0.9941 - val_loss: 0.1629 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.16262\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.1358 - acc: 0.9947 - val_loss: 0.1594 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00172: val_loss improved from 0.16262 to 0.15942, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.1345 - acc: 0.9954 - val_loss: 0.1626 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.15942\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.1344 - acc: 0.9954 - val_loss: 0.1603 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.15942\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.1338 - acc: 0.9947 - val_loss: 0.1579 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00175: val_loss improved from 0.15942 to 0.15795, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.1329 - acc: 0.9961 - val_loss: 0.1590 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.15795\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.1325 - acc: 0.9954 - val_loss: 0.1573 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00177: val_loss improved from 0.15795 to 0.15727, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.1321 - acc: 0.9954 - val_loss: 0.1563 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00178: val_loss improved from 0.15727 to 0.15633, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.1315 - acc: 0.9947 - val_loss: 0.1559 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00179: val_loss improved from 0.15633 to 0.15595, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.1311 - acc: 0.9954 - val_loss: 0.1546 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00180: val_loss improved from 0.15595 to 0.15463, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.1305 - acc: 0.9954 - val_loss: 0.1554 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.15463\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.1296 - acc: 0.9954 - val_loss: 0.1557 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.15463\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.1294 - acc: 0.9954 - val_loss: 0.1540 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00183: val_loss improved from 0.15463 to 0.15401, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.1287 - acc: 0.9961 - val_loss: 0.1544 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.15401\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.1284 - acc: 0.9954 - val_loss: 0.1533 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00185: val_loss improved from 0.15401 to 0.15327, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.1278 - acc: 0.9954 - val_loss: 0.1531 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.15327 to 0.15307, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.1271 - acc: 0.9954 - val_loss: 0.1533 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.15307\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.1268 - acc: 0.9954 - val_loss: 0.1513 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00188: val_loss improved from 0.15307 to 0.15127, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.1262 - acc: 0.9947 - val_loss: 0.1511 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.15127 to 0.15106, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.1258 - acc: 0.9947 - val_loss: 0.1504 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00190: val_loss improved from 0.15106 to 0.15042, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.1252 - acc: 0.9961 - val_loss: 0.1509 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.15042\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.1247 - acc: 0.9961 - val_loss: 0.1504 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.15042\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.1242 - acc: 0.9961 - val_loss: 0.1496 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00193: val_loss improved from 0.15042 to 0.14962, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.1234 - acc: 0.9967 - val_loss: 0.1480 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00194: val_loss improved from 0.14962 to 0.14804, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.1230 - acc: 0.9961 - val_loss: 0.1500 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.14804\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.1227 - acc: 0.9961 - val_loss: 0.1487 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.14804\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.1222 - acc: 0.9967 - val_loss: 0.1480 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00197: val_loss improved from 0.14804 to 0.14804, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.1218 - acc: 0.9961 - val_loss: 0.1467 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.14804 to 0.14671, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.1213 - acc: 0.9961 - val_loss: 0.1462 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00199: val_loss improved from 0.14671 to 0.14622, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.1209 - acc: 0.9961 - val_loss: 0.1464 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.14622\n",
      "batch_size=20   optimizer=Adagrad\n",
      "Test accuracy: 68.5237%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_29 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 1.9706 - acc: 0.3678 - val_loss: 1.2363 - val_acc: 0.5844\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.23627, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.1765 - acc: 0.6066 - val_loss: 1.0507 - val_acc: 0.6543\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.23627 to 1.05070, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 1.0342 - acc: 0.6467 - val_loss: 0.9362 - val_acc: 0.6790\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.05070 to 0.93620, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.9422 - acc: 0.6908 - val_loss: 0.8712 - val_acc: 0.7202\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.93620 to 0.87121, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.8630 - acc: 0.7283 - val_loss: 0.8584 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.87121 to 0.85845, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.8083 - acc: 0.7401 - val_loss: 0.7821 - val_acc: 0.7325\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.85845 to 0.78211, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.7742 - acc: 0.7493 - val_loss: 0.7681 - val_acc: 0.7325\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.78211 to 0.76806, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.7407 - acc: 0.7730 - val_loss: 0.7174 - val_acc: 0.7654\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.76806 to 0.71738, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.7065 - acc: 0.7829 - val_loss: 0.6930 - val_acc: 0.7737\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.71738 to 0.69301, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.6877 - acc: 0.7947 - val_loss: 0.6646 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.69301 to 0.66458, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.6601 - acc: 0.8046 - val_loss: 0.6513 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.66458 to 0.65127, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.6353 - acc: 0.8039 - val_loss: 0.6389 - val_acc: 0.8107\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.65127 to 0.63893, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.6159 - acc: 0.8151 - val_loss: 0.6158 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.63893 to 0.61580, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.6027 - acc: 0.8217 - val_loss: 0.6037 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.61580 to 0.60373, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.5862 - acc: 0.8296 - val_loss: 0.5917 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.60373 to 0.59172, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.5692 - acc: 0.8375 - val_loss: 0.5718 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.59172 to 0.57185, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.5556 - acc: 0.8454 - val_loss: 0.5542 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.57185 to 0.55422, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.5431 - acc: 0.8480 - val_loss: 0.5540 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.55422 to 0.55401, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.5311 - acc: 0.8480 - val_loss: 0.5364 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.55401 to 0.53641, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.5224 - acc: 0.8520 - val_loss: 0.5184 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.53641 to 0.51844, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.5091 - acc: 0.8592 - val_loss: 0.5146 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.51844 to 0.51462, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.4969 - acc: 0.8645 - val_loss: 0.5156 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.51462\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.4912 - acc: 0.8724 - val_loss: 0.5158 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.51462\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.4803 - acc: 0.8651 - val_loss: 0.4927 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.51462 to 0.49270, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.4710 - acc: 0.8776 - val_loss: 0.4895 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.49270 to 0.48950, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.4630 - acc: 0.8803 - val_loss: 0.4886 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.48950 to 0.48859, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.4567 - acc: 0.8836 - val_loss: 0.4759 - val_acc: 0.8765\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.48859 to 0.47588, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.4473 - acc: 0.8921 - val_loss: 0.4650 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.47588 to 0.46500, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.4418 - acc: 0.8901 - val_loss: 0.4554 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.46500 to 0.45543, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.4332 - acc: 0.8928 - val_loss: 0.4457 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.45543 to 0.44574, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.4279 - acc: 0.8941 - val_loss: 0.4465 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.44574\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.4211 - acc: 0.8941 - val_loss: 0.4282 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.44574 to 0.42822, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.4166 - acc: 0.9033 - val_loss: 0.4296 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.42822\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.4086 - acc: 0.9033 - val_loss: 0.4269 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.42822 to 0.42689, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.4035 - acc: 0.9053 - val_loss: 0.4206 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.42689 to 0.42058, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.3987 - acc: 0.9132 - val_loss: 0.4233 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.42058\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.3926 - acc: 0.9151 - val_loss: 0.4059 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.42058 to 0.40592, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.3870 - acc: 0.9217 - val_loss: 0.4007 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.40592 to 0.40071, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.3827 - acc: 0.9191 - val_loss: 0.3953 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.40071 to 0.39532, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.3769 - acc: 0.9164 - val_loss: 0.3918 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.39532 to 0.39179, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.3734 - acc: 0.9237 - val_loss: 0.3847 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.39179 to 0.38469, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.3686 - acc: 0.9250 - val_loss: 0.3826 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.38469 to 0.38263, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.3638 - acc: 0.9283 - val_loss: 0.3788 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.38263 to 0.37879, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.3597 - acc: 0.9296 - val_loss: 0.3748 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.37879 to 0.37483, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.3546 - acc: 0.9355 - val_loss: 0.3725 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.37483 to 0.37253, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.3504 - acc: 0.9349 - val_loss: 0.3744 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.37253\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.3475 - acc: 0.9322 - val_loss: 0.3661 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.37253 to 0.36608, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.3432 - acc: 0.9382 - val_loss: 0.3624 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.36608 to 0.36240, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.3396 - acc: 0.9395 - val_loss: 0.3526 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.36240 to 0.35264, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.3359 - acc: 0.9441 - val_loss: 0.3614 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.35264\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.3332 - acc: 0.9428 - val_loss: 0.3585 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.35264\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.3290 - acc: 0.9434 - val_loss: 0.3464 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.35264 to 0.34644, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.3247 - acc: 0.9414 - val_loss: 0.3404 - val_acc: 0.9547\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00053: val_loss improved from 0.34644 to 0.34038, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.3213 - acc: 0.9447 - val_loss: 0.3359 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.34038 to 0.33587, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.3178 - acc: 0.9480 - val_loss: 0.3347 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.33587 to 0.33465, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.3149 - acc: 0.9513 - val_loss: 0.3347 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.33465\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.3121 - acc: 0.9480 - val_loss: 0.3349 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.33465\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.3093 - acc: 0.9520 - val_loss: 0.3267 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.33465 to 0.32669, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.3054 - acc: 0.9493 - val_loss: 0.3323 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.32669\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.3035 - acc: 0.9572 - val_loss: 0.3272 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.32669\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.3001 - acc: 0.9520 - val_loss: 0.3206 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.32669 to 0.32055, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.2976 - acc: 0.9566 - val_loss: 0.3139 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.32055 to 0.31389, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.2951 - acc: 0.9566 - val_loss: 0.3145 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.31389\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.2914 - acc: 0.9572 - val_loss: 0.3088 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.31389 to 0.30876, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.2896 - acc: 0.9579 - val_loss: 0.3092 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.30876\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.2872 - acc: 0.9599 - val_loss: 0.3070 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.30876 to 0.30697, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.2842 - acc: 0.9625 - val_loss: 0.3021 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.30697 to 0.30210, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.2819 - acc: 0.9618 - val_loss: 0.3019 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.30210 to 0.30190, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.2789 - acc: 0.9625 - val_loss: 0.3009 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.30190 to 0.30085, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.2760 - acc: 0.9638 - val_loss: 0.2968 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.30085 to 0.29678, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.2742 - acc: 0.9638 - val_loss: 0.2942 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.29678 to 0.29419, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.2721 - acc: 0.9651 - val_loss: 0.2899 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.29419 to 0.28988, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.2700 - acc: 0.9658 - val_loss: 0.2878 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.28988 to 0.28785, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.2677 - acc: 0.9632 - val_loss: 0.2853 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.28785 to 0.28532, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.2654 - acc: 0.9658 - val_loss: 0.2862 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.28532\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.2640 - acc: 0.9678 - val_loss: 0.2830 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.28532 to 0.28303, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.2615 - acc: 0.9678 - val_loss: 0.2821 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.28303 to 0.28209, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.2595 - acc: 0.9678 - val_loss: 0.2801 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.28209 to 0.28006, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.2577 - acc: 0.9691 - val_loss: 0.2771 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.28006 to 0.27710, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.2546 - acc: 0.9737 - val_loss: 0.2769 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.27710 to 0.27689, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.2535 - acc: 0.9704 - val_loss: 0.2748 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.27689 to 0.27484, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.2514 - acc: 0.9711 - val_loss: 0.2697 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.27484 to 0.26973, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.2491 - acc: 0.9724 - val_loss: 0.2720 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.26973\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.2471 - acc: 0.9750 - val_loss: 0.2665 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.26973 to 0.26647, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.2450 - acc: 0.9704 - val_loss: 0.2694 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.26647\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.2440 - acc: 0.9750 - val_loss: 0.2672 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.26647\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.2419 - acc: 0.9730 - val_loss: 0.2621 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.26647 to 0.26213, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.2400 - acc: 0.9763 - val_loss: 0.2609 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.26213 to 0.26092, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.2385 - acc: 0.9730 - val_loss: 0.2647 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.26092\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.2374 - acc: 0.9737 - val_loss: 0.2589 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.26092 to 0.25890, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.2354 - acc: 0.9743 - val_loss: 0.2565 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.25890 to 0.25655, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.2333 - acc: 0.9757 - val_loss: 0.2567 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.25655\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.2319 - acc: 0.9757 - val_loss: 0.2529 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.25655 to 0.25289, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.2304 - acc: 0.9770 - val_loss: 0.2509 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.25289 to 0.25085, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.2290 - acc: 0.9763 - val_loss: 0.2527 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.25085\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.2270 - acc: 0.9776 - val_loss: 0.2484 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.25085 to 0.24842, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.2257 - acc: 0.9783 - val_loss: 0.2453 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.24842 to 0.24531, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.2238 - acc: 0.9796 - val_loss: 0.2458 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.24531\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.2224 - acc: 0.9796 - val_loss: 0.2445 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.24531 to 0.24452, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.2213 - acc: 0.9789 - val_loss: 0.2434 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.24452 to 0.24345, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.2203 - acc: 0.9803 - val_loss: 0.2417 - val_acc: 0.9753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00101: val_loss improved from 0.24345 to 0.24170, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.2181 - acc: 0.9789 - val_loss: 0.2415 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.24170 to 0.24149, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.2165 - acc: 0.9796 - val_loss: 0.2412 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.24149 to 0.24125, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.2156 - acc: 0.9816 - val_loss: 0.2373 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.24125 to 0.23734, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.2135 - acc: 0.9816 - val_loss: 0.2366 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.23734 to 0.23658, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.2127 - acc: 0.9822 - val_loss: 0.2347 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.23658 to 0.23471, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.2117 - acc: 0.9829 - val_loss: 0.2312 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.23471 to 0.23123, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.2101 - acc: 0.9816 - val_loss: 0.2352 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.23123\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.2089 - acc: 0.9816 - val_loss: 0.2304 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.23123 to 0.23037, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.2074 - acc: 0.9822 - val_loss: 0.2309 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.23037\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.2063 - acc: 0.9829 - val_loss: 0.2299 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.23037 to 0.22991, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.2042 - acc: 0.9829 - val_loss: 0.2311 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.22991\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.2039 - acc: 0.9822 - val_loss: 0.2299 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.22991\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.2025 - acc: 0.9829 - val_loss: 0.2254 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.22991 to 0.22543, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.2010 - acc: 0.9855 - val_loss: 0.2238 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.22543 to 0.22383, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.1995 - acc: 0.9829 - val_loss: 0.2224 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.22383 to 0.22240, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.1989 - acc: 0.9842 - val_loss: 0.2201 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.22240 to 0.22006, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.1977 - acc: 0.9836 - val_loss: 0.2217 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.22006\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.1960 - acc: 0.9829 - val_loss: 0.2203 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.22006\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.1950 - acc: 0.9868 - val_loss: 0.2163 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.22006 to 0.21630, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.1943 - acc: 0.9849 - val_loss: 0.2172 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.21630\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.1929 - acc: 0.9849 - val_loss: 0.2144 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.21630 to 0.21445, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.1920 - acc: 0.9836 - val_loss: 0.2163 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.21445\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.1908 - acc: 0.9855 - val_loss: 0.2118 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.21445 to 0.21182, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.1895 - acc: 0.9849 - val_loss: 0.2137 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.21182\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.1888 - acc: 0.9855 - val_loss: 0.2120 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.21182\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.1876 - acc: 0.9855 - val_loss: 0.2105 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.21182 to 0.21053, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.1869 - acc: 0.9862 - val_loss: 0.2080 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.21053 to 0.20802, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.1856 - acc: 0.9875 - val_loss: 0.2098 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.20802\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.1847 - acc: 0.9855 - val_loss: 0.2082 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.20802\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.1836 - acc: 0.9868 - val_loss: 0.2076 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.20802 to 0.20765, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.1824 - acc: 0.9875 - val_loss: 0.2086 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.20765\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.1820 - acc: 0.9875 - val_loss: 0.2061 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.20765 to 0.20609, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.1807 - acc: 0.9882 - val_loss: 0.2034 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.20609 to 0.20340, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.1797 - acc: 0.9862 - val_loss: 0.2042 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.20340\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.1786 - acc: 0.9868 - val_loss: 0.2019 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.20340 to 0.20191, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.1776 - acc: 0.9888 - val_loss: 0.1986 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.20191 to 0.19864, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.1767 - acc: 0.9895 - val_loss: 0.2018 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.19864\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.1759 - acc: 0.9895 - val_loss: 0.1994 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.19864\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.1750 - acc: 0.9888 - val_loss: 0.1983 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.19864 to 0.19826, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.1740 - acc: 0.9888 - val_loss: 0.1955 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.19826 to 0.19546, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.1736 - acc: 0.9888 - val_loss: 0.1964 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.19546\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.1723 - acc: 0.9895 - val_loss: 0.1946 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.19546 to 0.19462, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.1713 - acc: 0.9882 - val_loss: 0.1944 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.19462 to 0.19437, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.1703 - acc: 0.9895 - val_loss: 0.1950 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.19437\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.1697 - acc: 0.9875 - val_loss: 0.1938 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.19437 to 0.19381, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.1690 - acc: 0.9901 - val_loss: 0.1918 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.19381 to 0.19179, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.1681 - acc: 0.9908 - val_loss: 0.1916 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.19179 to 0.19161, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.1675 - acc: 0.9901 - val_loss: 0.1913 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.19161 to 0.19134, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.1667 - acc: 0.9888 - val_loss: 0.1916 - val_acc: 0.9877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00150: val_loss did not improve from 0.19134\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.1654 - acc: 0.9908 - val_loss: 0.1888 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.19134 to 0.18878, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.1650 - acc: 0.9901 - val_loss: 0.1887 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.18878 to 0.18866, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.1641 - acc: 0.9895 - val_loss: 0.1889 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.18866\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.1635 - acc: 0.9914 - val_loss: 0.1869 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.18866 to 0.18689, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.1623 - acc: 0.9921 - val_loss: 0.1875 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.18689\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.1617 - acc: 0.9921 - val_loss: 0.1854 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.18689 to 0.18540, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.1604 - acc: 0.9928 - val_loss: 0.1839 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.18540 to 0.18386, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.1601 - acc: 0.9921 - val_loss: 0.1842 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.18386\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.1594 - acc: 0.9928 - val_loss: 0.1819 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.18386 to 0.18193, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.1589 - acc: 0.9908 - val_loss: 0.1823 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.18193\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.1579 - acc: 0.9921 - val_loss: 0.1823 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.18193\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.1571 - acc: 0.9928 - val_loss: 0.1811 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.18193 to 0.18113, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.1565 - acc: 0.9928 - val_loss: 0.1814 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.18113\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.1558 - acc: 0.9921 - val_loss: 0.1795 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.18113 to 0.17947, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.1553 - acc: 0.9928 - val_loss: 0.1784 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.17947 to 0.17839, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.1542 - acc: 0.9928 - val_loss: 0.1784 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.17839\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.1539 - acc: 0.9934 - val_loss: 0.1766 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.17839 to 0.17660, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.1528 - acc: 0.9934 - val_loss: 0.1756 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.17660 to 0.17559, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.1526 - acc: 0.9934 - val_loss: 0.1773 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.17559\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.1513 - acc: 0.9941 - val_loss: 0.1755 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.17559 to 0.17550, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.1509 - acc: 0.9934 - val_loss: 0.1737 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00171: val_loss improved from 0.17550 to 0.17371, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.1502 - acc: 0.9928 - val_loss: 0.1748 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.17371\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.1496 - acc: 0.9934 - val_loss: 0.1739 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.17371\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.1489 - acc: 0.9934 - val_loss: 0.1729 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.17371 to 0.17286, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.1483 - acc: 0.9934 - val_loss: 0.1724 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00175: val_loss improved from 0.17286 to 0.17237, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.1476 - acc: 0.9941 - val_loss: 0.1741 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.17237\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.1470 - acc: 0.9928 - val_loss: 0.1705 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00177: val_loss improved from 0.17237 to 0.17055, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.1462 - acc: 0.9928 - val_loss: 0.1697 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00178: val_loss improved from 0.17055 to 0.16972, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.1458 - acc: 0.9947 - val_loss: 0.1724 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.16972\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.1452 - acc: 0.9934 - val_loss: 0.1701 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.16972\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.1443 - acc: 0.9921 - val_loss: 0.1713 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.16972\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.1442 - acc: 0.9947 - val_loss: 0.1692 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00182: val_loss improved from 0.16972 to 0.16919, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.1432 - acc: 0.9941 - val_loss: 0.1682 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00183: val_loss improved from 0.16919 to 0.16822, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.1429 - acc: 0.9947 - val_loss: 0.1680 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00184: val_loss improved from 0.16822 to 0.16798, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.1423 - acc: 0.9954 - val_loss: 0.1676 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00185: val_loss improved from 0.16798 to 0.16761, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.1416 - acc: 0.9954 - val_loss: 0.1649 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.16761 to 0.16486, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.1408 - acc: 0.9947 - val_loss: 0.1651 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.16486\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.1404 - acc: 0.9947 - val_loss: 0.1648 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00188: val_loss improved from 0.16486 to 0.16483, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.1399 - acc: 0.9954 - val_loss: 0.1641 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.16483 to 0.16413, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.1393 - acc: 0.9947 - val_loss: 0.1621 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00190: val_loss improved from 0.16413 to 0.16213, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.1387 - acc: 0.9954 - val_loss: 0.1634 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.16213\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.1383 - acc: 0.9954 - val_loss: 0.1615 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.16213 to 0.16146, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.1377 - acc: 0.9954 - val_loss: 0.1624 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.16146\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.1369 - acc: 0.9947 - val_loss: 0.1622 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.16146\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.1365 - acc: 0.9954 - val_loss: 0.1629 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.16146\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.1359 - acc: 0.9954 - val_loss: 0.1606 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00196: val_loss improved from 0.16146 to 0.16065, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.1353 - acc: 0.9961 - val_loss: 0.1607 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.16065\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.1349 - acc: 0.9954 - val_loss: 0.1609 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.16065\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.1344 - acc: 0.9967 - val_loss: 0.1597 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00199: val_loss improved from 0.16065 to 0.15974, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.1339 - acc: 0.9954 - val_loss: 0.1586 - val_acc: 0.9918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00200: val_loss improved from 0.15974 to 0.15861, saving model to weights.best.Resnet50.hdf5\n",
      "batch_size=40   optimizer=Adagrad\n",
      "Test accuracy: 68.2451%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 2.2571 - acc: 0.3316 - val_loss: 1.4234 - val_acc: 0.5062\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.42344, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.2751 - acc: 0.5849 - val_loss: 1.1322 - val_acc: 0.6461\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.42344 to 1.13221, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 1.1260 - acc: 0.6388 - val_loss: 1.0303 - val_acc: 0.6872\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.13221 to 1.03026, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 1.0258 - acc: 0.6684 - val_loss: 0.9711 - val_acc: 0.7078\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.03026 to 0.97108, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.9632 - acc: 0.6921 - val_loss: 0.8921 - val_acc: 0.7160\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.97108 to 0.89215, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.9039 - acc: 0.7099 - val_loss: 0.8518 - val_acc: 0.7531\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.89215 to 0.85178, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.8637 - acc: 0.7289 - val_loss: 0.8299 - val_acc: 0.7407\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.85178 to 0.82989, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.8253 - acc: 0.7408 - val_loss: 0.7900 - val_acc: 0.7613\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.82989 to 0.79002, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.7933 - acc: 0.7513 - val_loss: 0.7660 - val_acc: 0.7613\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.79002 to 0.76600, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.7620 - acc: 0.7632 - val_loss: 0.7529 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.76600 to 0.75285, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.7332 - acc: 0.7836 - val_loss: 0.7387 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.75285 to 0.73873, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.7168 - acc: 0.7770 - val_loss: 0.7060 - val_acc: 0.7819\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.73873 to 0.70599, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.6919 - acc: 0.8000 - val_loss: 0.6869 - val_acc: 0.8107\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.70599 to 0.68694, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.6756 - acc: 0.7993 - val_loss: 0.6722 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.68694 to 0.67220, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.6561 - acc: 0.8066 - val_loss: 0.6701 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.67220 to 0.67011, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.6449 - acc: 0.8112 - val_loss: 0.6438 - val_acc: 0.8148\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.67011 to 0.64380, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.6253 - acc: 0.8178 - val_loss: 0.6334 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.64380 to 0.63337, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.6130 - acc: 0.8224 - val_loss: 0.6268 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.63337 to 0.62683, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.6001 - acc: 0.8276 - val_loss: 0.6085 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.62683 to 0.60849, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.5876 - acc: 0.8355 - val_loss: 0.5988 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.60849 to 0.59879, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.5771 - acc: 0.8336 - val_loss: 0.5823 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.59879 to 0.58231, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.5667 - acc: 0.8388 - val_loss: 0.5756 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.58231 to 0.57559, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.5534 - acc: 0.8480 - val_loss: 0.5652 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.57559 to 0.56524, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.5462 - acc: 0.8467 - val_loss: 0.5676 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.56524\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.5364 - acc: 0.8579 - val_loss: 0.5458 - val_acc: 0.8765\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.56524 to 0.54580, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.5254 - acc: 0.8559 - val_loss: 0.5491 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.54580\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.5160 - acc: 0.8638 - val_loss: 0.5452 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.54580 to 0.54522, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.5101 - acc: 0.8625 - val_loss: 0.5242 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.54522 to 0.52421, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.5037 - acc: 0.8664 - val_loss: 0.5174 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.52421 to 0.51739, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.4938 - acc: 0.8691 - val_loss: 0.5138 - val_acc: 0.8765\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.51739 to 0.51378, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.4872 - acc: 0.8730 - val_loss: 0.5027 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.51378 to 0.50270, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.4799 - acc: 0.8750 - val_loss: 0.4956 - val_acc: 0.9012\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.50270 to 0.49560, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.4739 - acc: 0.8724 - val_loss: 0.4888 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.49560 to 0.48875, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.4656 - acc: 0.8862 - val_loss: 0.4939 - val_acc: 0.8765\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.48875\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.4589 - acc: 0.8842 - val_loss: 0.4745 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.48875 to 0.47449, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.4531 - acc: 0.8908 - val_loss: 0.4820 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.47449\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.4487 - acc: 0.8921 - val_loss: 0.4692 - val_acc: 0.9012\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.47449 to 0.46921, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.4436 - acc: 0.8961 - val_loss: 0.4653 - val_acc: 0.9012\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.46921 to 0.46532, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.4358 - acc: 0.8974 - val_loss: 0.4616 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.46532 to 0.46161, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.4304 - acc: 0.8993 - val_loss: 0.4509 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.46161 to 0.45094, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.4269 - acc: 0.8947 - val_loss: 0.4496 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.45094 to 0.44956, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.4222 - acc: 0.9059 - val_loss: 0.4441 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.44956 to 0.44407, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.4174 - acc: 0.9039 - val_loss: 0.4373 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.44407 to 0.43734, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.4111 - acc: 0.9125 - val_loss: 0.4372 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.43734 to 0.43724, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.4074 - acc: 0.9105 - val_loss: 0.4360 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.43724 to 0.43598, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.4039 - acc: 0.9086 - val_loss: 0.4218 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.43598 to 0.42184, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.3979 - acc: 0.9118 - val_loss: 0.4194 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.42184 to 0.41945, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.3941 - acc: 0.9138 - val_loss: 0.4191 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.41945 to 0.41911, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.3899 - acc: 0.9184 - val_loss: 0.4151 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.41911 to 0.41511, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.3850 - acc: 0.9197 - val_loss: 0.4079 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.41511 to 0.40786, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.3817 - acc: 0.9224 - val_loss: 0.4062 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.40786 to 0.40622, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.3772 - acc: 0.9263 - val_loss: 0.3984 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.40622 to 0.39842, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.3732 - acc: 0.9257 - val_loss: 0.3968 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.39842 to 0.39682, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.3718 - acc: 0.9283 - val_loss: 0.3921 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.39682 to 0.39210, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.3670 - acc: 0.9270 - val_loss: 0.3893 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.39210 to 0.38935, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.3634 - acc: 0.9309 - val_loss: 0.3854 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.38935 to 0.38536, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.3603 - acc: 0.9303 - val_loss: 0.3855 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.38536\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.3564 - acc: 0.9316 - val_loss: 0.3785 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.38536 to 0.37850, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.3545 - acc: 0.9336 - val_loss: 0.3776 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.37850 to 0.37759, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.3492 - acc: 0.9336 - val_loss: 0.3756 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.37759 to 0.37555, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.3466 - acc: 0.9388 - val_loss: 0.3679 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.37555 to 0.36787, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.3425 - acc: 0.9342 - val_loss: 0.3631 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.36787 to 0.36313, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.3395 - acc: 0.9349 - val_loss: 0.3604 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.36313 to 0.36036, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.3367 - acc: 0.9401 - val_loss: 0.3569 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.36036 to 0.35692, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.3324 - acc: 0.9375 - val_loss: 0.3617 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.35692\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.3302 - acc: 0.9401 - val_loss: 0.3550 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.35692 to 0.35503, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.3289 - acc: 0.9408 - val_loss: 0.3549 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.35503 to 0.35491, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.3261 - acc: 0.9434 - val_loss: 0.3496 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.35491 to 0.34956, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.3229 - acc: 0.9467 - val_loss: 0.3453 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.34956 to 0.34530, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.3197 - acc: 0.9467 - val_loss: 0.3459 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.34530\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.3171 - acc: 0.9487 - val_loss: 0.3445 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.34530 to 0.34447, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.3146 - acc: 0.9480 - val_loss: 0.3398 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.34447 to 0.33976, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.3120 - acc: 0.9480 - val_loss: 0.3352 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.33976 to 0.33517, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.3094 - acc: 0.9487 - val_loss: 0.3356 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33517\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.3069 - acc: 0.9493 - val_loss: 0.3332 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.33517 to 0.33323, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.3047 - acc: 0.9533 - val_loss: 0.3272 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.33323 to 0.32723, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.3037 - acc: 0.9513 - val_loss: 0.3272 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.32723\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.3008 - acc: 0.9533 - val_loss: 0.3255 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.32723 to 0.32552, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.2980 - acc: 0.9507 - val_loss: 0.3211 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.32552 to 0.32111, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.2950 - acc: 0.9520 - val_loss: 0.3241 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.32111\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.2936 - acc: 0.9539 - val_loss: 0.3189 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.32111 to 0.31891, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.2908 - acc: 0.9553 - val_loss: 0.3147 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.31891 to 0.31475, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.2883 - acc: 0.9559 - val_loss: 0.3121 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.31475 to 0.31205, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.2869 - acc: 0.9546 - val_loss: 0.3117 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.31205 to 0.31170, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.2846 - acc: 0.9559 - val_loss: 0.3134 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.31170\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.2826 - acc: 0.9579 - val_loss: 0.3072 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.31170 to 0.30717, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.2802 - acc: 0.9592 - val_loss: 0.3074 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.30717\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.2787 - acc: 0.9612 - val_loss: 0.3033 - val_acc: 0.9630\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00088: val_loss improved from 0.30717 to 0.30326, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.2763 - acc: 0.9572 - val_loss: 0.3086 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.30326\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.2748 - acc: 0.9599 - val_loss: 0.3040 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.30326\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.2731 - acc: 0.9612 - val_loss: 0.2945 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.30326 to 0.29445, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.2709 - acc: 0.9579 - val_loss: 0.2949 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.29445\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.2687 - acc: 0.9605 - val_loss: 0.2950 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.29445\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.2666 - acc: 0.9632 - val_loss: 0.2943 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.29445 to 0.29430, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.2656 - acc: 0.9658 - val_loss: 0.2891 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.29430 to 0.28911, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.2637 - acc: 0.9632 - val_loss: 0.2909 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.28911\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.2615 - acc: 0.9678 - val_loss: 0.2879 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.28911 to 0.28788, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.2608 - acc: 0.9638 - val_loss: 0.2852 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.28788 to 0.28523, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.2585 - acc: 0.9664 - val_loss: 0.2827 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.28523 to 0.28272, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.2560 - acc: 0.9658 - val_loss: 0.2813 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.28272 to 0.28127, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.2549 - acc: 0.9684 - val_loss: 0.2790 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.28127 to 0.27902, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.2529 - acc: 0.9664 - val_loss: 0.2793 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.27902\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.2517 - acc: 0.9684 - val_loss: 0.2771 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.27902 to 0.27715, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.2496 - acc: 0.9678 - val_loss: 0.2787 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.27715\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.2491 - acc: 0.9691 - val_loss: 0.2789 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.27715\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.2484 - acc: 0.9691 - val_loss: 0.2729 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.27715 to 0.27290, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.2456 - acc: 0.9691 - val_loss: 0.2720 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.27290 to 0.27199, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.2445 - acc: 0.9724 - val_loss: 0.2704 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.27199 to 0.27044, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.2432 - acc: 0.9717 - val_loss: 0.2663 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.27044 to 0.26629, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.2408 - acc: 0.9724 - val_loss: 0.2675 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.26629\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.2402 - acc: 0.9717 - val_loss: 0.2660 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.26629 to 0.26595, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.2380 - acc: 0.9724 - val_loss: 0.2629 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.26595 to 0.26287, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.2363 - acc: 0.9711 - val_loss: 0.2657 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.26287\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.2363 - acc: 0.9730 - val_loss: 0.2587 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.26287 to 0.25873, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.2344 - acc: 0.9763 - val_loss: 0.2584 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.25873 to 0.25841, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.2326 - acc: 0.9743 - val_loss: 0.2579 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.25841 to 0.25785, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.2316 - acc: 0.9750 - val_loss: 0.2562 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.25785 to 0.25618, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.2300 - acc: 0.9737 - val_loss: 0.2554 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.25618 to 0.25536, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.2291 - acc: 0.9750 - val_loss: 0.2539 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.25536 to 0.25394, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.2272 - acc: 0.9743 - val_loss: 0.2546 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.25394\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.2267 - acc: 0.9783 - val_loss: 0.2515 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.25394 to 0.25150, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.2252 - acc: 0.9750 - val_loss: 0.2504 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.25150 to 0.25042, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.2234 - acc: 0.9770 - val_loss: 0.2495 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.25042 to 0.24946, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.2227 - acc: 0.9776 - val_loss: 0.2472 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.24946 to 0.24723, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.2210 - acc: 0.9757 - val_loss: 0.2454 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.24723 to 0.24537, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.2200 - acc: 0.9789 - val_loss: 0.2444 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.24537 to 0.24443, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.2192 - acc: 0.9776 - val_loss: 0.2425 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.24443 to 0.24250, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.2171 - acc: 0.9789 - val_loss: 0.2435 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.24250\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.2164 - acc: 0.9796 - val_loss: 0.2431 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.24250\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.2155 - acc: 0.9776 - val_loss: 0.2408 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.24250 to 0.24082, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.2140 - acc: 0.9803 - val_loss: 0.2379 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.24082 to 0.23789, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.2128 - acc: 0.9822 - val_loss: 0.2382 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.23789\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.2117 - acc: 0.9809 - val_loss: 0.2364 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.23789 to 0.23635, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.2102 - acc: 0.9836 - val_loss: 0.2347 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.23635 to 0.23466, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.2096 - acc: 0.9816 - val_loss: 0.2339 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.23466 to 0.23394, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.2089 - acc: 0.9836 - val_loss: 0.2338 - val_acc: 0.9753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00136: val_loss improved from 0.23394 to 0.23379, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.2074 - acc: 0.9842 - val_loss: 0.2327 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.23379 to 0.23270, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.2062 - acc: 0.9849 - val_loss: 0.2302 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.23270 to 0.23024, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.2051 - acc: 0.9836 - val_loss: 0.2289 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.23024 to 0.22886, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.2042 - acc: 0.9849 - val_loss: 0.2291 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.22886\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.2031 - acc: 0.9836 - val_loss: 0.2269 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.22886 to 0.22693, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.2023 - acc: 0.9849 - val_loss: 0.2287 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.22693\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.2011 - acc: 0.9849 - val_loss: 0.2271 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.22693\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.2004 - acc: 0.9862 - val_loss: 0.2253 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.22693 to 0.22528, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.1996 - acc: 0.9836 - val_loss: 0.2252 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.22528 to 0.22518, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.1980 - acc: 0.9875 - val_loss: 0.2242 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.22518 to 0.22416, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.1970 - acc: 0.9849 - val_loss: 0.2241 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.22416 to 0.22406, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.1960 - acc: 0.9855 - val_loss: 0.2204 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.22406 to 0.22040, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.1953 - acc: 0.9855 - val_loss: 0.2196 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.22040 to 0.21955, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.1944 - acc: 0.9842 - val_loss: 0.2190 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.21955 to 0.21902, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.1939 - acc: 0.9875 - val_loss: 0.2190 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.21902 to 0.21897, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.1928 - acc: 0.9849 - val_loss: 0.2166 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.21897 to 0.21665, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.1915 - acc: 0.9875 - val_loss: 0.2184 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.21665\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.1904 - acc: 0.9882 - val_loss: 0.2170 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.21665\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.1899 - acc: 0.9875 - val_loss: 0.2138 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.21665 to 0.21383, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.1887 - acc: 0.9895 - val_loss: 0.2145 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.21383\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.1883 - acc: 0.9875 - val_loss: 0.2158 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.21383\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.1875 - acc: 0.9882 - val_loss: 0.2120 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.21383 to 0.21201, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.1865 - acc: 0.9882 - val_loss: 0.2119 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.21201 to 0.21189, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.1856 - acc: 0.9882 - val_loss: 0.2123 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.21189\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.1848 - acc: 0.9895 - val_loss: 0.2111 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.21189 to 0.21108, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.1839 - acc: 0.9888 - val_loss: 0.2094 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.21108 to 0.20943, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.1825 - acc: 0.9895 - val_loss: 0.2068 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00163: val_loss improved from 0.20943 to 0.20682, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.1817 - acc: 0.9901 - val_loss: 0.2079 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.20682\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.1811 - acc: 0.9908 - val_loss: 0.2072 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.20682\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.1801 - acc: 0.9908 - val_loss: 0.2072 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.20682\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.1797 - acc: 0.9901 - val_loss: 0.2051 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.20682 to 0.20508, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.1785 - acc: 0.9914 - val_loss: 0.2046 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.20508 to 0.20456, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.1781 - acc: 0.9908 - val_loss: 0.2008 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.20456 to 0.20078, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.1772 - acc: 0.9908 - val_loss: 0.2014 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.20078\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.1768 - acc: 0.9908 - val_loss: 0.2000 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00171: val_loss improved from 0.20078 to 0.20002, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.1753 - acc: 0.9921 - val_loss: 0.2007 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.20002\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.1750 - acc: 0.9914 - val_loss: 0.1996 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.20002 to 0.19956, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.1740 - acc: 0.9901 - val_loss: 0.1973 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.19956 to 0.19734, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.1733 - acc: 0.9928 - val_loss: 0.1967 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00175: val_loss improved from 0.19734 to 0.19671, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.1725 - acc: 0.9921 - val_loss: 0.1983 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.19671\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.1720 - acc: 0.9914 - val_loss: 0.1983 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.19671\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.1711 - acc: 0.9928 - val_loss: 0.1965 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00178: val_loss improved from 0.19671 to 0.19653, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.1705 - acc: 0.9921 - val_loss: 0.1945 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00179: val_loss improved from 0.19653 to 0.19454, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.1699 - acc: 0.9928 - val_loss: 0.1958 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.19454\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.1689 - acc: 0.9928 - val_loss: 0.1942 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00181: val_loss improved from 0.19454 to 0.19416, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.1684 - acc: 0.9921 - val_loss: 0.1941 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00182: val_loss improved from 0.19416 to 0.19415, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.1678 - acc: 0.9921 - val_loss: 0.1939 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00183: val_loss improved from 0.19415 to 0.19386, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.1672 - acc: 0.9928 - val_loss: 0.1911 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00184: val_loss improved from 0.19386 to 0.19109, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.1662 - acc: 0.9928 - val_loss: 0.1910 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00185: val_loss improved from 0.19109 to 0.19096, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.1656 - acc: 0.9921 - val_loss: 0.1906 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.19096 to 0.19064, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.1647 - acc: 0.9928 - val_loss: 0.1903 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.19064 to 0.19027, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.1641 - acc: 0.9921 - val_loss: 0.1882 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00188: val_loss improved from 0.19027 to 0.18823, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.1636 - acc: 0.9928 - val_loss: 0.1871 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.18823 to 0.18710, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.1628 - acc: 0.9928 - val_loss: 0.1850 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00190: val_loss improved from 0.18710 to 0.18503, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.1621 - acc: 0.9928 - val_loss: 0.1876 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.18503\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.1615 - acc: 0.9921 - val_loss: 0.1856 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.18503\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.1609 - acc: 0.9928 - val_loss: 0.1847 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00193: val_loss improved from 0.18503 to 0.18472, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.1604 - acc: 0.9921 - val_loss: 0.1843 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00194: val_loss improved from 0.18472 to 0.18429, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.1599 - acc: 0.9914 - val_loss: 0.1845 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.18429\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.1592 - acc: 0.9928 - val_loss: 0.1834 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00196: val_loss improved from 0.18429 to 0.18343, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.1582 - acc: 0.9928 - val_loss: 0.1838 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.18343\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.1579 - acc: 0.9928 - val_loss: 0.1829 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.18343 to 0.18291, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.1573 - acc: 0.9928 - val_loss: 0.1821 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00199: val_loss improved from 0.18291 to 0.18211, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.1567 - acc: 0.9928 - val_loss: 0.1818 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00200: val_loss improved from 0.18211 to 0.18185, saving model to weights.best.Resnet50.hdf5\n",
      "batch_size=80   optimizer=Adagrad\n",
      "Test accuracy: 67.9666%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 2.4076 - acc: 0.3092 - val_loss: 1.5141 - val_acc: 0.4815\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.51415, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.3701 - acc: 0.5204 - val_loss: 1.2429 - val_acc: 0.5597\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.51415 to 1.24285, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 1.1880 - acc: 0.6013 - val_loss: 1.1275 - val_acc: 0.6255\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.24285 to 1.12754, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 1.0870 - acc: 0.6289 - val_loss: 1.0541 - val_acc: 0.6420\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.12754 to 1.05406, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 1.0143 - acc: 0.6625 - val_loss: 0.9901 - val_acc: 0.6626\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.05406 to 0.99005, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.9512 - acc: 0.6822 - val_loss: 0.9545 - val_acc: 0.6914\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.99005 to 0.95448, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.9052 - acc: 0.7079 - val_loss: 0.8995 - val_acc: 0.7119\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.95448 to 0.89950, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.8698 - acc: 0.7336 - val_loss: 0.8824 - val_acc: 0.7078\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.89950 to 0.88238, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.8365 - acc: 0.7270 - val_loss: 0.8405 - val_acc: 0.7325\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.88238 to 0.84050, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.8081 - acc: 0.7441 - val_loss: 0.8096 - val_acc: 0.7407\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.84050 to 0.80956, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.7812 - acc: 0.7533 - val_loss: 0.7909 - val_acc: 0.7613\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.80956 to 0.79090, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.7595 - acc: 0.7678 - val_loss: 0.7829 - val_acc: 0.7490\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.79090 to 0.78292, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.7389 - acc: 0.7730 - val_loss: 0.7575 - val_acc: 0.7531\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.78292 to 0.75747, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.7172 - acc: 0.7829 - val_loss: 0.7506 - val_acc: 0.7695\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.75747 to 0.75055, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.7027 - acc: 0.7882 - val_loss: 0.7127 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.75055 to 0.71269, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.6823 - acc: 0.7888 - val_loss: 0.7115 - val_acc: 0.7572\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.71269 to 0.71151, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.6669 - acc: 0.8020 - val_loss: 0.6840 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.71151 to 0.68401, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.6529 - acc: 0.8053 - val_loss: 0.6699 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.68401 to 0.66991, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.6375 - acc: 0.8230 - val_loss: 0.6583 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.66991 to 0.65828, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.6287 - acc: 0.8164 - val_loss: 0.6418 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.65828 to 0.64181, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.6163 - acc: 0.8197 - val_loss: 0.6254 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.64181 to 0.62542, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.6019 - acc: 0.8243 - val_loss: 0.6510 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.62542\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.5950 - acc: 0.8263 - val_loss: 0.6130 - val_acc: 0.8107\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.62542 to 0.61295, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.5868 - acc: 0.8263 - val_loss: 0.6036 - val_acc: 0.8354\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.61295 to 0.60363, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.5705 - acc: 0.8336 - val_loss: 0.5946 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.60363 to 0.59460, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.5632 - acc: 0.8447 - val_loss: 0.5797 - val_acc: 0.8395\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00026: val_loss improved from 0.59460 to 0.57968, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.5552 - acc: 0.8382 - val_loss: 0.5676 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.57968 to 0.56757, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.5466 - acc: 0.8513 - val_loss: 0.5619 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.56757 to 0.56188, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.5368 - acc: 0.8447 - val_loss: 0.5566 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.56188 to 0.55656, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.5310 - acc: 0.8553 - val_loss: 0.5471 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.55656 to 0.54708, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.5223 - acc: 0.8599 - val_loss: 0.5501 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.54708\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.5151 - acc: 0.8579 - val_loss: 0.5389 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.54708 to 0.53889, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.5073 - acc: 0.8651 - val_loss: 0.5285 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.53889 to 0.52855, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.5021 - acc: 0.8697 - val_loss: 0.5216 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.52855 to 0.52165, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.4928 - acc: 0.8770 - val_loss: 0.5195 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.52165 to 0.51950, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.4871 - acc: 0.8724 - val_loss: 0.5133 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.51950 to 0.51331, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.4826 - acc: 0.8743 - val_loss: 0.5016 - val_acc: 0.8765\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.51331 to 0.50163, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.4745 - acc: 0.8796 - val_loss: 0.4979 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.50163 to 0.49794, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.4713 - acc: 0.8842 - val_loss: 0.4944 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.49794 to 0.49437, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.4624 - acc: 0.8849 - val_loss: 0.4872 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.49437 to 0.48724, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.4592 - acc: 0.8875 - val_loss: 0.4911 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.48724\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.4529 - acc: 0.8901 - val_loss: 0.4872 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.48724 to 0.48718, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.4488 - acc: 0.8980 - val_loss: 0.4693 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.48718 to 0.46928, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.4433 - acc: 0.8947 - val_loss: 0.4642 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.46928 to 0.46422, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.4378 - acc: 0.8947 - val_loss: 0.4610 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.46422 to 0.46103, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.4355 - acc: 0.8980 - val_loss: 0.4567 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.46103 to 0.45673, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.4287 - acc: 0.9033 - val_loss: 0.4502 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.45673 to 0.45017, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.4240 - acc: 0.9066 - val_loss: 0.4549 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.45017\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.4216 - acc: 0.9039 - val_loss: 0.4390 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.45017 to 0.43902, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.4182 - acc: 0.9099 - val_loss: 0.4349 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.43902 to 0.43489, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.4115 - acc: 0.9099 - val_loss: 0.4356 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.43489\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.4096 - acc: 0.9059 - val_loss: 0.4395 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.43489\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.4044 - acc: 0.9171 - val_loss: 0.4259 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.43489 to 0.42593, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.4010 - acc: 0.9151 - val_loss: 0.4217 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.42593 to 0.42174, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.3963 - acc: 0.9158 - val_loss: 0.4216 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.42174 to 0.42157, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.3937 - acc: 0.9164 - val_loss: 0.4171 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.42157 to 0.41709, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.3886 - acc: 0.9243 - val_loss: 0.4146 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.41709 to 0.41456, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.3852 - acc: 0.9217 - val_loss: 0.4094 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.41456 to 0.40943, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.3824 - acc: 0.9197 - val_loss: 0.4174 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.40943\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.3806 - acc: 0.9204 - val_loss: 0.4032 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.40943 to 0.40315, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.3749 - acc: 0.9211 - val_loss: 0.3972 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.40315 to 0.39718, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.3725 - acc: 0.9250 - val_loss: 0.3920 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.39718 to 0.39199, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.3683 - acc: 0.9263 - val_loss: 0.3925 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.39199\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.3653 - acc: 0.9303 - val_loss: 0.3855 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.39199 to 0.38547, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.3639 - acc: 0.9276 - val_loss: 0.3878 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.38547\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.3595 - acc: 0.9296 - val_loss: 0.3804 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.38547 to 0.38036, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.3564 - acc: 0.9316 - val_loss: 0.3791 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.38036 to 0.37912, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.3531 - acc: 0.9368 - val_loss: 0.3834 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.37912\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.3505 - acc: 0.9375 - val_loss: 0.3763 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.37912 to 0.37633, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.3468 - acc: 0.9336 - val_loss: 0.3680 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.37633 to 0.36798, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.3453 - acc: 0.9382 - val_loss: 0.3692 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.36798\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.3420 - acc: 0.9408 - val_loss: 0.3718 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.36798\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.3396 - acc: 0.9421 - val_loss: 0.3632 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.36798 to 0.36316, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.3371 - acc: 0.9434 - val_loss: 0.3609 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.36316 to 0.36091, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.3336 - acc: 0.9441 - val_loss: 0.3564 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.36091 to 0.35638, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.3310 - acc: 0.9434 - val_loss: 0.3534 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.35638 to 0.35341, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.3304 - acc: 0.9461 - val_loss: 0.3561 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.35341\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.3258 - acc: 0.9480 - val_loss: 0.3502 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.35341 to 0.35022, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.3233 - acc: 0.9474 - val_loss: 0.3508 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.35022\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.3212 - acc: 0.9526 - val_loss: 0.3495 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.35022 to 0.34954, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.3193 - acc: 0.9487 - val_loss: 0.3411 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.34954 to 0.34108, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.3176 - acc: 0.9500 - val_loss: 0.3450 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.34108\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.3163 - acc: 0.9500 - val_loss: 0.3413 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.34108\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.3124 - acc: 0.9526 - val_loss: 0.3379 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.34108 to 0.33795, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.3101 - acc: 0.9526 - val_loss: 0.3312 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.33795 to 0.33118, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.3087 - acc: 0.9493 - val_loss: 0.3328 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33118\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.3054 - acc: 0.9546 - val_loss: 0.3327 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33118\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.3039 - acc: 0.9559 - val_loss: 0.3277 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.33118 to 0.32766, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.3013 - acc: 0.9553 - val_loss: 0.3256 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.32766 to 0.32563, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.2997 - acc: 0.9539 - val_loss: 0.3240 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.32563 to 0.32403, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.2977 - acc: 0.9572 - val_loss: 0.3232 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.32403 to 0.32320, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.2959 - acc: 0.9586 - val_loss: 0.3194 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.32320 to 0.31936, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.2938 - acc: 0.9572 - val_loss: 0.3171 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.31936 to 0.31707, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.2913 - acc: 0.9612 - val_loss: 0.3181 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.31707\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.2898 - acc: 0.9586 - val_loss: 0.3118 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.31707 to 0.31179, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.2880 - acc: 0.9599 - val_loss: 0.3160 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.31179\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.2869 - acc: 0.9579 - val_loss: 0.3090 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.31179 to 0.30898, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.2841 - acc: 0.9612 - val_loss: 0.3110 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.30898\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.2831 - acc: 0.9618 - val_loss: 0.3052 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.30898 to 0.30522, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.2812 - acc: 0.9579 - val_loss: 0.3071 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.30522\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.2785 - acc: 0.9658 - val_loss: 0.3027 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.30522 to 0.30269, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.2774 - acc: 0.9625 - val_loss: 0.3002 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.30269 to 0.30022, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.2753 - acc: 0.9664 - val_loss: 0.3009 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.30022\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.2732 - acc: 0.9671 - val_loss: 0.2982 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.30022 to 0.29820, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.2724 - acc: 0.9651 - val_loss: 0.2966 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.29820 to 0.29664, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.2719 - acc: 0.9645 - val_loss: 0.2939 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.29664 to 0.29389, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.2687 - acc: 0.9671 - val_loss: 0.2908 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.29389 to 0.29083, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.2685 - acc: 0.9671 - val_loss: 0.2933 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.29083\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.2656 - acc: 0.9664 - val_loss: 0.2902 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.29083 to 0.29020, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.2636 - acc: 0.9697 - val_loss: 0.2907 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.29020\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.2621 - acc: 0.9671 - val_loss: 0.2838 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.29020 to 0.28384, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.2607 - acc: 0.9711 - val_loss: 0.2863 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.28384\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.2601 - acc: 0.9671 - val_loss: 0.2832 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.28384 to 0.28323, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.2582 - acc: 0.9717 - val_loss: 0.2853 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.28323\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.2566 - acc: 0.9684 - val_loss: 0.2804 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.28323 to 0.28040, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.2552 - acc: 0.9697 - val_loss: 0.2803 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.28040 to 0.28034, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.2536 - acc: 0.9717 - val_loss: 0.2795 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.28034 to 0.27946, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.2525 - acc: 0.9697 - val_loss: 0.2753 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.27946 to 0.27525, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.2514 - acc: 0.9704 - val_loss: 0.2741 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.27525 to 0.27409, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.2494 - acc: 0.9750 - val_loss: 0.2731 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.27409 to 0.27307, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.2486 - acc: 0.9704 - val_loss: 0.2730 - val_acc: 0.9671\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00121: val_loss improved from 0.27307 to 0.27302, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.2464 - acc: 0.9730 - val_loss: 0.2701 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.27302 to 0.27013, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.2457 - acc: 0.9717 - val_loss: 0.2703 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.27013\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.2444 - acc: 0.9717 - val_loss: 0.2679 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.27013 to 0.26786, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.2421 - acc: 0.9750 - val_loss: 0.2666 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.26786 to 0.26661, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.2412 - acc: 0.9743 - val_loss: 0.2635 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.26661 to 0.26345, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.2400 - acc: 0.9750 - val_loss: 0.2634 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.26345 to 0.26341, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.2393 - acc: 0.9737 - val_loss: 0.2602 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.26341 to 0.26021, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.2375 - acc: 0.9763 - val_loss: 0.2621 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.26021\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.2360 - acc: 0.9770 - val_loss: 0.2617 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.26021\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.2357 - acc: 0.9737 - val_loss: 0.2592 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.26021 to 0.25915, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.2338 - acc: 0.9743 - val_loss: 0.2573 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.25915 to 0.25734, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.2326 - acc: 0.9750 - val_loss: 0.2579 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.25734\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.2313 - acc: 0.9776 - val_loss: 0.2555 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.25734 to 0.25547, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.2300 - acc: 0.9783 - val_loss: 0.2561 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.25547\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.2295 - acc: 0.9796 - val_loss: 0.2546 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.25547 to 0.25461, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.2290 - acc: 0.9763 - val_loss: 0.2527 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.25461 to 0.25267, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.2268 - acc: 0.9789 - val_loss: 0.2513 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.25267 to 0.25125, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.2259 - acc: 0.9809 - val_loss: 0.2493 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.25125 to 0.24928, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.2254 - acc: 0.9783 - val_loss: 0.2510 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.24928\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.2238 - acc: 0.9789 - val_loss: 0.2473 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.24928 to 0.24728, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.2222 - acc: 0.9789 - val_loss: 0.2492 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.24728\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.2218 - acc: 0.9789 - val_loss: 0.2461 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.24728 to 0.24608, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.2201 - acc: 0.9809 - val_loss: 0.2434 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.24608 to 0.24337, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.2188 - acc: 0.9816 - val_loss: 0.2438 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.24337\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.2179 - acc: 0.9803 - val_loss: 0.2409 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.24337 to 0.24095, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.2170 - acc: 0.9809 - val_loss: 0.2400 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.24095 to 0.23997, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.2161 - acc: 0.9809 - val_loss: 0.2376 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.23997 to 0.23756, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.2155 - acc: 0.9809 - val_loss: 0.2390 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.23756\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.2141 - acc: 0.9836 - val_loss: 0.2385 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.23756\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.2133 - acc: 0.9836 - val_loss: 0.2358 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.23756 to 0.23583, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.2122 - acc: 0.9809 - val_loss: 0.2371 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.23583\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.2105 - acc: 0.9836 - val_loss: 0.2358 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.23583 to 0.23576, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.2101 - acc: 0.9829 - val_loss: 0.2334 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.23576 to 0.23342, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.2086 - acc: 0.9836 - val_loss: 0.2363 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.23342\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.2084 - acc: 0.9816 - val_loss: 0.2311 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.23342 to 0.23106, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.2071 - acc: 0.9836 - val_loss: 0.2313 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.23106\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.2062 - acc: 0.9842 - val_loss: 0.2285 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.23106 to 0.22854, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.2055 - acc: 0.9849 - val_loss: 0.2296 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.22854\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.2042 - acc: 0.9855 - val_loss: 0.2294 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.22854\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.2030 - acc: 0.9862 - val_loss: 0.2283 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.22854 to 0.22833, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.2023 - acc: 0.9842 - val_loss: 0.2246 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.22833 to 0.22461, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.2018 - acc: 0.9849 - val_loss: 0.2273 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.22461\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.2007 - acc: 0.9862 - val_loss: 0.2255 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.22461\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.1998 - acc: 0.9855 - val_loss: 0.2264 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.22461\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.1984 - acc: 0.9862 - val_loss: 0.2220 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00166: val_loss improved from 0.22461 to 0.22203, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.1979 - acc: 0.9849 - val_loss: 0.2225 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.22203\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.1971 - acc: 0.9868 - val_loss: 0.2211 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.22203 to 0.22109, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.1960 - acc: 0.9855 - val_loss: 0.2200 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.22109 to 0.21998, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.1957 - acc: 0.9855 - val_loss: 0.2194 - val_acc: 0.9835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00170: val_loss improved from 0.21998 to 0.21941, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.1944 - acc: 0.9868 - val_loss: 0.2191 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00171: val_loss improved from 0.21941 to 0.21910, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.1935 - acc: 0.9868 - val_loss: 0.2155 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00172: val_loss improved from 0.21910 to 0.21548, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.1932 - acc: 0.9868 - val_loss: 0.2173 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.21548\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.1918 - acc: 0.9875 - val_loss: 0.2184 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.21548\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.1915 - acc: 0.9888 - val_loss: 0.2182 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.21548\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.1906 - acc: 0.9882 - val_loss: 0.2177 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.21548\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.1894 - acc: 0.9882 - val_loss: 0.2147 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00177: val_loss improved from 0.21548 to 0.21471, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.1887 - acc: 0.9882 - val_loss: 0.2138 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00178: val_loss improved from 0.21471 to 0.21380, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.1884 - acc: 0.9868 - val_loss: 0.2129 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00179: val_loss improved from 0.21380 to 0.21287, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.1875 - acc: 0.9888 - val_loss: 0.2096 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00180: val_loss improved from 0.21287 to 0.20956, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.1864 - acc: 0.9895 - val_loss: 0.2118 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.20956\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.1857 - acc: 0.9895 - val_loss: 0.2116 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.20956\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.1852 - acc: 0.9895 - val_loss: 0.2101 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.20956\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.1841 - acc: 0.9882 - val_loss: 0.2087 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00184: val_loss improved from 0.20956 to 0.20874, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.1833 - acc: 0.9888 - val_loss: 0.2091 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.20874\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.1829 - acc: 0.9888 - val_loss: 0.2081 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.20874 to 0.20813, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.1826 - acc: 0.9882 - val_loss: 0.2050 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.20813 to 0.20499, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.1811 - acc: 0.9908 - val_loss: 0.2061 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.20499\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.1805 - acc: 0.9895 - val_loss: 0.2052 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.20499\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.1802 - acc: 0.9888 - val_loss: 0.2036 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00190: val_loss improved from 0.20499 to 0.20364, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.1789 - acc: 0.9882 - val_loss: 0.2059 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.20364\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.1785 - acc: 0.9895 - val_loss: 0.2025 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.20364 to 0.20247, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.1775 - acc: 0.9888 - val_loss: 0.2018 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00193: val_loss improved from 0.20247 to 0.20185, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.1770 - acc: 0.9901 - val_loss: 0.2003 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00194: val_loss improved from 0.20185 to 0.20028, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.1768 - acc: 0.9908 - val_loss: 0.2003 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.20028\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.1757 - acc: 0.9888 - val_loss: 0.2004 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.20028\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.1749 - acc: 0.9908 - val_loss: 0.1993 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00197: val_loss improved from 0.20028 to 0.19925, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.1742 - acc: 0.9901 - val_loss: 0.1989 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.19925 to 0.19892, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.1733 - acc: 0.9908 - val_loss: 0.1985 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00199: val_loss improved from 0.19892 to 0.19851, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.1733 - acc: 0.9895 - val_loss: 0.1973 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00200: val_loss improved from 0.19851 to 0.19728, saving model to weights.best.Resnet50.hdf5\n",
      "batch_size=120   optimizer=Adagrad\n",
      "Test accuracy: 67.1309%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_32 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 2.6790 - acc: 0.2257 - val_loss: 1.6737 - val_acc: 0.3786\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.67368, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.4481 - acc: 0.5178 - val_loss: 1.3049 - val_acc: 0.5514\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.67368 to 1.30493, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 1.2944 - acc: 0.5691 - val_loss: 1.2119 - val_acc: 0.6091\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.30493 to 1.21186, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 1.1505 - acc: 0.6296 - val_loss: 1.1107 - val_acc: 0.6626\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.21186 to 1.11071, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 1.0681 - acc: 0.6638 - val_loss: 1.0690 - val_acc: 0.6461\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.11071 to 1.06904, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 1.0170 - acc: 0.6829 - val_loss: 0.9792 - val_acc: 0.7202\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.06904 to 0.97922, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.9712 - acc: 0.7066 - val_loss: 0.9841 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.97922\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.9315 - acc: 0.7092 - val_loss: 0.9266 - val_acc: 0.7160\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.97922 to 0.92659, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.8863 - acc: 0.7237 - val_loss: 0.8713 - val_acc: 0.7366\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.92659 to 0.87127, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.8605 - acc: 0.7428 - val_loss: 0.8648 - val_acc: 0.7284\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.87127 to 0.86482, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.8336 - acc: 0.7520 - val_loss: 0.8691 - val_acc: 0.7119\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.86482\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.8093 - acc: 0.7539 - val_loss: 0.8271 - val_acc: 0.7284\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.86482 to 0.82715, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.7931 - acc: 0.7599 - val_loss: 0.7986 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.82715 to 0.79855, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.7726 - acc: 0.7730 - val_loss: 0.7874 - val_acc: 0.7531\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.79855 to 0.78736, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.7524 - acc: 0.7803 - val_loss: 0.7551 - val_acc: 0.7695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00015: val_loss improved from 0.78736 to 0.75511, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.7376 - acc: 0.7822 - val_loss: 0.7475 - val_acc: 0.7695\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.75511 to 0.74752, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.7191 - acc: 0.7875 - val_loss: 0.7235 - val_acc: 0.7819\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.74752 to 0.72352, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.7021 - acc: 0.7941 - val_loss: 0.7246 - val_acc: 0.7613\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.72352\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.6954 - acc: 0.7961 - val_loss: 0.6939 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.72352 to 0.69386, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.6764 - acc: 0.8072 - val_loss: 0.6844 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.69386 to 0.68439, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.6661 - acc: 0.8086 - val_loss: 0.6734 - val_acc: 0.8148\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.68439 to 0.67344, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.6524 - acc: 0.8178 - val_loss: 0.6552 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.67344 to 0.65517, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.6398 - acc: 0.8178 - val_loss: 0.6679 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.65517\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.6303 - acc: 0.8257 - val_loss: 0.6623 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.65517\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.6242 - acc: 0.8243 - val_loss: 0.6313 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.65517 to 0.63128, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.6120 - acc: 0.8316 - val_loss: 0.6322 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.63128\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.6034 - acc: 0.8355 - val_loss: 0.6211 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.63128 to 0.62115, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.5932 - acc: 0.8362 - val_loss: 0.6321 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.62115\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.5879 - acc: 0.8408 - val_loss: 0.6028 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.62115 to 0.60284, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.5768 - acc: 0.8401 - val_loss: 0.5899 - val_acc: 0.8354\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.60284 to 0.58989, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.5681 - acc: 0.8480 - val_loss: 0.5752 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.58989 to 0.57522, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.5588 - acc: 0.8487 - val_loss: 0.5848 - val_acc: 0.8354\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.57522\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.5545 - acc: 0.8553 - val_loss: 0.5813 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.57522\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.5484 - acc: 0.8526 - val_loss: 0.5567 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.57522 to 0.55670, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.5379 - acc: 0.8579 - val_loss: 0.5460 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.55670 to 0.54604, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.5321 - acc: 0.8658 - val_loss: 0.5504 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.54604\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.5266 - acc: 0.8625 - val_loss: 0.5448 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.54604 to 0.54475, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.5234 - acc: 0.8632 - val_loss: 0.5399 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.54475 to 0.53994, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.5139 - acc: 0.8750 - val_loss: 0.5261 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.53994 to 0.52614, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.5079 - acc: 0.8717 - val_loss: 0.5208 - val_acc: 0.8765\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.52614 to 0.52077, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.5022 - acc: 0.8684 - val_loss: 0.5145 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.52077 to 0.51451, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.4955 - acc: 0.8796 - val_loss: 0.5094 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.51451 to 0.50939, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.4912 - acc: 0.8743 - val_loss: 0.5091 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.50939 to 0.50909, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.4863 - acc: 0.8822 - val_loss: 0.5099 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.50909\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.4809 - acc: 0.8809 - val_loss: 0.5043 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.50909 to 0.50427, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.4743 - acc: 0.8822 - val_loss: 0.5050 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.50427\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.4705 - acc: 0.8868 - val_loss: 0.4896 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.50427 to 0.48957, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.4656 - acc: 0.8888 - val_loss: 0.4914 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.48957\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.4624 - acc: 0.8895 - val_loss: 0.4771 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.48957 to 0.47710, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.4562 - acc: 0.8954 - val_loss: 0.4703 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.47710 to 0.47030, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.4521 - acc: 0.8974 - val_loss: 0.4704 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.47030\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.4469 - acc: 0.8961 - val_loss: 0.4677 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.47030 to 0.46774, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.4434 - acc: 0.8954 - val_loss: 0.4642 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.46774 to 0.46418, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.4394 - acc: 0.9000 - val_loss: 0.4550 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.46418 to 0.45502, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.4355 - acc: 0.8987 - val_loss: 0.4469 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.45502 to 0.44693, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.4305 - acc: 0.9086 - val_loss: 0.4527 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.44693\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.4279 - acc: 0.9039 - val_loss: 0.4469 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.44693\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.4229 - acc: 0.9072 - val_loss: 0.4367 - val_acc: 0.9012\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.44693 to 0.43673, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.4196 - acc: 0.9092 - val_loss: 0.4346 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.43673 to 0.43461, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.4175 - acc: 0.9092 - val_loss: 0.4380 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.43461\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.4131 - acc: 0.9066 - val_loss: 0.4205 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.43461 to 0.42051, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.4111 - acc: 0.9132 - val_loss: 0.4256 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.42051\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.4048 - acc: 0.9197 - val_loss: 0.4186 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.42051 to 0.41862, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.4024 - acc: 0.9125 - val_loss: 0.4091 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.41862 to 0.40912, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.3994 - acc: 0.9151 - val_loss: 0.4201 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.40912\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.3949 - acc: 0.9164 - val_loss: 0.4125 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.40912\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.3917 - acc: 0.9158 - val_loss: 0.4062 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.40912 to 0.40623, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.3876 - acc: 0.9224 - val_loss: 0.4097 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.40623\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.3859 - acc: 0.9204 - val_loss: 0.4082 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.40623\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.3852 - acc: 0.9243 - val_loss: 0.4028 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.40623 to 0.40278, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.3796 - acc: 0.9257 - val_loss: 0.3916 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.40278 to 0.39158, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.3772 - acc: 0.9263 - val_loss: 0.3918 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.39158\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.3737 - acc: 0.9296 - val_loss: 0.3896 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.39158 to 0.38959, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.3717 - acc: 0.9289 - val_loss: 0.3841 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.38959 to 0.38410, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.3691 - acc: 0.9309 - val_loss: 0.3858 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.38410\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.3660 - acc: 0.9336 - val_loss: 0.3784 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.38410 to 0.37839, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.3639 - acc: 0.9349 - val_loss: 0.3793 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.37839\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.3612 - acc: 0.9342 - val_loss: 0.3794 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.37839\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.3584 - acc: 0.9336 - val_loss: 0.3730 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.37839 to 0.37296, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.3567 - acc: 0.9349 - val_loss: 0.3706 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.37296 to 0.37064, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.3524 - acc: 0.9408 - val_loss: 0.3697 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.37064 to 0.36973, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.3500 - acc: 0.9388 - val_loss: 0.3725 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.36973\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.3480 - acc: 0.9401 - val_loss: 0.3701 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.36973\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.3467 - acc: 0.9408 - val_loss: 0.3666 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.36973 to 0.36663, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.3432 - acc: 0.9388 - val_loss: 0.3541 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.36663 to 0.35410, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.3397 - acc: 0.9421 - val_loss: 0.3526 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.35410 to 0.35256, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.3394 - acc: 0.9434 - val_loss: 0.3528 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.35256\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.3354 - acc: 0.9454 - val_loss: 0.3525 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.35256 to 0.35246, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.3347 - acc: 0.9434 - val_loss: 0.3606 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.35246\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.3320 - acc: 0.9434 - val_loss: 0.3441 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.35246 to 0.34410, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.3303 - acc: 0.9454 - val_loss: 0.3463 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.34410\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.3268 - acc: 0.9467 - val_loss: 0.3413 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.34410 to 0.34125, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.3262 - acc: 0.9487 - val_loss: 0.3448 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.34125\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.3232 - acc: 0.9480 - val_loss: 0.3439 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.34125\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.3209 - acc: 0.9474 - val_loss: 0.3379 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.34125 to 0.33793, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.3184 - acc: 0.9526 - val_loss: 0.3349 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.33793 to 0.33492, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.3165 - acc: 0.9493 - val_loss: 0.3339 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.33492 to 0.33391, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.3145 - acc: 0.9520 - val_loss: 0.3379 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33391\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.3134 - acc: 0.9579 - val_loss: 0.3321 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.33391 to 0.33214, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.3117 - acc: 0.9546 - val_loss: 0.3256 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.33214 to 0.32563, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.3095 - acc: 0.9520 - val_loss: 0.3255 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.32563 to 0.32554, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.3070 - acc: 0.9546 - val_loss: 0.3263 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.32554\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.3062 - acc: 0.9566 - val_loss: 0.3246 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.32554 to 0.32459, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.3044 - acc: 0.9539 - val_loss: 0.3149 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.32459 to 0.31493, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.3029 - acc: 0.9546 - val_loss: 0.3212 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.31493\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.3008 - acc: 0.9553 - val_loss: 0.3208 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.31493\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.2982 - acc: 0.9592 - val_loss: 0.3125 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.31493 to 0.31248, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.2957 - acc: 0.9579 - val_loss: 0.3146 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.31248\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.2951 - acc: 0.9566 - val_loss: 0.3141 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.31248\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.2941 - acc: 0.9579 - val_loss: 0.3099 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.31248 to 0.30990, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.2916 - acc: 0.9612 - val_loss: 0.3090 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.30990 to 0.30902, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.2904 - acc: 0.9592 - val_loss: 0.3078 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.30902 to 0.30778, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.2888 - acc: 0.9612 - val_loss: 0.3057 - val_acc: 0.9630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00113: val_loss improved from 0.30778 to 0.30565, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.2869 - acc: 0.9612 - val_loss: 0.3073 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.30565\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.2849 - acc: 0.9592 - val_loss: 0.3062 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.30565\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.2847 - acc: 0.9612 - val_loss: 0.2974 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.30565 to 0.29737, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.2817 - acc: 0.9645 - val_loss: 0.3046 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.29737\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.2804 - acc: 0.9618 - val_loss: 0.2952 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.29737 to 0.29515, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.2794 - acc: 0.9658 - val_loss: 0.2942 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.29515 to 0.29423, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.2786 - acc: 0.9638 - val_loss: 0.2940 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.29423 to 0.29397, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.2755 - acc: 0.9658 - val_loss: 0.2977 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.29397\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.2748 - acc: 0.9658 - val_loss: 0.2921 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.29397 to 0.29208, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.2726 - acc: 0.9664 - val_loss: 0.2905 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.29208 to 0.29052, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.2722 - acc: 0.9651 - val_loss: 0.2888 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.29052 to 0.28880, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.2699 - acc: 0.9664 - val_loss: 0.2842 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.28880 to 0.28419, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.2690 - acc: 0.9671 - val_loss: 0.2830 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.28419 to 0.28297, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.2682 - acc: 0.9664 - val_loss: 0.2845 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.28297\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.2661 - acc: 0.9691 - val_loss: 0.2792 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.28297 to 0.27918, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.2640 - acc: 0.9697 - val_loss: 0.2827 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.27918\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.2627 - acc: 0.9691 - val_loss: 0.2764 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.27918 to 0.27644, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.2626 - acc: 0.9704 - val_loss: 0.2785 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.27644\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.2611 - acc: 0.9697 - val_loss: 0.2735 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.27644 to 0.27351, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.2590 - acc: 0.9724 - val_loss: 0.2776 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.27351\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.2578 - acc: 0.9697 - val_loss: 0.2762 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.27351\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.2568 - acc: 0.9697 - val_loss: 0.2702 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.27351 to 0.27020, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.2557 - acc: 0.9711 - val_loss: 0.2726 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.27020\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.2542 - acc: 0.9711 - val_loss: 0.2690 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.27020 to 0.26904, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.2530 - acc: 0.9737 - val_loss: 0.2713 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.26904\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.2520 - acc: 0.9750 - val_loss: 0.2734 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.26904\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.2503 - acc: 0.9743 - val_loss: 0.2707 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.26904\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.2493 - acc: 0.9743 - val_loss: 0.2662 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.26904 to 0.26622, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.2488 - acc: 0.9730 - val_loss: 0.2641 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.26622 to 0.26412, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.2471 - acc: 0.9750 - val_loss: 0.2633 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.26412 to 0.26334, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.2460 - acc: 0.9737 - val_loss: 0.2618 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.26334 to 0.26178, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.2444 - acc: 0.9737 - val_loss: 0.2619 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.26178\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.2434 - acc: 0.9757 - val_loss: 0.2599 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.26178 to 0.25989, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.2420 - acc: 0.9757 - val_loss: 0.2644 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.25989\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.2407 - acc: 0.9770 - val_loss: 0.2581 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.25989 to 0.25807, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.2398 - acc: 0.9750 - val_loss: 0.2578 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.25807 to 0.25781, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.2390 - acc: 0.9796 - val_loss: 0.2550 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.25781 to 0.25502, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.2373 - acc: 0.9776 - val_loss: 0.2543 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.25502 to 0.25432, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.2376 - acc: 0.9770 - val_loss: 0.2529 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.25432 to 0.25293, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.2354 - acc: 0.9789 - val_loss: 0.2566 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.25293\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.2345 - acc: 0.9770 - val_loss: 0.2543 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.25293\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.2335 - acc: 0.9763 - val_loss: 0.2554 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.25293\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.2325 - acc: 0.9803 - val_loss: 0.2496 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.25293 to 0.24959, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.2317 - acc: 0.9770 - val_loss: 0.2483 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.24959 to 0.24826, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.2301 - acc: 0.9803 - val_loss: 0.2462 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.24826 to 0.24619, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.2296 - acc: 0.9789 - val_loss: 0.2479 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.24619\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.2281 - acc: 0.9816 - val_loss: 0.2436 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.24619 to 0.24359, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.2276 - acc: 0.9783 - val_loss: 0.2452 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.24359\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.2265 - acc: 0.9809 - val_loss: 0.2423 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.24359 to 0.24225, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.2254 - acc: 0.9816 - val_loss: 0.2422 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00163: val_loss improved from 0.24225 to 0.24219, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.2241 - acc: 0.9803 - val_loss: 0.2451 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.24219\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.2228 - acc: 0.9816 - val_loss: 0.2412 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.24219 to 0.24121, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.2221 - acc: 0.9829 - val_loss: 0.2409 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00166: val_loss improved from 0.24121 to 0.24088, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.2210 - acc: 0.9809 - val_loss: 0.2404 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.24088 to 0.24036, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.2203 - acc: 0.9829 - val_loss: 0.2384 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.24036 to 0.23842, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.2194 - acc: 0.9803 - val_loss: 0.2376 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.23842 to 0.23758, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.2186 - acc: 0.9822 - val_loss: 0.2374 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.23758 to 0.23738, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.2175 - acc: 0.9816 - val_loss: 0.2355 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00171: val_loss improved from 0.23738 to 0.23546, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.2166 - acc: 0.9822 - val_loss: 0.2365 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.23546\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.2157 - acc: 0.9822 - val_loss: 0.2335 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.23546 to 0.23350, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.2151 - acc: 0.9822 - val_loss: 0.2307 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.23350 to 0.23073, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.2140 - acc: 0.9809 - val_loss: 0.2338 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.23073\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.2132 - acc: 0.9842 - val_loss: 0.2341 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.23073\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.2121 - acc: 0.9836 - val_loss: 0.2324 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.23073\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.2114 - acc: 0.9816 - val_loss: 0.2286 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00178: val_loss improved from 0.23073 to 0.22856, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.2107 - acc: 0.9829 - val_loss: 0.2309 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.22856\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.2100 - acc: 0.9836 - val_loss: 0.2276 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00180: val_loss improved from 0.22856 to 0.22758, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.2095 - acc: 0.9855 - val_loss: 0.2265 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00181: val_loss improved from 0.22758 to 0.22646, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.2076 - acc: 0.9842 - val_loss: 0.2320 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.22646\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.2079 - acc: 0.9836 - val_loss: 0.2254 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00183: val_loss improved from 0.22646 to 0.22542, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.2065 - acc: 0.9842 - val_loss: 0.2272 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.22542\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.2057 - acc: 0.9855 - val_loss: 0.2226 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00185: val_loss improved from 0.22542 to 0.22263, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.2050 - acc: 0.9836 - val_loss: 0.2242 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.22263\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.2038 - acc: 0.9836 - val_loss: 0.2221 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.22263 to 0.22212, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.2032 - acc: 0.9842 - val_loss: 0.2203 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00188: val_loss improved from 0.22212 to 0.22027, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.2021 - acc: 0.9849 - val_loss: 0.2189 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.22027 to 0.21885, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.2018 - acc: 0.9849 - val_loss: 0.2198 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.21885\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.2007 - acc: 0.9849 - val_loss: 0.2199 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.21885\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.2006 - acc: 0.9842 - val_loss: 0.2178 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.21885 to 0.21780, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.1993 - acc: 0.9862 - val_loss: 0.2179 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.21780\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.1987 - acc: 0.9855 - val_loss: 0.2171 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00194: val_loss improved from 0.21780 to 0.21714, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.1984 - acc: 0.9836 - val_loss: 0.2149 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00195: val_loss improved from 0.21714 to 0.21489, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.1969 - acc: 0.9855 - val_loss: 0.2158 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.21489\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.1958 - acc: 0.9868 - val_loss: 0.2152 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.21489\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.1955 - acc: 0.9855 - val_loss: 0.2121 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.21489 to 0.21210, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.1948 - acc: 0.9862 - val_loss: 0.2136 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.21210\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.1942 - acc: 0.9868 - val_loss: 0.2131 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.21210\n",
      "batch_size=160   optimizer=Adagrad\n",
      "Test accuracy: 67.6880%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_33 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 2.9183 - acc: 0.2224 - val_loss: 1.6391 - val_acc: 0.4033\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.63909, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.5137 - acc: 0.4954 - val_loss: 1.3644 - val_acc: 0.5473\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.63909 to 1.36442, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 1.2911 - acc: 0.5783 - val_loss: 1.2256 - val_acc: 0.6255\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.36442 to 1.22561, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 1.1767 - acc: 0.6276 - val_loss: 1.1643 - val_acc: 0.6091\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.22561 to 1.16435, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 1.0996 - acc: 0.6520 - val_loss: 1.1252 - val_acc: 0.6132\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.16435 to 1.12520, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 1.0429 - acc: 0.6724 - val_loss: 1.0375 - val_acc: 0.6626\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.12520 to 1.03747, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.9895 - acc: 0.6875 - val_loss: 1.0070 - val_acc: 0.6708\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00007: val_loss improved from 1.03747 to 1.00704, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.9548 - acc: 0.6901 - val_loss: 0.9741 - val_acc: 0.6914\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.00704 to 0.97410, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.9184 - acc: 0.7099 - val_loss: 0.9687 - val_acc: 0.6872\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.97410 to 0.96866, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.8871 - acc: 0.7132 - val_loss: 0.9036 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.96866 to 0.90359, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.8647 - acc: 0.7217 - val_loss: 0.8979 - val_acc: 0.6831\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.90359 to 0.89792, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.8400 - acc: 0.7322 - val_loss: 0.8446 - val_acc: 0.7325\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.89792 to 0.84456, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.8123 - acc: 0.7441 - val_loss: 0.8559 - val_acc: 0.7078\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.84456\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.7939 - acc: 0.7526 - val_loss: 0.8140 - val_acc: 0.7325\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.84456 to 0.81401, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.7749 - acc: 0.7566 - val_loss: 0.7894 - val_acc: 0.7531\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.81401 to 0.78940, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.7567 - acc: 0.7704 - val_loss: 0.7863 - val_acc: 0.7490\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.78940 to 0.78629, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.7394 - acc: 0.7711 - val_loss: 0.7746 - val_acc: 0.7449\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.78629 to 0.77465, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.7249 - acc: 0.7783 - val_loss: 0.7674 - val_acc: 0.7325\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.77465 to 0.76739, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.7078 - acc: 0.7809 - val_loss: 0.7577 - val_acc: 0.7490\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.76739 to 0.75770, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.6993 - acc: 0.7908 - val_loss: 0.7413 - val_acc: 0.7531\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.75770 to 0.74134, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.6854 - acc: 0.7921 - val_loss: 0.7230 - val_acc: 0.7572\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.74134 to 0.72298, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.6728 - acc: 0.8059 - val_loss: 0.7032 - val_acc: 0.7737\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.72298 to 0.70321, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.6598 - acc: 0.8086 - val_loss: 0.7072 - val_acc: 0.7695\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.70321\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.6540 - acc: 0.8020 - val_loss: 0.6898 - val_acc: 0.7613\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.70321 to 0.68984, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.6388 - acc: 0.8112 - val_loss: 0.6762 - val_acc: 0.7695\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.68984 to 0.67624, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.6274 - acc: 0.8197 - val_loss: 0.6571 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.67624 to 0.65715, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.6233 - acc: 0.8112 - val_loss: 0.6645 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.65715\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.6155 - acc: 0.8171 - val_loss: 0.6514 - val_acc: 0.8148\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.65715 to 0.65138, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.6060 - acc: 0.8237 - val_loss: 0.6287 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.65138 to 0.62865, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.5954 - acc: 0.8289 - val_loss: 0.6236 - val_acc: 0.8107\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.62865 to 0.62363, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.5878 - acc: 0.8395 - val_loss: 0.6422 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.62363\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.5808 - acc: 0.8322 - val_loss: 0.6049 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.62363 to 0.60492, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.5701 - acc: 0.8388 - val_loss: 0.6023 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.60492 to 0.60233, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.5647 - acc: 0.8388 - val_loss: 0.5933 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.60233 to 0.59326, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.5550 - acc: 0.8520 - val_loss: 0.5927 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.59326 to 0.59270, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.5489 - acc: 0.8572 - val_loss: 0.5914 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.59270 to 0.59137, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.5439 - acc: 0.8434 - val_loss: 0.5748 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.59137 to 0.57479, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.5399 - acc: 0.8546 - val_loss: 0.5736 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.57479 to 0.57358, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.5300 - acc: 0.8533 - val_loss: 0.5696 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.57358 to 0.56962, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.5216 - acc: 0.8612 - val_loss: 0.5524 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.56962 to 0.55244, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.5178 - acc: 0.8612 - val_loss: 0.5404 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.55244 to 0.54037, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.5140 - acc: 0.8658 - val_loss: 0.5469 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.54037\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.5063 - acc: 0.8691 - val_loss: 0.5427 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.54037\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.5017 - acc: 0.8711 - val_loss: 0.5343 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.54037 to 0.53430, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.4965 - acc: 0.8724 - val_loss: 0.5247 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.53430 to 0.52472, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.4912 - acc: 0.8770 - val_loss: 0.5135 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.52472 to 0.51346, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.4850 - acc: 0.8783 - val_loss: 0.5150 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.51346\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.4810 - acc: 0.8803 - val_loss: 0.5126 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.51346 to 0.51263, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.4767 - acc: 0.8809 - val_loss: 0.5119 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.51263 to 0.51185, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.4725 - acc: 0.8809 - val_loss: 0.4997 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.51185 to 0.49967, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.4703 - acc: 0.8882 - val_loss: 0.4963 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.49967 to 0.49632, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.4636 - acc: 0.8868 - val_loss: 0.5042 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.49632\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.4584 - acc: 0.8954 - val_loss: 0.5110 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.49632\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.4535 - acc: 0.8941 - val_loss: 0.4880 - val_acc: 0.8930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00054: val_loss improved from 0.49632 to 0.48804, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.4494 - acc: 0.8947 - val_loss: 0.4855 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.48804 to 0.48554, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.4459 - acc: 0.8941 - val_loss: 0.4737 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.48554 to 0.47371, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.4417 - acc: 0.8961 - val_loss: 0.4721 - val_acc: 0.9012\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.47371 to 0.47206, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.4399 - acc: 0.8941 - val_loss: 0.4682 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.47206 to 0.46821, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.4351 - acc: 0.8974 - val_loss: 0.4645 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.46821 to 0.46451, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.4304 - acc: 0.9007 - val_loss: 0.4643 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.46451 to 0.46426, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.4277 - acc: 0.9053 - val_loss: 0.4540 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.46426 to 0.45400, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.4221 - acc: 0.9033 - val_loss: 0.4506 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.45400 to 0.45063, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.4194 - acc: 0.9020 - val_loss: 0.4530 - val_acc: 0.9012\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.45063\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.4164 - acc: 0.9086 - val_loss: 0.4503 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.45063 to 0.45026, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.4145 - acc: 0.9033 - val_loss: 0.4474 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.45026 to 0.44741, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.4105 - acc: 0.9086 - val_loss: 0.4453 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.44741 to 0.44532, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.4077 - acc: 0.9125 - val_loss: 0.4388 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.44532 to 0.43881, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.4031 - acc: 0.9112 - val_loss: 0.4321 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.43881 to 0.43213, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.3995 - acc: 0.9125 - val_loss: 0.4269 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.43213 to 0.42690, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.3972 - acc: 0.9112 - val_loss: 0.4323 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.42690\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.3939 - acc: 0.9191 - val_loss: 0.4219 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.42690 to 0.42191, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.3907 - acc: 0.9138 - val_loss: 0.4187 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.42191 to 0.41868, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.3886 - acc: 0.9184 - val_loss: 0.4213 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.41868\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.3861 - acc: 0.9158 - val_loss: 0.4179 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.41868 to 0.41791, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.3827 - acc: 0.9197 - val_loss: 0.4101 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.41791 to 0.41012, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.3785 - acc: 0.9237 - val_loss: 0.4120 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.41012\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.3773 - acc: 0.9276 - val_loss: 0.4014 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.41012 to 0.40143, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.3757 - acc: 0.9237 - val_loss: 0.3992 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.40143 to 0.39919, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.3707 - acc: 0.9243 - val_loss: 0.4061 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.39919\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.3678 - acc: 0.9289 - val_loss: 0.4061 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.39919\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.3666 - acc: 0.9276 - val_loss: 0.4066 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.39919\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.3655 - acc: 0.9329 - val_loss: 0.3892 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.39919 to 0.38922, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.3614 - acc: 0.9309 - val_loss: 0.3905 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.38922\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.3588 - acc: 0.9355 - val_loss: 0.3887 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.38922 to 0.38874, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.3563 - acc: 0.9303 - val_loss: 0.3792 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.38874 to 0.37915, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.3527 - acc: 0.9349 - val_loss: 0.3805 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.37915\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.3509 - acc: 0.9368 - val_loss: 0.3762 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.37915 to 0.37623, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.3498 - acc: 0.9414 - val_loss: 0.3715 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.37623 to 0.37149, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.3469 - acc: 0.9368 - val_loss: 0.3733 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.37149\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.3450 - acc: 0.9375 - val_loss: 0.3767 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.37149\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.3422 - acc: 0.9408 - val_loss: 0.3708 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.37149 to 0.37081, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.3420 - acc: 0.9368 - val_loss: 0.3637 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.37081 to 0.36372, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.3371 - acc: 0.9428 - val_loss: 0.3661 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.36372\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.3363 - acc: 0.9414 - val_loss: 0.3581 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.36372 to 0.35808, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.3346 - acc: 0.9388 - val_loss: 0.3611 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.35808\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.3313 - acc: 0.9461 - val_loss: 0.3555 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.35808 to 0.35551, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.3296 - acc: 0.9467 - val_loss: 0.3555 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.35551 to 0.35548, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.3275 - acc: 0.9434 - val_loss: 0.3516 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.35548 to 0.35155, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.3250 - acc: 0.9500 - val_loss: 0.3549 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.35155\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.3242 - acc: 0.9447 - val_loss: 0.3476 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.35155 to 0.34760, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.3227 - acc: 0.9513 - val_loss: 0.3528 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.34760\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.3188 - acc: 0.9467 - val_loss: 0.3470 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.34760 to 0.34705, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.3181 - acc: 0.9513 - val_loss: 0.3427 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.34705 to 0.34275, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.3166 - acc: 0.9493 - val_loss: 0.3460 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.34275\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.3140 - acc: 0.9507 - val_loss: 0.3428 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.34275\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.3123 - acc: 0.9539 - val_loss: 0.3348 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.34275 to 0.33480, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.3114 - acc: 0.9539 - val_loss: 0.3343 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.33480 to 0.33426, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.3097 - acc: 0.9533 - val_loss: 0.3350 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.33426\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.3069 - acc: 0.9572 - val_loss: 0.3338 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.33426 to 0.33375, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.3049 - acc: 0.9553 - val_loss: 0.3347 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.33375\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.3036 - acc: 0.9546 - val_loss: 0.3350 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.33375\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.3014 - acc: 0.9599 - val_loss: 0.3284 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.33375 to 0.32841, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.3000 - acc: 0.9546 - val_loss: 0.3273 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.32841 to 0.32729, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.2992 - acc: 0.9566 - val_loss: 0.3204 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.32729 to 0.32042, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.2967 - acc: 0.9579 - val_loss: 0.3214 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.32042\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.2951 - acc: 0.9572 - val_loss: 0.3174 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.32042 to 0.31737, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.2928 - acc: 0.9592 - val_loss: 0.3193 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.31737\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.2917 - acc: 0.9612 - val_loss: 0.3203 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.31737\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.2903 - acc: 0.9572 - val_loss: 0.3168 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.31737 to 0.31680, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.2884 - acc: 0.9625 - val_loss: 0.3169 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.31680\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.2869 - acc: 0.9638 - val_loss: 0.3132 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.31680 to 0.31317, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.2853 - acc: 0.9632 - val_loss: 0.3114 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.31317 to 0.31141, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.2840 - acc: 0.9645 - val_loss: 0.3150 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.31141\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.2817 - acc: 0.9618 - val_loss: 0.3081 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.31141 to 0.30805, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.2813 - acc: 0.9645 - val_loss: 0.3086 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.30805\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.2792 - acc: 0.9664 - val_loss: 0.3055 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.30805 to 0.30553, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.2795 - acc: 0.9625 - val_loss: 0.3081 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.30553\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.2770 - acc: 0.9632 - val_loss: 0.3039 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.30553 to 0.30390, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.2746 - acc: 0.9664 - val_loss: 0.3063 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.30390\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.2738 - acc: 0.9671 - val_loss: 0.2997 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.30390 to 0.29973, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.2721 - acc: 0.9684 - val_loss: 0.2970 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.29973 to 0.29704, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.2711 - acc: 0.9678 - val_loss: 0.2987 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.29704\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.2698 - acc: 0.9671 - val_loss: 0.2962 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.29704 to 0.29623, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.2682 - acc: 0.9664 - val_loss: 0.2947 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.29623 to 0.29471, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.2670 - acc: 0.9697 - val_loss: 0.2943 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.29471 to 0.29427, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.2653 - acc: 0.9704 - val_loss: 0.2903 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.29427 to 0.29032, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.2653 - acc: 0.9691 - val_loss: 0.2878 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.29032 to 0.28784, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.2637 - acc: 0.9697 - val_loss: 0.2879 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.28784\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.2622 - acc: 0.9678 - val_loss: 0.2887 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.28784\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.2605 - acc: 0.9717 - val_loss: 0.2871 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.28784 to 0.28714, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.2598 - acc: 0.9743 - val_loss: 0.2883 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.28714\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.2574 - acc: 0.9717 - val_loss: 0.2830 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.28714 to 0.28301, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.2576 - acc: 0.9737 - val_loss: 0.2874 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.28301\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.2564 - acc: 0.9730 - val_loss: 0.2855 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.28301\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.2549 - acc: 0.9750 - val_loss: 0.2827 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.28301 to 0.28275, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.2530 - acc: 0.9724 - val_loss: 0.2818 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.28275 to 0.28178, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.2515 - acc: 0.9770 - val_loss: 0.2777 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.28178 to 0.27767, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.2516 - acc: 0.9737 - val_loss: 0.2745 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.27767 to 0.27454, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.2501 - acc: 0.9757 - val_loss: 0.2749 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.27454\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.2488 - acc: 0.9750 - val_loss: 0.2773 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.27454\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.2475 - acc: 0.9743 - val_loss: 0.2741 - val_acc: 0.9753\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00151: val_loss improved from 0.27454 to 0.27409, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.2465 - acc: 0.9743 - val_loss: 0.2704 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.27409 to 0.27039, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.2449 - acc: 0.9750 - val_loss: 0.2718 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.27039\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.2435 - acc: 0.9783 - val_loss: 0.2729 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.27039\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.2426 - acc: 0.9796 - val_loss: 0.2670 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.27039 to 0.26701, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.2420 - acc: 0.9776 - val_loss: 0.2686 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.26701\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.2406 - acc: 0.9783 - val_loss: 0.2658 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.26701 to 0.26577, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.2394 - acc: 0.9757 - val_loss: 0.2657 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.26577 to 0.26565, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.2388 - acc: 0.9763 - val_loss: 0.2660 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.26565\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.2384 - acc: 0.9757 - val_loss: 0.2664 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.26565\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.2368 - acc: 0.9770 - val_loss: 0.2646 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.26565 to 0.26458, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.2358 - acc: 0.9776 - val_loss: 0.2601 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.26458 to 0.26006, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.2341 - acc: 0.9783 - val_loss: 0.2649 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.26006\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.2338 - acc: 0.9783 - val_loss: 0.2599 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.26006 to 0.25995, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.2331 - acc: 0.9796 - val_loss: 0.2581 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.25995 to 0.25812, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.2316 - acc: 0.9816 - val_loss: 0.2583 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.25812\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.2309 - acc: 0.9783 - val_loss: 0.2560 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.25812 to 0.25600, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.2306 - acc: 0.9789 - val_loss: 0.2557 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.25600 to 0.25569, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.2287 - acc: 0.9789 - val_loss: 0.2558 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.25569\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.2276 - acc: 0.9796 - val_loss: 0.2536 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.25569 to 0.25363, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.2267 - acc: 0.9796 - val_loss: 0.2504 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00171: val_loss improved from 0.25363 to 0.25038, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.2260 - acc: 0.9796 - val_loss: 0.2534 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.25038\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.2246 - acc: 0.9822 - val_loss: 0.2501 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.25038 to 0.25010, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.2239 - acc: 0.9796 - val_loss: 0.2531 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.25010\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.2228 - acc: 0.9809 - val_loss: 0.2520 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.25010\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.2225 - acc: 0.9796 - val_loss: 0.2462 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00176: val_loss improved from 0.25010 to 0.24621, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.2224 - acc: 0.9803 - val_loss: 0.2479 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.24621\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.2205 - acc: 0.9842 - val_loss: 0.2459 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00178: val_loss improved from 0.24621 to 0.24591, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.2193 - acc: 0.9803 - val_loss: 0.2462 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.24591\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.2188 - acc: 0.9816 - val_loss: 0.2444 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00180: val_loss improved from 0.24591 to 0.24443, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.2179 - acc: 0.9829 - val_loss: 0.2433 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00181: val_loss improved from 0.24443 to 0.24333, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.2163 - acc: 0.9803 - val_loss: 0.2436 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.24333\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.2161 - acc: 0.9849 - val_loss: 0.2433 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.24333\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.2156 - acc: 0.9829 - val_loss: 0.2441 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.24333\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.2145 - acc: 0.9836 - val_loss: 0.2422 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00185: val_loss improved from 0.24333 to 0.24220, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.2137 - acc: 0.9842 - val_loss: 0.2381 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.24220 to 0.23812, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.2129 - acc: 0.9822 - val_loss: 0.2398 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.23812\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.2115 - acc: 0.9829 - val_loss: 0.2367 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00188: val_loss improved from 0.23812 to 0.23670, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.2109 - acc: 0.9842 - val_loss: 0.2361 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.23670 to 0.23612, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.2104 - acc: 0.9849 - val_loss: 0.2371 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.23612\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.2093 - acc: 0.9829 - val_loss: 0.2374 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.23612\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.2089 - acc: 0.9842 - val_loss: 0.2336 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.23612 to 0.23364, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.2081 - acc: 0.9836 - val_loss: 0.2318 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00193: val_loss improved from 0.23364 to 0.23176, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.2066 - acc: 0.9836 - val_loss: 0.2329 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.23176\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.2059 - acc: 0.9842 - val_loss: 0.2325 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.23176\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.2049 - acc: 0.9836 - val_loss: 0.2344 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.23176\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.2041 - acc: 0.9849 - val_loss: 0.2295 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00197: val_loss improved from 0.23176 to 0.22951, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.2040 - acc: 0.9842 - val_loss: 0.2292 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.22951 to 0.22923, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.2029 - acc: 0.9849 - val_loss: 0.2292 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00199: val_loss improved from 0.22923 to 0.22920, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.2029 - acc: 0.9836 - val_loss: 0.2270 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00200: val_loss improved from 0.22920 to 0.22705, saving model to weights.best.Resnet50.hdf5\n",
      "batch_size=200   optimizer=Adagrad\n",
      "Test accuracy: 68.2451%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 2s - loss: 1.6863 - acc: 0.4033 - val_loss: 1.1669 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.16688, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 1s - loss: 1.0920 - acc: 0.6368 - val_loss: 1.0046 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.16688 to 1.00462, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 1s - loss: 0.9140 - acc: 0.6954 - val_loss: 0.8933 - val_acc: 0.6790\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.00462 to 0.89327, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 1s - loss: 0.8087 - acc: 0.7322 - val_loss: 0.7806 - val_acc: 0.7160\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.89327 to 0.78057, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 1s - loss: 0.7351 - acc: 0.7612 - val_loss: 0.6725 - val_acc: 0.7819\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.78057 to 0.67253, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 1s - loss: 0.6627 - acc: 0.7836 - val_loss: 0.5941 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.67253 to 0.59406, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 1s - loss: 0.6054 - acc: 0.8118 - val_loss: 0.5496 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.59406 to 0.54965, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 1s - loss: 0.5613 - acc: 0.8171 - val_loss: 0.5232 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.54965 to 0.52321, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 1s - loss: 0.5177 - acc: 0.8395 - val_loss: 0.4511 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.52321 to 0.45111, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 1s - loss: 0.4741 - acc: 0.8533 - val_loss: 0.4491 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.45111 to 0.44906, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 1s - loss: 0.4490 - acc: 0.8586 - val_loss: 0.4638 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.44906\n",
      "Epoch 12/200\n",
      " - 1s - loss: 0.4155 - acc: 0.8803 - val_loss: 0.4049 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.44906 to 0.40490, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 1s - loss: 0.3845 - acc: 0.8822 - val_loss: 0.3530 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.40490 to 0.35304, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 1s - loss: 0.3641 - acc: 0.9033 - val_loss: 0.3517 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.35304 to 0.35169, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 1s - loss: 0.3377 - acc: 0.9184 - val_loss: 0.3550 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.35169\n",
      "Epoch 16/200\n",
      " - 1s - loss: 0.3200 - acc: 0.9204 - val_loss: 0.2888 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.35169 to 0.28877, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 1s - loss: 0.3033 - acc: 0.9270 - val_loss: 0.2965 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.28877\n",
      "Epoch 18/200\n",
      " - 1s - loss: 0.2819 - acc: 0.9408 - val_loss: 0.2855 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.28877 to 0.28550, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 1s - loss: 0.2686 - acc: 0.9401 - val_loss: 0.2550 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.28550 to 0.25498, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 1s - loss: 0.2486 - acc: 0.9526 - val_loss: 0.2736 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.25498\n",
      "Epoch 21/200\n",
      " - 1s - loss: 0.2395 - acc: 0.9553 - val_loss: 0.2470 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.25498 to 0.24705, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 1s - loss: 0.2217 - acc: 0.9566 - val_loss: 0.2411 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.24705 to 0.24109, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 1s - loss: 0.2100 - acc: 0.9599 - val_loss: 0.2105 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.24109 to 0.21046, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 24/200\n",
      " - 1s - loss: 0.1961 - acc: 0.9651 - val_loss: 0.2140 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.21046\n",
      "Epoch 25/200\n",
      " - 1s - loss: 0.1869 - acc: 0.9704 - val_loss: 0.1786 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.21046 to 0.17856, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 26/200\n",
      " - 1s - loss: 0.1722 - acc: 0.9783 - val_loss: 0.1606 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.17856 to 0.16063, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 27/200\n",
      " - 1s - loss: 0.1682 - acc: 0.9743 - val_loss: 0.1586 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.16063 to 0.15862, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 28/200\n",
      " - 1s - loss: 0.1583 - acc: 0.9770 - val_loss: 0.1618 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.15862\n",
      "Epoch 29/200\n",
      " - 1s - loss: 0.1505 - acc: 0.9803 - val_loss: 0.1358 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.15862 to 0.13575, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 30/200\n",
      " - 1s - loss: 0.1406 - acc: 0.9829 - val_loss: 0.1817 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.13575\n",
      "Epoch 31/200\n",
      " - 1s - loss: 0.1321 - acc: 0.9829 - val_loss: 0.1265 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.13575 to 0.12650, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 32/200\n",
      " - 1s - loss: 0.1261 - acc: 0.9868 - val_loss: 0.1283 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.12650\n",
      "Epoch 33/200\n",
      " - 1s - loss: 0.1190 - acc: 0.9849 - val_loss: 0.1378 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.12650\n",
      "Epoch 34/200\n",
      " - 1s - loss: 0.1140 - acc: 0.9868 - val_loss: 0.1285 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.12650\n",
      "Epoch 35/200\n",
      " - 1s - loss: 0.1065 - acc: 0.9882 - val_loss: 0.1068 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.12650 to 0.10676, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 36/200\n",
      " - 1s - loss: 0.1041 - acc: 0.9908 - val_loss: 0.1143 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.10676\n",
      "Epoch 37/200\n",
      " - 1s - loss: 0.0946 - acc: 0.9934 - val_loss: 0.1090 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.10676\n",
      "Epoch 38/200\n",
      " - 1s - loss: 0.0931 - acc: 0.9934 - val_loss: 0.1008 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.10676 to 0.10076, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 39/200\n",
      " - 1s - loss: 0.0864 - acc: 0.9934 - val_loss: 0.0904 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.10076 to 0.09040, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 40/200\n",
      " - 1s - loss: 0.0820 - acc: 0.9921 - val_loss: 0.1125 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.09040\n",
      "Epoch 41/200\n",
      " - 1s - loss: 0.0794 - acc: 0.9947 - val_loss: 0.0884 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.09040 to 0.08845, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 42/200\n",
      " - 1s - loss: 0.0748 - acc: 0.9961 - val_loss: 0.0866 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.08845 to 0.08658, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 43/200\n",
      " - 1s - loss: 0.0707 - acc: 0.9928 - val_loss: 0.0916 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.08658\n",
      "Epoch 44/200\n",
      " - 1s - loss: 0.0677 - acc: 0.9947 - val_loss: 0.0733 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.08658 to 0.07327, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 45/200\n",
      " - 1s - loss: 0.0643 - acc: 0.9947 - val_loss: 0.0702 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.07327 to 0.07019, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 46/200\n",
      " - 1s - loss: 0.0627 - acc: 0.9947 - val_loss: 0.0612 - val_acc: 0.9959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00046: val_loss improved from 0.07019 to 0.06115, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 47/200\n",
      " - 1s - loss: 0.0574 - acc: 0.9967 - val_loss: 0.0770 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.06115\n",
      "Epoch 48/200\n",
      " - 1s - loss: 0.0561 - acc: 0.9980 - val_loss: 0.0641 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.06115\n",
      "Epoch 49/200\n",
      " - 1s - loss: 0.0534 - acc: 0.9980 - val_loss: 0.0690 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.06115\n",
      "Epoch 50/200\n",
      " - 1s - loss: 0.0504 - acc: 0.9974 - val_loss: 0.0636 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.06115\n",
      "Epoch 51/200\n",
      " - 1s - loss: 0.0506 - acc: 0.9961 - val_loss: 0.0600 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.06115 to 0.06002, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 52/200\n",
      " - 1s - loss: 0.0456 - acc: 0.9961 - val_loss: 0.0557 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.06002 to 0.05574, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 53/200\n",
      " - 1s - loss: 0.0441 - acc: 0.9974 - val_loss: 0.0693 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.05574\n",
      "Epoch 54/200\n",
      " - 1s - loss: 0.0424 - acc: 0.9987 - val_loss: 0.0583 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.05574\n",
      "Epoch 55/200\n",
      " - 1s - loss: 0.0411 - acc: 0.9961 - val_loss: 0.0658 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.05574\n",
      "Epoch 56/200\n",
      " - 1s - loss: 0.0388 - acc: 0.9974 - val_loss: 0.0575 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.05574\n",
      "Epoch 57/200\n",
      " - 1s - loss: 0.0379 - acc: 0.9974 - val_loss: 0.0559 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.05574\n",
      "Epoch 58/200\n",
      " - 1s - loss: 0.0359 - acc: 0.9974 - val_loss: 0.0478 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.05574 to 0.04779, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 59/200\n",
      " - 1s - loss: 0.0351 - acc: 0.9961 - val_loss: 0.0534 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.04779\n",
      "Epoch 60/200\n",
      " - 1s - loss: 0.0328 - acc: 0.9974 - val_loss: 0.0593 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.04779\n",
      "Epoch 61/200\n",
      " - 1s - loss: 0.0315 - acc: 0.9974 - val_loss: 0.0566 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.04779\n",
      "Epoch 62/200\n",
      " - 1s - loss: 0.0313 - acc: 0.9961 - val_loss: 0.0539 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.04779\n",
      "Epoch 63/200\n",
      " - 1s - loss: 0.0289 - acc: 0.9974 - val_loss: 0.0482 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.04779\n",
      "Epoch 64/200\n",
      " - 1s - loss: 0.0280 - acc: 0.9980 - val_loss: 0.0388 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.04779 to 0.03878, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 65/200\n",
      " - 1s - loss: 0.0276 - acc: 0.9967 - val_loss: 0.0435 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.03878\n",
      "Epoch 66/200\n",
      " - 1s - loss: 0.0265 - acc: 0.9974 - val_loss: 0.0423 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.03878\n",
      "Epoch 67/200\n",
      " - 1s - loss: 0.0254 - acc: 0.9974 - val_loss: 0.0612 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.03878\n",
      "Epoch 68/200\n",
      " - 1s - loss: 0.0238 - acc: 0.9980 - val_loss: 0.0391 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.03878\n",
      "Epoch 69/200\n",
      " - 1s - loss: 0.0233 - acc: 0.9974 - val_loss: 0.0512 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.03878\n",
      "Epoch 70/200\n",
      " - 1s - loss: 0.0229 - acc: 0.9967 - val_loss: 0.0406 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.03878\n",
      "Epoch 71/200\n",
      " - 1s - loss: 0.0218 - acc: 0.9967 - val_loss: 0.0396 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.03878\n",
      "Epoch 72/200\n",
      " - 1s - loss: 0.0212 - acc: 0.9974 - val_loss: 0.0410 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.03878\n",
      "Epoch 73/200\n",
      " - 1s - loss: 0.0214 - acc: 0.9974 - val_loss: 0.0381 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.03878 to 0.03806, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 74/200\n",
      " - 1s - loss: 0.0197 - acc: 0.9974 - val_loss: 0.0440 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.03806\n",
      "Epoch 75/200\n",
      " - 1s - loss: 0.0205 - acc: 0.9961 - val_loss: 0.0419 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.03806\n",
      "Epoch 76/200\n",
      " - 1s - loss: 0.0190 - acc: 0.9967 - val_loss: 0.0301 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.03806 to 0.03006, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 77/200\n",
      " - 1s - loss: 0.0186 - acc: 0.9967 - val_loss: 0.0428 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.03006\n",
      "Epoch 78/200\n",
      " - 1s - loss: 0.0179 - acc: 0.9974 - val_loss: 0.0431 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.03006\n",
      "Epoch 79/200\n",
      " - 1s - loss: 0.0170 - acc: 0.9974 - val_loss: 0.0412 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.03006\n",
      "Epoch 80/200\n",
      " - 1s - loss: 0.0178 - acc: 0.9974 - val_loss: 0.0384 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.03006\n",
      "Epoch 81/200\n",
      " - 1s - loss: 0.0161 - acc: 0.9974 - val_loss: 0.0330 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.03006\n",
      "Epoch 82/200\n",
      " - 1s - loss: 0.0162 - acc: 0.9980 - val_loss: 0.0328 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.03006\n",
      "Epoch 83/200\n",
      " - 1s - loss: 0.0159 - acc: 0.9980 - val_loss: 0.0324 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.03006\n",
      "Epoch 84/200\n",
      " - 1s - loss: 0.0152 - acc: 0.9967 - val_loss: 0.0344 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.03006\n",
      "Epoch 85/200\n",
      " - 1s - loss: 0.0150 - acc: 0.9967 - val_loss: 0.0402 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.03006\n",
      "Epoch 86/200\n",
      " - 1s - loss: 0.0146 - acc: 0.9980 - val_loss: 0.0332 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.03006\n",
      "Epoch 87/200\n",
      " - 1s - loss: 0.0142 - acc: 0.9974 - val_loss: 0.0349 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.03006\n",
      "Epoch 88/200\n",
      " - 1s - loss: 0.0137 - acc: 0.9974 - val_loss: 0.0336 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.03006\n",
      "Epoch 89/200\n",
      " - 1s - loss: 0.0133 - acc: 0.9967 - val_loss: 0.0430 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.03006\n",
      "Epoch 90/200\n",
      " - 1s - loss: 0.0127 - acc: 0.9974 - val_loss: 0.0374 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.03006\n",
      "Epoch 91/200\n",
      " - 1s - loss: 0.0127 - acc: 0.9967 - val_loss: 0.0406 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.03006\n",
      "Epoch 92/200\n",
      " - 1s - loss: 0.0127 - acc: 0.9967 - val_loss: 0.0314 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.03006\n",
      "Epoch 93/200\n",
      " - 1s - loss: 0.0123 - acc: 0.9980 - val_loss: 0.0299 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.03006 to 0.02990, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 94/200\n",
      " - 1s - loss: 0.0123 - acc: 0.9967 - val_loss: 0.0322 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.02990\n",
      "Epoch 95/200\n",
      " - 1s - loss: 0.0117 - acc: 0.9974 - val_loss: 0.0294 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.02990 to 0.02938, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 96/200\n",
      " - 1s - loss: 0.0120 - acc: 0.9967 - val_loss: 0.0340 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.02938\n",
      "Epoch 97/200\n",
      " - 1s - loss: 0.0115 - acc: 0.9980 - val_loss: 0.0370 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.02938\n",
      "Epoch 98/200\n",
      " - 1s - loss: 0.0110 - acc: 0.9974 - val_loss: 0.0417 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.02938\n",
      "Epoch 99/200\n",
      " - 1s - loss: 0.0114 - acc: 0.9961 - val_loss: 0.0256 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.02938 to 0.02557, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 100/200\n",
      " - 1s - loss: 0.0113 - acc: 0.9961 - val_loss: 0.0319 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.02557\n",
      "Epoch 101/200\n",
      " - 1s - loss: 0.0105 - acc: 0.9967 - val_loss: 0.0312 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.02557\n",
      "Epoch 102/200\n",
      " - 1s - loss: 0.0100 - acc: 0.9974 - val_loss: 0.0272 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.02557\n",
      "Epoch 103/200\n",
      " - 1s - loss: 0.0103 - acc: 0.9974 - val_loss: 0.0266 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.02557\n",
      "Epoch 104/200\n",
      " - 1s - loss: 0.0103 - acc: 0.9980 - val_loss: 0.0313 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.02557\n",
      "Epoch 105/200\n",
      " - 1s - loss: 0.0102 - acc: 0.9961 - val_loss: 0.0286 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.02557\n",
      "Epoch 106/200\n",
      " - 1s - loss: 0.0097 - acc: 0.9967 - val_loss: 0.0376 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.02557\n",
      "Epoch 107/200\n",
      " - 1s - loss: 0.0097 - acc: 0.9974 - val_loss: 0.0297 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.02557\n",
      "Epoch 108/200\n",
      " - 1s - loss: 0.0092 - acc: 0.9974 - val_loss: 0.0325 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.02557\n",
      "Epoch 109/200\n",
      " - 1s - loss: 0.0104 - acc: 0.9974 - val_loss: 0.0381 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.02557\n",
      "Epoch 110/200\n",
      " - 1s - loss: 0.0095 - acc: 0.9974 - val_loss: 0.0257 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.02557\n",
      "Epoch 111/200\n",
      " - 1s - loss: 0.0088 - acc: 0.9980 - val_loss: 0.0380 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.02557\n",
      "Epoch 112/200\n",
      " - 1s - loss: 0.0088 - acc: 0.9974 - val_loss: 0.0287 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.02557\n",
      "Epoch 113/200\n",
      " - 1s - loss: 0.0093 - acc: 0.9961 - val_loss: 0.0298 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.02557\n",
      "Epoch 114/200\n",
      " - 1s - loss: 0.0086 - acc: 0.9974 - val_loss: 0.0301 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.02557\n",
      "Epoch 115/200\n",
      " - 1s - loss: 0.0086 - acc: 0.9974 - val_loss: 0.0319 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.02557\n",
      "Epoch 116/200\n",
      " - 1s - loss: 0.0085 - acc: 0.9974 - val_loss: 0.0287 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.02557\n",
      "Epoch 117/200\n",
      " - 1s - loss: 0.0085 - acc: 0.9980 - val_loss: 0.0294 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.02557\n",
      "Epoch 118/200\n",
      " - 1s - loss: 0.0079 - acc: 0.9974 - val_loss: 0.0329 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.02557\n",
      "Epoch 119/200\n",
      " - 1s - loss: 0.0085 - acc: 0.9974 - val_loss: 0.0276 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.02557\n",
      "Epoch 120/200\n",
      " - 1s - loss: 0.0083 - acc: 0.9974 - val_loss: 0.0305 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.02557\n",
      "Epoch 121/200\n",
      " - 1s - loss: 0.0080 - acc: 0.9980 - val_loss: 0.0300 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.02557\n",
      "Epoch 122/200\n",
      " - 1s - loss: 0.0082 - acc: 0.9980 - val_loss: 0.0265 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.02557\n",
      "Epoch 123/200\n",
      " - 1s - loss: 0.0077 - acc: 0.9974 - val_loss: 0.0332 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.02557\n",
      "Epoch 124/200\n",
      " - 1s - loss: 0.0082 - acc: 0.9967 - val_loss: 0.0265 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.02557\n",
      "Epoch 125/200\n",
      " - 1s - loss: 0.0077 - acc: 0.9974 - val_loss: 0.0274 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.02557\n",
      "Epoch 126/200\n",
      " - 1s - loss: 0.0078 - acc: 0.9961 - val_loss: 0.0291 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.02557\n",
      "Epoch 127/200\n",
      " - 1s - loss: 0.0075 - acc: 0.9967 - val_loss: 0.0307 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.02557\n",
      "Epoch 128/200\n",
      " - 1s - loss: 0.0076 - acc: 0.9974 - val_loss: 0.0313 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.02557\n",
      "Epoch 129/200\n",
      " - 1s - loss: 0.0079 - acc: 0.9974 - val_loss: 0.0292 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.02557\n",
      "Epoch 130/200\n",
      " - 1s - loss: 0.0071 - acc: 0.9967 - val_loss: 0.0340 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.02557\n",
      "Epoch 131/200\n",
      " - 1s - loss: 0.0072 - acc: 0.9967 - val_loss: 0.0289 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.02557\n",
      "Epoch 132/200\n",
      " - 1s - loss: 0.0072 - acc: 0.9980 - val_loss: 0.0253 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.02557 to 0.02535, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 133/200\n",
      " - 1s - loss: 0.0073 - acc: 0.9974 - val_loss: 0.0323 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.02535\n",
      "Epoch 134/200\n",
      " - 1s - loss: 0.0076 - acc: 0.9967 - val_loss: 0.0263 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.02535\n",
      "Epoch 135/200\n",
      " - 1s - loss: 0.0069 - acc: 0.9980 - val_loss: 0.0340 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.02535\n",
      "Epoch 136/200\n",
      " - 1s - loss: 0.0070 - acc: 0.9980 - val_loss: 0.0324 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.02535\n",
      "Epoch 137/200\n",
      " - 1s - loss: 0.0069 - acc: 0.9974 - val_loss: 0.0270 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.02535\n",
      "Epoch 138/200\n",
      " - 1s - loss: 0.0073 - acc: 0.9961 - val_loss: 0.0251 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.02535 to 0.02508, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 139/200\n",
      " - 1s - loss: 0.0072 - acc: 0.9974 - val_loss: 0.0248 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.02508 to 0.02478, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 140/200\n",
      " - 1s - loss: 0.0069 - acc: 0.9974 - val_loss: 0.0316 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.02478\n",
      "Epoch 141/200\n",
      " - 1s - loss: 0.0070 - acc: 0.9967 - val_loss: 0.0257 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.02478\n",
      "Epoch 142/200\n",
      " - 1s - loss: 0.0070 - acc: 0.9961 - val_loss: 0.0311 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.02478\n",
      "Epoch 143/200\n",
      " - 1s - loss: 0.0066 - acc: 0.9974 - val_loss: 0.0315 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.02478\n",
      "Epoch 144/200\n",
      " - 1s - loss: 0.0066 - acc: 0.9974 - val_loss: 0.0281 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.02478\n",
      "Epoch 145/200\n",
      " - 1s - loss: 0.0061 - acc: 0.9974 - val_loss: 0.0286 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.02478\n",
      "Epoch 146/200\n",
      " - 1s - loss: 0.0066 - acc: 0.9974 - val_loss: 0.0356 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.02478\n",
      "Epoch 147/200\n",
      " - 1s - loss: 0.0065 - acc: 0.9967 - val_loss: 0.0303 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.02478\n",
      "Epoch 148/200\n",
      " - 1s - loss: 0.0065 - acc: 0.9980 - val_loss: 0.0248 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.02478\n",
      "Epoch 149/200\n",
      " - 1s - loss: 0.0067 - acc: 0.9980 - val_loss: 0.0268 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.02478\n",
      "Epoch 150/200\n",
      " - 1s - loss: 0.0065 - acc: 0.9967 - val_loss: 0.0262 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.02478\n",
      "Epoch 151/200\n",
      " - 1s - loss: 0.0059 - acc: 0.9967 - val_loss: 0.0367 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.02478\n",
      "Epoch 152/200\n",
      " - 1s - loss: 0.0062 - acc: 0.9974 - val_loss: 0.0302 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.02478\n",
      "Epoch 153/200\n",
      " - 1s - loss: 0.0067 - acc: 0.9967 - val_loss: 0.0269 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.02478\n",
      "Epoch 154/200\n",
      " - 1s - loss: 0.0063 - acc: 0.9967 - val_loss: 0.0280 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.02478\n",
      "Epoch 155/200\n",
      " - 1s - loss: 0.0066 - acc: 0.9974 - val_loss: 0.0324 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.02478\n",
      "Epoch 156/200\n",
      " - 1s - loss: 0.0064 - acc: 0.9967 - val_loss: 0.0244 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.02478 to 0.02439, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 157/200\n",
      " - 1s - loss: 0.0065 - acc: 0.9967 - val_loss: 0.0252 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.02439\n",
      "Epoch 158/200\n",
      " - 1s - loss: 0.0062 - acc: 0.9974 - val_loss: 0.0302 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.02439\n",
      "Epoch 159/200\n",
      " - 1s - loss: 0.0062 - acc: 0.9974 - val_loss: 0.0255 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.02439\n",
      "Epoch 160/200\n",
      " - 1s - loss: 0.0064 - acc: 0.9974 - val_loss: 0.0285 - val_acc: 0.9918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00160: val_loss did not improve from 0.02439\n",
      "Epoch 161/200\n",
      " - 1s - loss: 0.0061 - acc: 0.9967 - val_loss: 0.0377 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.02439\n",
      "Epoch 162/200\n",
      " - 1s - loss: 0.0061 - acc: 0.9974 - val_loss: 0.0282 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.02439\n",
      "Epoch 163/200\n",
      " - 1s - loss: 0.0063 - acc: 0.9974 - val_loss: 0.0257 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.02439\n",
      "Epoch 164/200\n",
      " - 1s - loss: 0.0064 - acc: 0.9980 - val_loss: 0.0272 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.02439\n",
      "Epoch 165/200\n",
      " - 1s - loss: 0.0061 - acc: 0.9974 - val_loss: 0.0323 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.02439\n",
      "Epoch 166/200\n",
      " - 1s - loss: 0.0058 - acc: 0.9980 - val_loss: 0.0280 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.02439\n",
      "Epoch 167/200\n",
      " - 1s - loss: 0.0058 - acc: 0.9980 - val_loss: 0.0319 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.02439\n",
      "Epoch 168/200\n",
      " - 1s - loss: 0.0059 - acc: 0.9974 - val_loss: 0.0334 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.02439\n",
      "Epoch 169/200\n",
      " - 1s - loss: 0.0059 - acc: 0.9961 - val_loss: 0.0276 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.02439\n",
      "Epoch 170/200\n",
      " - 1s - loss: 0.0060 - acc: 0.9974 - val_loss: 0.0239 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.02439 to 0.02395, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 171/200\n",
      " - 1s - loss: 0.0061 - acc: 0.9967 - val_loss: 0.0286 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.02395\n",
      "Epoch 172/200\n",
      " - 1s - loss: 0.0061 - acc: 0.9961 - val_loss: 0.0246 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.02395\n",
      "Epoch 173/200\n",
      " - 1s - loss: 0.0062 - acc: 0.9974 - val_loss: 0.0283 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.02395\n",
      "Epoch 174/200\n",
      " - 1s - loss: 0.0060 - acc: 0.9967 - val_loss: 0.0269 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.02395\n",
      "Epoch 175/200\n",
      " - 1s - loss: 0.0060 - acc: 0.9967 - val_loss: 0.0247 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.02395\n",
      "Epoch 176/200\n",
      " - 1s - loss: 0.0056 - acc: 0.9974 - val_loss: 0.0265 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.02395\n",
      "Epoch 177/200\n",
      " - 1s - loss: 0.0055 - acc: 0.9974 - val_loss: 0.0348 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.02395\n",
      "Epoch 178/200\n",
      " - 1s - loss: 0.0065 - acc: 0.9974 - val_loss: 0.0244 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.02395\n",
      "Epoch 179/200\n",
      " - 1s - loss: 0.0060 - acc: 0.9961 - val_loss: 0.0277 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.02395\n",
      "Epoch 180/200\n",
      " - 1s - loss: 0.0055 - acc: 0.9967 - val_loss: 0.0292 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.02395\n",
      "Epoch 181/200\n",
      " - 1s - loss: 0.0056 - acc: 0.9974 - val_loss: 0.0310 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.02395\n",
      "Epoch 182/200\n",
      " - 1s - loss: 0.0055 - acc: 0.9974 - val_loss: 0.0363 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.02395\n",
      "Epoch 183/200\n",
      " - 1s - loss: 0.0052 - acc: 0.9980 - val_loss: 0.0272 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.02395\n",
      "Epoch 184/200\n",
      " - 1s - loss: 0.0058 - acc: 0.9967 - val_loss: 0.0268 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.02395\n",
      "Epoch 185/200\n",
      " - 1s - loss: 0.0057 - acc: 0.9974 - val_loss: 0.0269 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.02395\n",
      "Epoch 186/200\n",
      " - 1s - loss: 0.0057 - acc: 0.9980 - val_loss: 0.0264 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.02395\n",
      "Epoch 187/200\n",
      " - 1s - loss: 0.0059 - acc: 0.9974 - val_loss: 0.0233 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.02395 to 0.02332, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 188/200\n",
      " - 1s - loss: 0.0052 - acc: 0.9967 - val_loss: 0.0276 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.02332\n",
      "Epoch 189/200\n",
      " - 1s - loss: 0.0060 - acc: 0.9961 - val_loss: 0.0283 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.02332\n",
      "Epoch 190/200\n",
      " - 1s - loss: 0.0058 - acc: 0.9974 - val_loss: 0.0274 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.02332\n",
      "Epoch 191/200\n",
      " - 1s - loss: 0.0054 - acc: 0.9974 - val_loss: 0.0330 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.02332\n",
      "Epoch 192/200\n",
      " - 1s - loss: 0.0055 - acc: 0.9974 - val_loss: 0.0252 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.02332\n",
      "Epoch 193/200\n",
      " - 1s - loss: 0.0052 - acc: 0.9980 - val_loss: 0.0261 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.02332\n",
      "Epoch 194/200\n",
      " - 1s - loss: 0.0056 - acc: 0.9961 - val_loss: 0.0260 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.02332\n",
      "Epoch 195/200\n",
      " - 1s - loss: 0.0056 - acc: 0.9974 - val_loss: 0.0258 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.02332\n",
      "Epoch 196/200\n",
      " - 1s - loss: 0.0054 - acc: 0.9967 - val_loss: 0.0281 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.02332\n",
      "Epoch 197/200\n",
      " - 1s - loss: 0.0057 - acc: 0.9961 - val_loss: 0.0261 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.02332\n",
      "Epoch 198/200\n",
      " - 1s - loss: 0.0057 - acc: 0.9974 - val_loss: 0.0266 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.02332\n",
      "Epoch 199/200\n",
      " - 1s - loss: 0.0056 - acc: 0.9967 - val_loss: 0.0282 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.02332\n",
      "Epoch 200/200\n",
      " - 1s - loss: 0.0056 - acc: 0.9974 - val_loss: 0.0278 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.02332\n",
      "batch_size=10   optimizer=Adadelta\n",
      "Test accuracy: 67.6880%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_35 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 1.7308 - acc: 0.3993 - val_loss: 1.3753 - val_acc: 0.5226\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.37530, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.1612 - acc: 0.6250 - val_loss: 1.0664 - val_acc: 0.6502\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.37530 to 1.06642, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.9856 - acc: 0.6763 - val_loss: 0.9240 - val_acc: 0.6955\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.06642 to 0.92401, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.8635 - acc: 0.7118 - val_loss: 0.8599 - val_acc: 0.7078\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.92401 to 0.85992, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.7864 - acc: 0.7447 - val_loss: 0.7763 - val_acc: 0.7243\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.85992 to 0.77627, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.7280 - acc: 0.7586 - val_loss: 0.6763 - val_acc: 0.7901\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.77627 to 0.67626, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.6648 - acc: 0.7901 - val_loss: 0.6626 - val_acc: 0.7737\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.67626 to 0.66265, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.6279 - acc: 0.7967 - val_loss: 0.6056 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.66265 to 0.60557, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.5890 - acc: 0.8145 - val_loss: 0.5649 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.60557 to 0.56486, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.5378 - acc: 0.8270 - val_loss: 0.5338 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.56486 to 0.53376, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.5124 - acc: 0.8434 - val_loss: 0.5008 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.53376 to 0.50083, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.4783 - acc: 0.8592 - val_loss: 0.4553 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.50083 to 0.45526, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.4508 - acc: 0.8671 - val_loss: 0.5037 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.45526\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.4230 - acc: 0.8770 - val_loss: 0.4087 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.45526 to 0.40874, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.4017 - acc: 0.8875 - val_loss: 0.3879 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.40874 to 0.38789, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.3857 - acc: 0.8934 - val_loss: 0.3767 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.38789 to 0.37665, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.3603 - acc: 0.9158 - val_loss: 0.3785 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.37665\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.3457 - acc: 0.9092 - val_loss: 0.3317 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.37665 to 0.33170, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.3283 - acc: 0.9243 - val_loss: 0.3118 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.33170 to 0.31180, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.3086 - acc: 0.9303 - val_loss: 0.3005 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.31180 to 0.30054, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2913 - acc: 0.9382 - val_loss: 0.3028 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.30054\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2783 - acc: 0.9434 - val_loss: 0.2742 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.30054 to 0.27418, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2688 - acc: 0.9461 - val_loss: 0.2734 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.27418 to 0.27340, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2488 - acc: 0.9513 - val_loss: 0.2543 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.27340 to 0.25425, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2379 - acc: 0.9605 - val_loss: 0.2499 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.25425 to 0.24991, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2270 - acc: 0.9625 - val_loss: 0.2361 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.24991 to 0.23615, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2169 - acc: 0.9658 - val_loss: 0.2494 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.23615\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2077 - acc: 0.9651 - val_loss: 0.2382 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.23615\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.1960 - acc: 0.9743 - val_loss: 0.2240 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.23615 to 0.22398, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.1880 - acc: 0.9737 - val_loss: 0.2097 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.22398 to 0.20969, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.1787 - acc: 0.9789 - val_loss: 0.1864 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.20969 to 0.18643, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.1665 - acc: 0.9836 - val_loss: 0.1892 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.18643\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.1650 - acc: 0.9743 - val_loss: 0.1869 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.18643\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.1526 - acc: 0.9836 - val_loss: 0.1653 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.18643 to 0.16525, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.1486 - acc: 0.9849 - val_loss: 0.1625 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.16525 to 0.16253, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.1392 - acc: 0.9855 - val_loss: 0.1696 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.16253\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.1367 - acc: 0.9901 - val_loss: 0.1557 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.16253 to 0.15573, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.1287 - acc: 0.9901 - val_loss: 0.1348 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.15573 to 0.13476, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.1236 - acc: 0.9875 - val_loss: 0.1301 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.13476 to 0.13011, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.1159 - acc: 0.9934 - val_loss: 0.1252 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.13011 to 0.12521, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.1123 - acc: 0.9888 - val_loss: 0.1405 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.12521\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.1063 - acc: 0.9928 - val_loss: 0.1186 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.12521 to 0.11858, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1024 - acc: 0.9914 - val_loss: 0.1141 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.11858 to 0.11408, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.0970 - acc: 0.9928 - val_loss: 0.1183 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.11408\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.0928 - acc: 0.9934 - val_loss: 0.1006 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.11408 to 0.10062, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.0906 - acc: 0.9941 - val_loss: 0.1033 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.10062\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.0857 - acc: 0.9967 - val_loss: 0.1088 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.10062\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.0818 - acc: 0.9961 - val_loss: 0.1039 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.10062\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.0791 - acc: 0.9947 - val_loss: 0.1023 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.10062\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.0738 - acc: 0.9954 - val_loss: 0.0895 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.10062 to 0.08945, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.0731 - acc: 0.9967 - val_loss: 0.0868 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.08945 to 0.08676, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.0707 - acc: 0.9961 - val_loss: 0.0797 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.08676 to 0.07969, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.0669 - acc: 0.9974 - val_loss: 0.0946 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.07969\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.0633 - acc: 0.9974 - val_loss: 0.0794 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.07969 to 0.07943, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.0610 - acc: 0.9954 - val_loss: 0.0757 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.07943 to 0.07572, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.0592 - acc: 0.9961 - val_loss: 0.0742 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.07572 to 0.07421, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.0571 - acc: 0.9961 - val_loss: 0.0681 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.07421 to 0.06814, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.0541 - acc: 0.9974 - val_loss: 0.0738 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.06814\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.0525 - acc: 0.9967 - val_loss: 0.0657 - val_acc: 0.9959\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00059: val_loss improved from 0.06814 to 0.06568, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.0506 - acc: 0.9974 - val_loss: 0.0751 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.06568\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.0485 - acc: 0.9974 - val_loss: 0.0675 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.06568\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.0484 - acc: 0.9974 - val_loss: 0.0687 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.06568\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.0451 - acc: 0.9967 - val_loss: 0.0614 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.06568 to 0.06137, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.0440 - acc: 0.9961 - val_loss: 0.0590 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.06137 to 0.05901, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.0424 - acc: 0.9967 - val_loss: 0.0678 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.05901\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.0421 - acc: 0.9967 - val_loss: 0.0585 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.05901 to 0.05850, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.0387 - acc: 0.9980 - val_loss: 0.0592 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.05850\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.0379 - acc: 0.9967 - val_loss: 0.0566 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.05850 to 0.05659, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.0360 - acc: 0.9987 - val_loss: 0.0577 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.05659\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.0367 - acc: 0.9967 - val_loss: 0.0583 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.05659\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.0354 - acc: 0.9967 - val_loss: 0.0476 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.05659 to 0.04763, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.0325 - acc: 0.9980 - val_loss: 0.0500 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.04763\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.0330 - acc: 0.9974 - val_loss: 0.0518 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.04763\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.0308 - acc: 0.9967 - val_loss: 0.0583 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.04763\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.0307 - acc: 0.9974 - val_loss: 0.0496 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.04763\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.0296 - acc: 0.9980 - val_loss: 0.0619 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.04763\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.0296 - acc: 0.9961 - val_loss: 0.0476 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.04763 to 0.04756, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.0280 - acc: 0.9967 - val_loss: 0.0414 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.04756 to 0.04135, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.0271 - acc: 0.9980 - val_loss: 0.0391 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.04135 to 0.03908, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0267 - acc: 0.9974 - val_loss: 0.0471 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.03908\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0254 - acc: 0.9974 - val_loss: 0.0382 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.03908 to 0.03816, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0239 - acc: 0.9987 - val_loss: 0.0405 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.03816\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0241 - acc: 0.9974 - val_loss: 0.0370 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.03816 to 0.03704, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0237 - acc: 0.9967 - val_loss: 0.0434 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.03704\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0225 - acc: 0.9974 - val_loss: 0.0507 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.03704\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0227 - acc: 0.9974 - val_loss: 0.0465 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.03704\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0215 - acc: 0.9967 - val_loss: 0.0403 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.03704\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0214 - acc: 0.9967 - val_loss: 0.0385 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.03704\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0209 - acc: 0.9974 - val_loss: 0.0406 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.03704\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0202 - acc: 0.9961 - val_loss: 0.0472 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.03704\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0198 - acc: 0.9974 - val_loss: 0.0449 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.03704\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0194 - acc: 0.9967 - val_loss: 0.0434 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.03704\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0187 - acc: 0.9980 - val_loss: 0.0350 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.03704 to 0.03505, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0185 - acc: 0.9974 - val_loss: 0.0368 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.03505\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0184 - acc: 0.9967 - val_loss: 0.0468 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.03505\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0182 - acc: 0.9974 - val_loss: 0.0400 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.03505\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0171 - acc: 0.9961 - val_loss: 0.0385 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.03505\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0171 - acc: 0.9967 - val_loss: 0.0340 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.03505 to 0.03405, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0167 - acc: 0.9967 - val_loss: 0.0413 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.03405\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0157 - acc: 0.9980 - val_loss: 0.0405 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.03405\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0162 - acc: 0.9974 - val_loss: 0.0339 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.03405 to 0.03394, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0160 - acc: 0.9974 - val_loss: 0.0383 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.03394\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0154 - acc: 0.9967 - val_loss: 0.0324 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.03394 to 0.03241, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0152 - acc: 0.9974 - val_loss: 0.0303 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.03241 to 0.03030, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0148 - acc: 0.9967 - val_loss: 0.0339 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.03030\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0145 - acc: 0.9974 - val_loss: 0.0382 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.03030\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0146 - acc: 0.9967 - val_loss: 0.0357 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.03030\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0144 - acc: 0.9967 - val_loss: 0.0331 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.03030\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0137 - acc: 0.9961 - val_loss: 0.0331 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.03030\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0133 - acc: 0.9974 - val_loss: 0.0312 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.03030\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0136 - acc: 0.9974 - val_loss: 0.0340 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.03030\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0131 - acc: 0.9967 - val_loss: 0.0320 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.03030\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0127 - acc: 0.9980 - val_loss: 0.0383 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.03030\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0128 - acc: 0.9974 - val_loss: 0.0316 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.03030\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0126 - acc: 0.9980 - val_loss: 0.0337 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.03030\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0119 - acc: 0.9974 - val_loss: 0.0288 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.03030 to 0.02881, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0120 - acc: 0.9974 - val_loss: 0.0385 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.02881\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0117 - acc: 0.9974 - val_loss: 0.0319 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.02881\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0121 - acc: 0.9967 - val_loss: 0.0307 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.02881\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0118 - acc: 0.9967 - val_loss: 0.0298 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.02881\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0117 - acc: 0.9961 - val_loss: 0.0305 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.02881\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0114 - acc: 0.9967 - val_loss: 0.0319 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.02881\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0114 - acc: 0.9967 - val_loss: 0.0342 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.02881\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0113 - acc: 0.9974 - val_loss: 0.0304 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.02881\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0106 - acc: 0.9974 - val_loss: 0.0290 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.02881\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0109 - acc: 0.9967 - val_loss: 0.0311 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.02881\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0108 - acc: 0.9967 - val_loss: 0.0299 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.02881\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0106 - acc: 0.9974 - val_loss: 0.0275 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.02881 to 0.02752, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0106 - acc: 0.9980 - val_loss: 0.0324 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.02752\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0107 - acc: 0.9961 - val_loss: 0.0312 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.02752\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0100 - acc: 0.9974 - val_loss: 0.0277 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.02752\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0098 - acc: 0.9987 - val_loss: 0.0302 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.02752\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0099 - acc: 0.9974 - val_loss: 0.0311 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.02752\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0097 - acc: 0.9974 - val_loss: 0.0324 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.02752\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0096 - acc: 0.9974 - val_loss: 0.0288 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.02752\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0098 - acc: 0.9967 - val_loss: 0.0295 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.02752\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0100 - acc: 0.9961 - val_loss: 0.0340 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.02752\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0095 - acc: 0.9974 - val_loss: 0.0314 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.02752\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0094 - acc: 0.9980 - val_loss: 0.0308 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.02752\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0089 - acc: 0.9967 - val_loss: 0.0307 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.02752\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0092 - acc: 0.9967 - val_loss: 0.0258 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.02752 to 0.02577, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0094 - acc: 0.9967 - val_loss: 0.0263 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.02577\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0088 - acc: 0.9961 - val_loss: 0.0272 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.02577\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0086 - acc: 0.9974 - val_loss: 0.0339 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.02577\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0087 - acc: 0.9974 - val_loss: 0.0320 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.02577\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0092 - acc: 0.9961 - val_loss: 0.0296 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.02577\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0084 - acc: 0.9974 - val_loss: 0.0367 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.02577\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0083 - acc: 0.9974 - val_loss: 0.0306 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.02577\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0079 - acc: 0.9980 - val_loss: 0.0264 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.02577\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0083 - acc: 0.9987 - val_loss: 0.0274 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.02577\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0088 - acc: 0.9980 - val_loss: 0.0328 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.02577\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0084 - acc: 0.9974 - val_loss: 0.0279 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.02577\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0080 - acc: 0.9974 - val_loss: 0.0286 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.02577\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0086 - acc: 0.9967 - val_loss: 0.0256 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.02577 to 0.02556, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.0085 - acc: 0.9974 - val_loss: 0.0302 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.02556\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.0085 - acc: 0.9974 - val_loss: 0.0271 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.02556\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0080 - acc: 0.9974 - val_loss: 0.0320 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.02556\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.0081 - acc: 0.9967 - val_loss: 0.0314 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.02556\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.0081 - acc: 0.9967 - val_loss: 0.0249 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.02556 to 0.02486, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.0080 - acc: 0.9974 - val_loss: 0.0307 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.02486\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.0080 - acc: 0.9961 - val_loss: 0.0278 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.02486\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.0071 - acc: 0.9987 - val_loss: 0.0265 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.02486\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.0081 - acc: 0.9974 - val_loss: 0.0251 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.02486\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.0075 - acc: 0.9980 - val_loss: 0.0269 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.02486\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.0079 - acc: 0.9974 - val_loss: 0.0317 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.02486\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.0078 - acc: 0.9967 - val_loss: 0.0291 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.02486\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.0077 - acc: 0.9980 - val_loss: 0.0301 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.02486\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.0077 - acc: 0.9980 - val_loss: 0.0316 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.02486\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.0080 - acc: 0.9974 - val_loss: 0.0256 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.02486\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.0076 - acc: 0.9961 - val_loss: 0.0268 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.02486\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.0074 - acc: 0.9980 - val_loss: 0.0281 - val_acc: 0.9959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00171: val_loss did not improve from 0.02486\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.0069 - acc: 0.9967 - val_loss: 0.0266 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.02486\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.0076 - acc: 0.9974 - val_loss: 0.0246 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.02486 to 0.02462, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.0073 - acc: 0.9967 - val_loss: 0.0255 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.02462\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.0068 - acc: 0.9980 - val_loss: 0.0336 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.02462\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.0070 - acc: 0.9967 - val_loss: 0.0330 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.02462\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.0070 - acc: 0.9974 - val_loss: 0.0267 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.02462\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.0072 - acc: 0.9967 - val_loss: 0.0273 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.02462\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.0073 - acc: 0.9974 - val_loss: 0.0276 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.02462\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.0073 - acc: 0.9974 - val_loss: 0.0281 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.02462\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.0071 - acc: 0.9967 - val_loss: 0.0262 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.02462\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.0068 - acc: 0.9974 - val_loss: 0.0296 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.02462\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.0072 - acc: 0.9974 - val_loss: 0.0266 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.02462\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.0068 - acc: 0.9967 - val_loss: 0.0270 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.02462\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.0070 - acc: 0.9974 - val_loss: 0.0266 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.02462\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.0069 - acc: 0.9961 - val_loss: 0.0267 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.02462\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.0073 - acc: 0.9967 - val_loss: 0.0290 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.02462\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.0066 - acc: 0.9961 - val_loss: 0.0295 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.02462\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.0073 - acc: 0.9967 - val_loss: 0.0328 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.02462\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.0071 - acc: 0.9974 - val_loss: 0.0300 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.02462\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.0067 - acc: 0.9974 - val_loss: 0.0282 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.02462\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.0071 - acc: 0.9961 - val_loss: 0.0278 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.02462\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.0066 - acc: 0.9967 - val_loss: 0.0280 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.02462\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.0071 - acc: 0.9974 - val_loss: 0.0250 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.02462\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.0066 - acc: 0.9974 - val_loss: 0.0347 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.02462\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.0064 - acc: 0.9967 - val_loss: 0.0363 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.02462\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.0070 - acc: 0.9967 - val_loss: 0.0249 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.02462\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.0066 - acc: 0.9967 - val_loss: 0.0261 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.02462\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.0065 - acc: 0.9980 - val_loss: 0.0287 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.02462\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.0066 - acc: 0.9974 - val_loss: 0.0283 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.02462\n",
      "batch_size=20   optimizer=Adadelta\n",
      "Test accuracy: 68.5237%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 1.9946 - acc: 0.2855 - val_loss: 1.4463 - val_acc: 0.5144\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.44632, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.3390 - acc: 0.5566 - val_loss: 1.1850 - val_acc: 0.6420\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.44632 to 1.18503, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 1.1200 - acc: 0.6289 - val_loss: 1.0398 - val_acc: 0.6626\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.18503 to 1.03982, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.9857 - acc: 0.6724 - val_loss: 0.9169 - val_acc: 0.7078\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.03982 to 0.91688, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.8966 - acc: 0.7053 - val_loss: 0.8390 - val_acc: 0.7490\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.91688 to 0.83899, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.8369 - acc: 0.7283 - val_loss: 0.7855 - val_acc: 0.7572\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.83899 to 0.78545, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.7637 - acc: 0.7599 - val_loss: 0.7719 - val_acc: 0.7202\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.78545 to 0.77193, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.7189 - acc: 0.7664 - val_loss: 0.6891 - val_acc: 0.7819\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.77193 to 0.68912, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.6817 - acc: 0.7855 - val_loss: 0.6520 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.68912 to 0.65200, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.6333 - acc: 0.7987 - val_loss: 0.6445 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.65200 to 0.64446, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.5962 - acc: 0.8230 - val_loss: 0.5861 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.64446 to 0.58611, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.5741 - acc: 0.8276 - val_loss: 0.5437 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.58611 to 0.54366, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.5411 - acc: 0.8447 - val_loss: 0.5193 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.54366 to 0.51932, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.5146 - acc: 0.8533 - val_loss: 0.4808 - val_acc: 0.8765\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.51932 to 0.48083, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.4867 - acc: 0.8704 - val_loss: 0.4527 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.48083 to 0.45268, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.4650 - acc: 0.8757 - val_loss: 0.4330 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.45268 to 0.43305, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.4545 - acc: 0.8638 - val_loss: 0.4220 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.43305 to 0.42202, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.4284 - acc: 0.8875 - val_loss: 0.4218 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.42202 to 0.42182, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.4076 - acc: 0.8901 - val_loss: 0.3952 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.42182 to 0.39523, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.3864 - acc: 0.9112 - val_loss: 0.3661 - val_acc: 0.9342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00020: val_loss improved from 0.39523 to 0.36614, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.3698 - acc: 0.9171 - val_loss: 0.3710 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.36614\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.3602 - acc: 0.9099 - val_loss: 0.3390 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.36614 to 0.33897, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.3486 - acc: 0.9151 - val_loss: 0.3332 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.33897 to 0.33318, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.3304 - acc: 0.9276 - val_loss: 0.3237 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.33318 to 0.32372, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.3192 - acc: 0.9322 - val_loss: 0.3115 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.32372 to 0.31146, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.3049 - acc: 0.9414 - val_loss: 0.2861 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.31146 to 0.28610, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2828 - acc: 0.9513 - val_loss: 0.2905 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.28610\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2815 - acc: 0.9480 - val_loss: 0.2892 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.28610\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2682 - acc: 0.9507 - val_loss: 0.2612 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.28610 to 0.26123, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2563 - acc: 0.9586 - val_loss: 0.2443 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.26123 to 0.24430, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2466 - acc: 0.9658 - val_loss: 0.2411 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.24430 to 0.24108, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2403 - acc: 0.9592 - val_loss: 0.2408 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.24108 to 0.24081, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2265 - acc: 0.9645 - val_loss: 0.2195 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.24081 to 0.21952, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2224 - acc: 0.9671 - val_loss: 0.2268 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.21952\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2136 - acc: 0.9684 - val_loss: 0.2048 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.21952 to 0.20481, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2036 - acc: 0.9743 - val_loss: 0.1942 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.20481 to 0.19420, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.1959 - acc: 0.9757 - val_loss: 0.2027 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.19420\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.1902 - acc: 0.9789 - val_loss: 0.1796 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.19420 to 0.17960, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.1819 - acc: 0.9803 - val_loss: 0.2021 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.17960\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.1737 - acc: 0.9809 - val_loss: 0.1731 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.17960 to 0.17307, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.1693 - acc: 0.9809 - val_loss: 0.1719 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.17307 to 0.17195, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.1631 - acc: 0.9868 - val_loss: 0.1714 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.17195 to 0.17138, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1555 - acc: 0.9849 - val_loss: 0.1829 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.17138\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1508 - acc: 0.9914 - val_loss: 0.1552 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.17138 to 0.15520, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1456 - acc: 0.9895 - val_loss: 0.1398 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.15520 to 0.13984, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1401 - acc: 0.9895 - val_loss: 0.1380 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.13984 to 0.13801, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1347 - acc: 0.9901 - val_loss: 0.1476 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.13801\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1299 - acc: 0.9914 - val_loss: 0.1337 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.13801 to 0.13370, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1283 - acc: 0.9888 - val_loss: 0.1314 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.13370 to 0.13140, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1202 - acc: 0.9941 - val_loss: 0.1317 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.13140\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1172 - acc: 0.9914 - val_loss: 0.1287 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.13140 to 0.12868, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1121 - acc: 0.9941 - val_loss: 0.1245 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.12868 to 0.12448, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1083 - acc: 0.9961 - val_loss: 0.1207 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.12448 to 0.12070, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1046 - acc: 0.9961 - val_loss: 0.1205 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.12070 to 0.12052, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1018 - acc: 0.9967 - val_loss: 0.1140 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.12052 to 0.11395, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.0980 - acc: 0.9947 - val_loss: 0.1145 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.11395\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.0927 - acc: 0.9967 - val_loss: 0.1120 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.11395 to 0.11197, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.0916 - acc: 0.9974 - val_loss: 0.1043 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.11197 to 0.10432, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.0883 - acc: 0.9954 - val_loss: 0.1091 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.10432\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.0859 - acc: 0.9961 - val_loss: 0.0991 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.10432 to 0.09915, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.0843 - acc: 0.9954 - val_loss: 0.0862 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.09915 to 0.08618, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.0803 - acc: 0.9954 - val_loss: 0.0904 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.08618\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.0786 - acc: 0.9961 - val_loss: 0.0917 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.08618\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.0742 - acc: 0.9967 - val_loss: 0.0898 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.08618\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.0739 - acc: 0.9961 - val_loss: 0.0912 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.08618\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.0687 - acc: 0.9987 - val_loss: 0.0838 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.08618 to 0.08381, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.0682 - acc: 0.9967 - val_loss: 0.0890 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.08381\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.0666 - acc: 0.9967 - val_loss: 0.0760 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.08381 to 0.07601, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.0627 - acc: 0.9967 - val_loss: 0.0768 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.07601\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.0624 - acc: 0.9974 - val_loss: 0.0708 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.07601 to 0.07081, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.0590 - acc: 0.9974 - val_loss: 0.0697 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.07081 to 0.06972, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.0592 - acc: 0.9967 - val_loss: 0.0677 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.06972 to 0.06767, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.0553 - acc: 0.9974 - val_loss: 0.0706 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.06767\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.0554 - acc: 0.9974 - val_loss: 0.0746 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.06767\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.0549 - acc: 0.9974 - val_loss: 0.0720 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.06767\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.0513 - acc: 0.9980 - val_loss: 0.0623 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.06767 to 0.06234, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.0503 - acc: 0.9974 - val_loss: 0.0624 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.06234\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.0478 - acc: 0.9980 - val_loss: 0.0831 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.06234\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.0473 - acc: 0.9987 - val_loss: 0.0626 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.06234\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0475 - acc: 0.9961 - val_loss: 0.0597 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.06234 to 0.05971, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0457 - acc: 0.9967 - val_loss: 0.0597 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.05971\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0442 - acc: 0.9974 - val_loss: 0.0642 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.05971\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0419 - acc: 0.9987 - val_loss: 0.0666 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.05971\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0408 - acc: 0.9980 - val_loss: 0.0579 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.05971 to 0.05788, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0407 - acc: 0.9967 - val_loss: 0.0534 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.05788 to 0.05344, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0401 - acc: 0.9980 - val_loss: 0.0539 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.05344\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0387 - acc: 0.9974 - val_loss: 0.0572 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.05344\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0374 - acc: 0.9980 - val_loss: 0.0561 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.05344\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0369 - acc: 0.9967 - val_loss: 0.0547 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.05344\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0362 - acc: 0.9980 - val_loss: 0.0531 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.05344 to 0.05309, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0350 - acc: 0.9967 - val_loss: 0.0533 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.05309\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0336 - acc: 0.9974 - val_loss: 0.0508 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.05309 to 0.05079, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0332 - acc: 0.9967 - val_loss: 0.0499 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.05079 to 0.04989, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0336 - acc: 0.9980 - val_loss: 0.0460 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.04989 to 0.04600, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0317 - acc: 0.9974 - val_loss: 0.0545 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.04600\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0304 - acc: 0.9974 - val_loss: 0.0447 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.04600 to 0.04475, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0298 - acc: 0.9980 - val_loss: 0.0502 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.04475\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0294 - acc: 0.9967 - val_loss: 0.0497 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.04475\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0295 - acc: 0.9967 - val_loss: 0.0438 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.04475 to 0.04383, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0282 - acc: 0.9967 - val_loss: 0.0572 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.04383\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0276 - acc: 0.9974 - val_loss: 0.0470 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.04383\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0275 - acc: 0.9967 - val_loss: 0.0462 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.04383\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0271 - acc: 0.9967 - val_loss: 0.0469 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.04383\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0264 - acc: 0.9974 - val_loss: 0.0461 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.04383\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0260 - acc: 0.9974 - val_loss: 0.0497 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.04383\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0248 - acc: 0.9974 - val_loss: 0.0378 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.04383 to 0.03780, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0245 - acc: 0.9980 - val_loss: 0.0415 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.03780\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0240 - acc: 0.9961 - val_loss: 0.0497 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.03780\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0240 - acc: 0.9980 - val_loss: 0.0389 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.03780\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0228 - acc: 0.9974 - val_loss: 0.0387 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.03780\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0221 - acc: 0.9974 - val_loss: 0.0392 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.03780\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0227 - acc: 0.9980 - val_loss: 0.0349 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.03780 to 0.03489, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0217 - acc: 0.9967 - val_loss: 0.0444 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.03489\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0222 - acc: 0.9961 - val_loss: 0.0395 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.03489\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0210 - acc: 0.9967 - val_loss: 0.0440 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.03489\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0206 - acc: 0.9980 - val_loss: 0.0348 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.03489 to 0.03482, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0206 - acc: 0.9967 - val_loss: 0.0425 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.03482\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0196 - acc: 0.9967 - val_loss: 0.0423 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.03482\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0201 - acc: 0.9974 - val_loss: 0.0381 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.03482\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0200 - acc: 0.9967 - val_loss: 0.0361 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.03482\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0197 - acc: 0.9967 - val_loss: 0.0353 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.03482\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0184 - acc: 0.9980 - val_loss: 0.0382 - val_acc: 0.9959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00122: val_loss did not improve from 0.03482\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0192 - acc: 0.9967 - val_loss: 0.0355 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.03482\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0177 - acc: 0.9980 - val_loss: 0.0448 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.03482\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0189 - acc: 0.9980 - val_loss: 0.0355 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.03482\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0182 - acc: 0.9974 - val_loss: 0.0369 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.03482\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0183 - acc: 0.9967 - val_loss: 0.0382 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.03482\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0174 - acc: 0.9967 - val_loss: 0.0340 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.03482 to 0.03405, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0171 - acc: 0.9967 - val_loss: 0.0379 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.03405\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0166 - acc: 0.9974 - val_loss: 0.0376 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.03405\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0168 - acc: 0.9961 - val_loss: 0.0381 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.03405\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0169 - acc: 0.9974 - val_loss: 0.0379 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.03405\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0162 - acc: 0.9974 - val_loss: 0.0330 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.03405 to 0.03302, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0161 - acc: 0.9967 - val_loss: 0.0299 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.03302 to 0.02991, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0158 - acc: 0.9974 - val_loss: 0.0331 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.02991\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0148 - acc: 0.9974 - val_loss: 0.0363 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.02991\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0148 - acc: 0.9974 - val_loss: 0.0354 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.02991\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0153 - acc: 0.9961 - val_loss: 0.0305 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.02991\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0151 - acc: 0.9967 - val_loss: 0.0319 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.02991\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0150 - acc: 0.9967 - val_loss: 0.0302 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.02991\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0151 - acc: 0.9974 - val_loss: 0.0340 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.02991\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0145 - acc: 0.9967 - val_loss: 0.0368 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.02991\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0138 - acc: 0.9980 - val_loss: 0.0371 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.02991\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0135 - acc: 0.9980 - val_loss: 0.0300 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.02991\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0144 - acc: 0.9967 - val_loss: 0.0302 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.02991\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0138 - acc: 0.9974 - val_loss: 0.0321 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.02991\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0139 - acc: 0.9974 - val_loss: 0.0356 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.02991\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0133 - acc: 0.9974 - val_loss: 0.0318 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.02991\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0131 - acc: 0.9980 - val_loss: 0.0324 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.02991\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0133 - acc: 0.9974 - val_loss: 0.0313 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.02991\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0132 - acc: 0.9974 - val_loss: 0.0346 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.02991\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0126 - acc: 0.9974 - val_loss: 0.0297 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.02991 to 0.02965, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0133 - acc: 0.9961 - val_loss: 0.0302 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.02965\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0123 - acc: 0.9961 - val_loss: 0.0338 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.02965\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.0122 - acc: 0.9980 - val_loss: 0.0314 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.02965\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.0122 - acc: 0.9967 - val_loss: 0.0285 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.02965 to 0.02845, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0123 - acc: 0.9967 - val_loss: 0.0343 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.02845\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.0122 - acc: 0.9967 - val_loss: 0.0326 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.02845\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.0126 - acc: 0.9980 - val_loss: 0.0323 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.02845\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.0119 - acc: 0.9961 - val_loss: 0.0301 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.02845\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.0121 - acc: 0.9974 - val_loss: 0.0302 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.02845\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.0117 - acc: 0.9974 - val_loss: 0.0291 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.02845\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.0114 - acc: 0.9980 - val_loss: 0.0339 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.02845\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.0112 - acc: 0.9974 - val_loss: 0.0303 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.02845\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.0117 - acc: 0.9967 - val_loss: 0.0366 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.02845\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.0118 - acc: 0.9961 - val_loss: 0.0316 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.02845\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.0110 - acc: 0.9967 - val_loss: 0.0352 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.02845\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.0112 - acc: 0.9974 - val_loss: 0.0322 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.02845\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.0108 - acc: 0.9987 - val_loss: 0.0337 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.02845\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.0111 - acc: 0.9967 - val_loss: 0.0310 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.02845\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.0104 - acc: 0.9974 - val_loss: 0.0291 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.02845\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.0109 - acc: 0.9980 - val_loss: 0.0273 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00172: val_loss improved from 0.02845 to 0.02729, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.0109 - acc: 0.9967 - val_loss: 0.0261 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.02729 to 0.02609, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.0104 - acc: 0.9974 - val_loss: 0.0300 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.02609\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.0102 - acc: 0.9980 - val_loss: 0.0306 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.02609\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.0102 - acc: 0.9967 - val_loss: 0.0326 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.02609\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.0101 - acc: 0.9967 - val_loss: 0.0285 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.02609\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.0102 - acc: 0.9967 - val_loss: 0.0313 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.02609\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.0105 - acc: 0.9967 - val_loss: 0.0296 - val_acc: 0.9959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00179: val_loss did not improve from 0.02609\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.0103 - acc: 0.9967 - val_loss: 0.0288 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.02609\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.0102 - acc: 0.9961 - val_loss: 0.0260 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00181: val_loss improved from 0.02609 to 0.02597, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.0099 - acc: 0.9967 - val_loss: 0.0261 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.02597\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.0101 - acc: 0.9967 - val_loss: 0.0266 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.02597\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.0100 - acc: 0.9967 - val_loss: 0.0272 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.02597\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.0093 - acc: 0.9980 - val_loss: 0.0265 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.02597\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.0096 - acc: 0.9974 - val_loss: 0.0272 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.02597\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.0101 - acc: 0.9961 - val_loss: 0.0235 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.02597 to 0.02350, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.0094 - acc: 0.9987 - val_loss: 0.0294 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.02350\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.0094 - acc: 0.9980 - val_loss: 0.0247 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.02350\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.0095 - acc: 0.9974 - val_loss: 0.0241 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.02350\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.0093 - acc: 0.9980 - val_loss: 0.0251 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.02350\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.0089 - acc: 0.9980 - val_loss: 0.0328 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.02350\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.0093 - acc: 0.9974 - val_loss: 0.0277 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.02350\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.0097 - acc: 0.9967 - val_loss: 0.0259 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.02350\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.0092 - acc: 0.9967 - val_loss: 0.0269 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.02350\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.0093 - acc: 0.9974 - val_loss: 0.0272 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.02350\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.0091 - acc: 0.9961 - val_loss: 0.0278 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.02350\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.0090 - acc: 0.9974 - val_loss: 0.0242 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.02350\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.0095 - acc: 0.9974 - val_loss: 0.0259 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.02350\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.0092 - acc: 0.9974 - val_loss: 0.0262 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.02350\n",
      "batch_size=40   optimizer=Adadelta\n",
      "Test accuracy: 67.9666%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 2.0455 - acc: 0.2776 - val_loss: 1.6058 - val_acc: 0.4568\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.60578, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.5213 - acc: 0.4691 - val_loss: 1.3378 - val_acc: 0.5679\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.60578 to 1.33780, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 1.2778 - acc: 0.5737 - val_loss: 1.2178 - val_acc: 0.5679\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.33780 to 1.21778, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 1.1447 - acc: 0.6151 - val_loss: 1.0948 - val_acc: 0.6091\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.21778 to 1.09478, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 1.0380 - acc: 0.6618 - val_loss: 1.0038 - val_acc: 0.6708\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.09478 to 1.00385, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.9646 - acc: 0.6849 - val_loss: 0.9544 - val_acc: 0.6749\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.00385 to 0.95436, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.9062 - acc: 0.7092 - val_loss: 0.8905 - val_acc: 0.7078\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.95436 to 0.89047, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.8575 - acc: 0.7230 - val_loss: 0.8505 - val_acc: 0.7407\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.89047 to 0.85054, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.8135 - acc: 0.7382 - val_loss: 0.8559 - val_acc: 0.7078\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.85054\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.7736 - acc: 0.7487 - val_loss: 0.7546 - val_acc: 0.7572\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.85054 to 0.75460, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.7349 - acc: 0.7645 - val_loss: 0.7194 - val_acc: 0.7860\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.75460 to 0.71938, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.6966 - acc: 0.7842 - val_loss: 0.6888 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.71938 to 0.68883, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.6739 - acc: 0.7895 - val_loss: 0.6973 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.68883\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.6515 - acc: 0.7967 - val_loss: 0.6419 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.68883 to 0.64189, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.6241 - acc: 0.8118 - val_loss: 0.6208 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.64189 to 0.62075, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.6074 - acc: 0.8204 - val_loss: 0.6457 - val_acc: 0.7737\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.62075\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.5821 - acc: 0.8250 - val_loss: 0.5748 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.62075 to 0.57479, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.5597 - acc: 0.8349 - val_loss: 0.5589 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.57479 to 0.55889, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.5294 - acc: 0.8539 - val_loss: 0.5383 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.55889 to 0.53830, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.5105 - acc: 0.8618 - val_loss: 0.5068 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.53830 to 0.50680, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.4980 - acc: 0.8651 - val_loss: 0.5014 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.50680 to 0.50138, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.4843 - acc: 0.8730 - val_loss: 0.5043 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.50138\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.4718 - acc: 0.8743 - val_loss: 0.4968 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.50138 to 0.49679, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.4576 - acc: 0.8776 - val_loss: 0.4590 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.49679 to 0.45898, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.4382 - acc: 0.8836 - val_loss: 0.4454 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.45898 to 0.44538, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.4205 - acc: 0.8987 - val_loss: 0.4421 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.44538 to 0.44213, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.4132 - acc: 0.8934 - val_loss: 0.4281 - val_acc: 0.8765\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.44213 to 0.42810, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.3973 - acc: 0.9112 - val_loss: 0.4154 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.42810 to 0.41542, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.3827 - acc: 0.9086 - val_loss: 0.3783 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.41542 to 0.37825, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.3725 - acc: 0.9171 - val_loss: 0.3762 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.37825 to 0.37623, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.3603 - acc: 0.9250 - val_loss: 0.3819 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.37623\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.3468 - acc: 0.9316 - val_loss: 0.3701 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.37623 to 0.37008, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.3432 - acc: 0.9224 - val_loss: 0.3452 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.37008 to 0.34521, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.3357 - acc: 0.9322 - val_loss: 0.3621 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.34521\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.3267 - acc: 0.9322 - val_loss: 0.3143 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.34521 to 0.31428, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.3117 - acc: 0.9454 - val_loss: 0.3170 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.31428\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.3017 - acc: 0.9441 - val_loss: 0.3209 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.31428\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2968 - acc: 0.9454 - val_loss: 0.3068 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.31428 to 0.30680, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.2841 - acc: 0.9507 - val_loss: 0.2934 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.30680 to 0.29336, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.2760 - acc: 0.9566 - val_loss: 0.2824 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.29336 to 0.28244, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.2670 - acc: 0.9572 - val_loss: 0.2750 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.28244 to 0.27503, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.2586 - acc: 0.9625 - val_loss: 0.2643 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.27503 to 0.26429, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.2522 - acc: 0.9618 - val_loss: 0.2655 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.26429\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.2449 - acc: 0.9645 - val_loss: 0.2503 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.26429 to 0.25026, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.2436 - acc: 0.9651 - val_loss: 0.2479 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.25026 to 0.24786, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.2301 - acc: 0.9711 - val_loss: 0.2395 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.24786 to 0.23948, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.2267 - acc: 0.9711 - val_loss: 0.2406 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.23948\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.2224 - acc: 0.9684 - val_loss: 0.2204 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.23948 to 0.22039, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.2142 - acc: 0.9717 - val_loss: 0.2581 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.22039\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.2095 - acc: 0.9757 - val_loss: 0.2144 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.22039 to 0.21443, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.2063 - acc: 0.9750 - val_loss: 0.2209 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.21443\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1977 - acc: 0.9796 - val_loss: 0.2065 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.21443 to 0.20649, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1891 - acc: 0.9796 - val_loss: 0.2034 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.20649 to 0.20340, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1866 - acc: 0.9829 - val_loss: 0.2051 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.20340\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1804 - acc: 0.9829 - val_loss: 0.2089 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.20340\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1782 - acc: 0.9809 - val_loss: 0.1952 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.20340 to 0.19515, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1738 - acc: 0.9776 - val_loss: 0.1844 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.19515 to 0.18439, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1646 - acc: 0.9888 - val_loss: 0.1918 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.18439\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1639 - acc: 0.9842 - val_loss: 0.1854 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.18439\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1595 - acc: 0.9862 - val_loss: 0.1660 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.18439 to 0.16602, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1568 - acc: 0.9875 - val_loss: 0.1749 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.16602\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1502 - acc: 0.9882 - val_loss: 0.1835 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.16602\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1498 - acc: 0.9875 - val_loss: 0.1638 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.16602 to 0.16384, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1394 - acc: 0.9895 - val_loss: 0.1573 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.16384 to 0.15734, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1375 - acc: 0.9934 - val_loss: 0.1660 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.15734\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1347 - acc: 0.9928 - val_loss: 0.1673 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.15734\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1294 - acc: 0.9947 - val_loss: 0.1473 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.15734 to 0.14732, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1280 - acc: 0.9928 - val_loss: 0.1581 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.14732\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1270 - acc: 0.9901 - val_loss: 0.1471 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.14732 to 0.14713, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1222 - acc: 0.9921 - val_loss: 0.1454 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.14713 to 0.14536, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1194 - acc: 0.9947 - val_loss: 0.1298 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.14536 to 0.12975, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1177 - acc: 0.9908 - val_loss: 0.1329 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.12975\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1112 - acc: 0.9954 - val_loss: 0.1376 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.12975\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1113 - acc: 0.9941 - val_loss: 0.1394 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.12975\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1075 - acc: 0.9947 - val_loss: 0.1293 - val_acc: 0.9918\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00075: val_loss improved from 0.12975 to 0.12926, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1060 - acc: 0.9941 - val_loss: 0.1231 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.12926 to 0.12311, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1038 - acc: 0.9961 - val_loss: 0.1208 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.12311 to 0.12078, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.0998 - acc: 0.9967 - val_loss: 0.1159 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.12078 to 0.11587, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.0976 - acc: 0.9967 - val_loss: 0.1325 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.11587\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0961 - acc: 0.9954 - val_loss: 0.1254 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.11587\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0938 - acc: 0.9967 - val_loss: 0.1048 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.11587 to 0.10483, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0892 - acc: 0.9961 - val_loss: 0.1027 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.10483 to 0.10268, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0903 - acc: 0.9980 - val_loss: 0.1110 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.10268\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0870 - acc: 0.9974 - val_loss: 0.1163 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.10268\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0854 - acc: 0.9961 - val_loss: 0.1146 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.10268\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0838 - acc: 0.9967 - val_loss: 0.1109 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.10268\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0820 - acc: 0.9961 - val_loss: 0.1156 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.10268\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0793 - acc: 0.9974 - val_loss: 0.0966 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.10268 to 0.09657, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0771 - acc: 0.9954 - val_loss: 0.1012 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.09657\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0746 - acc: 0.9961 - val_loss: 0.1058 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.09657\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0737 - acc: 0.9967 - val_loss: 0.0951 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.09657 to 0.09510, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0715 - acc: 0.9967 - val_loss: 0.0862 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.09510 to 0.08620, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0707 - acc: 0.9967 - val_loss: 0.0865 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.08620\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0694 - acc: 0.9974 - val_loss: 0.0845 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.08620 to 0.08454, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0673 - acc: 0.9980 - val_loss: 0.0874 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.08454\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0654 - acc: 0.9961 - val_loss: 0.0953 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.08454\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0645 - acc: 0.9980 - val_loss: 0.0889 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.08454\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0631 - acc: 0.9961 - val_loss: 0.0883 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.08454\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0637 - acc: 0.9961 - val_loss: 0.0823 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.08454 to 0.08231, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0606 - acc: 0.9967 - val_loss: 0.0875 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.08231\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0593 - acc: 0.9974 - val_loss: 0.0842 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.08231\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0593 - acc: 0.9967 - val_loss: 0.0887 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.08231\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0608 - acc: 0.9961 - val_loss: 0.0749 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.08231 to 0.07492, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0572 - acc: 0.9980 - val_loss: 0.0814 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.07492\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0542 - acc: 0.9961 - val_loss: 0.0724 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.07492 to 0.07245, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0524 - acc: 0.9967 - val_loss: 0.0719 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.07245 to 0.07195, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0532 - acc: 0.9961 - val_loss: 0.0759 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.07195\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0513 - acc: 0.9974 - val_loss: 0.0771 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.07195\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0497 - acc: 0.9980 - val_loss: 0.0770 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.07195\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0497 - acc: 0.9974 - val_loss: 0.0654 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.07195 to 0.06544, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0486 - acc: 0.9967 - val_loss: 0.0719 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.06544\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0509 - acc: 0.9974 - val_loss: 0.0680 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.06544\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0466 - acc: 0.9967 - val_loss: 0.0660 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.06544\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0447 - acc: 0.9967 - val_loss: 0.0713 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.06544\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0451 - acc: 0.9967 - val_loss: 0.0664 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.06544\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0442 - acc: 0.9974 - val_loss: 0.0647 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.06544 to 0.06468, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0435 - acc: 0.9980 - val_loss: 0.0639 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.06468 to 0.06391, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0431 - acc: 0.9974 - val_loss: 0.0599 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.06391 to 0.05992, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0423 - acc: 0.9974 - val_loss: 0.0614 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.05992\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0407 - acc: 0.9980 - val_loss: 0.0665 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.05992\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0406 - acc: 0.9980 - val_loss: 0.0684 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.05992\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0407 - acc: 0.9967 - val_loss: 0.0713 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.05992\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0385 - acc: 0.9980 - val_loss: 0.0525 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.05992 to 0.05248, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0390 - acc: 0.9967 - val_loss: 0.0594 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.05248\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0378 - acc: 0.9967 - val_loss: 0.0567 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.05248\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0375 - acc: 0.9980 - val_loss: 0.0649 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.05248\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0368 - acc: 0.9967 - val_loss: 0.0691 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.05248\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0363 - acc: 0.9974 - val_loss: 0.0585 - val_acc: 0.9959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00128: val_loss did not improve from 0.05248\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0354 - acc: 0.9980 - val_loss: 0.0542 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.05248\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0349 - acc: 0.9967 - val_loss: 0.0600 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.05248\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0344 - acc: 0.9974 - val_loss: 0.0624 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.05248\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0332 - acc: 0.9974 - val_loss: 0.0579 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.05248\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0348 - acc: 0.9961 - val_loss: 0.0535 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.05248\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0327 - acc: 0.9980 - val_loss: 0.0515 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.05248 to 0.05148, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0322 - acc: 0.9974 - val_loss: 0.0541 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.05148\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0315 - acc: 0.9987 - val_loss: 0.0497 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.05148 to 0.04966, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0308 - acc: 0.9980 - val_loss: 0.0561 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.04966\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0308 - acc: 0.9980 - val_loss: 0.0564 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.04966\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0303 - acc: 0.9974 - val_loss: 0.0584 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.04966\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0295 - acc: 0.9967 - val_loss: 0.0547 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.04966\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0302 - acc: 0.9974 - val_loss: 0.0507 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.04966\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0291 - acc: 0.9961 - val_loss: 0.0550 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.04966\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0290 - acc: 0.9961 - val_loss: 0.0525 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.04966\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0280 - acc: 0.9967 - val_loss: 0.0482 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.04966 to 0.04825, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0273 - acc: 0.9980 - val_loss: 0.0505 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.04825\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0275 - acc: 0.9974 - val_loss: 0.0508 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.04825\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0270 - acc: 0.9967 - val_loss: 0.0497 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.04825\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0257 - acc: 0.9980 - val_loss: 0.0453 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.04825 to 0.04530, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0263 - acc: 0.9974 - val_loss: 0.0504 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.04530\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0261 - acc: 0.9967 - val_loss: 0.0449 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.04530 to 0.04494, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0256 - acc: 0.9974 - val_loss: 0.0434 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.04494 to 0.04341, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0253 - acc: 0.9974 - val_loss: 0.0472 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.04341\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0246 - acc: 0.9974 - val_loss: 0.0477 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.04341\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0253 - acc: 0.9974 - val_loss: 0.0427 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.04341 to 0.04270, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.0246 - acc: 0.9974 - val_loss: 0.0420 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.04270 to 0.04197, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.0247 - acc: 0.9961 - val_loss: 0.0449 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.04197\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0239 - acc: 0.9980 - val_loss: 0.0439 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.04197\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.0225 - acc: 0.9987 - val_loss: 0.0422 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.04197\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.0225 - acc: 0.9974 - val_loss: 0.0447 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.04197\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.0225 - acc: 0.9980 - val_loss: 0.0414 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.04197 to 0.04145, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.0220 - acc: 0.9974 - val_loss: 0.0440 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.04145\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.0221 - acc: 0.9974 - val_loss: 0.0377 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.04145 to 0.03768, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.0216 - acc: 0.9974 - val_loss: 0.0413 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.03768\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.0224 - acc: 0.9980 - val_loss: 0.0469 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.03768\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.0213 - acc: 0.9974 - val_loss: 0.0421 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.03768\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.0209 - acc: 0.9974 - val_loss: 0.0405 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.03768\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.0205 - acc: 0.9980 - val_loss: 0.0374 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.03768 to 0.03742, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.0208 - acc: 0.9974 - val_loss: 0.0414 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.03742\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.0204 - acc: 0.9967 - val_loss: 0.0471 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.03742\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.0202 - acc: 0.9980 - val_loss: 0.0449 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.03742\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.0201 - acc: 0.9967 - val_loss: 0.0399 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.03742\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.0204 - acc: 0.9967 - val_loss: 0.0413 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.03742\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.0193 - acc: 0.9974 - val_loss: 0.0390 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.03742\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.0192 - acc: 0.9974 - val_loss: 0.0419 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.03742\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.0198 - acc: 0.9967 - val_loss: 0.0432 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.03742\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.0188 - acc: 0.9974 - val_loss: 0.0370 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00176: val_loss improved from 0.03742 to 0.03697, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.0187 - acc: 0.9967 - val_loss: 0.0427 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.03697\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.0182 - acc: 0.9967 - val_loss: 0.0401 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.03697\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.0188 - acc: 0.9967 - val_loss: 0.0435 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.03697\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.0185 - acc: 0.9974 - val_loss: 0.0382 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.03697\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.0181 - acc: 0.9961 - val_loss: 0.0386 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.03697\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.0179 - acc: 0.9967 - val_loss: 0.0380 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.03697\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.0177 - acc: 0.9980 - val_loss: 0.0375 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.03697\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.0174 - acc: 0.9967 - val_loss: 0.0408 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.03697\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.0177 - acc: 0.9980 - val_loss: 0.0385 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.03697\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.0170 - acc: 0.9967 - val_loss: 0.0379 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.03697\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.0173 - acc: 0.9967 - val_loss: 0.0415 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.03697\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.0170 - acc: 0.9974 - val_loss: 0.0349 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00188: val_loss improved from 0.03697 to 0.03485, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.0167 - acc: 0.9974 - val_loss: 0.0444 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.03485\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.0168 - acc: 0.9974 - val_loss: 0.0371 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.03485\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.0162 - acc: 0.9980 - val_loss: 0.0380 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.03485\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.0157 - acc: 0.9980 - val_loss: 0.0391 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.03485\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.0168 - acc: 0.9974 - val_loss: 0.0368 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.03485\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.0156 - acc: 0.9967 - val_loss: 0.0381 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.03485\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.0159 - acc: 0.9980 - val_loss: 0.0355 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.03485\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.0150 - acc: 0.9980 - val_loss: 0.0393 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.03485\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.0161 - acc: 0.9967 - val_loss: 0.0407 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.03485\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.0153 - acc: 0.9974 - val_loss: 0.0336 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.03485 to 0.03363, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.0152 - acc: 0.9980 - val_loss: 0.0340 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.03363\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.0149 - acc: 0.9980 - val_loss: 0.0338 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.03363\n",
      "batch_size=80   optimizer=Adadelta\n",
      "Test accuracy: 67.6880%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_38 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 2.1038 - acc: 0.2224 - val_loss: 1.7976 - val_acc: 0.3498\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.79757, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.6051 - acc: 0.4507 - val_loss: 1.4884 - val_acc: 0.4691\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.79757 to 1.48844, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 1.3644 - acc: 0.5487 - val_loss: 1.3438 - val_acc: 0.5103\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.48844 to 1.34376, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 1.2342 - acc: 0.5921 - val_loss: 1.2212 - val_acc: 0.5761\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.34376 to 1.22119, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 1.1321 - acc: 0.6349 - val_loss: 1.1148 - val_acc: 0.6049\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.22119 to 1.11475, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 1.0508 - acc: 0.6664 - val_loss: 1.0547 - val_acc: 0.6214\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.11475 to 1.05474, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.9791 - acc: 0.6993 - val_loss: 0.9817 - val_acc: 0.6955\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.05474 to 0.98171, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.9280 - acc: 0.7145 - val_loss: 0.9818 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.98171\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.8922 - acc: 0.7250 - val_loss: 0.9244 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.98171 to 0.92435, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.8488 - acc: 0.7401 - val_loss: 0.8778 - val_acc: 0.7160\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.92435 to 0.87781, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.8093 - acc: 0.7566 - val_loss: 0.8491 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.87781 to 0.84908, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.7878 - acc: 0.7533 - val_loss: 0.7952 - val_acc: 0.7572\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.84908 to 0.79518, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.7553 - acc: 0.7691 - val_loss: 0.7871 - val_acc: 0.7490\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.79518 to 0.78711, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.7338 - acc: 0.7776 - val_loss: 0.7487 - val_acc: 0.7572\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.78711 to 0.74875, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.7045 - acc: 0.7855 - val_loss: 0.7118 - val_acc: 0.7695\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.74875 to 0.71176, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.6754 - acc: 0.7974 - val_loss: 0.6983 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.71176 to 0.69826, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.6506 - acc: 0.8145 - val_loss: 0.6554 - val_acc: 0.7901\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.69826 to 0.65537, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.6357 - acc: 0.8112 - val_loss: 0.6463 - val_acc: 0.7901\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.65537 to 0.64630, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.6093 - acc: 0.8217 - val_loss: 0.6383 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.64630 to 0.63827, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.5982 - acc: 0.8316 - val_loss: 0.6278 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.63827 to 0.62779, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.5782 - acc: 0.8283 - val_loss: 0.6016 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.62779 to 0.60161, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.5631 - acc: 0.8441 - val_loss: 0.6171 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.60161\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.5446 - acc: 0.8526 - val_loss: 0.5789 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.60161 to 0.57890, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.5224 - acc: 0.8533 - val_loss: 0.5563 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.57890 to 0.55635, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.5133 - acc: 0.8474 - val_loss: 0.5538 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.55635 to 0.55381, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.4997 - acc: 0.8697 - val_loss: 0.5137 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.55381 to 0.51375, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.4796 - acc: 0.8770 - val_loss: 0.5050 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.51375 to 0.50495, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.4731 - acc: 0.8678 - val_loss: 0.4843 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.50495 to 0.48433, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.4533 - acc: 0.8789 - val_loss: 0.4910 - val_acc: 0.8930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00029: val_loss did not improve from 0.48433\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.4401 - acc: 0.8829 - val_loss: 0.4691 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.48433 to 0.46911, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.4398 - acc: 0.8842 - val_loss: 0.4507 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.46911 to 0.45070, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.4173 - acc: 0.9000 - val_loss: 0.4721 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.45070\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.4105 - acc: 0.8941 - val_loss: 0.4387 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.45070 to 0.43869, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.4066 - acc: 0.8987 - val_loss: 0.4171 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.43869 to 0.41705, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.3879 - acc: 0.9072 - val_loss: 0.4007 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.41705 to 0.40067, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.3833 - acc: 0.9053 - val_loss: 0.4096 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.40067\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.3650 - acc: 0.9125 - val_loss: 0.3784 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.40067 to 0.37835, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.3581 - acc: 0.9158 - val_loss: 0.3982 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.37835\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.3539 - acc: 0.9211 - val_loss: 0.3781 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.37835 to 0.37813, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.3452 - acc: 0.9224 - val_loss: 0.3618 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.37813 to 0.36182, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.3348 - acc: 0.9296 - val_loss: 0.3532 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.36182 to 0.35319, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.3278 - acc: 0.9309 - val_loss: 0.3638 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.35319\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.3158 - acc: 0.9395 - val_loss: 0.3370 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.35319 to 0.33704, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.3141 - acc: 0.9414 - val_loss: 0.3373 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.33704\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.3078 - acc: 0.9461 - val_loss: 0.3439 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.33704\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.3000 - acc: 0.9461 - val_loss: 0.3369 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.33704 to 0.33686, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.2865 - acc: 0.9553 - val_loss: 0.3346 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.33686 to 0.33456, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.2806 - acc: 0.9546 - val_loss: 0.3235 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.33456 to 0.32352, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.2762 - acc: 0.9566 - val_loss: 0.3118 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.32352 to 0.31184, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.2660 - acc: 0.9625 - val_loss: 0.2987 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.31184 to 0.29874, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.2641 - acc: 0.9572 - val_loss: 0.2847 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.29874 to 0.28468, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.2575 - acc: 0.9664 - val_loss: 0.2781 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.28468 to 0.27806, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.2508 - acc: 0.9632 - val_loss: 0.2962 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.27806\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.2442 - acc: 0.9697 - val_loss: 0.2618 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.27806 to 0.26177, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.2419 - acc: 0.9704 - val_loss: 0.2625 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.26177\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.2382 - acc: 0.9645 - val_loss: 0.2419 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.26177 to 0.24194, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.2297 - acc: 0.9704 - val_loss: 0.2616 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.24194\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.2211 - acc: 0.9750 - val_loss: 0.2368 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.24194 to 0.23676, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.2181 - acc: 0.9704 - val_loss: 0.2600 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.23676\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.2172 - acc: 0.9743 - val_loss: 0.2326 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.23676 to 0.23264, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.2123 - acc: 0.9763 - val_loss: 0.2362 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.23264\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.2077 - acc: 0.9757 - val_loss: 0.2154 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.23264 to 0.21543, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1966 - acc: 0.9783 - val_loss: 0.2060 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.21543 to 0.20599, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1984 - acc: 0.9796 - val_loss: 0.2051 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.20599 to 0.20514, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1852 - acc: 0.9829 - val_loss: 0.2111 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.20514\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1830 - acc: 0.9796 - val_loss: 0.2259 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.20514\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1856 - acc: 0.9829 - val_loss: 0.1892 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.20514 to 0.18920, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1753 - acc: 0.9822 - val_loss: 0.2094 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.18920\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1810 - acc: 0.9855 - val_loss: 0.1961 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.18920\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1685 - acc: 0.9855 - val_loss: 0.1906 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.18920\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1676 - acc: 0.9888 - val_loss: 0.1851 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.18920 to 0.18505, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1666 - acc: 0.9842 - val_loss: 0.1928 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.18505\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1605 - acc: 0.9908 - val_loss: 0.1902 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.18505\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1581 - acc: 0.9895 - val_loss: 0.1803 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.18505 to 0.18034, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1557 - acc: 0.9868 - val_loss: 0.1834 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.18034\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1509 - acc: 0.9882 - val_loss: 0.1774 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.18034 to 0.17742, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1471 - acc: 0.9895 - val_loss: 0.1681 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.17742 to 0.16810, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.1424 - acc: 0.9914 - val_loss: 0.1608 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.16810 to 0.16078, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.1382 - acc: 0.9941 - val_loss: 0.1860 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.16078\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.1398 - acc: 0.9908 - val_loss: 0.1646 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.16078\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.1360 - acc: 0.9901 - val_loss: 0.1654 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.16078\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.1347 - acc: 0.9914 - val_loss: 0.1571 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.16078 to 0.15707, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.1308 - acc: 0.9914 - val_loss: 0.1497 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.15707 to 0.14972, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.1250 - acc: 0.9961 - val_loss: 0.1443 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.14972 to 0.14429, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.1227 - acc: 0.9934 - val_loss: 0.1419 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.14429 to 0.14187, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.1272 - acc: 0.9921 - val_loss: 0.1511 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.14187\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.1222 - acc: 0.9954 - val_loss: 0.1433 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.14187\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.1197 - acc: 0.9934 - val_loss: 0.1294 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.14187 to 0.12938, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.1122 - acc: 0.9967 - val_loss: 0.1308 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.12938\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.1144 - acc: 0.9928 - val_loss: 0.1365 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.12938\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.1111 - acc: 0.9941 - val_loss: 0.1476 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.12938\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.1095 - acc: 0.9914 - val_loss: 0.1289 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.12938 to 0.12887, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.1047 - acc: 0.9961 - val_loss: 0.1185 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.12887 to 0.11851, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.1044 - acc: 0.9967 - val_loss: 0.1269 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.11851\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.1023 - acc: 0.9954 - val_loss: 0.1184 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.11851 to 0.11839, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.1004 - acc: 0.9974 - val_loss: 0.1199 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.11839\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0978 - acc: 0.9961 - val_loss: 0.1220 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.11839\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0966 - acc: 0.9974 - val_loss: 0.1283 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.11839\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0974 - acc: 0.9954 - val_loss: 0.1143 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.11839 to 0.11435, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0946 - acc: 0.9947 - val_loss: 0.1235 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.11435\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0907 - acc: 0.9961 - val_loss: 0.1039 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.11435 to 0.10385, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0907 - acc: 0.9954 - val_loss: 0.1065 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.10385\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0854 - acc: 0.9974 - val_loss: 0.1069 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.10385\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0876 - acc: 0.9980 - val_loss: 0.1042 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.10385\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0833 - acc: 0.9967 - val_loss: 0.1047 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.10385\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0819 - acc: 0.9961 - val_loss: 0.1093 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.10385\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0823 - acc: 0.9980 - val_loss: 0.0971 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.10385 to 0.09710, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0817 - acc: 0.9967 - val_loss: 0.0999 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.09710\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0784 - acc: 0.9967 - val_loss: 0.0990 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.09710\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0823 - acc: 0.9954 - val_loss: 0.0959 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.09710 to 0.09592, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0763 - acc: 0.9980 - val_loss: 0.0988 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.09592\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0762 - acc: 0.9974 - val_loss: 0.1007 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.09592\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0721 - acc: 0.9974 - val_loss: 0.1077 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.09592\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0745 - acc: 0.9967 - val_loss: 0.0990 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.09592\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0704 - acc: 0.9974 - val_loss: 0.0882 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.09592 to 0.08824, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0696 - acc: 0.9974 - val_loss: 0.1111 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.08824\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0692 - acc: 0.9974 - val_loss: 0.0955 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.08824\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0690 - acc: 0.9967 - val_loss: 0.0925 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.08824\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0646 - acc: 0.9974 - val_loss: 0.0865 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.08824 to 0.08650, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0648 - acc: 0.9987 - val_loss: 0.0821 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.08650 to 0.08212, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0638 - acc: 0.9980 - val_loss: 0.0747 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.08212 to 0.07469, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0626 - acc: 0.9974 - val_loss: 0.0863 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.07469\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0626 - acc: 0.9980 - val_loss: 0.0836 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.07469\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0620 - acc: 0.9980 - val_loss: 0.0865 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.07469\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0590 - acc: 0.9961 - val_loss: 0.0881 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.07469\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0599 - acc: 0.9967 - val_loss: 0.0888 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.07469\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0588 - acc: 0.9974 - val_loss: 0.0844 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.07469\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0578 - acc: 0.9961 - val_loss: 0.0807 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.07469\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0562 - acc: 0.9980 - val_loss: 0.0867 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.07469\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0545 - acc: 0.9967 - val_loss: 0.0743 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.07469 to 0.07433, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0538 - acc: 0.9961 - val_loss: 0.0788 - val_acc: 0.9918\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00131: val_loss did not improve from 0.07433\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0528 - acc: 0.9967 - val_loss: 0.0784 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.07433\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0526 - acc: 0.9974 - val_loss: 0.0796 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.07433\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0540 - acc: 0.9954 - val_loss: 0.0781 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.07433\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0509 - acc: 0.9980 - val_loss: 0.0715 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.07433 to 0.07148, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0508 - acc: 0.9967 - val_loss: 0.0756 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.07148\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0492 - acc: 0.9980 - val_loss: 0.0780 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.07148\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0493 - acc: 0.9967 - val_loss: 0.0663 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.07148 to 0.06630, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0510 - acc: 0.9974 - val_loss: 0.0836 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.06630\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0462 - acc: 0.9967 - val_loss: 0.0664 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.06630\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0469 - acc: 0.9967 - val_loss: 0.0690 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.06630\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0459 - acc: 0.9974 - val_loss: 0.0723 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.06630\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0451 - acc: 0.9961 - val_loss: 0.0625 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.06630 to 0.06247, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0456 - acc: 0.9961 - val_loss: 0.0679 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.06247\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0448 - acc: 0.9980 - val_loss: 0.0716 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.06247\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0426 - acc: 0.9980 - val_loss: 0.0669 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.06247\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0413 - acc: 0.9974 - val_loss: 0.0664 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.06247\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0426 - acc: 0.9967 - val_loss: 0.0661 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.06247\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0425 - acc: 0.9967 - val_loss: 0.0565 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.06247 to 0.05645, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0403 - acc: 0.9987 - val_loss: 0.0638 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.05645\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0417 - acc: 0.9967 - val_loss: 0.0584 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.05645\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0401 - acc: 0.9974 - val_loss: 0.0599 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.05645\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0397 - acc: 0.9961 - val_loss: 0.0588 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.05645\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0396 - acc: 0.9980 - val_loss: 0.0621 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.05645\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.0382 - acc: 0.9967 - val_loss: 0.0642 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.05645\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.0374 - acc: 0.9980 - val_loss: 0.0553 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.05645 to 0.05532, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0363 - acc: 0.9974 - val_loss: 0.0631 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.05532\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.0357 - acc: 0.9987 - val_loss: 0.0597 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.05532\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.0354 - acc: 0.9967 - val_loss: 0.0640 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.05532\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.0356 - acc: 0.9987 - val_loss: 0.0561 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.05532\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.0352 - acc: 0.9967 - val_loss: 0.0609 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.05532\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.0358 - acc: 0.9967 - val_loss: 0.0532 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.05532 to 0.05318, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.0351 - acc: 0.9967 - val_loss: 0.0545 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.05318\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.0343 - acc: 0.9974 - val_loss: 0.0561 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.05318\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.0336 - acc: 0.9967 - val_loss: 0.0508 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.05318 to 0.05075, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.0325 - acc: 0.9974 - val_loss: 0.0523 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.05075\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.0329 - acc: 0.9967 - val_loss: 0.0542 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.05075\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.0322 - acc: 0.9974 - val_loss: 0.0496 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.05075 to 0.04957, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.0333 - acc: 0.9961 - val_loss: 0.0541 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.04957\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.0329 - acc: 0.9967 - val_loss: 0.0545 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.04957\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.0311 - acc: 0.9961 - val_loss: 0.0547 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.04957\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.0303 - acc: 0.9974 - val_loss: 0.0503 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.04957\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.0309 - acc: 0.9987 - val_loss: 0.0521 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.04957\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.0300 - acc: 0.9974 - val_loss: 0.0531 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.04957\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.0295 - acc: 0.9974 - val_loss: 0.0480 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00175: val_loss improved from 0.04957 to 0.04797, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.0285 - acc: 0.9987 - val_loss: 0.0477 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00176: val_loss improved from 0.04797 to 0.04768, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.0290 - acc: 0.9987 - val_loss: 0.0446 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00177: val_loss improved from 0.04768 to 0.04463, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.0281 - acc: 0.9980 - val_loss: 0.0509 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.04463\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.0287 - acc: 0.9980 - val_loss: 0.0489 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.04463\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.0282 - acc: 0.9967 - val_loss: 0.0507 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.04463\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.0282 - acc: 0.9961 - val_loss: 0.0465 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.04463\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.0277 - acc: 0.9987 - val_loss: 0.0465 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.04463\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.0262 - acc: 0.9987 - val_loss: 0.0463 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.04463\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.0267 - acc: 0.9967 - val_loss: 0.0512 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.04463\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.0273 - acc: 0.9961 - val_loss: 0.0490 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.04463\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.0283 - acc: 0.9967 - val_loss: 0.0533 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.04463\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.0278 - acc: 0.9961 - val_loss: 0.0561 - val_acc: 0.9877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00187: val_loss did not improve from 0.04463\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.0259 - acc: 0.9974 - val_loss: 0.0483 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.04463\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.0253 - acc: 0.9967 - val_loss: 0.0444 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.04463 to 0.04444, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.0246 - acc: 0.9967 - val_loss: 0.0523 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.04444\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.0255 - acc: 0.9967 - val_loss: 0.0474 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.04444\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.0250 - acc: 0.9974 - val_loss: 0.0513 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.04444\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.0257 - acc: 0.9980 - val_loss: 0.0460 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.04444\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.0241 - acc: 0.9974 - val_loss: 0.0461 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.04444\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.0236 - acc: 0.9980 - val_loss: 0.0444 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00195: val_loss improved from 0.04444 to 0.04443, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.0237 - acc: 0.9967 - val_loss: 0.0460 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.04443\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.0230 - acc: 0.9980 - val_loss: 0.0465 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.04443\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.0233 - acc: 0.9974 - val_loss: 0.0446 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.04443\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.0243 - acc: 0.9974 - val_loss: 0.0419 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00199: val_loss improved from 0.04443 to 0.04193, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.0222 - acc: 0.9980 - val_loss: 0.0435 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.04193\n",
      "batch_size=120   optimizer=Adadelta\n",
      "Test accuracy: 68.5237%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_39 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 2.2426 - acc: 0.1809 - val_loss: 1.8911 - val_acc: 0.3333\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.89108, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.7334 - acc: 0.3921 - val_loss: 1.6371 - val_acc: 0.4486\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.89108 to 1.63706, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 1.5087 - acc: 0.4895 - val_loss: 1.4087 - val_acc: 0.5350\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.63706 to 1.40873, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 1.3221 - acc: 0.5586 - val_loss: 1.3273 - val_acc: 0.5185\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.40873 to 1.32727, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 1.2155 - acc: 0.5974 - val_loss: 1.2048 - val_acc: 0.6132\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.32727 to 1.20476, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 1.1244 - acc: 0.6329 - val_loss: 1.1193 - val_acc: 0.6420\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.20476 to 1.11930, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 1.0609 - acc: 0.6493 - val_loss: 1.0754 - val_acc: 0.6543\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.11930 to 1.07541, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 0s - loss: 1.0205 - acc: 0.6711 - val_loss: 1.0402 - val_acc: 0.6420\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.07541 to 1.04016, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.9605 - acc: 0.6895 - val_loss: 0.9804 - val_acc: 0.6914\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.04016 to 0.98035, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.9246 - acc: 0.7158 - val_loss: 0.9439 - val_acc: 0.6831\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.98035 to 0.94391, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.8849 - acc: 0.7263 - val_loss: 0.8860 - val_acc: 0.7284\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.94391 to 0.88596, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.8513 - acc: 0.7441 - val_loss: 0.8774 - val_acc: 0.6872\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.88596 to 0.87744, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.8494 - acc: 0.7349 - val_loss: 0.8372 - val_acc: 0.7407\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.87744 to 0.83723, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.8068 - acc: 0.7493 - val_loss: 0.8205 - val_acc: 0.7243\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.83723 to 0.82046, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.7763 - acc: 0.7645 - val_loss: 0.7809 - val_acc: 0.7490\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.82046 to 0.78085, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.7495 - acc: 0.7671 - val_loss: 0.7805 - val_acc: 0.7572\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.78085 to 0.78053, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.7347 - acc: 0.7842 - val_loss: 0.7545 - val_acc: 0.7737\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.78053 to 0.75448, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.7026 - acc: 0.7941 - val_loss: 0.7228 - val_acc: 0.7942\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.75448 to 0.72281, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.6794 - acc: 0.8000 - val_loss: 0.7283 - val_acc: 0.7572\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.72281\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.6669 - acc: 0.8099 - val_loss: 0.6835 - val_acc: 0.7819\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.72281 to 0.68349, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.6445 - acc: 0.8132 - val_loss: 0.6933 - val_acc: 0.7819\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.68349\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.6377 - acc: 0.8204 - val_loss: 0.6459 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.68349 to 0.64592, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.6139 - acc: 0.8197 - val_loss: 0.6416 - val_acc: 0.7942\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.64592 to 0.64157, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.6099 - acc: 0.8276 - val_loss: 0.6774 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.64157\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.5887 - acc: 0.8401 - val_loss: 0.6262 - val_acc: 0.8107\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.64157 to 0.62622, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.5686 - acc: 0.8401 - val_loss: 0.6466 - val_acc: 0.7737\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.62622\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.5610 - acc: 0.8474 - val_loss: 0.5626 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.62622 to 0.56258, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.5435 - acc: 0.8520 - val_loss: 0.5662 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.56258\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.5386 - acc: 0.8487 - val_loss: 0.5355 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.56258 to 0.53547, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.5160 - acc: 0.8625 - val_loss: 0.5357 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.53547\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.5013 - acc: 0.8618 - val_loss: 0.5221 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.53547 to 0.52212, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.4961 - acc: 0.8671 - val_loss: 0.5530 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.52212\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.4859 - acc: 0.8651 - val_loss: 0.5113 - val_acc: 0.8724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00033: val_loss improved from 0.52212 to 0.51128, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.4778 - acc: 0.8671 - val_loss: 0.4956 - val_acc: 0.8765\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.51128 to 0.49565, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.4633 - acc: 0.8816 - val_loss: 0.4866 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.49565 to 0.48662, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.4510 - acc: 0.8770 - val_loss: 0.5020 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.48662\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.4403 - acc: 0.8908 - val_loss: 0.4650 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.48662 to 0.46503, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.4331 - acc: 0.8908 - val_loss: 0.4742 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.46503\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.4189 - acc: 0.8993 - val_loss: 0.4448 - val_acc: 0.9012\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.46503 to 0.44480, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.4166 - acc: 0.9007 - val_loss: 0.4700 - val_acc: 0.8765\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.44480\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.4107 - acc: 0.8895 - val_loss: 0.4177 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.44480 to 0.41773, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.3987 - acc: 0.9092 - val_loss: 0.4244 - val_acc: 0.9012\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.41773\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.3898 - acc: 0.9099 - val_loss: 0.4075 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.41773 to 0.40745, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.3792 - acc: 0.9171 - val_loss: 0.4101 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.40745\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.3714 - acc: 0.9145 - val_loss: 0.4191 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.40745\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.3624 - acc: 0.9250 - val_loss: 0.3805 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.40745 to 0.38055, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.3540 - acc: 0.9303 - val_loss: 0.4104 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.38055\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.3614 - acc: 0.9178 - val_loss: 0.3804 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.38055 to 0.38041, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.3445 - acc: 0.9270 - val_loss: 0.3642 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.38041 to 0.36421, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.3332 - acc: 0.9362 - val_loss: 0.4245 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.36421\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.3337 - acc: 0.9342 - val_loss: 0.3533 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.36421 to 0.35334, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.3218 - acc: 0.9447 - val_loss: 0.3577 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.35334\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.3151 - acc: 0.9401 - val_loss: 0.3706 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.35334\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.3133 - acc: 0.9428 - val_loss: 0.3535 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.35334\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.3011 - acc: 0.9520 - val_loss: 0.3463 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.35334 to 0.34625, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.2983 - acc: 0.9467 - val_loss: 0.3290 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.34625 to 0.32904, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.2938 - acc: 0.9539 - val_loss: 0.3525 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.32904\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.2887 - acc: 0.9520 - val_loss: 0.2958 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.32904 to 0.29580, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.2807 - acc: 0.9546 - val_loss: 0.3160 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.29580\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.2750 - acc: 0.9572 - val_loss: 0.2801 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.29580 to 0.28013, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.2713 - acc: 0.9586 - val_loss: 0.3011 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.28013\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.2647 - acc: 0.9651 - val_loss: 0.2917 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.28013\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.2546 - acc: 0.9704 - val_loss: 0.2821 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.28013\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.2549 - acc: 0.9618 - val_loss: 0.2855 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.28013\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.2488 - acc: 0.9711 - val_loss: 0.2624 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.28013 to 0.26241, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.2452 - acc: 0.9658 - val_loss: 0.2804 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.26241\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.2371 - acc: 0.9651 - val_loss: 0.2564 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.26241 to 0.25639, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.2341 - acc: 0.9750 - val_loss: 0.2612 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.25639\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.2348 - acc: 0.9717 - val_loss: 0.2533 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.25639 to 0.25329, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.2337 - acc: 0.9697 - val_loss: 0.2512 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.25329 to 0.25122, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.2250 - acc: 0.9730 - val_loss: 0.2603 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.25122\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.2186 - acc: 0.9737 - val_loss: 0.2384 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.25122 to 0.23840, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.2138 - acc: 0.9776 - val_loss: 0.2679 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.23840\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.2153 - acc: 0.9711 - val_loss: 0.2326 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.23840 to 0.23262, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.2075 - acc: 0.9770 - val_loss: 0.2328 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.23262\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.2008 - acc: 0.9796 - val_loss: 0.2198 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.23262 to 0.21982, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1974 - acc: 0.9816 - val_loss: 0.2513 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.21982\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.1998 - acc: 0.9776 - val_loss: 0.2208 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.21982\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.1957 - acc: 0.9770 - val_loss: 0.2152 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.21982 to 0.21515, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.1932 - acc: 0.9809 - val_loss: 0.2173 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.21515\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.1830 - acc: 0.9849 - val_loss: 0.2145 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.21515 to 0.21452, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.1823 - acc: 0.9789 - val_loss: 0.2091 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.21452 to 0.20906, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.1765 - acc: 0.9855 - val_loss: 0.1955 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.20906 to 0.19551, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.1718 - acc: 0.9862 - val_loss: 0.2080 - val_acc: 0.9794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00084: val_loss did not improve from 0.19551\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.1702 - acc: 0.9862 - val_loss: 0.1884 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.19551 to 0.18840, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.1669 - acc: 0.9875 - val_loss: 0.1942 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.18840\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.1725 - acc: 0.9842 - val_loss: 0.2122 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.18840\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.1625 - acc: 0.9875 - val_loss: 0.2069 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.18840\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.1625 - acc: 0.9882 - val_loss: 0.2048 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.18840\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.1552 - acc: 0.9875 - val_loss: 0.1800 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.18840 to 0.18004, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.1545 - acc: 0.9921 - val_loss: 0.1993 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.18004\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.1546 - acc: 0.9888 - val_loss: 0.1674 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.18004 to 0.16737, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.1472 - acc: 0.9908 - val_loss: 0.1807 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.16737\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.1459 - acc: 0.9908 - val_loss: 0.1797 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.16737\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.1454 - acc: 0.9914 - val_loss: 0.1631 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.16737 to 0.16312, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.1417 - acc: 0.9934 - val_loss: 0.1726 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.16312\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.1393 - acc: 0.9921 - val_loss: 0.1582 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.16312 to 0.15820, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.1350 - acc: 0.9908 - val_loss: 0.1698 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.15820\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.1352 - acc: 0.9928 - val_loss: 0.1468 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.15820 to 0.14680, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.1306 - acc: 0.9908 - val_loss: 0.1792 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.14680\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.1306 - acc: 0.9908 - val_loss: 0.1775 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.14680\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.1294 - acc: 0.9941 - val_loss: 0.1512 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.14680\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.1271 - acc: 0.9921 - val_loss: 0.1556 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.14680\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.1242 - acc: 0.9928 - val_loss: 0.1575 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.14680\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.1194 - acc: 0.9941 - val_loss: 0.1440 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.14680 to 0.14396, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.1174 - acc: 0.9947 - val_loss: 0.1502 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.14396\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.1226 - acc: 0.9928 - val_loss: 0.1386 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.14396 to 0.13859, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.1142 - acc: 0.9961 - val_loss: 0.1455 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.13859\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.1125 - acc: 0.9954 - val_loss: 0.1385 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.13859 to 0.13851, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.1129 - acc: 0.9947 - val_loss: 0.1447 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.13851\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.1077 - acc: 0.9961 - val_loss: 0.1566 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.13851\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.1119 - acc: 0.9954 - val_loss: 0.1362 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.13851 to 0.13616, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.1051 - acc: 0.9954 - val_loss: 0.1442 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.13616\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.1049 - acc: 0.9934 - val_loss: 0.1369 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.13616\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.1026 - acc: 0.9961 - val_loss: 0.1408 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.13616\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.1018 - acc: 0.9961 - val_loss: 0.1325 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.13616 to 0.13248, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.1000 - acc: 0.9961 - val_loss: 0.1263 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.13248 to 0.12627, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0970 - acc: 0.9954 - val_loss: 0.1259 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.12627 to 0.12586, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0940 - acc: 0.9967 - val_loss: 0.1349 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.12586\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0942 - acc: 0.9980 - val_loss: 0.1248 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.12586 to 0.12478, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0954 - acc: 0.9961 - val_loss: 0.1326 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.12478\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0940 - acc: 0.9974 - val_loss: 0.1187 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.12478 to 0.11866, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0894 - acc: 0.9967 - val_loss: 0.1275 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.11866\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0889 - acc: 0.9967 - val_loss: 0.1165 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.11866 to 0.11654, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0874 - acc: 0.9967 - val_loss: 0.1186 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.11654\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0867 - acc: 0.9954 - val_loss: 0.1240 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.11654\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0868 - acc: 0.9961 - val_loss: 0.1149 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.11654 to 0.11492, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0839 - acc: 0.9967 - val_loss: 0.1023 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.11492 to 0.10234, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0795 - acc: 0.9993 - val_loss: 0.1113 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.10234\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0800 - acc: 0.9974 - val_loss: 0.1166 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.10234\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0823 - acc: 0.9980 - val_loss: 0.1083 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.10234\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0802 - acc: 0.9967 - val_loss: 0.1054 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.10234\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0801 - acc: 0.9967 - val_loss: 0.1034 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.10234\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0770 - acc: 0.9974 - val_loss: 0.0935 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.10234 to 0.09355, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0770 - acc: 0.9974 - val_loss: 0.1099 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.09355\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0755 - acc: 0.9980 - val_loss: 0.1095 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.09355\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0737 - acc: 0.9947 - val_loss: 0.1122 - val_acc: 0.9835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00137: val_loss did not improve from 0.09355\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0713 - acc: 0.9980 - val_loss: 0.0887 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.09355 to 0.08867, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0717 - acc: 0.9967 - val_loss: 0.1123 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.08867\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0729 - acc: 0.9961 - val_loss: 0.0903 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.08867\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0685 - acc: 0.9987 - val_loss: 0.1107 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.08867\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0703 - acc: 0.9974 - val_loss: 0.1030 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.08867\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0689 - acc: 0.9967 - val_loss: 0.0900 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.08867\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0657 - acc: 0.9980 - val_loss: 0.1131 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.08867\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0668 - acc: 0.9974 - val_loss: 0.0978 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.08867\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0635 - acc: 0.9980 - val_loss: 0.0851 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.08867 to 0.08506, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0626 - acc: 0.9974 - val_loss: 0.0804 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.08506 to 0.08043, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0626 - acc: 0.9974 - val_loss: 0.0941 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.08043\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0604 - acc: 0.9980 - val_loss: 0.0891 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.08043\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0599 - acc: 0.9967 - val_loss: 0.0879 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.08043\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0607 - acc: 0.9974 - val_loss: 0.0890 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.08043\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0602 - acc: 0.9980 - val_loss: 0.0847 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.08043\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0601 - acc: 0.9974 - val_loss: 0.0952 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.08043\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0567 - acc: 0.9967 - val_loss: 0.0864 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.08043\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.0576 - acc: 0.9974 - val_loss: 0.0844 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.08043\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.0576 - acc: 0.9961 - val_loss: 0.0824 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.08043\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0554 - acc: 0.9974 - val_loss: 0.0767 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.08043 to 0.07671, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.0553 - acc: 0.9980 - val_loss: 0.0798 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.07671\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.0540 - acc: 0.9974 - val_loss: 0.0835 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.07671\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.0542 - acc: 0.9980 - val_loss: 0.0805 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.07671\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.0535 - acc: 0.9980 - val_loss: 0.0796 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.07671\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.0516 - acc: 0.9967 - val_loss: 0.0858 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.07671\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.0522 - acc: 0.9987 - val_loss: 0.0831 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.07671\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.0506 - acc: 0.9967 - val_loss: 0.0832 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.07671\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.0501 - acc: 0.9974 - val_loss: 0.0824 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.07671\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.0495 - acc: 0.9967 - val_loss: 0.0824 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.07671\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.0480 - acc: 0.9980 - val_loss: 0.0742 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.07671 to 0.07418, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.0481 - acc: 0.9967 - val_loss: 0.0709 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.07418 to 0.07087, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.0471 - acc: 0.9974 - val_loss: 0.0895 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.07087\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.0488 - acc: 0.9980 - val_loss: 0.0721 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.07087\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.0476 - acc: 0.9974 - val_loss: 0.0820 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.07087\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.0455 - acc: 0.9987 - val_loss: 0.0807 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.07087\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.0459 - acc: 0.9980 - val_loss: 0.0741 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.07087\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.0456 - acc: 0.9967 - val_loss: 0.0797 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.07087\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.0444 - acc: 0.9967 - val_loss: 0.0684 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00175: val_loss improved from 0.07087 to 0.06842, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.0432 - acc: 0.9974 - val_loss: 0.0698 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.06842\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.0441 - acc: 0.9967 - val_loss: 0.0749 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.06842\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.0420 - acc: 0.9967 - val_loss: 0.0795 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.06842\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.0422 - acc: 0.9974 - val_loss: 0.0628 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00179: val_loss improved from 0.06842 to 0.06276, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.0412 - acc: 0.9980 - val_loss: 0.0809 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.06276\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.0434 - acc: 0.9980 - val_loss: 0.0717 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.06276\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.0408 - acc: 0.9967 - val_loss: 0.0723 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.06276\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.0418 - acc: 0.9980 - val_loss: 0.0648 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.06276\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.0400 - acc: 0.9974 - val_loss: 0.0704 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.06276\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.0401 - acc: 0.9974 - val_loss: 0.0788 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.06276\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.0403 - acc: 0.9980 - val_loss: 0.0646 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.06276\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.0401 - acc: 0.9967 - val_loss: 0.0624 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.06276 to 0.06241, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.0380 - acc: 0.9974 - val_loss: 0.0581 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00188: val_loss improved from 0.06241 to 0.05815, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.0375 - acc: 0.9980 - val_loss: 0.0638 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.05815\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.0371 - acc: 0.9980 - val_loss: 0.0674 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.05815\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.0379 - acc: 0.9974 - val_loss: 0.0644 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.05815\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.0372 - acc: 0.9967 - val_loss: 0.0683 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.05815\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.0362 - acc: 0.9974 - val_loss: 0.0656 - val_acc: 0.9918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00193: val_loss did not improve from 0.05815\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.0350 - acc: 0.9987 - val_loss: 0.0660 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.05815\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.0384 - acc: 0.9974 - val_loss: 0.0685 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.05815\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.0353 - acc: 0.9980 - val_loss: 0.0635 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.05815\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.0346 - acc: 0.9967 - val_loss: 0.0619 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.05815\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.0341 - acc: 0.9967 - val_loss: 0.0576 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.05815 to 0.05763, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.0347 - acc: 0.9974 - val_loss: 0.0555 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00199: val_loss improved from 0.05763 to 0.05555, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.0359 - acc: 0.9974 - val_loss: 0.0620 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.05555\n",
      "batch_size=160   optimizer=Adadelta\n",
      "Test accuracy: 68.2451%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 2.2627 - acc: 0.1763 - val_loss: 1.9095 - val_acc: 0.3004\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.90949, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.8131 - acc: 0.3546 - val_loss: 1.6144 - val_acc: 0.4444\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.90949 to 1.61439, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 1.5450 - acc: 0.4717 - val_loss: 1.4232 - val_acc: 0.5226\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.61439 to 1.42319, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 1.4028 - acc: 0.5237 - val_loss: 1.2987 - val_acc: 0.5597\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.42319 to 1.29873, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 1.2812 - acc: 0.5763 - val_loss: 1.2206 - val_acc: 0.5720\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.29873 to 1.22057, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 1.1879 - acc: 0.6257 - val_loss: 1.1427 - val_acc: 0.6091\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.22057 to 1.14273, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 1.1348 - acc: 0.6355 - val_loss: 1.1300 - val_acc: 0.5967\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.14273 to 1.13004, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 0s - loss: 1.0710 - acc: 0.6559 - val_loss: 1.0292 - val_acc: 0.6502\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.13004 to 1.02921, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 0s - loss: 1.0194 - acc: 0.6796 - val_loss: 1.0209 - val_acc: 0.6420\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.02921 to 1.02093, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.9921 - acc: 0.6822 - val_loss: 0.9605 - val_acc: 0.6749\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.02093 to 0.96049, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.9473 - acc: 0.6947 - val_loss: 0.9560 - val_acc: 0.6543\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.96049 to 0.95598, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.9199 - acc: 0.7053 - val_loss: 0.9087 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.95598 to 0.90868, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.8868 - acc: 0.7283 - val_loss: 0.9278 - val_acc: 0.6502\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.90868\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.8709 - acc: 0.7164 - val_loss: 0.8727 - val_acc: 0.6955\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.90868 to 0.87271, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.8318 - acc: 0.7474 - val_loss: 0.8366 - val_acc: 0.7284\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.87271 to 0.83657, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.8070 - acc: 0.7579 - val_loss: 0.7865 - val_acc: 0.7366\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.83657 to 0.78653, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.7875 - acc: 0.7651 - val_loss: 0.8536 - val_acc: 0.7119\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.78653\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.7616 - acc: 0.7697 - val_loss: 0.7718 - val_acc: 0.7613\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.78653 to 0.77183, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.7474 - acc: 0.7763 - val_loss: 0.7379 - val_acc: 0.7819\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.77183 to 0.73795, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.7221 - acc: 0.7822 - val_loss: 0.7475 - val_acc: 0.7366\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.73795\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.7030 - acc: 0.7875 - val_loss: 0.7371 - val_acc: 0.7860\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.73795 to 0.73714, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.6960 - acc: 0.7947 - val_loss: 0.7254 - val_acc: 0.7737\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.73714 to 0.72543, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.6716 - acc: 0.7954 - val_loss: 0.6664 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.72543 to 0.66642, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.6613 - acc: 0.7993 - val_loss: 0.6525 - val_acc: 0.8107\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.66642 to 0.65248, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.6405 - acc: 0.8092 - val_loss: 0.6642 - val_acc: 0.7737\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.65248\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.6267 - acc: 0.8178 - val_loss: 0.6765 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.65248\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.6138 - acc: 0.8211 - val_loss: 0.6138 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.65248 to 0.61378, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.5928 - acc: 0.8257 - val_loss: 0.6004 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.61378 to 0.60039, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.5822 - acc: 0.8296 - val_loss: 0.6064 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.60039\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.5808 - acc: 0.8296 - val_loss: 0.5825 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.60039 to 0.58247, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.5579 - acc: 0.8421 - val_loss: 0.5830 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.58247\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.5430 - acc: 0.8480 - val_loss: 0.5669 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.58247 to 0.56693, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.5357 - acc: 0.8447 - val_loss: 0.5694 - val_acc: 0.7942\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.56693\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.5220 - acc: 0.8546 - val_loss: 0.5265 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.56693 to 0.52645, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.5117 - acc: 0.8671 - val_loss: 0.5095 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.52645 to 0.50946, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.5087 - acc: 0.8612 - val_loss: 0.5135 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.50946\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.4916 - acc: 0.8664 - val_loss: 0.5188 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.50946\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.4936 - acc: 0.8592 - val_loss: 0.5265 - val_acc: 0.8354\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.50946\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.4838 - acc: 0.8684 - val_loss: 0.4968 - val_acc: 0.8683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00039: val_loss improved from 0.50946 to 0.49683, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.4760 - acc: 0.8717 - val_loss: 0.5432 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.49683\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.4731 - acc: 0.8724 - val_loss: 0.4974 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.49683\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.4506 - acc: 0.8875 - val_loss: 0.4727 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.49683 to 0.47266, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.4393 - acc: 0.8770 - val_loss: 0.4498 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.47266 to 0.44979, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.4345 - acc: 0.8849 - val_loss: 0.4396 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.44979 to 0.43958, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.4216 - acc: 0.8947 - val_loss: 0.4346 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.43958 to 0.43460, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.4198 - acc: 0.8993 - val_loss: 0.4179 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.43460 to 0.41786, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.4070 - acc: 0.9020 - val_loss: 0.4419 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.41786\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.4020 - acc: 0.9079 - val_loss: 0.4011 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.41786 to 0.40112, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.3975 - acc: 0.8993 - val_loss: 0.3958 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.40112 to 0.39575, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.3853 - acc: 0.9072 - val_loss: 0.4034 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.39575\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.3814 - acc: 0.9184 - val_loss: 0.3999 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.39575\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.3824 - acc: 0.9171 - val_loss: 0.3762 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.39575 to 0.37617, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.3601 - acc: 0.9230 - val_loss: 0.3746 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.37617 to 0.37456, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.3548 - acc: 0.9171 - val_loss: 0.3663 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.37456 to 0.36632, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.3500 - acc: 0.9276 - val_loss: 0.3777 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.36632\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.3460 - acc: 0.9237 - val_loss: 0.3691 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.36632\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.3401 - acc: 0.9289 - val_loss: 0.3462 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.36632 to 0.34622, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.3358 - acc: 0.9303 - val_loss: 0.3464 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.34622\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.3314 - acc: 0.9263 - val_loss: 0.3588 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.34622\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.3193 - acc: 0.9421 - val_loss: 0.3281 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.34622 to 0.32806, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.3152 - acc: 0.9434 - val_loss: 0.3249 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.32806 to 0.32486, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.3137 - acc: 0.9349 - val_loss: 0.3146 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.32486 to 0.31461, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.3050 - acc: 0.9447 - val_loss: 0.3091 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.31461 to 0.30906, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.2999 - acc: 0.9467 - val_loss: 0.3162 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.30906\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.2984 - acc: 0.9461 - val_loss: 0.3097 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.30906\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.2833 - acc: 0.9546 - val_loss: 0.2989 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.30906 to 0.29895, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.2797 - acc: 0.9553 - val_loss: 0.3080 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.29895\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.2858 - acc: 0.9513 - val_loss: 0.3180 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.29895\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.2736 - acc: 0.9586 - val_loss: 0.3247 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.29895\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.2716 - acc: 0.9566 - val_loss: 0.2780 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.29895 to 0.27802, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.2603 - acc: 0.9605 - val_loss: 0.2871 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.27802\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.2597 - acc: 0.9586 - val_loss: 0.2872 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.27802\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.2539 - acc: 0.9697 - val_loss: 0.2743 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.27802 to 0.27434, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.2507 - acc: 0.9632 - val_loss: 0.2794 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.27434\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.2462 - acc: 0.9664 - val_loss: 0.2603 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.27434 to 0.26025, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.2438 - acc: 0.9704 - val_loss: 0.2793 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.26025\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.2427 - acc: 0.9697 - val_loss: 0.2560 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.26025 to 0.25596, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.2328 - acc: 0.9711 - val_loss: 0.2515 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.25596 to 0.25152, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.2286 - acc: 0.9743 - val_loss: 0.2539 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.25152\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.2268 - acc: 0.9730 - val_loss: 0.2481 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.25152 to 0.24814, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.2315 - acc: 0.9651 - val_loss: 0.2347 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.24814 to 0.23474, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.2189 - acc: 0.9776 - val_loss: 0.2326 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.23474 to 0.23259, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.2166 - acc: 0.9717 - val_loss: 0.2415 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.23259\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.2155 - acc: 0.9743 - val_loss: 0.2247 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.23259 to 0.22465, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.2116 - acc: 0.9770 - val_loss: 0.2299 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.22465\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.2070 - acc: 0.9789 - val_loss: 0.2311 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.22465\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.2049 - acc: 0.9783 - val_loss: 0.2254 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.22465\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.2007 - acc: 0.9789 - val_loss: 0.2238 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.22465 to 0.22379, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.2023 - acc: 0.9743 - val_loss: 0.2366 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.22379\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.1970 - acc: 0.9789 - val_loss: 0.2103 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.22379 to 0.21035, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.1851 - acc: 0.9803 - val_loss: 0.2320 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.21035\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.1927 - acc: 0.9783 - val_loss: 0.2173 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.21035\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.1823 - acc: 0.9855 - val_loss: 0.2002 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.21035 to 0.20017, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.1804 - acc: 0.9855 - val_loss: 0.2183 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.20017\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.1846 - acc: 0.9783 - val_loss: 0.2046 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.20017\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.1757 - acc: 0.9875 - val_loss: 0.1878 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.20017 to 0.18781, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.1694 - acc: 0.9888 - val_loss: 0.1838 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.18781 to 0.18384, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.1674 - acc: 0.9842 - val_loss: 0.1898 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.18384\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.1651 - acc: 0.9888 - val_loss: 0.1851 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.18384\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.1674 - acc: 0.9875 - val_loss: 0.1895 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.18384\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.1668 - acc: 0.9842 - val_loss: 0.2122 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.18384\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.1593 - acc: 0.9855 - val_loss: 0.1766 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.18384 to 0.17659, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.1561 - acc: 0.9895 - val_loss: 0.1748 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.17659 to 0.17483, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.1563 - acc: 0.9875 - val_loss: 0.1818 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.17483\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.1509 - acc: 0.9908 - val_loss: 0.1765 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.17483\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.1469 - acc: 0.9901 - val_loss: 0.1841 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.17483\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.1465 - acc: 0.9914 - val_loss: 0.1719 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.17483 to 0.17189, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.1474 - acc: 0.9928 - val_loss: 0.1815 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.17189\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.1445 - acc: 0.9888 - val_loss: 0.1634 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.17189 to 0.16338, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.1431 - acc: 0.9882 - val_loss: 0.1692 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.16338\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.1400 - acc: 0.9888 - val_loss: 0.1552 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.16338 to 0.15521, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.1341 - acc: 0.9947 - val_loss: 0.1551 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.15521 to 0.15505, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.1331 - acc: 0.9921 - val_loss: 0.1595 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.15505\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.1340 - acc: 0.9908 - val_loss: 0.1499 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.15505 to 0.14993, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.1329 - acc: 0.9928 - val_loss: 0.1440 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.14993 to 0.14402, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.1266 - acc: 0.9954 - val_loss: 0.1542 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.14402\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.1285 - acc: 0.9908 - val_loss: 0.1714 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.14402\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.1288 - acc: 0.9941 - val_loss: 0.1551 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.14402\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.1270 - acc: 0.9947 - val_loss: 0.1499 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.14402\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.1223 - acc: 0.9921 - val_loss: 0.1333 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.14402 to 0.13326, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.1186 - acc: 0.9954 - val_loss: 0.1359 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.13326\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.1184 - acc: 0.9934 - val_loss: 0.1338 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.13326\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.1146 - acc: 0.9980 - val_loss: 0.1324 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.13326 to 0.13242, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.1166 - acc: 0.9947 - val_loss: 0.1347 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.13242\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.1181 - acc: 0.9934 - val_loss: 0.1311 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.13242 to 0.13105, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.1082 - acc: 0.9980 - val_loss: 0.1244 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.13105 to 0.12440, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.1101 - acc: 0.9961 - val_loss: 0.1394 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.12440\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.1094 - acc: 0.9967 - val_loss: 0.1271 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.12440\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.1061 - acc: 0.9974 - val_loss: 0.1253 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.12440\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.1060 - acc: 0.9934 - val_loss: 0.1245 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.12440\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.1019 - acc: 0.9974 - val_loss: 0.1243 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.12440 to 0.12428, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.1022 - acc: 0.9961 - val_loss: 0.1212 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.12428 to 0.12118, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.1051 - acc: 0.9974 - val_loss: 0.1184 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.12118 to 0.11837, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0988 - acc: 0.9954 - val_loss: 0.1193 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.11837\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.1004 - acc: 0.9967 - val_loss: 0.1657 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.11837\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.1017 - acc: 0.9954 - val_loss: 0.1319 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.11837\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0945 - acc: 0.9967 - val_loss: 0.1219 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.11837\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0981 - acc: 0.9961 - val_loss: 0.1122 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.11837 to 0.11219, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0917 - acc: 0.9967 - val_loss: 0.1278 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.11219\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0908 - acc: 0.9974 - val_loss: 0.1167 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.11219\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0886 - acc: 0.9967 - val_loss: 0.1140 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.11219\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0877 - acc: 0.9974 - val_loss: 0.1089 - val_acc: 0.9959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00142: val_loss improved from 0.11219 to 0.10893, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0870 - acc: 0.9980 - val_loss: 0.1227 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.10893\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0881 - acc: 0.9980 - val_loss: 0.1086 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.10893 to 0.10863, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0843 - acc: 0.9974 - val_loss: 0.1098 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.10863\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0847 - acc: 0.9987 - val_loss: 0.1031 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.10863 to 0.10310, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0849 - acc: 0.9974 - val_loss: 0.1138 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.10310\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0824 - acc: 0.9967 - val_loss: 0.1019 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.10310 to 0.10190, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0801 - acc: 0.9974 - val_loss: 0.0972 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.10190 to 0.09720, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0789 - acc: 0.9987 - val_loss: 0.1066 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.09720\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0817 - acc: 0.9974 - val_loss: 0.1123 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.09720\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0768 - acc: 0.9967 - val_loss: 0.0953 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.09720 to 0.09534, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0774 - acc: 0.9967 - val_loss: 0.0993 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.09534\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0773 - acc: 0.9987 - val_loss: 0.0992 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.09534\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.0758 - acc: 0.9967 - val_loss: 0.1017 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.09534\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.0729 - acc: 0.9974 - val_loss: 0.0963 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.09534\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0732 - acc: 0.9967 - val_loss: 0.1070 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.09534\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.0724 - acc: 0.9967 - val_loss: 0.0922 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.09534 to 0.09217, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.0725 - acc: 0.9961 - val_loss: 0.1087 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.09217\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.0732 - acc: 0.9961 - val_loss: 0.0858 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.09217 to 0.08578, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.0696 - acc: 0.9967 - val_loss: 0.0873 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.08578\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.0717 - acc: 0.9987 - val_loss: 0.1113 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.08578\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.0752 - acc: 0.9967 - val_loss: 0.0819 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00163: val_loss improved from 0.08578 to 0.08186, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.0664 - acc: 0.9987 - val_loss: 0.0818 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.08186 to 0.08179, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.0670 - acc: 0.9974 - val_loss: 0.0929 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.08179\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.0650 - acc: 0.9980 - val_loss: 0.0905 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.08179\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.0666 - acc: 0.9967 - val_loss: 0.0808 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.08179 to 0.08077, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.0639 - acc: 0.9974 - val_loss: 0.0840 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.08077\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.0633 - acc: 0.9974 - val_loss: 0.0817 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.08077\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.0623 - acc: 0.9967 - val_loss: 0.0875 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.08077\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.0631 - acc: 0.9967 - val_loss: 0.0864 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.08077\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.0627 - acc: 0.9974 - val_loss: 0.0896 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.08077\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.0607 - acc: 0.9987 - val_loss: 0.0998 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.08077\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.0649 - acc: 0.9967 - val_loss: 0.0765 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.08077 to 0.07655, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.0581 - acc: 0.9974 - val_loss: 0.0812 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.07655\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.0582 - acc: 0.9987 - val_loss: 0.0843 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.07655\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.0570 - acc: 0.9980 - val_loss: 0.0767 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.07655\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.0593 - acc: 0.9967 - val_loss: 0.0775 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.07655\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.0548 - acc: 0.9980 - val_loss: 0.0801 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.07655\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.0543 - acc: 0.9974 - val_loss: 0.0708 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00180: val_loss improved from 0.07655 to 0.07078, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.0538 - acc: 0.9974 - val_loss: 0.0710 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.07078\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.0543 - acc: 0.9967 - val_loss: 0.0785 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.07078\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.0560 - acc: 0.9974 - val_loss: 0.0773 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.07078\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.0531 - acc: 0.9967 - val_loss: 0.0771 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.07078\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.0531 - acc: 0.9974 - val_loss: 0.0731 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.07078\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.0516 - acc: 0.9987 - val_loss: 0.0725 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.07078\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.0534 - acc: 0.9974 - val_loss: 0.0647 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.07078 to 0.06469, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.0509 - acc: 0.9974 - val_loss: 0.0751 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.06469\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.0499 - acc: 0.9987 - val_loss: 0.0684 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.06469\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.0494 - acc: 0.9980 - val_loss: 0.0717 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.06469\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.0488 - acc: 0.9980 - val_loss: 0.0784 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.06469\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.0493 - acc: 0.9980 - val_loss: 0.0699 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.06469\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.0483 - acc: 0.9974 - val_loss: 0.0803 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.06469\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.0479 - acc: 0.9980 - val_loss: 0.0660 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.06469\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.0480 - acc: 0.9974 - val_loss: 0.0731 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.06469\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.0476 - acc: 0.9967 - val_loss: 0.0719 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.06469\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.0463 - acc: 0.9967 - val_loss: 0.0690 - val_acc: 0.9959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00197: val_loss did not improve from 0.06469\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.0477 - acc: 0.9974 - val_loss: 0.0696 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.06469\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.0475 - acc: 0.9967 - val_loss: 0.0656 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.06469\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.0460 - acc: 0.9974 - val_loss: 0.0713 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.06469\n",
      "batch_size=200   optimizer=Adadelta\n",
      "Test accuracy: 66.2953%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_41 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 2s - loss: 1.6419 - acc: 0.4243 - val_loss: 1.2024 - val_acc: 0.5761\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.20235, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 1s - loss: 1.0618 - acc: 0.6487 - val_loss: 0.8871 - val_acc: 0.7078\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.20235 to 0.88714, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 1s - loss: 0.8607 - acc: 0.7178 - val_loss: 0.7494 - val_acc: 0.7942\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.88714 to 0.74939, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 1s - loss: 0.7332 - acc: 0.7625 - val_loss: 0.6785 - val_acc: 0.7860\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.74939 to 0.67849, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 1s - loss: 0.6563 - acc: 0.7974 - val_loss: 0.6060 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.67849 to 0.60597, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 1s - loss: 0.5836 - acc: 0.8125 - val_loss: 0.5476 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.60597 to 0.54760, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 1s - loss: 0.5274 - acc: 0.8421 - val_loss: 0.5142 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.54760 to 0.51417, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 1s - loss: 0.4710 - acc: 0.8586 - val_loss: 0.4313 - val_acc: 0.9012\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.51417 to 0.43133, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 1s - loss: 0.4267 - acc: 0.8862 - val_loss: 0.4101 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.43133 to 0.41011, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 1s - loss: 0.3856 - acc: 0.9046 - val_loss: 0.3808 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.41011 to 0.38077, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 1s - loss: 0.3508 - acc: 0.9197 - val_loss: 0.3178 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.38077 to 0.31782, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 1s - loss: 0.3270 - acc: 0.9263 - val_loss: 0.3223 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.31782\n",
      "Epoch 13/200\n",
      " - 1s - loss: 0.3034 - acc: 0.9329 - val_loss: 0.2699 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.31782 to 0.26990, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 1s - loss: 0.2745 - acc: 0.9480 - val_loss: 0.3307 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.26990\n",
      "Epoch 15/200\n",
      " - 1s - loss: 0.2616 - acc: 0.9454 - val_loss: 0.2597 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.26990 to 0.25974, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 1s - loss: 0.2360 - acc: 0.9632 - val_loss: 0.2164 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.25974 to 0.21643, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 1s - loss: 0.2133 - acc: 0.9711 - val_loss: 0.2071 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.21643 to 0.20706, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/200\n",
      " - 1s - loss: 0.1952 - acc: 0.9704 - val_loss: 0.1983 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.20706 to 0.19826, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 1s - loss: 0.1817 - acc: 0.9770 - val_loss: 0.1976 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.19826 to 0.19764, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 1s - loss: 0.1676 - acc: 0.9842 - val_loss: 0.1699 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.19764 to 0.16989, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 21/200\n",
      " - 1s - loss: 0.1579 - acc: 0.9868 - val_loss: 0.1693 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.16989 to 0.16928, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 1s - loss: 0.1442 - acc: 0.9862 - val_loss: 0.1428 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.16928 to 0.14281, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 1s - loss: 0.1371 - acc: 0.9882 - val_loss: 0.1437 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.14281\n",
      "Epoch 24/200\n",
      " - 1s - loss: 0.1277 - acc: 0.9921 - val_loss: 0.1301 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.14281 to 0.13010, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 25/200\n",
      " - 1s - loss: 0.1187 - acc: 0.9921 - val_loss: 0.1201 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.13010 to 0.12012, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 26/200\n",
      " - 1s - loss: 0.1121 - acc: 0.9901 - val_loss: 0.1118 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.12012 to 0.11182, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 27/200\n",
      " - 1s - loss: 0.1031 - acc: 0.9934 - val_loss: 0.1105 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.11182 to 0.11055, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 28/200\n",
      " - 1s - loss: 0.0982 - acc: 0.9954 - val_loss: 0.1265 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.11055\n",
      "Epoch 29/200\n",
      " - 1s - loss: 0.0941 - acc: 0.9941 - val_loss: 0.1087 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.11055 to 0.10872, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 30/200\n",
      " - 1s - loss: 0.0841 - acc: 0.9961 - val_loss: 0.1084 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.10872 to 0.10842, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 31/200\n",
      " - 1s - loss: 0.0778 - acc: 0.9974 - val_loss: 0.0904 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.10842 to 0.09038, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 32/200\n",
      " - 1s - loss: 0.0760 - acc: 0.9961 - val_loss: 0.0832 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.09038 to 0.08325, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 33/200\n",
      " - 1s - loss: 0.0721 - acc: 0.9974 - val_loss: 0.0826 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.08325 to 0.08258, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 34/200\n",
      " - 1s - loss: 0.0660 - acc: 0.9961 - val_loss: 0.0745 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.08258 to 0.07449, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 35/200\n",
      " - 1s - loss: 0.0619 - acc: 0.9980 - val_loss: 0.0749 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.07449\n",
      "Epoch 36/200\n",
      " - 1s - loss: 0.0586 - acc: 0.9980 - val_loss: 0.0703 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.07449 to 0.07034, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 37/200\n",
      " - 1s - loss: 0.0587 - acc: 0.9974 - val_loss: 0.0667 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.07034 to 0.06668, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 38/200\n",
      " - 1s - loss: 0.0527 - acc: 0.9980 - val_loss: 0.0775 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.06668\n",
      "Epoch 39/200\n",
      " - 1s - loss: 0.0499 - acc: 0.9967 - val_loss: 0.0729 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.06668\n",
      "Epoch 40/200\n",
      " - 1s - loss: 0.0469 - acc: 0.9967 - val_loss: 0.0631 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.06668 to 0.06311, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 41/200\n",
      " - 1s - loss: 0.0458 - acc: 0.9974 - val_loss: 0.0635 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.06311\n",
      "Epoch 42/200\n",
      " - 1s - loss: 0.0441 - acc: 0.9961 - val_loss: 0.0645 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.06311\n",
      "Epoch 43/200\n",
      " - 1s - loss: 0.0417 - acc: 0.9967 - val_loss: 0.0581 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.06311 to 0.05808, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 44/200\n",
      " - 1s - loss: 0.0389 - acc: 0.9974 - val_loss: 0.0642 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.05808\n",
      "Epoch 45/200\n",
      " - 1s - loss: 0.0372 - acc: 0.9961 - val_loss: 0.0578 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.05808 to 0.05783, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 46/200\n",
      " - 1s - loss: 0.0343 - acc: 0.9974 - val_loss: 0.0611 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.05783\n",
      "Epoch 47/200\n",
      " - 1s - loss: 0.0365 - acc: 0.9961 - val_loss: 0.0488 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.05783 to 0.04880, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 48/200\n",
      " - 1s - loss: 0.0337 - acc: 0.9967 - val_loss: 0.0534 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.04880\n",
      "Epoch 49/200\n",
      " - 1s - loss: 0.0325 - acc: 0.9974 - val_loss: 0.0487 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.04880 to 0.04875, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 50/200\n",
      " - 1s - loss: 0.0281 - acc: 0.9974 - val_loss: 0.0418 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.04875 to 0.04182, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 51/200\n",
      " - 1s - loss: 0.0303 - acc: 0.9954 - val_loss: 0.0487 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.04182\n",
      "Epoch 52/200\n",
      " - 1s - loss: 0.0281 - acc: 0.9967 - val_loss: 0.0603 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.04182\n",
      "Epoch 53/200\n",
      " - 1s - loss: 0.0254 - acc: 0.9974 - val_loss: 0.0528 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.04182\n",
      "Epoch 54/200\n",
      " - 1s - loss: 0.0254 - acc: 0.9974 - val_loss: 0.0547 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.04182\n",
      "Epoch 55/200\n",
      " - 1s - loss: 0.0230 - acc: 0.9967 - val_loss: 0.0389 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.04182 to 0.03892, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 56/200\n",
      " - 1s - loss: 0.0245 - acc: 0.9967 - val_loss: 0.0425 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.03892\n",
      "Epoch 57/200\n",
      " - 1s - loss: 0.0243 - acc: 0.9974 - val_loss: 0.0438 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.03892\n",
      "Epoch 58/200\n",
      " - 1s - loss: 0.0220 - acc: 0.9980 - val_loss: 0.0394 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.03892\n",
      "Epoch 59/200\n",
      " - 1s - loss: 0.0195 - acc: 0.9974 - val_loss: 0.0371 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.03892 to 0.03712, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 60/200\n",
      " - 1s - loss: 0.0222 - acc: 0.9967 - val_loss: 0.0400 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.03712\n",
      "Epoch 61/200\n",
      " - 1s - loss: 0.0202 - acc: 0.9961 - val_loss: 0.0546 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.03712\n",
      "Epoch 62/200\n",
      " - 1s - loss: 0.0195 - acc: 0.9967 - val_loss: 0.0304 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.03712 to 0.03037, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 63/200\n",
      " - 1s - loss: 0.0201 - acc: 0.9967 - val_loss: 0.0339 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.03037\n",
      "Epoch 64/200\n",
      " - 1s - loss: 0.0189 - acc: 0.9967 - val_loss: 0.0300 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.03037 to 0.03003, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 65/200\n",
      " - 1s - loss: 0.0171 - acc: 0.9967 - val_loss: 0.0474 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.03003\n",
      "Epoch 66/200\n",
      " - 1s - loss: 0.0171 - acc: 0.9974 - val_loss: 0.0498 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.03003\n",
      "Epoch 67/200\n",
      " - 1s - loss: 0.0176 - acc: 0.9974 - val_loss: 0.0417 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.03003\n",
      "Epoch 68/200\n",
      " - 1s - loss: 0.0159 - acc: 0.9974 - val_loss: 0.0331 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.03003\n",
      "Epoch 69/200\n",
      " - 1s - loss: 0.0149 - acc: 0.9974 - val_loss: 0.0335 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.03003\n",
      "Epoch 70/200\n",
      " - 1s - loss: 0.0158 - acc: 0.9967 - val_loss: 0.0332 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.03003\n",
      "Epoch 71/200\n",
      " - 1s - loss: 0.0160 - acc: 0.9967 - val_loss: 0.0534 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.03003\n",
      "Epoch 72/200\n",
      " - 1s - loss: 0.0175 - acc: 0.9967 - val_loss: 0.0307 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.03003\n",
      "Epoch 73/200\n",
      " - 1s - loss: 0.0129 - acc: 0.9980 - val_loss: 0.0560 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.03003\n",
      "Epoch 74/200\n",
      " - 1s - loss: 0.0137 - acc: 0.9974 - val_loss: 0.0363 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.03003\n",
      "Epoch 75/200\n",
      " - 1s - loss: 0.0128 - acc: 0.9974 - val_loss: 0.0513 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.03003\n",
      "Epoch 76/200\n",
      " - 1s - loss: 0.0181 - acc: 0.9974 - val_loss: 0.0301 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.03003\n",
      "Epoch 77/200\n",
      " - 1s - loss: 0.0124 - acc: 0.9980 - val_loss: 0.0333 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.03003\n",
      "Epoch 78/200\n",
      " - 1s - loss: 0.0139 - acc: 0.9967 - val_loss: 0.0406 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.03003\n",
      "Epoch 79/200\n",
      " - 1s - loss: 0.0144 - acc: 0.9967 - val_loss: 0.0446 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.03003\n",
      "Epoch 80/200\n",
      " - 1s - loss: 0.0122 - acc: 0.9980 - val_loss: 0.0409 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.03003\n",
      "Epoch 81/200\n",
      " - 1s - loss: 0.0122 - acc: 0.9967 - val_loss: 0.0298 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.03003 to 0.02979, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 82/200\n",
      " - 1s - loss: 0.0129 - acc: 0.9974 - val_loss: 0.0326 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.02979\n",
      "Epoch 83/200\n",
      " - 1s - loss: 0.0122 - acc: 0.9967 - val_loss: 0.0385 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.02979\n",
      "Epoch 84/200\n",
      " - 1s - loss: 0.0114 - acc: 0.9967 - val_loss: 0.0358 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.02979\n",
      "Epoch 85/200\n",
      " - 1s - loss: 0.0103 - acc: 0.9980 - val_loss: 0.0363 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.02979\n",
      "Epoch 86/200\n",
      " - 1s - loss: 0.0149 - acc: 0.9961 - val_loss: 0.0389 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.02979\n",
      "Epoch 87/200\n",
      " - 1s - loss: 0.0129 - acc: 0.9967 - val_loss: 0.0311 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.02979\n",
      "Epoch 88/200\n",
      " - 1s - loss: 0.0119 - acc: 0.9967 - val_loss: 0.0258 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.02979 to 0.02575, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 89/200\n",
      " - 1s - loss: 0.0133 - acc: 0.9961 - val_loss: 0.0305 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.02575\n",
      "Epoch 90/200\n",
      " - 1s - loss: 0.0103 - acc: 0.9974 - val_loss: 0.0436 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.02575\n",
      "Epoch 91/200\n",
      " - 1s - loss: 0.0110 - acc: 0.9967 - val_loss: 0.0420 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.02575\n",
      "Epoch 92/200\n",
      " - 1s - loss: 0.0096 - acc: 0.9967 - val_loss: 0.0410 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.02575\n",
      "Epoch 93/200\n",
      " - 1s - loss: 0.0099 - acc: 0.9967 - val_loss: 0.0281 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.02575\n",
      "Epoch 94/200\n",
      " - 1s - loss: 0.0109 - acc: 0.9967 - val_loss: 0.0366 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.02575\n",
      "Epoch 95/200\n",
      " - 1s - loss: 0.0108 - acc: 0.9961 - val_loss: 0.0305 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.02575\n",
      "Epoch 96/200\n",
      " - 1s - loss: 0.0113 - acc: 0.9967 - val_loss: 0.0311 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.02575\n",
      "Epoch 97/200\n",
      " - 1s - loss: 0.0131 - acc: 0.9967 - val_loss: 0.0500 - val_acc: 0.9877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00097: val_loss did not improve from 0.02575\n",
      "Epoch 98/200\n",
      " - 1s - loss: 0.0104 - acc: 0.9974 - val_loss: 0.0285 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.02575\n",
      "Epoch 99/200\n",
      " - 1s - loss: 0.0098 - acc: 0.9974 - val_loss: 0.0336 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.02575\n",
      "Epoch 100/200\n",
      " - 1s - loss: 0.0166 - acc: 0.9961 - val_loss: 0.0387 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.02575\n",
      "Epoch 101/200\n",
      " - 1s - loss: 0.0123 - acc: 0.9974 - val_loss: 0.0279 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.02575\n",
      "Epoch 102/200\n",
      " - 1s - loss: 0.0093 - acc: 0.9980 - val_loss: 0.0297 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.02575\n",
      "Epoch 103/200\n",
      " - 1s - loss: 0.0107 - acc: 0.9980 - val_loss: 0.0351 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.02575\n",
      "Epoch 104/200\n",
      " - 1s - loss: 0.0085 - acc: 0.9974 - val_loss: 0.0420 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.02575\n",
      "Epoch 105/200\n",
      " - 1s - loss: 0.0109 - acc: 0.9961 - val_loss: 0.0310 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.02575\n",
      "Epoch 106/200\n",
      " - 1s - loss: 0.0093 - acc: 0.9974 - val_loss: 0.0321 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.02575\n",
      "Epoch 107/200\n",
      " - 1s - loss: 0.0079 - acc: 0.9974 - val_loss: 0.0332 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.02575\n",
      "Epoch 108/200\n",
      " - 1s - loss: 0.0100 - acc: 0.9967 - val_loss: 0.0352 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.02575\n",
      "Epoch 109/200\n",
      " - 1s - loss: 0.0098 - acc: 0.9974 - val_loss: 0.0293 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.02575\n",
      "Epoch 110/200\n",
      " - 1s - loss: 0.0074 - acc: 0.9980 - val_loss: 0.0365 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.02575\n",
      "Epoch 111/200\n",
      " - 1s - loss: 0.0108 - acc: 0.9967 - val_loss: 0.0278 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.02575\n",
      "Epoch 112/200\n",
      " - 1s - loss: 0.0110 - acc: 0.9974 - val_loss: 0.0346 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.02575\n",
      "Epoch 113/200\n",
      " - 1s - loss: 0.0116 - acc: 0.9961 - val_loss: 0.0323 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.02575\n",
      "Epoch 114/200\n",
      " - 1s - loss: 0.0087 - acc: 0.9967 - val_loss: 0.0317 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.02575\n",
      "Epoch 115/200\n",
      " - 1s - loss: 0.0114 - acc: 0.9967 - val_loss: 0.0251 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.02575 to 0.02506, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 116/200\n",
      " - 1s - loss: 0.0078 - acc: 0.9974 - val_loss: 0.0371 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.02506\n",
      "Epoch 117/200\n",
      " - 1s - loss: 0.0117 - acc: 0.9967 - val_loss: 0.0427 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.02506\n",
      "Epoch 118/200\n",
      " - 1s - loss: 0.0100 - acc: 0.9974 - val_loss: 0.0368 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.02506\n",
      "Epoch 119/200\n",
      " - 1s - loss: 0.0086 - acc: 0.9974 - val_loss: 0.0369 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.02506\n",
      "Epoch 120/200\n",
      " - 1s - loss: 0.0108 - acc: 0.9974 - val_loss: 0.0396 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.02506\n",
      "Epoch 121/200\n",
      " - 1s - loss: 0.0116 - acc: 0.9967 - val_loss: 0.0366 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.02506\n",
      "Epoch 122/200\n",
      " - 1s - loss: 0.0100 - acc: 0.9974 - val_loss: 0.0259 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.02506\n",
      "Epoch 123/200\n",
      " - 1s - loss: 0.0105 - acc: 0.9967 - val_loss: 0.0282 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.02506\n",
      "Epoch 124/200\n",
      " - 1s - loss: 0.0100 - acc: 0.9967 - val_loss: 0.0460 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.02506\n",
      "Epoch 125/200\n",
      " - 1s - loss: 0.0085 - acc: 0.9967 - val_loss: 0.0646 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.02506\n",
      "Epoch 126/200\n",
      " - 1s - loss: 0.0070 - acc: 0.9980 - val_loss: 0.0277 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.02506\n",
      "Epoch 127/200\n",
      " - 1s - loss: 0.0088 - acc: 0.9974 - val_loss: 0.0439 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.02506\n",
      "Epoch 128/200\n",
      " - 1s - loss: 0.0094 - acc: 0.9967 - val_loss: 0.0285 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.02506\n",
      "Epoch 129/200\n",
      " - 1s - loss: 0.0091 - acc: 0.9974 - val_loss: 0.0322 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.02506\n",
      "Epoch 130/200\n",
      " - 1s - loss: 0.0098 - acc: 0.9967 - val_loss: 0.0361 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.02506\n",
      "Epoch 131/200\n",
      " - 1s - loss: 0.0110 - acc: 0.9974 - val_loss: 0.0368 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.02506\n",
      "Epoch 132/200\n",
      " - 1s - loss: 0.0077 - acc: 0.9980 - val_loss: 0.0311 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.02506\n",
      "Epoch 133/200\n",
      " - 1s - loss: 0.0100 - acc: 0.9974 - val_loss: 0.0312 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.02506\n",
      "Epoch 134/200\n",
      " - 1s - loss: 0.0075 - acc: 0.9974 - val_loss: 0.0259 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.02506\n",
      "Epoch 135/200\n",
      " - 1s - loss: 0.0140 - acc: 0.9961 - val_loss: 0.0386 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.02506\n",
      "Epoch 136/200\n",
      " - 1s - loss: 0.0108 - acc: 0.9974 - val_loss: 0.0349 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.02506\n",
      "Epoch 137/200\n",
      " - 1s - loss: 0.0128 - acc: 0.9967 - val_loss: 0.0335 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.02506\n",
      "Epoch 138/200\n",
      " - 1s - loss: 0.0079 - acc: 0.9974 - val_loss: 0.0302 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.02506\n",
      "Epoch 139/200\n",
      " - 1s - loss: 0.0112 - acc: 0.9974 - val_loss: 0.0515 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.02506\n",
      "Epoch 140/200\n",
      " - 1s - loss: 0.0081 - acc: 0.9974 - val_loss: 0.0365 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.02506\n",
      "Epoch 141/200\n",
      " - 1s - loss: 0.0077 - acc: 0.9980 - val_loss: 0.0388 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.02506\n",
      "Epoch 142/200\n",
      " - 1s - loss: 0.0082 - acc: 0.9974 - val_loss: 0.0315 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.02506\n",
      "Epoch 143/200\n",
      " - 1s - loss: 0.0153 - acc: 0.9961 - val_loss: 0.0279 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.02506\n",
      "Epoch 144/200\n",
      " - 1s - loss: 0.0072 - acc: 0.9980 - val_loss: 0.0527 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.02506\n",
      "Epoch 145/200\n",
      " - 1s - loss: 0.0107 - acc: 0.9967 - val_loss: 0.0484 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.02506\n",
      "Epoch 146/200\n",
      " - 1s - loss: 0.0092 - acc: 0.9967 - val_loss: 0.0355 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.02506\n",
      "Epoch 147/200\n",
      " - 1s - loss: 0.0085 - acc: 0.9974 - val_loss: 0.0428 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.02506\n",
      "Epoch 148/200\n",
      " - 1s - loss: 0.0101 - acc: 0.9967 - val_loss: 0.0311 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.02506\n",
      "Epoch 149/200\n",
      " - 1s - loss: 0.0096 - acc: 0.9967 - val_loss: 0.0278 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.02506\n",
      "Epoch 150/200\n",
      " - 1s - loss: 0.0088 - acc: 0.9980 - val_loss: 0.0583 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.02506\n",
      "Epoch 151/200\n",
      " - 1s - loss: 0.0065 - acc: 0.9974 - val_loss: 0.0394 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.02506\n",
      "Epoch 152/200\n",
      " - 1s - loss: 0.0058 - acc: 0.9980 - val_loss: 0.0415 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.02506\n",
      "Epoch 153/200\n",
      " - 1s - loss: 0.0098 - acc: 0.9980 - val_loss: 0.0335 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.02506\n",
      "Epoch 154/200\n",
      " - 1s - loss: 0.0084 - acc: 0.9974 - val_loss: 0.0330 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.02506\n",
      "Epoch 155/200\n",
      " - 1s - loss: 0.0076 - acc: 0.9967 - val_loss: 0.0237 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.02506 to 0.02366, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 156/200\n",
      " - 1s - loss: 0.0096 - acc: 0.9974 - val_loss: 0.0388 - val_acc: 0.9877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00156: val_loss did not improve from 0.02366\n",
      "Epoch 157/200\n",
      " - 1s - loss: 0.0096 - acc: 0.9974 - val_loss: 0.0317 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.02366\n",
      "Epoch 158/200\n",
      " - 1s - loss: 0.0065 - acc: 0.9974 - val_loss: 0.0489 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.02366\n",
      "Epoch 159/200\n",
      " - 1s - loss: 0.0131 - acc: 0.9967 - val_loss: 0.0253 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.02366\n",
      "Epoch 160/200\n",
      " - 1s - loss: 0.0098 - acc: 0.9980 - val_loss: 0.0404 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.02366\n",
      "Epoch 161/200\n",
      " - 1s - loss: 0.0117 - acc: 0.9961 - val_loss: 0.0334 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.02366\n",
      "Epoch 162/200\n",
      " - 1s - loss: 0.0056 - acc: 0.9980 - val_loss: 0.0348 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.02366\n",
      "Epoch 163/200\n",
      " - 1s - loss: 0.0068 - acc: 0.9980 - val_loss: 0.0326 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.02366\n",
      "Epoch 164/200\n",
      " - 1s - loss: 0.0082 - acc: 0.9974 - val_loss: 0.0340 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.02366\n",
      "Epoch 165/200\n",
      " - 1s - loss: 0.0073 - acc: 0.9980 - val_loss: 0.0477 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.02366\n",
      "Epoch 166/200\n",
      " - 1s - loss: 0.0093 - acc: 0.9967 - val_loss: 0.0333 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.02366\n",
      "Epoch 167/200\n",
      " - 1s - loss: 0.0076 - acc: 0.9974 - val_loss: 0.0451 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.02366\n",
      "Epoch 168/200\n",
      " - 1s - loss: 0.0100 - acc: 0.9967 - val_loss: 0.0373 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.02366\n",
      "Epoch 169/200\n",
      " - 1s - loss: 0.0090 - acc: 0.9974 - val_loss: 0.0436 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.02366\n",
      "Epoch 170/200\n",
      " - 1s - loss: 0.0069 - acc: 0.9974 - val_loss: 0.0499 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.02366\n",
      "Epoch 171/200\n",
      " - 1s - loss: 0.0094 - acc: 0.9974 - val_loss: 0.0380 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.02366\n",
      "Epoch 172/200\n",
      " - 1s - loss: 0.0074 - acc: 0.9974 - val_loss: 0.0362 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.02366\n",
      "Epoch 173/200\n",
      " - 1s - loss: 0.0072 - acc: 0.9987 - val_loss: 0.0309 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.02366\n",
      "Epoch 174/200\n",
      " - 1s - loss: 0.0090 - acc: 0.9974 - val_loss: 0.0332 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.02366\n",
      "Epoch 175/200\n",
      " - 1s - loss: 0.0072 - acc: 0.9980 - val_loss: 0.0365 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.02366\n",
      "Epoch 176/200\n",
      " - 1s - loss: 0.0123 - acc: 0.9967 - val_loss: 0.0379 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.02366\n",
      "Epoch 177/200\n",
      " - 1s - loss: 0.0100 - acc: 0.9967 - val_loss: 0.0459 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.02366\n",
      "Epoch 178/200\n",
      " - 1s - loss: 0.0080 - acc: 0.9980 - val_loss: 0.0452 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.02366\n",
      "Epoch 179/200\n",
      " - 1s - loss: 0.0069 - acc: 0.9980 - val_loss: 0.0397 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.02366\n",
      "Epoch 180/200\n",
      " - 1s - loss: 0.0137 - acc: 0.9961 - val_loss: 0.0414 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.02366\n",
      "Epoch 181/200\n",
      " - 1s - loss: 0.0071 - acc: 0.9980 - val_loss: 0.0396 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.02366\n",
      "Epoch 182/200\n",
      " - 1s - loss: 0.0090 - acc: 0.9974 - val_loss: 0.0411 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.02366\n",
      "Epoch 183/200\n",
      " - 1s - loss: 0.0078 - acc: 0.9974 - val_loss: 0.0353 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.02366\n",
      "Epoch 184/200\n",
      " - 1s - loss: 0.0106 - acc: 0.9967 - val_loss: 0.0373 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.02366\n",
      "Epoch 185/200\n",
      " - 1s - loss: 0.0091 - acc: 0.9967 - val_loss: 0.0325 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.02366\n",
      "Epoch 186/200\n",
      " - 1s - loss: 0.0084 - acc: 0.9967 - val_loss: 0.0404 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.02366\n",
      "Epoch 187/200\n",
      " - 1s - loss: 0.0107 - acc: 0.9967 - val_loss: 0.0538 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.02366\n",
      "Epoch 188/200\n",
      " - 1s - loss: 0.0087 - acc: 0.9974 - val_loss: 0.0368 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.02366\n",
      "Epoch 189/200\n",
      " - 1s - loss: 0.0087 - acc: 0.9974 - val_loss: 0.0384 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.02366\n",
      "Epoch 190/200\n",
      " - 1s - loss: 0.0095 - acc: 0.9967 - val_loss: 0.0368 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.02366\n",
      "Epoch 191/200\n",
      " - 1s - loss: 0.0112 - acc: 0.9967 - val_loss: 0.0365 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.02366\n",
      "Epoch 192/200\n",
      " - 1s - loss: 0.0063 - acc: 0.9980 - val_loss: 0.0566 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.02366\n",
      "Epoch 193/200\n",
      " - 1s - loss: 0.0115 - acc: 0.9961 - val_loss: 0.0382 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.02366\n",
      "Epoch 194/200\n",
      " - 1s - loss: 0.0083 - acc: 0.9980 - val_loss: 0.0404 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.02366\n",
      "Epoch 195/200\n",
      " - 1s - loss: 0.0081 - acc: 0.9974 - val_loss: 0.0477 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.02366\n",
      "Epoch 196/200\n",
      " - 1s - loss: 0.0108 - acc: 0.9967 - val_loss: 0.0483 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.02366\n",
      "Epoch 197/200\n",
      " - 1s - loss: 0.0083 - acc: 0.9974 - val_loss: 0.0333 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.02366\n",
      "Epoch 198/200\n",
      " - 1s - loss: 0.0090 - acc: 0.9967 - val_loss: 0.0459 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.02366\n",
      "Epoch 199/200\n",
      " - 1s - loss: 0.0095 - acc: 0.9974 - val_loss: 0.0374 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.02366\n",
      "Epoch 200/200\n",
      " - 1s - loss: 0.0083 - acc: 0.9967 - val_loss: 0.0320 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.02366\n",
      "batch_size=10   optimizer=Adam\n",
      "Test accuracy: 68.2451%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_42 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 2s - loss: 1.8352 - acc: 0.3658 - val_loss: 1.3071 - val_acc: 0.5432\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.30712, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.1828 - acc: 0.6046 - val_loss: 1.0678 - val_acc: 0.6543\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.30712 to 1.06783, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.9918 - acc: 0.6691 - val_loss: 0.8950 - val_acc: 0.7078\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.06783 to 0.89497, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.8697 - acc: 0.7184 - val_loss: 0.8176 - val_acc: 0.7202\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.89497 to 0.81760, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.7767 - acc: 0.7467 - val_loss: 0.7143 - val_acc: 0.7901\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.81760 to 0.71425, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.7045 - acc: 0.7691 - val_loss: 0.6897 - val_acc: 0.7901\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.71425 to 0.68966, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.6421 - acc: 0.7954 - val_loss: 0.6021 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.68966 to 0.60211, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.5919 - acc: 0.8178 - val_loss: 0.5855 - val_acc: 0.8354\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.60211 to 0.58550, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.5447 - acc: 0.8382 - val_loss: 0.5192 - val_acc: 0.9012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00009: val_loss improved from 0.58550 to 0.51921, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.5102 - acc: 0.8586 - val_loss: 0.5395 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.51921\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.4821 - acc: 0.8586 - val_loss: 0.4764 - val_acc: 0.8765\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.51921 to 0.47637, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.4615 - acc: 0.8717 - val_loss: 0.4276 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.47637 to 0.42761, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.4047 - acc: 0.9020 - val_loss: 0.4283 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.42761\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3889 - acc: 0.9066 - val_loss: 0.3811 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.42761 to 0.38114, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.3629 - acc: 0.9211 - val_loss: 0.3601 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.38114 to 0.36007, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.3375 - acc: 0.9204 - val_loss: 0.3347 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.36007 to 0.33468, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.3168 - acc: 0.9401 - val_loss: 0.3111 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.33468 to 0.31114, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.2999 - acc: 0.9454 - val_loss: 0.3013 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.31114 to 0.30128, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2802 - acc: 0.9599 - val_loss: 0.2725 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.30128 to 0.27253, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2703 - acc: 0.9539 - val_loss: 0.2710 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.27253 to 0.27105, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.2581 - acc: 0.9599 - val_loss: 0.2654 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.27105 to 0.26543, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2385 - acc: 0.9691 - val_loss: 0.2465 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.26543 to 0.24647, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2283 - acc: 0.9717 - val_loss: 0.2385 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.24647 to 0.23849, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2173 - acc: 0.9691 - val_loss: 0.2184 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.23849 to 0.21836, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2022 - acc: 0.9816 - val_loss: 0.2041 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.21836 to 0.20414, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.1891 - acc: 0.9842 - val_loss: 0.2092 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.20414\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.1836 - acc: 0.9803 - val_loss: 0.1966 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.20414 to 0.19658, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.1737 - acc: 0.9868 - val_loss: 0.1790 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.19658 to 0.17896, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.1629 - acc: 0.9901 - val_loss: 0.1855 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.17896\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.1547 - acc: 0.9921 - val_loss: 0.1620 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.17896 to 0.16202, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.1491 - acc: 0.9908 - val_loss: 0.1727 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.16202\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.1428 - acc: 0.9914 - val_loss: 0.1555 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.16202 to 0.15551, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.1344 - acc: 0.9928 - val_loss: 0.1521 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.15551 to 0.15211, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.1281 - acc: 0.9941 - val_loss: 0.1373 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.15211 to 0.13726, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.1246 - acc: 0.9947 - val_loss: 0.1453 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.13726\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.1174 - acc: 0.9934 - val_loss: 0.1410 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.13726\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.1119 - acc: 0.9967 - val_loss: 0.1351 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.13726 to 0.13514, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.1087 - acc: 0.9947 - val_loss: 0.1345 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.13514 to 0.13455, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.1048 - acc: 0.9967 - val_loss: 0.1154 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.13455 to 0.11540, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.0991 - acc: 0.9947 - val_loss: 0.1129 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.11540 to 0.11287, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.0945 - acc: 0.9947 - val_loss: 0.1205 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.11287\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.0893 - acc: 0.9980 - val_loss: 0.1007 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.11287 to 0.10072, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.0860 - acc: 0.9961 - val_loss: 0.1038 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.10072\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.0818 - acc: 0.9980 - val_loss: 0.1135 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.10072\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.0818 - acc: 0.9974 - val_loss: 0.0981 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.10072 to 0.09807, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.0775 - acc: 0.9967 - val_loss: 0.0977 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.09807 to 0.09766, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.0743 - acc: 0.9961 - val_loss: 0.0967 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.09766 to 0.09674, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.0743 - acc: 0.9974 - val_loss: 0.0906 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.09674 to 0.09055, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.0693 - acc: 0.9967 - val_loss: 0.0895 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.09055 to 0.08948, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.0646 - acc: 0.9974 - val_loss: 0.0942 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.08948\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.0631 - acc: 0.9967 - val_loss: 0.0844 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.08948 to 0.08437, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.0605 - acc: 0.9967 - val_loss: 0.0855 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.08437\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.0594 - acc: 0.9974 - val_loss: 0.0779 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.08437 to 0.07788, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.0570 - acc: 0.9974 - val_loss: 0.0747 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.07788 to 0.07470, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.0537 - acc: 0.9974 - val_loss: 0.0793 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.07470\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.0545 - acc: 0.9967 - val_loss: 0.0754 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.07470\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.0507 - acc: 0.9967 - val_loss: 0.0781 - val_acc: 0.9877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00057: val_loss did not improve from 0.07470\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.0484 - acc: 0.9980 - val_loss: 0.0653 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.07470 to 0.06528, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.0471 - acc: 0.9967 - val_loss: 0.0674 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.06528\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.0460 - acc: 0.9974 - val_loss: 0.0691 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.06528\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.0448 - acc: 0.9980 - val_loss: 0.0794 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.06528\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.0426 - acc: 0.9974 - val_loss: 0.0728 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.06528\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.0418 - acc: 0.9974 - val_loss: 0.0705 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.06528\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.0405 - acc: 0.9974 - val_loss: 0.0653 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.06528\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.0394 - acc: 0.9980 - val_loss: 0.0588 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.06528 to 0.05882, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.0373 - acc: 0.9987 - val_loss: 0.0640 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.05882\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.0362 - acc: 0.9974 - val_loss: 0.0618 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.05882\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.0361 - acc: 0.9967 - val_loss: 0.0569 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.05882 to 0.05687, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.0368 - acc: 0.9980 - val_loss: 0.0630 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.05687\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.0332 - acc: 0.9980 - val_loss: 0.0519 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.05687 to 0.05185, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.0338 - acc: 0.9967 - val_loss: 0.0567 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.05185\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.0326 - acc: 0.9967 - val_loss: 0.0569 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.05185\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.0300 - acc: 0.9961 - val_loss: 0.0523 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.05185\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.0302 - acc: 0.9974 - val_loss: 0.0592 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.05185\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.0290 - acc: 0.9974 - val_loss: 0.0523 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.05185\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.0279 - acc: 0.9974 - val_loss: 0.0607 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.05185\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.0286 - acc: 0.9967 - val_loss: 0.0504 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.05185 to 0.05036, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.0264 - acc: 0.9967 - val_loss: 0.0488 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.05036 to 0.04885, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.0254 - acc: 0.9974 - val_loss: 0.0475 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.04885 to 0.04747, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0250 - acc: 0.9974 - val_loss: 0.0432 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.04747 to 0.04325, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0256 - acc: 0.9961 - val_loss: 0.0470 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.04325\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0228 - acc: 0.9980 - val_loss: 0.0500 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.04325\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0228 - acc: 0.9967 - val_loss: 0.0451 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.04325\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0229 - acc: 0.9980 - val_loss: 0.0551 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.04325\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0228 - acc: 0.9974 - val_loss: 0.0451 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.04325\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0221 - acc: 0.9974 - val_loss: 0.0442 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.04325\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0224 - acc: 0.9980 - val_loss: 0.0513 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.04325\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0204 - acc: 0.9980 - val_loss: 0.0486 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.04325\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0197 - acc: 0.9974 - val_loss: 0.0396 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.04325 to 0.03962, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0213 - acc: 0.9974 - val_loss: 0.0450 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.03962\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0225 - acc: 0.9967 - val_loss: 0.0461 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.03962\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0200 - acc: 0.9961 - val_loss: 0.0471 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.03962\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0193 - acc: 0.9974 - val_loss: 0.0474 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.03962\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0164 - acc: 0.9980 - val_loss: 0.0425 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.03962\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0178 - acc: 0.9974 - val_loss: 0.0438 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.03962\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0172 - acc: 0.9980 - val_loss: 0.0423 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.03962\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0175 - acc: 0.9974 - val_loss: 0.0455 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.03962\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0183 - acc: 0.9974 - val_loss: 0.0414 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.03962\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0158 - acc: 0.9967 - val_loss: 0.0377 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.03962 to 0.03769, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0159 - acc: 0.9974 - val_loss: 0.0415 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.03769\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0161 - acc: 0.9974 - val_loss: 0.0470 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.03769\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0169 - acc: 0.9967 - val_loss: 0.0429 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.03769\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0143 - acc: 0.9974 - val_loss: 0.0348 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.03769 to 0.03484, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0146 - acc: 0.9967 - val_loss: 0.0381 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.03484\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0148 - acc: 0.9967 - val_loss: 0.0411 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.03484\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0145 - acc: 0.9961 - val_loss: 0.0394 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.03484\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0137 - acc: 0.9974 - val_loss: 0.0431 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.03484\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0135 - acc: 0.9980 - val_loss: 0.0378 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.03484\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0144 - acc: 0.9980 - val_loss: 0.0494 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.03484\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0137 - acc: 0.9980 - val_loss: 0.0429 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.03484\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0130 - acc: 0.9974 - val_loss: 0.0393 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.03484\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0127 - acc: 0.9974 - val_loss: 0.0398 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.03484\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0133 - acc: 0.9974 - val_loss: 0.0375 - val_acc: 0.9918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00113: val_loss did not improve from 0.03484\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0127 - acc: 0.9974 - val_loss: 0.0465 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.03484\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0130 - acc: 0.9974 - val_loss: 0.0436 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.03484\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0141 - acc: 0.9974 - val_loss: 0.0364 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.03484\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0129 - acc: 0.9974 - val_loss: 0.0321 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.03484 to 0.03205, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0136 - acc: 0.9974 - val_loss: 0.0360 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.03205\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0145 - acc: 0.9961 - val_loss: 0.0438 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.03205\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0120 - acc: 0.9974 - val_loss: 0.0323 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.03205\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0109 - acc: 0.9974 - val_loss: 0.0302 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.03205 to 0.03023, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0123 - acc: 0.9974 - val_loss: 0.0372 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.03023\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0106 - acc: 0.9987 - val_loss: 0.0339 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.03023\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0110 - acc: 0.9967 - val_loss: 0.0308 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.03023\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0112 - acc: 0.9974 - val_loss: 0.0403 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.03023\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0125 - acc: 0.9961 - val_loss: 0.0397 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.03023\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0118 - acc: 0.9980 - val_loss: 0.0341 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.03023\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0112 - acc: 0.9974 - val_loss: 0.0371 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.03023\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0103 - acc: 0.9974 - val_loss: 0.0356 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.03023\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0102 - acc: 0.9967 - val_loss: 0.0441 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.03023\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0092 - acc: 0.9980 - val_loss: 0.0422 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.03023\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0110 - acc: 0.9974 - val_loss: 0.0328 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.03023\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0100 - acc: 0.9980 - val_loss: 0.0348 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.03023\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0099 - acc: 0.9967 - val_loss: 0.0354 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.03023\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0108 - acc: 0.9974 - val_loss: 0.0382 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.03023\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0095 - acc: 0.9974 - val_loss: 0.0376 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.03023\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0091 - acc: 0.9967 - val_loss: 0.0335 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.03023\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0090 - acc: 0.9974 - val_loss: 0.0372 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.03023\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0095 - acc: 0.9974 - val_loss: 0.0380 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.03023\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0098 - acc: 0.9974 - val_loss: 0.0394 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.03023\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0084 - acc: 0.9974 - val_loss: 0.0331 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.03023\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0104 - acc: 0.9967 - val_loss: 0.0363 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.03023\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0099 - acc: 0.9980 - val_loss: 0.0398 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.03023\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0110 - acc: 0.9967 - val_loss: 0.0347 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.03023\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0099 - acc: 0.9974 - val_loss: 0.0425 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.03023\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0077 - acc: 0.9980 - val_loss: 0.0393 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.03023\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0089 - acc: 0.9974 - val_loss: 0.0405 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.03023\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0079 - acc: 0.9980 - val_loss: 0.0441 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.03023\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0120 - acc: 0.9967 - val_loss: 0.0373 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.03023\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0099 - acc: 0.9967 - val_loss: 0.0348 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.03023\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0104 - acc: 0.9967 - val_loss: 0.0327 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.03023\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0085 - acc: 0.9980 - val_loss: 0.0305 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.03023\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0095 - acc: 0.9967 - val_loss: 0.0355 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.03023\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0096 - acc: 0.9967 - val_loss: 0.0319 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.03023\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.0080 - acc: 0.9974 - val_loss: 0.0372 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.03023\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.0084 - acc: 0.9967 - val_loss: 0.0415 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.03023\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0092 - acc: 0.9967 - val_loss: 0.0414 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.03023\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.0089 - acc: 0.9974 - val_loss: 0.0355 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.03023\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.0080 - acc: 0.9974 - val_loss: 0.0346 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.03023\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.0069 - acc: 0.9980 - val_loss: 0.0319 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.03023\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.0098 - acc: 0.9967 - val_loss: 0.0298 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.03023 to 0.02980, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.0079 - acc: 0.9967 - val_loss: 0.0471 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.02980\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.0103 - acc: 0.9967 - val_loss: 0.0373 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.02980\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.0085 - acc: 0.9967 - val_loss: 0.0334 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.02980\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.0072 - acc: 0.9980 - val_loss: 0.0395 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.02980\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.0091 - acc: 0.9974 - val_loss: 0.0320 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.02980\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.0105 - acc: 0.9961 - val_loss: 0.0313 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.02980\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.0081 - acc: 0.9974 - val_loss: 0.0324 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.02980\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.0063 - acc: 0.9980 - val_loss: 0.0351 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.02980\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.0066 - acc: 0.9974 - val_loss: 0.0405 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.02980\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.0087 - acc: 0.9974 - val_loss: 0.0342 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.02980\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.0078 - acc: 0.9967 - val_loss: 0.0426 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.02980\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.0085 - acc: 0.9967 - val_loss: 0.0347 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.02980\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.0070 - acc: 0.9974 - val_loss: 0.0357 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.02980\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.0091 - acc: 0.9967 - val_loss: 0.0316 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.02980\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.0088 - acc: 0.9974 - val_loss: 0.0292 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00176: val_loss improved from 0.02980 to 0.02922, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.0074 - acc: 0.9974 - val_loss: 0.0310 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.02922\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.0084 - acc: 0.9974 - val_loss: 0.0329 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.02922\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.0087 - acc: 0.9967 - val_loss: 0.0499 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.02922\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.0096 - acc: 0.9967 - val_loss: 0.0274 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00180: val_loss improved from 0.02922 to 0.02739, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.0083 - acc: 0.9974 - val_loss: 0.0344 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.02739\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.0094 - acc: 0.9967 - val_loss: 0.0419 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.02739\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.0068 - acc: 0.9974 - val_loss: 0.0297 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.02739\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.0081 - acc: 0.9974 - val_loss: 0.0420 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.02739\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.0072 - acc: 0.9974 - val_loss: 0.0469 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.02739\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.0076 - acc: 0.9967 - val_loss: 0.0291 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.02739\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.0074 - acc: 0.9967 - val_loss: 0.0348 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.02739\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.0079 - acc: 0.9967 - val_loss: 0.0331 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.02739\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.0081 - acc: 0.9974 - val_loss: 0.0492 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.02739\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.0078 - acc: 0.9974 - val_loss: 0.0313 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.02739\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.0094 - acc: 0.9967 - val_loss: 0.0347 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.02739\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.0051 - acc: 0.9974 - val_loss: 0.0333 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.02739\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.0074 - acc: 0.9974 - val_loss: 0.0400 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.02739\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.0075 - acc: 0.9974 - val_loss: 0.0295 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.02739\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.0093 - acc: 0.9967 - val_loss: 0.0362 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.02739\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.0058 - acc: 0.9980 - val_loss: 0.0367 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.02739\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.0059 - acc: 0.9980 - val_loss: 0.0333 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.02739\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.0064 - acc: 0.9974 - val_loss: 0.0359 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.02739\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.0088 - acc: 0.9974 - val_loss: 0.0329 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.02739\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.0077 - acc: 0.9967 - val_loss: 0.0360 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.02739\n",
      "batch_size=20   optimizer=Adam\n",
      "Test accuracy: 68.5237%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_43 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 2.0219 - acc: 0.2822 - val_loss: 1.5380 - val_acc: 0.4733\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.53801, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.3267 - acc: 0.5697 - val_loss: 1.1697 - val_acc: 0.6132\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.53801 to 1.16965, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 1.0955 - acc: 0.6447 - val_loss: 1.0440 - val_acc: 0.6543\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.16965 to 1.04400, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.9660 - acc: 0.6947 - val_loss: 0.9219 - val_acc: 0.6872\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.04400 to 0.92188, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.8812 - acc: 0.7224 - val_loss: 0.8555 - val_acc: 0.7366\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.92188 to 0.85547, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.8180 - acc: 0.7507 - val_loss: 0.7742 - val_acc: 0.7572\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.85547 to 0.77415, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.7628 - acc: 0.7658 - val_loss: 0.7415 - val_acc: 0.7737\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.77415 to 0.74153, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.7029 - acc: 0.7875 - val_loss: 0.6916 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.74153 to 0.69157, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.6565 - acc: 0.8053 - val_loss: 0.6399 - val_acc: 0.8148\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.69157 to 0.63990, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.6264 - acc: 0.8132 - val_loss: 0.6125 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.63990 to 0.61246, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.5944 - acc: 0.8197 - val_loss: 0.5907 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.61246 to 0.59073, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.5579 - acc: 0.8414 - val_loss: 0.5448 - val_acc: 0.8354\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.59073 to 0.54479, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.5239 - acc: 0.8533 - val_loss: 0.5137 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.54479 to 0.51368, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.5017 - acc: 0.8553 - val_loss: 0.4923 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.51368 to 0.49234, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.4763 - acc: 0.8730 - val_loss: 0.4848 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.49234 to 0.48476, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.4532 - acc: 0.8776 - val_loss: 0.4664 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.48476 to 0.46641, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.4307 - acc: 0.8961 - val_loss: 0.4290 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.46641 to 0.42904, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.4109 - acc: 0.8980 - val_loss: 0.4148 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.42904 to 0.41478, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.3904 - acc: 0.9112 - val_loss: 0.3989 - val_acc: 0.9218\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00019: val_loss improved from 0.41478 to 0.39891, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.3780 - acc: 0.9145 - val_loss: 0.3782 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.39891 to 0.37821, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.3618 - acc: 0.9243 - val_loss: 0.3646 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.37821 to 0.36460, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.3494 - acc: 0.9243 - val_loss: 0.3498 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.36460 to 0.34984, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.3335 - acc: 0.9303 - val_loss: 0.3413 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.34984 to 0.34133, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.3161 - acc: 0.9428 - val_loss: 0.3385 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.34133 to 0.33855, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.3050 - acc: 0.9395 - val_loss: 0.3174 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.33855 to 0.31738, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2931 - acc: 0.9507 - val_loss: 0.3069 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.31738 to 0.30694, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2793 - acc: 0.9520 - val_loss: 0.2941 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.30694 to 0.29409, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2674 - acc: 0.9625 - val_loss: 0.2668 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.29409 to 0.26678, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2583 - acc: 0.9658 - val_loss: 0.2813 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.26678\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2547 - acc: 0.9632 - val_loss: 0.2750 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.26678\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2371 - acc: 0.9730 - val_loss: 0.2553 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.26678 to 0.25530, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2307 - acc: 0.9737 - val_loss: 0.2397 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.25530 to 0.23969, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2221 - acc: 0.9763 - val_loss: 0.2288 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.23969 to 0.22876, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2116 - acc: 0.9803 - val_loss: 0.2312 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.22876\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2063 - acc: 0.9750 - val_loss: 0.2217 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.22876 to 0.22168, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2019 - acc: 0.9803 - val_loss: 0.2085 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.22168 to 0.20851, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.1928 - acc: 0.9822 - val_loss: 0.2156 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.20851\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.1856 - acc: 0.9849 - val_loss: 0.1909 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.20851 to 0.19089, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.1789 - acc: 0.9842 - val_loss: 0.1855 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.19089 to 0.18548, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.1725 - acc: 0.9875 - val_loss: 0.1861 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.18548\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.1675 - acc: 0.9888 - val_loss: 0.1835 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.18548 to 0.18346, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.1619 - acc: 0.9875 - val_loss: 0.1705 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.18346 to 0.17052, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1544 - acc: 0.9901 - val_loss: 0.1747 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.17052\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1517 - acc: 0.9928 - val_loss: 0.1679 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.17052 to 0.16787, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1482 - acc: 0.9934 - val_loss: 0.1601 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.16787 to 0.16010, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1420 - acc: 0.9928 - val_loss: 0.1606 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.16010\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1378 - acc: 0.9954 - val_loss: 0.1511 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.16010 to 0.15108, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1337 - acc: 0.9934 - val_loss: 0.1663 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.15108\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1308 - acc: 0.9941 - val_loss: 0.1463 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.15108 to 0.14634, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1251 - acc: 0.9941 - val_loss: 0.1380 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.14634 to 0.13804, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1240 - acc: 0.9947 - val_loss: 0.1344 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.13804 to 0.13439, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1239 - acc: 0.9908 - val_loss: 0.1297 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.13439 to 0.12968, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1157 - acc: 0.9941 - val_loss: 0.1300 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.12968\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1099 - acc: 0.9967 - val_loss: 0.1269 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.12968 to 0.12687, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1064 - acc: 0.9967 - val_loss: 0.1204 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.12687 to 0.12040, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1046 - acc: 0.9961 - val_loss: 0.1197 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.12040 to 0.11970, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1013 - acc: 0.9967 - val_loss: 0.1229 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.11970\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.0976 - acc: 0.9967 - val_loss: 0.1170 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.11970 to 0.11705, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.0951 - acc: 0.9967 - val_loss: 0.1156 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.11705 to 0.11560, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.0956 - acc: 0.9967 - val_loss: 0.1108 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.11560 to 0.11076, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.0910 - acc: 0.9980 - val_loss: 0.1084 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.11076 to 0.10844, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.0872 - acc: 0.9967 - val_loss: 0.1050 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.10844 to 0.10502, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.0876 - acc: 0.9967 - val_loss: 0.1052 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.10502\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.0868 - acc: 0.9954 - val_loss: 0.1019 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.10502 to 0.10189, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.0816 - acc: 0.9980 - val_loss: 0.0949 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.10189 to 0.09487, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.0797 - acc: 0.9974 - val_loss: 0.0937 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.09487 to 0.09371, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.0762 - acc: 0.9987 - val_loss: 0.0991 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.09371\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.0765 - acc: 0.9967 - val_loss: 0.0995 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.09371\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.0742 - acc: 0.9974 - val_loss: 0.1004 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.09371\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.0718 - acc: 0.9980 - val_loss: 0.0905 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.09371 to 0.09053, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.0710 - acc: 0.9967 - val_loss: 0.0869 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.09053 to 0.08694, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.0689 - acc: 0.9974 - val_loss: 0.0879 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.08694\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.0664 - acc: 0.9967 - val_loss: 0.0812 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.08694 to 0.08123, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.0658 - acc: 0.9967 - val_loss: 0.0824 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.08123\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.0637 - acc: 0.9974 - val_loss: 0.0814 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.08123\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.0614 - acc: 0.9980 - val_loss: 0.0771 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.08123 to 0.07710, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.0605 - acc: 0.9974 - val_loss: 0.0779 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.07710\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.0591 - acc: 0.9974 - val_loss: 0.0787 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.07710\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.0576 - acc: 0.9974 - val_loss: 0.0766 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.07710 to 0.07662, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0567 - acc: 0.9980 - val_loss: 0.0732 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.07662 to 0.07324, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0546 - acc: 0.9980 - val_loss: 0.0779 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.07324\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0539 - acc: 0.9967 - val_loss: 0.0697 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.07324 to 0.06972, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0530 - acc: 0.9980 - val_loss: 0.0714 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.06972\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0515 - acc: 0.9974 - val_loss: 0.0683 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.06972 to 0.06834, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0506 - acc: 0.9974 - val_loss: 0.0669 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.06834 to 0.06687, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0491 - acc: 0.9987 - val_loss: 0.0698 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.06687\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0483 - acc: 0.9974 - val_loss: 0.0658 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.06687 to 0.06580, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0469 - acc: 0.9987 - val_loss: 0.0722 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.06580\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0467 - acc: 0.9967 - val_loss: 0.0678 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.06580\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0456 - acc: 0.9980 - val_loss: 0.0658 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.06580\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0441 - acc: 0.9974 - val_loss: 0.0617 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.06580 to 0.06168, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0446 - acc: 0.9974 - val_loss: 0.0616 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.06168 to 0.06164, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0429 - acc: 0.9961 - val_loss: 0.0606 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.06164 to 0.06064, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0419 - acc: 0.9974 - val_loss: 0.0622 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.06064\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0420 - acc: 0.9980 - val_loss: 0.0590 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.06064 to 0.05903, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0398 - acc: 0.9980 - val_loss: 0.0567 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.05903 to 0.05674, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0390 - acc: 0.9967 - val_loss: 0.0555 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.05674 to 0.05548, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0387 - acc: 0.9980 - val_loss: 0.0565 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.05548\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0386 - acc: 0.9967 - val_loss: 0.0589 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.05548\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0369 - acc: 0.9980 - val_loss: 0.0582 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.05548\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0375 - acc: 0.9967 - val_loss: 0.0552 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.05548 to 0.05525, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0362 - acc: 0.9974 - val_loss: 0.0543 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.05525 to 0.05426, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0345 - acc: 0.9974 - val_loss: 0.0508 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.05426 to 0.05083, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0347 - acc: 0.9961 - val_loss: 0.0518 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.05083\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0342 - acc: 0.9980 - val_loss: 0.0496 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.05083 to 0.04960, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0334 - acc: 0.9980 - val_loss: 0.0510 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.04960\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0333 - acc: 0.9967 - val_loss: 0.0516 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.04960\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0323 - acc: 0.9967 - val_loss: 0.0481 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.04960 to 0.04809, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0318 - acc: 0.9974 - val_loss: 0.0494 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.04809\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0315 - acc: 0.9974 - val_loss: 0.0520 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.04809\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0317 - acc: 0.9967 - val_loss: 0.0455 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.04809 to 0.04549, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0300 - acc: 0.9987 - val_loss: 0.0461 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.04549\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0298 - acc: 0.9967 - val_loss: 0.0508 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.04549\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0294 - acc: 0.9987 - val_loss: 0.0436 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.04549 to 0.04362, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0280 - acc: 0.9974 - val_loss: 0.0457 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.04362\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0279 - acc: 0.9967 - val_loss: 0.0451 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.04362\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0274 - acc: 0.9967 - val_loss: 0.0466 - val_acc: 0.9959\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00117: val_loss did not improve from 0.04362\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0267 - acc: 0.9967 - val_loss: 0.0458 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.04362\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0258 - acc: 0.9980 - val_loss: 0.0468 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.04362\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0265 - acc: 0.9974 - val_loss: 0.0428 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.04362 to 0.04276, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0259 - acc: 0.9967 - val_loss: 0.0470 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.04276\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0254 - acc: 0.9967 - val_loss: 0.0426 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.04276 to 0.04259, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0249 - acc: 0.9980 - val_loss: 0.0417 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.04259 to 0.04170, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0242 - acc: 0.9980 - val_loss: 0.0435 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.04170\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0238 - acc: 0.9974 - val_loss: 0.0408 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.04170 to 0.04075, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0240 - acc: 0.9967 - val_loss: 0.0452 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.04075\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0225 - acc: 0.9980 - val_loss: 0.0425 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.04075\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0230 - acc: 0.9967 - val_loss: 0.0423 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.04075\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0228 - acc: 0.9974 - val_loss: 0.0409 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.04075\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0221 - acc: 0.9974 - val_loss: 0.0392 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.04075 to 0.03918, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0223 - acc: 0.9967 - val_loss: 0.0415 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.03918\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0218 - acc: 0.9967 - val_loss: 0.0405 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.03918\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0207 - acc: 0.9974 - val_loss: 0.0439 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.03918\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0210 - acc: 0.9974 - val_loss: 0.0417 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.03918\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0224 - acc: 0.9974 - val_loss: 0.0429 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.03918\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0206 - acc: 0.9974 - val_loss: 0.0419 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.03918\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0197 - acc: 0.9974 - val_loss: 0.0392 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.03918 to 0.03917, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0193 - acc: 0.9967 - val_loss: 0.0413 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.03917\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0194 - acc: 0.9974 - val_loss: 0.0354 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.03917 to 0.03539, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0195 - acc: 0.9967 - val_loss: 0.0357 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.03539\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0185 - acc: 0.9967 - val_loss: 0.0380 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.03539\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0187 - acc: 0.9961 - val_loss: 0.0358 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.03539\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0189 - acc: 0.9974 - val_loss: 0.0374 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.03539\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0195 - acc: 0.9967 - val_loss: 0.0370 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.03539\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0180 - acc: 0.9980 - val_loss: 0.0363 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.03539\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0177 - acc: 0.9980 - val_loss: 0.0364 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.03539\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0176 - acc: 0.9974 - val_loss: 0.0370 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.03539\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0169 - acc: 0.9980 - val_loss: 0.0359 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.03539\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0164 - acc: 0.9974 - val_loss: 0.0392 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.03539\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0163 - acc: 0.9974 - val_loss: 0.0383 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.03539\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0160 - acc: 0.9974 - val_loss: 0.0372 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.03539\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0166 - acc: 0.9987 - val_loss: 0.0329 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.03539 to 0.03291, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0158 - acc: 0.9974 - val_loss: 0.0382 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.03291\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0166 - acc: 0.9967 - val_loss: 0.0371 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.03291\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.0162 - acc: 0.9974 - val_loss: 0.0358 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.03291\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.0155 - acc: 0.9967 - val_loss: 0.0330 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.03291\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0156 - acc: 0.9974 - val_loss: 0.0399 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.03291\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.0161 - acc: 0.9974 - val_loss: 0.0345 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.03291\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.0151 - acc: 0.9967 - val_loss: 0.0334 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.03291\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.0152 - acc: 0.9974 - val_loss: 0.0308 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.03291 to 0.03077, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.0148 - acc: 0.9974 - val_loss: 0.0316 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.03077\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.0147 - acc: 0.9961 - val_loss: 0.0348 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.03077\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.0166 - acc: 0.9967 - val_loss: 0.0307 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00163: val_loss improved from 0.03077 to 0.03075, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.0142 - acc: 0.9967 - val_loss: 0.0347 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.03075\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.0138 - acc: 0.9974 - val_loss: 0.0319 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.03075\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.0146 - acc: 0.9974 - val_loss: 0.0310 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.03075\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.0149 - acc: 0.9967 - val_loss: 0.0323 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.03075\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.0135 - acc: 0.9967 - val_loss: 0.0318 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.03075\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.0139 - acc: 0.9980 - val_loss: 0.0468 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.03075\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.0131 - acc: 0.9980 - val_loss: 0.0341 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.03075\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.0131 - acc: 0.9967 - val_loss: 0.0355 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.03075\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.0137 - acc: 0.9974 - val_loss: 0.0365 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.03075\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.0127 - acc: 0.9980 - val_loss: 0.0303 - val_acc: 0.9959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00173: val_loss improved from 0.03075 to 0.03033, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.0122 - acc: 0.9967 - val_loss: 0.0289 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.03033 to 0.02892, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.0120 - acc: 0.9967 - val_loss: 0.0357 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.02892\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.0119 - acc: 0.9980 - val_loss: 0.0323 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.02892\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.0137 - acc: 0.9967 - val_loss: 0.0405 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.02892\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.0126 - acc: 0.9974 - val_loss: 0.0321 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.02892\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.0123 - acc: 0.9974 - val_loss: 0.0310 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.02892\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.0142 - acc: 0.9967 - val_loss: 0.0312 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.02892\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.0124 - acc: 0.9974 - val_loss: 0.0318 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.02892\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.0112 - acc: 0.9967 - val_loss: 0.0307 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.02892\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.0107 - acc: 0.9980 - val_loss: 0.0311 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.02892\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.0118 - acc: 0.9967 - val_loss: 0.0319 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.02892\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.0114 - acc: 0.9980 - val_loss: 0.0305 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.02892\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.0113 - acc: 0.9980 - val_loss: 0.0302 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.02892\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.0109 - acc: 0.9974 - val_loss: 0.0298 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.02892\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.0118 - acc: 0.9967 - val_loss: 0.0282 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00188: val_loss improved from 0.02892 to 0.02823, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.0111 - acc: 0.9974 - val_loss: 0.0300 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.02823\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.0115 - acc: 0.9967 - val_loss: 0.0329 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.02823\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.0109 - acc: 0.9961 - val_loss: 0.0320 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.02823\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.0106 - acc: 0.9974 - val_loss: 0.0269 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.02823 to 0.02692, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.0108 - acc: 0.9974 - val_loss: 0.0298 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.02692\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.0110 - acc: 0.9987 - val_loss: 0.0315 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.02692\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.0099 - acc: 0.9967 - val_loss: 0.0300 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.02692\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.0103 - acc: 0.9980 - val_loss: 0.0285 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.02692\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.0101 - acc: 0.9974 - val_loss: 0.0297 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.02692\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.0105 - acc: 0.9974 - val_loss: 0.0278 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.02692\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.0112 - acc: 0.9974 - val_loss: 0.0307 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.02692\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.0109 - acc: 0.9967 - val_loss: 0.0294 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.02692\n",
      "batch_size=40   optimizer=Adam\n",
      "Test accuracy: 67.1309%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_44 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 2.1320 - acc: 0.2263 - val_loss: 1.7571 - val_acc: 0.3909\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.75710, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.4998 - acc: 0.4836 - val_loss: 1.3713 - val_acc: 0.5144\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.75710 to 1.37135, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 1.2460 - acc: 0.5868 - val_loss: 1.2207 - val_acc: 0.6091\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.37135 to 1.22066, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 1.0996 - acc: 0.6461 - val_loss: 1.0881 - val_acc: 0.6255\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.22066 to 1.08809, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.9995 - acc: 0.6763 - val_loss: 1.0064 - val_acc: 0.6502\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.08809 to 1.00645, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.9240 - acc: 0.7046 - val_loss: 0.9501 - val_acc: 0.6708\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.00645 to 0.95010, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.8654 - acc: 0.7322 - val_loss: 0.8880 - val_acc: 0.7160\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.95010 to 0.88795, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.8219 - acc: 0.7382 - val_loss: 0.8342 - val_acc: 0.7160\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.88795 to 0.83420, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.7712 - acc: 0.7579 - val_loss: 0.7859 - val_acc: 0.7490\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.83420 to 0.78591, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.7392 - acc: 0.7599 - val_loss: 0.7707 - val_acc: 0.7490\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.78591 to 0.77068, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.6993 - acc: 0.7737 - val_loss: 0.7162 - val_acc: 0.7737\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.77068 to 0.71620, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.6618 - acc: 0.7974 - val_loss: 0.6824 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.71620 to 0.68239, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.6422 - acc: 0.8033 - val_loss: 0.6926 - val_acc: 0.7613\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.68239\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.6102 - acc: 0.8224 - val_loss: 0.6295 - val_acc: 0.8107\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.68239 to 0.62954, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.5886 - acc: 0.8197 - val_loss: 0.6434 - val_acc: 0.7860\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.62954\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.5669 - acc: 0.8421 - val_loss: 0.6126 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.62954 to 0.61259, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.5419 - acc: 0.8447 - val_loss: 0.5561 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.61259 to 0.55612, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.5226 - acc: 0.8592 - val_loss: 0.5468 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.55612 to 0.54678, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.5110 - acc: 0.8586 - val_loss: 0.5219 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.54678 to 0.52189, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.4921 - acc: 0.8684 - val_loss: 0.5069 - val_acc: 0.8765\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.52189 to 0.50686, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.4753 - acc: 0.8697 - val_loss: 0.4873 - val_acc: 0.8724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00021: val_loss improved from 0.50686 to 0.48733, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.4574 - acc: 0.8783 - val_loss: 0.4657 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.48733 to 0.46567, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.4421 - acc: 0.8868 - val_loss: 0.4573 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.46567 to 0.45732, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.4216 - acc: 0.9000 - val_loss: 0.4365 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.45732 to 0.43645, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.4156 - acc: 0.9013 - val_loss: 0.4399 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.43645\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.3996 - acc: 0.9046 - val_loss: 0.4142 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.43645 to 0.41421, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.3838 - acc: 0.9125 - val_loss: 0.4062 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.41421 to 0.40624, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.3771 - acc: 0.9145 - val_loss: 0.3897 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.40624 to 0.38974, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.3648 - acc: 0.9250 - val_loss: 0.3907 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.38974\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.3548 - acc: 0.9230 - val_loss: 0.3729 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.38974 to 0.37286, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.3463 - acc: 0.9263 - val_loss: 0.3719 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.37286 to 0.37191, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.3308 - acc: 0.9401 - val_loss: 0.3764 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.37191\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.3242 - acc: 0.9408 - val_loss: 0.3532 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.37191 to 0.35321, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.3104 - acc: 0.9493 - val_loss: 0.3335 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.35321 to 0.33350, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.3055 - acc: 0.9480 - val_loss: 0.3204 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.33350 to 0.32043, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2943 - acc: 0.9559 - val_loss: 0.3122 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.32043 to 0.31225, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2911 - acc: 0.9553 - val_loss: 0.3103 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.31225 to 0.31029, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2821 - acc: 0.9592 - val_loss: 0.2920 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.31029 to 0.29200, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.2743 - acc: 0.9618 - val_loss: 0.2933 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.29200\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.2679 - acc: 0.9605 - val_loss: 0.2898 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.29200 to 0.28978, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.2601 - acc: 0.9664 - val_loss: 0.2744 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.28978 to 0.27442, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.2520 - acc: 0.9651 - val_loss: 0.2758 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.27442\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.2465 - acc: 0.9711 - val_loss: 0.2652 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.27442 to 0.26519, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.2375 - acc: 0.9711 - val_loss: 0.2542 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.26519 to 0.25420, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.2322 - acc: 0.9691 - val_loss: 0.2535 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.25420 to 0.25345, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.2269 - acc: 0.9743 - val_loss: 0.2597 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.25345\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.2251 - acc: 0.9678 - val_loss: 0.2380 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.25345 to 0.23801, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.2201 - acc: 0.9757 - val_loss: 0.2257 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.23801 to 0.22573, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.2114 - acc: 0.9750 - val_loss: 0.2385 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.22573\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.2079 - acc: 0.9803 - val_loss: 0.2261 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.22573\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.2020 - acc: 0.9809 - val_loss: 0.2226 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.22573 to 0.22256, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1986 - acc: 0.9829 - val_loss: 0.2127 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.22256 to 0.21270, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1930 - acc: 0.9822 - val_loss: 0.2152 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.21270\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1870 - acc: 0.9855 - val_loss: 0.2116 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.21270 to 0.21156, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1821 - acc: 0.9862 - val_loss: 0.1985 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.21156 to 0.19851, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1794 - acc: 0.9868 - val_loss: 0.1989 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.19851\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1749 - acc: 0.9862 - val_loss: 0.1888 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.19851 to 0.18875, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1706 - acc: 0.9888 - val_loss: 0.1921 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.18875\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1680 - acc: 0.9882 - val_loss: 0.1949 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.18875\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1649 - acc: 0.9888 - val_loss: 0.1886 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.18875 to 0.18856, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1589 - acc: 0.9928 - val_loss: 0.1810 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.18856 to 0.18099, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1558 - acc: 0.9928 - val_loss: 0.1762 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.18099 to 0.17621, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1543 - acc: 0.9908 - val_loss: 0.1710 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.17621 to 0.17098, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1495 - acc: 0.9941 - val_loss: 0.1692 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.17098 to 0.16919, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1455 - acc: 0.9941 - val_loss: 0.1678 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.16919 to 0.16783, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1443 - acc: 0.9914 - val_loss: 0.1613 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.16783 to 0.16129, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1418 - acc: 0.9928 - val_loss: 0.1616 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.16129\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1398 - acc: 0.9941 - val_loss: 0.1624 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.16129\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1347 - acc: 0.9934 - val_loss: 0.1579 - val_acc: 0.9918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00069: val_loss improved from 0.16129 to 0.15787, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1317 - acc: 0.9947 - val_loss: 0.1545 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.15787 to 0.15453, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1290 - acc: 0.9954 - val_loss: 0.1444 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.15453 to 0.14445, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1266 - acc: 0.9947 - val_loss: 0.1510 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.14445\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1237 - acc: 0.9947 - val_loss: 0.1466 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.14445\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1220 - acc: 0.9954 - val_loss: 0.1394 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.14445 to 0.13944, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1198 - acc: 0.9947 - val_loss: 0.1418 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.13944\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1165 - acc: 0.9974 - val_loss: 0.1353 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.13944 to 0.13533, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1149 - acc: 0.9947 - val_loss: 0.1334 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.13533 to 0.13338, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.1137 - acc: 0.9961 - val_loss: 0.1379 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.13338\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.1104 - acc: 0.9967 - val_loss: 0.1276 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.13338 to 0.12755, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.1085 - acc: 0.9954 - val_loss: 0.1368 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.12755\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.1062 - acc: 0.9974 - val_loss: 0.1261 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.12755 to 0.12612, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.1046 - acc: 0.9974 - val_loss: 0.1244 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.12612 to 0.12439, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.1022 - acc: 0.9980 - val_loss: 0.1269 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.12439\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.1014 - acc: 0.9961 - val_loss: 0.1232 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.12439 to 0.12316, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0994 - acc: 0.9980 - val_loss: 0.1176 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.12316 to 0.11763, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0984 - acc: 0.9974 - val_loss: 0.1231 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.11763\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0946 - acc: 0.9967 - val_loss: 0.1166 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.11763 to 0.11662, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0930 - acc: 0.9974 - val_loss: 0.1141 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.11662 to 0.11408, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0915 - acc: 0.9967 - val_loss: 0.1156 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.11408\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0920 - acc: 0.9967 - val_loss: 0.1129 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.11408 to 0.11292, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0893 - acc: 0.9974 - val_loss: 0.1088 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.11292 to 0.10876, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0866 - acc: 0.9967 - val_loss: 0.1091 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.10876\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0855 - acc: 0.9974 - val_loss: 0.1065 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.10876 to 0.10652, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0839 - acc: 0.9974 - val_loss: 0.1049 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.10652 to 0.10493, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0819 - acc: 0.9980 - val_loss: 0.1055 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.10493\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0804 - acc: 0.9980 - val_loss: 0.1030 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.10493 to 0.10305, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0802 - acc: 0.9961 - val_loss: 0.1011 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.10305 to 0.10115, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0785 - acc: 0.9967 - val_loss: 0.1042 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.10115\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0777 - acc: 0.9974 - val_loss: 0.1000 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.10115 to 0.09996, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0769 - acc: 0.9974 - val_loss: 0.1015 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.09996\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0755 - acc: 0.9980 - val_loss: 0.1011 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.09996\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0736 - acc: 0.9974 - val_loss: 0.0971 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.09996 to 0.09706, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0732 - acc: 0.9974 - val_loss: 0.0947 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.09706 to 0.09466, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0709 - acc: 0.9980 - val_loss: 0.0974 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.09466\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0715 - acc: 0.9974 - val_loss: 0.0942 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.09466 to 0.09416, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0695 - acc: 0.9974 - val_loss: 0.0938 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.09416 to 0.09379, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0684 - acc: 0.9987 - val_loss: 0.0887 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.09379 to 0.08868, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0672 - acc: 0.9987 - val_loss: 0.0951 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.08868\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0659 - acc: 0.9967 - val_loss: 0.0899 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.08868\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0649 - acc: 0.9967 - val_loss: 0.0886 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.08868 to 0.08859, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0639 - acc: 0.9974 - val_loss: 0.0848 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.08859 to 0.08475, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0625 - acc: 0.9974 - val_loss: 0.0877 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.08475\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0617 - acc: 0.9980 - val_loss: 0.0847 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.08475 to 0.08471, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0611 - acc: 0.9967 - val_loss: 0.0882 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.08471\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0616 - acc: 0.9974 - val_loss: 0.0816 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.08471 to 0.08161, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0594 - acc: 0.9974 - val_loss: 0.0828 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.08161\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0595 - acc: 0.9961 - val_loss: 0.0819 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.08161\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0584 - acc: 0.9974 - val_loss: 0.0795 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.08161 to 0.07951, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0572 - acc: 0.9974 - val_loss: 0.0824 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.07951\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0567 - acc: 0.9974 - val_loss: 0.0790 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.07951 to 0.07898, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0555 - acc: 0.9974 - val_loss: 0.0800 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.07898\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0544 - acc: 0.9980 - val_loss: 0.0745 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.07898 to 0.07454, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0538 - acc: 0.9974 - val_loss: 0.0806 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.07454\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0532 - acc: 0.9980 - val_loss: 0.0750 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.07454\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0521 - acc: 0.9980 - val_loss: 0.0771 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.07454\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0517 - acc: 0.9974 - val_loss: 0.0736 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.07454 to 0.07357, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0504 - acc: 0.9974 - val_loss: 0.0779 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.07357\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0501 - acc: 0.9967 - val_loss: 0.0701 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.07357 to 0.07015, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0494 - acc: 0.9974 - val_loss: 0.0742 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.07015\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0492 - acc: 0.9967 - val_loss: 0.0740 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.07015\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0483 - acc: 0.9974 - val_loss: 0.0737 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.07015\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0475 - acc: 0.9974 - val_loss: 0.0699 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.07015 to 0.06989, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0466 - acc: 0.9967 - val_loss: 0.0684 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.06989 to 0.06837, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0460 - acc: 0.9974 - val_loss: 0.0687 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.06837\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0454 - acc: 0.9980 - val_loss: 0.0688 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.06837\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0455 - acc: 0.9961 - val_loss: 0.0689 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.06837\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0451 - acc: 0.9974 - val_loss: 0.0655 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.06837 to 0.06548, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0445 - acc: 0.9967 - val_loss: 0.0695 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.06548\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0437 - acc: 0.9980 - val_loss: 0.0695 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.06548\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0438 - acc: 0.9967 - val_loss: 0.0646 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.06548 to 0.06462, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0423 - acc: 0.9974 - val_loss: 0.0676 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.06462\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0421 - acc: 0.9967 - val_loss: 0.0636 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.06462 to 0.06364, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0416 - acc: 0.9974 - val_loss: 0.0648 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.06364\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0407 - acc: 0.9974 - val_loss: 0.0680 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.06364\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0404 - acc: 0.9967 - val_loss: 0.0633 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.06364 to 0.06331, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0398 - acc: 0.9980 - val_loss: 0.0635 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.06331\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0395 - acc: 0.9980 - val_loss: 0.0639 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.06331\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0389 - acc: 0.9974 - val_loss: 0.0633 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.06331\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0380 - acc: 0.9980 - val_loss: 0.0634 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.06331\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0379 - acc: 0.9974 - val_loss: 0.0593 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.06331 to 0.05927, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0375 - acc: 0.9974 - val_loss: 0.0614 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.05927\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0370 - acc: 0.9967 - val_loss: 0.0619 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.05927\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0362 - acc: 0.9967 - val_loss: 0.0578 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.05927 to 0.05779, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0360 - acc: 0.9974 - val_loss: 0.0607 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.05779\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.0355 - acc: 0.9974 - val_loss: 0.0599 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.05779\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.0353 - acc: 0.9980 - val_loss: 0.0566 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.05779 to 0.05662, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0348 - acc: 0.9974 - val_loss: 0.0598 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.05662\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.0340 - acc: 0.9967 - val_loss: 0.0557 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.05662 to 0.05570, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.0344 - acc: 0.9974 - val_loss: 0.0581 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.05570\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.0335 - acc: 0.9987 - val_loss: 0.0611 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.05570\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.0341 - acc: 0.9974 - val_loss: 0.0547 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.05570 to 0.05467, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.0331 - acc: 0.9980 - val_loss: 0.0582 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.05467\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.0327 - acc: 0.9974 - val_loss: 0.0548 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.05467\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.0321 - acc: 0.9980 - val_loss: 0.0556 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.05467\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.0321 - acc: 0.9974 - val_loss: 0.0556 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.05467\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.0313 - acc: 0.9974 - val_loss: 0.0532 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00166: val_loss improved from 0.05467 to 0.05322, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.0308 - acc: 0.9974 - val_loss: 0.0553 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.05322\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.0308 - acc: 0.9967 - val_loss: 0.0533 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.05322\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.0303 - acc: 0.9974 - val_loss: 0.0540 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.05322\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.0306 - acc: 0.9974 - val_loss: 0.0525 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.05322 to 0.05254, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.0296 - acc: 0.9974 - val_loss: 0.0536 - val_acc: 0.9877\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00171: val_loss did not improve from 0.05254\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.0295 - acc: 0.9980 - val_loss: 0.0501 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00172: val_loss improved from 0.05254 to 0.05009, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.0294 - acc: 0.9961 - val_loss: 0.0533 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.05009\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.0292 - acc: 0.9967 - val_loss: 0.0499 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.05009 to 0.04991, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.0290 - acc: 0.9974 - val_loss: 0.0531 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.04991\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.0281 - acc: 0.9974 - val_loss: 0.0516 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.04991\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.0276 - acc: 0.9974 - val_loss: 0.0505 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.04991\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.0279 - acc: 0.9967 - val_loss: 0.0497 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00178: val_loss improved from 0.04991 to 0.04971, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.0275 - acc: 0.9974 - val_loss: 0.0513 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.04971\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.0271 - acc: 0.9974 - val_loss: 0.0516 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.04971\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.0269 - acc: 0.9967 - val_loss: 0.0494 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00181: val_loss improved from 0.04971 to 0.04943, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.0263 - acc: 0.9980 - val_loss: 0.0496 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.04943\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.0261 - acc: 0.9974 - val_loss: 0.0502 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.04943\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.0263 - acc: 0.9974 - val_loss: 0.0486 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00184: val_loss improved from 0.04943 to 0.04863, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.0257 - acc: 0.9967 - val_loss: 0.0505 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.04863\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.0253 - acc: 0.9980 - val_loss: 0.0475 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.04863 to 0.04753, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.0252 - acc: 0.9974 - val_loss: 0.0472 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.04753 to 0.04715, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.0252 - acc: 0.9974 - val_loss: 0.0490 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.04715\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.0255 - acc: 0.9967 - val_loss: 0.0481 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.04715\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.0243 - acc: 0.9974 - val_loss: 0.0476 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.04715\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.0242 - acc: 0.9967 - val_loss: 0.0467 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00191: val_loss improved from 0.04715 to 0.04671, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.0238 - acc: 0.9974 - val_loss: 0.0482 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.04671\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.0235 - acc: 0.9974 - val_loss: 0.0460 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00193: val_loss improved from 0.04671 to 0.04602, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.0230 - acc: 0.9980 - val_loss: 0.0474 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.04602\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.0233 - acc: 0.9967 - val_loss: 0.0465 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.04602\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.0232 - acc: 0.9961 - val_loss: 0.0465 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.04602\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.0232 - acc: 0.9967 - val_loss: 0.0459 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00197: val_loss improved from 0.04602 to 0.04587, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.0223 - acc: 0.9980 - val_loss: 0.0459 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.04587\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.0226 - acc: 0.9974 - val_loss: 0.0452 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00199: val_loss improved from 0.04587 to 0.04515, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.0221 - acc: 0.9967 - val_loss: 0.0452 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.04515\n",
      "batch_size=80   optimizer=Adam\n",
      "Test accuracy: 67.6880%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_45 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 2.3205 - acc: 0.1691 - val_loss: 2.0018 - val_acc: 0.2551\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.00184, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.7342 - acc: 0.3704 - val_loss: 1.5850 - val_acc: 0.3909\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.00184 to 1.58496, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 1.4269 - acc: 0.5191 - val_loss: 1.3584 - val_acc: 0.5226\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.58496 to 1.35841, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 1.2466 - acc: 0.5954 - val_loss: 1.2348 - val_acc: 0.5844\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.35841 to 1.23480, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 1.1322 - acc: 0.6309 - val_loss: 1.1382 - val_acc: 0.6049\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.23480 to 1.13821, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 1.0501 - acc: 0.6618 - val_loss: 1.0599 - val_acc: 0.6461\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.13821 to 1.05990, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.9895 - acc: 0.6934 - val_loss: 1.0074 - val_acc: 0.6708\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.05990 to 1.00740, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.9292 - acc: 0.7099 - val_loss: 0.9556 - val_acc: 0.6831\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.00740 to 0.95558, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.8865 - acc: 0.7296 - val_loss: 0.9175 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.95558 to 0.91747, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.8424 - acc: 0.7336 - val_loss: 0.8719 - val_acc: 0.6872\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.91747 to 0.87186, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.8057 - acc: 0.7500 - val_loss: 0.8338 - val_acc: 0.7119\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.87186 to 0.83378, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.7755 - acc: 0.7645 - val_loss: 0.7965 - val_acc: 0.7202\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.83378 to 0.79652, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.7448 - acc: 0.7711 - val_loss: 0.7788 - val_acc: 0.7202\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.79652 to 0.77876, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.7179 - acc: 0.7836 - val_loss: 0.7371 - val_acc: 0.7654\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.77876 to 0.73709, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.6935 - acc: 0.7928 - val_loss: 0.7205 - val_acc: 0.7654\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.73709 to 0.72054, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.6619 - acc: 0.8072 - val_loss: 0.7096 - val_acc: 0.7572\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.72054 to 0.70957, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.6523 - acc: 0.8000 - val_loss: 0.6767 - val_acc: 0.7737\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.70957 to 0.67670, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.6173 - acc: 0.8171 - val_loss: 0.6365 - val_acc: 0.8148\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.67670 to 0.63655, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.6044 - acc: 0.8355 - val_loss: 0.6119 - val_acc: 0.8148\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.63655 to 0.61189, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.5791 - acc: 0.8322 - val_loss: 0.6159 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.61189\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.5650 - acc: 0.8447 - val_loss: 0.5792 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.61189 to 0.57919, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.5507 - acc: 0.8408 - val_loss: 0.5660 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.57919 to 0.56596, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.5332 - acc: 0.8546 - val_loss: 0.5653 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.56596 to 0.56532, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.5204 - acc: 0.8658 - val_loss: 0.5412 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.56532 to 0.54122, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.5034 - acc: 0.8697 - val_loss: 0.5347 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.54122 to 0.53466, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.4881 - acc: 0.8750 - val_loss: 0.5086 - val_acc: 0.8765\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.53466 to 0.50864, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.4745 - acc: 0.8743 - val_loss: 0.4916 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.50864 to 0.49161, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.4611 - acc: 0.8809 - val_loss: 0.4835 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.49161 to 0.48353, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.4503 - acc: 0.8928 - val_loss: 0.4795 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.48353 to 0.47954, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.4400 - acc: 0.8882 - val_loss: 0.4680 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.47954 to 0.46801, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.4297 - acc: 0.9000 - val_loss: 0.4597 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.46801 to 0.45969, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.4212 - acc: 0.9046 - val_loss: 0.4418 - val_acc: 0.9012\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.45969 to 0.44180, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.4070 - acc: 0.9105 - val_loss: 0.4374 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.44180 to 0.43741, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.4016 - acc: 0.9138 - val_loss: 0.4186 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.43741 to 0.41861, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.3887 - acc: 0.9191 - val_loss: 0.4150 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.41861 to 0.41499, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.3802 - acc: 0.9191 - val_loss: 0.3996 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.41499 to 0.39959, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.3697 - acc: 0.9257 - val_loss: 0.3898 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.39959 to 0.38982, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.3606 - acc: 0.9329 - val_loss: 0.3812 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.38982 to 0.38122, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.3548 - acc: 0.9322 - val_loss: 0.3811 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.38122 to 0.38107, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.3445 - acc: 0.9342 - val_loss: 0.3652 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.38107 to 0.36518, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.3395 - acc: 0.9349 - val_loss: 0.3503 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.36518 to 0.35029, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.3299 - acc: 0.9342 - val_loss: 0.3582 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.35029\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.3196 - acc: 0.9441 - val_loss: 0.3396 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.35029 to 0.33960, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.3127 - acc: 0.9474 - val_loss: 0.3393 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.33960 to 0.33926, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.3075 - acc: 0.9507 - val_loss: 0.3310 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.33926 to 0.33099, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.2998 - acc: 0.9520 - val_loss: 0.3199 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.33099 to 0.31987, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.2940 - acc: 0.9500 - val_loss: 0.3184 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.31987 to 0.31840, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.2895 - acc: 0.9520 - val_loss: 0.3184 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.31840 to 0.31835, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.2849 - acc: 0.9553 - val_loss: 0.3002 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.31835 to 0.30017, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.2797 - acc: 0.9618 - val_loss: 0.2958 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.30017 to 0.29584, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.2720 - acc: 0.9632 - val_loss: 0.2966 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.29584\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.2630 - acc: 0.9651 - val_loss: 0.2809 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.29584 to 0.28088, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.2573 - acc: 0.9651 - val_loss: 0.2783 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.28088 to 0.27835, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.2538 - acc: 0.9678 - val_loss: 0.2778 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.27835 to 0.27782, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.2482 - acc: 0.9691 - val_loss: 0.2680 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.27782 to 0.26801, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.2435 - acc: 0.9724 - val_loss: 0.2684 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.26801\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.2393 - acc: 0.9750 - val_loss: 0.2613 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.26801 to 0.26127, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.2332 - acc: 0.9750 - val_loss: 0.2530 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.26127 to 0.25299, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.2294 - acc: 0.9724 - val_loss: 0.2487 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.25299 to 0.24874, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.2238 - acc: 0.9776 - val_loss: 0.2432 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.24874 to 0.24320, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.2195 - acc: 0.9796 - val_loss: 0.2429 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.24320 to 0.24285, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.2156 - acc: 0.9783 - val_loss: 0.2306 - val_acc: 0.9712\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00062: val_loss improved from 0.24285 to 0.23057, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.2103 - acc: 0.9796 - val_loss: 0.2376 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.23057\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.2091 - acc: 0.9789 - val_loss: 0.2261 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.23057 to 0.22612, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.2041 - acc: 0.9842 - val_loss: 0.2245 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.22612 to 0.22454, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.2001 - acc: 0.9816 - val_loss: 0.2175 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.22454 to 0.21747, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1953 - acc: 0.9822 - val_loss: 0.2196 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.21747\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1910 - acc: 0.9849 - val_loss: 0.2133 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.21747 to 0.21330, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1898 - acc: 0.9875 - val_loss: 0.2117 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.21330 to 0.21169, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1874 - acc: 0.9849 - val_loss: 0.2051 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.21169 to 0.20508, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1826 - acc: 0.9855 - val_loss: 0.2011 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.20508 to 0.20114, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1782 - acc: 0.9868 - val_loss: 0.2013 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.20114\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1752 - acc: 0.9868 - val_loss: 0.1929 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.20114 to 0.19293, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1718 - acc: 0.9882 - val_loss: 0.1907 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.19293 to 0.19071, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1695 - acc: 0.9895 - val_loss: 0.1904 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.19071 to 0.19038, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1663 - acc: 0.9895 - val_loss: 0.1861 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.19038 to 0.18615, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1649 - acc: 0.9875 - val_loss: 0.1803 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.18615 to 0.18035, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.1628 - acc: 0.9901 - val_loss: 0.1810 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.18035\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.1578 - acc: 0.9901 - val_loss: 0.1753 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.18035 to 0.17529, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.1558 - acc: 0.9921 - val_loss: 0.1763 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.17529\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.1540 - acc: 0.9908 - val_loss: 0.1700 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.17529 to 0.16996, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.1509 - acc: 0.9928 - val_loss: 0.1712 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.16996\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.1481 - acc: 0.9914 - val_loss: 0.1662 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.16996 to 0.16618, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.1463 - acc: 0.9934 - val_loss: 0.1687 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.16618\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.1437 - acc: 0.9941 - val_loss: 0.1612 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.16618 to 0.16116, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.1400 - acc: 0.9934 - val_loss: 0.1591 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.16116 to 0.15914, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.1382 - acc: 0.9941 - val_loss: 0.1626 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.15914\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.1377 - acc: 0.9954 - val_loss: 0.1532 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.15914 to 0.15321, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.1323 - acc: 0.9947 - val_loss: 0.1542 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.15321\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.1305 - acc: 0.9954 - val_loss: 0.1505 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.15321 to 0.15051, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.1281 - acc: 0.9954 - val_loss: 0.1473 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.15051 to 0.14726, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.1268 - acc: 0.9961 - val_loss: 0.1481 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.14726\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.1241 - acc: 0.9954 - val_loss: 0.1431 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.14726 to 0.14309, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.1243 - acc: 0.9954 - val_loss: 0.1442 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.14309\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.1220 - acc: 0.9947 - val_loss: 0.1444 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.14309\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.1204 - acc: 0.9954 - val_loss: 0.1402 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.14309 to 0.14019, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.1179 - acc: 0.9974 - val_loss: 0.1383 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.14019 to 0.13830, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.1162 - acc: 0.9947 - val_loss: 0.1361 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.13830 to 0.13605, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.1144 - acc: 0.9961 - val_loss: 0.1317 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.13605 to 0.13174, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.1124 - acc: 0.9974 - val_loss: 0.1333 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.13174\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.1111 - acc: 0.9967 - val_loss: 0.1301 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.13174 to 0.13005, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.1099 - acc: 0.9974 - val_loss: 0.1291 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.13005 to 0.12911, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.1076 - acc: 0.9974 - val_loss: 0.1279 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.12911 to 0.12791, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.1067 - acc: 0.9967 - val_loss: 0.1276 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.12791 to 0.12758, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.1044 - acc: 0.9967 - val_loss: 0.1251 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.12758 to 0.12510, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.1042 - acc: 0.9974 - val_loss: 0.1235 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.12510 to 0.12348, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.1009 - acc: 0.9974 - val_loss: 0.1245 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.12348\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.1007 - acc: 0.9967 - val_loss: 0.1188 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.12348 to 0.11882, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0994 - acc: 0.9967 - val_loss: 0.1205 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.11882\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0966 - acc: 0.9974 - val_loss: 0.1163 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.11882 to 0.11634, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0953 - acc: 0.9967 - val_loss: 0.1165 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.11634\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0947 - acc: 0.9974 - val_loss: 0.1144 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.11634 to 0.11444, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0930 - acc: 0.9980 - val_loss: 0.1143 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.11444 to 0.11433, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0920 - acc: 0.9980 - val_loss: 0.1132 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.11433 to 0.11325, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0913 - acc: 0.9974 - val_loss: 0.1137 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.11325\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0898 - acc: 0.9980 - val_loss: 0.1090 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.11325 to 0.10902, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0875 - acc: 0.9974 - val_loss: 0.1115 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.10902\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0869 - acc: 0.9974 - val_loss: 0.1065 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.10902 to 0.10648, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0858 - acc: 0.9980 - val_loss: 0.1079 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.10648\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0849 - acc: 0.9974 - val_loss: 0.1054 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.10648 to 0.10537, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0842 - acc: 0.9974 - val_loss: 0.1042 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.10537 to 0.10421, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0833 - acc: 0.9974 - val_loss: 0.1014 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.10421 to 0.10144, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0814 - acc: 0.9967 - val_loss: 0.1037 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.10144\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0802 - acc: 0.9974 - val_loss: 0.1006 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.10144 to 0.10060, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0794 - acc: 0.9974 - val_loss: 0.0989 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.10060 to 0.09895, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0782 - acc: 0.9974 - val_loss: 0.1009 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.09895\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0774 - acc: 0.9974 - val_loss: 0.0978 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.09895 to 0.09781, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0763 - acc: 0.9980 - val_loss: 0.0980 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.09781\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0754 - acc: 0.9980 - val_loss: 0.0958 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.09781 to 0.09578, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0745 - acc: 0.9987 - val_loss: 0.0974 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.09578\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0736 - acc: 0.9980 - val_loss: 0.0949 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.09578 to 0.09487, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0731 - acc: 0.9974 - val_loss: 0.0947 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.09487 to 0.09466, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0717 - acc: 0.9974 - val_loss: 0.0939 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.09466 to 0.09393, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0713 - acc: 0.9974 - val_loss: 0.0921 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.09393 to 0.09213, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0712 - acc: 0.9980 - val_loss: 0.0916 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.09213 to 0.09160, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0700 - acc: 0.9980 - val_loss: 0.0906 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.09160 to 0.09062, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0692 - acc: 0.9980 - val_loss: 0.0893 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.09062 to 0.08930, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0676 - acc: 0.9974 - val_loss: 0.0890 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.08930 to 0.08896, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0667 - acc: 0.9980 - val_loss: 0.0887 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.08896 to 0.08873, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0660 - acc: 0.9974 - val_loss: 0.0880 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.08873 to 0.08800, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0649 - acc: 0.9987 - val_loss: 0.0873 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.08800 to 0.08732, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0648 - acc: 0.9974 - val_loss: 0.0856 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.08732 to 0.08564, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0641 - acc: 0.9980 - val_loss: 0.0846 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.08564 to 0.08461, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0625 - acc: 0.9980 - val_loss: 0.0842 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.08461 to 0.08419, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0621 - acc: 0.9980 - val_loss: 0.0825 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.08419 to 0.08249, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0622 - acc: 0.9974 - val_loss: 0.0836 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.08249\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0608 - acc: 0.9974 - val_loss: 0.0809 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.08249 to 0.08090, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0601 - acc: 0.9967 - val_loss: 0.0827 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.08090\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0592 - acc: 0.9980 - val_loss: 0.0794 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.08090 to 0.07938, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0586 - acc: 0.9980 - val_loss: 0.0798 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.07938\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0581 - acc: 0.9974 - val_loss: 0.0797 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.07938\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0577 - acc: 0.9980 - val_loss: 0.0788 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.07938 to 0.07883, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0570 - acc: 0.9967 - val_loss: 0.0774 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.07883 to 0.07741, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0562 - acc: 0.9980 - val_loss: 0.0772 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.07741 to 0.07724, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.0560 - acc: 0.9967 - val_loss: 0.0768 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.07724 to 0.07685, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.0548 - acc: 0.9980 - val_loss: 0.0741 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.07685 to 0.07414, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0543 - acc: 0.9980 - val_loss: 0.0773 - val_acc: 0.9918\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00157: val_loss did not improve from 0.07414\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.0539 - acc: 0.9980 - val_loss: 0.0733 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.07414 to 0.07329, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.0533 - acc: 0.9980 - val_loss: 0.0738 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.07329\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.0526 - acc: 0.9974 - val_loss: 0.0734 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.07329\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.0519 - acc: 0.9980 - val_loss: 0.0729 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.07329 to 0.07293, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.0516 - acc: 0.9967 - val_loss: 0.0725 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.07293 to 0.07253, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.0512 - acc: 0.9967 - val_loss: 0.0712 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00163: val_loss improved from 0.07253 to 0.07116, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.0502 - acc: 0.9974 - val_loss: 0.0712 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.07116\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.0499 - acc: 0.9974 - val_loss: 0.0725 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.07116\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.0491 - acc: 0.9967 - val_loss: 0.0694 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00166: val_loss improved from 0.07116 to 0.06939, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.0487 - acc: 0.9974 - val_loss: 0.0695 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.06939\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.0481 - acc: 0.9974 - val_loss: 0.0699 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.06939\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.0480 - acc: 0.9980 - val_loss: 0.0677 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.06939 to 0.06772, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.0476 - acc: 0.9974 - val_loss: 0.0685 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.06772\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.0473 - acc: 0.9974 - val_loss: 0.0686 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.06772\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.0468 - acc: 0.9974 - val_loss: 0.0675 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00172: val_loss improved from 0.06772 to 0.06749, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.0460 - acc: 0.9967 - val_loss: 0.0659 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.06749 to 0.06594, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.0456 - acc: 0.9967 - val_loss: 0.0664 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.06594\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.0449 - acc: 0.9980 - val_loss: 0.0662 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.06594\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.0446 - acc: 0.9974 - val_loss: 0.0665 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.06594\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.0442 - acc: 0.9967 - val_loss: 0.0640 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00177: val_loss improved from 0.06594 to 0.06398, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.0439 - acc: 0.9980 - val_loss: 0.0649 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.06398\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.0434 - acc: 0.9974 - val_loss: 0.0639 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00179: val_loss improved from 0.06398 to 0.06389, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.0428 - acc: 0.9980 - val_loss: 0.0635 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00180: val_loss improved from 0.06389 to 0.06347, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.0427 - acc: 0.9967 - val_loss: 0.0626 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00181: val_loss improved from 0.06347 to 0.06261, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.0420 - acc: 0.9980 - val_loss: 0.0632 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.06261\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.0420 - acc: 0.9974 - val_loss: 0.0620 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00183: val_loss improved from 0.06261 to 0.06200, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.0418 - acc: 0.9974 - val_loss: 0.0628 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.06200\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.0411 - acc: 0.9974 - val_loss: 0.0613 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00185: val_loss improved from 0.06200 to 0.06129, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.0408 - acc: 0.9974 - val_loss: 0.0623 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.06129\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.0400 - acc: 0.9980 - val_loss: 0.0597 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.06129 to 0.05969, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.0396 - acc: 0.9980 - val_loss: 0.0607 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.05969\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.0394 - acc: 0.9974 - val_loss: 0.0596 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.05969 to 0.05964, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.0389 - acc: 0.9980 - val_loss: 0.0603 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.05964\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.0385 - acc: 0.9974 - val_loss: 0.0586 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00191: val_loss improved from 0.05964 to 0.05857, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.0385 - acc: 0.9974 - val_loss: 0.0590 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.05857\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.0380 - acc: 0.9974 - val_loss: 0.0585 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00193: val_loss improved from 0.05857 to 0.05850, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.0376 - acc: 0.9974 - val_loss: 0.0588 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.05850\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.0371 - acc: 0.9974 - val_loss: 0.0572 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00195: val_loss improved from 0.05850 to 0.05721, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.0369 - acc: 0.9974 - val_loss: 0.0595 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.05721\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.0370 - acc: 0.9967 - val_loss: 0.0567 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00197: val_loss improved from 0.05721 to 0.05666, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.0362 - acc: 0.9967 - val_loss: 0.0579 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.05666\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.0358 - acc: 0.9974 - val_loss: 0.0556 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00199: val_loss improved from 0.05666 to 0.05562, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.0356 - acc: 0.9974 - val_loss: 0.0566 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.05562\n",
      "batch_size=120   optimizer=Adam\n",
      "Test accuracy: 67.9666%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_46 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 2.2959 - acc: 0.1711 - val_loss: 1.9691 - val_acc: 0.2798\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.96914, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.7608 - acc: 0.3974 - val_loss: 1.5669 - val_acc: 0.4691\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.96914 to 1.56692, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 1.4393 - acc: 0.5303 - val_loss: 1.3526 - val_acc: 0.5267\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.56692 to 1.35256, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 1.2683 - acc: 0.5980 - val_loss: 1.2052 - val_acc: 0.6337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00004: val_loss improved from 1.35256 to 1.20521, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 1.1512 - acc: 0.6408 - val_loss: 1.1344 - val_acc: 0.6214\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.20521 to 1.13442, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 1.0728 - acc: 0.6553 - val_loss: 1.0453 - val_acc: 0.6831\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.13442 to 1.04531, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 1.0051 - acc: 0.6875 - val_loss: 0.9881 - val_acc: 0.6872\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.04531 to 0.98805, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.9515 - acc: 0.7020 - val_loss: 0.9494 - val_acc: 0.7078\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.98805 to 0.94944, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.9101 - acc: 0.7217 - val_loss: 0.9045 - val_acc: 0.7202\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.94944 to 0.90452, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.8678 - acc: 0.7342 - val_loss: 0.8702 - val_acc: 0.7366\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.90452 to 0.87020, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.8334 - acc: 0.7461 - val_loss: 0.8340 - val_acc: 0.7449\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.87020 to 0.83399, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.8060 - acc: 0.7480 - val_loss: 0.8093 - val_acc: 0.7613\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.83399 to 0.80926, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.7748 - acc: 0.7671 - val_loss: 0.7774 - val_acc: 0.7531\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.80926 to 0.77744, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.7419 - acc: 0.7704 - val_loss: 0.7485 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.77744 to 0.74846, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.7180 - acc: 0.7888 - val_loss: 0.7231 - val_acc: 0.7901\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.74846 to 0.72315, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.6979 - acc: 0.7875 - val_loss: 0.7118 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.72315 to 0.71183, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.6741 - acc: 0.8026 - val_loss: 0.6878 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.71183 to 0.68779, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.6543 - acc: 0.8026 - val_loss: 0.6603 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.68779 to 0.66035, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.6353 - acc: 0.8138 - val_loss: 0.6465 - val_acc: 0.7942\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.66035 to 0.64646, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.6173 - acc: 0.8191 - val_loss: 0.6224 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.64646 to 0.62240, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.5985 - acc: 0.8276 - val_loss: 0.6070 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.62240 to 0.60699, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.5825 - acc: 0.8401 - val_loss: 0.5968 - val_acc: 0.8354\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.60699 to 0.59680, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.5791 - acc: 0.8375 - val_loss: 0.5873 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.59680 to 0.58730, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.5543 - acc: 0.8474 - val_loss: 0.5654 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.58730 to 0.56542, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.5413 - acc: 0.8592 - val_loss: 0.5529 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.56542 to 0.55294, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.5267 - acc: 0.8566 - val_loss: 0.5369 - val_acc: 0.8765\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.55294 to 0.53690, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.5117 - acc: 0.8684 - val_loss: 0.5213 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.53690 to 0.52135, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.5008 - acc: 0.8704 - val_loss: 0.5237 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.52135\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.4891 - acc: 0.8757 - val_loss: 0.4983 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.52135 to 0.49827, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.4731 - acc: 0.8849 - val_loss: 0.4906 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.49827 to 0.49057, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.4637 - acc: 0.8849 - val_loss: 0.4726 - val_acc: 0.9012\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.49057 to 0.47263, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.4531 - acc: 0.8908 - val_loss: 0.4658 - val_acc: 0.9012\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.47263 to 0.46576, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.4438 - acc: 0.8928 - val_loss: 0.4574 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.46576 to 0.45743, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.4326 - acc: 0.8961 - val_loss: 0.4460 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.45743 to 0.44604, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.4216 - acc: 0.9046 - val_loss: 0.4352 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.44604 to 0.43521, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.4158 - acc: 0.9053 - val_loss: 0.4272 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.43521 to 0.42721, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.4054 - acc: 0.9145 - val_loss: 0.4194 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.42721 to 0.41942, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.3967 - acc: 0.9158 - val_loss: 0.4097 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.41942 to 0.40970, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.3884 - acc: 0.9224 - val_loss: 0.4021 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.40970 to 0.40212, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.3780 - acc: 0.9224 - val_loss: 0.3945 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.40212 to 0.39447, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.3717 - acc: 0.9257 - val_loss: 0.3847 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.39447 to 0.38473, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.3623 - acc: 0.9289 - val_loss: 0.3777 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.38473 to 0.37767, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.3549 - acc: 0.9349 - val_loss: 0.3736 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.37767 to 0.37359, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.3508 - acc: 0.9309 - val_loss: 0.3752 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.37359\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.3470 - acc: 0.9368 - val_loss: 0.3615 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.37359 to 0.36150, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.3360 - acc: 0.9395 - val_loss: 0.3616 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.36150\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.3278 - acc: 0.9447 - val_loss: 0.3477 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.36150 to 0.34765, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.3259 - acc: 0.9395 - val_loss: 0.3446 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.34765 to 0.34455, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.3215 - acc: 0.9454 - val_loss: 0.3406 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.34455 to 0.34058, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.3135 - acc: 0.9461 - val_loss: 0.3285 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.34058 to 0.32845, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.3074 - acc: 0.9500 - val_loss: 0.3288 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.32845\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.2984 - acc: 0.9507 - val_loss: 0.3122 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.32845 to 0.31222, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.2937 - acc: 0.9487 - val_loss: 0.3121 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.31222 to 0.31206, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.2885 - acc: 0.9546 - val_loss: 0.3053 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.31206 to 0.30526, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.2813 - acc: 0.9579 - val_loss: 0.2980 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.30526 to 0.29804, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.2755 - acc: 0.9625 - val_loss: 0.2939 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.29804 to 0.29388, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.2706 - acc: 0.9645 - val_loss: 0.2889 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.29388 to 0.28888, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.2672 - acc: 0.9664 - val_loss: 0.2835 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.28888 to 0.28350, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.2626 - acc: 0.9678 - val_loss: 0.2799 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.28350 to 0.27985, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.2587 - acc: 0.9691 - val_loss: 0.2736 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.27985 to 0.27356, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.2533 - acc: 0.9691 - val_loss: 0.2707 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.27356 to 0.27068, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.2493 - acc: 0.9697 - val_loss: 0.2690 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.27068 to 0.26901, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.2444 - acc: 0.9750 - val_loss: 0.2627 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.26901 to 0.26270, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.2396 - acc: 0.9711 - val_loss: 0.2586 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.26270 to 0.25860, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.2364 - acc: 0.9730 - val_loss: 0.2540 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.25860 to 0.25402, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.2309 - acc: 0.9770 - val_loss: 0.2525 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.25402 to 0.25246, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.2275 - acc: 0.9816 - val_loss: 0.2481 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.25246 to 0.24812, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.2246 - acc: 0.9783 - val_loss: 0.2436 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.24812 to 0.24364, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.2202 - acc: 0.9776 - val_loss: 0.2385 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.24364 to 0.23852, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.2150 - acc: 0.9803 - val_loss: 0.2372 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.23852 to 0.23725, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.2119 - acc: 0.9822 - val_loss: 0.2302 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.23725 to 0.23017, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.2086 - acc: 0.9796 - val_loss: 0.2318 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.23017\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.2059 - acc: 0.9829 - val_loss: 0.2237 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.23017 to 0.22371, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.2015 - acc: 0.9829 - val_loss: 0.2201 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.22371 to 0.22006, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1977 - acc: 0.9829 - val_loss: 0.2158 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.22006 to 0.21580, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1948 - acc: 0.9855 - val_loss: 0.2138 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.21580 to 0.21383, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1930 - acc: 0.9855 - val_loss: 0.2125 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.21383 to 0.21246, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.1906 - acc: 0.9842 - val_loss: 0.2057 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.21246 to 0.20569, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.1883 - acc: 0.9882 - val_loss: 0.2072 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.20569\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.1844 - acc: 0.9862 - val_loss: 0.2000 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.20569 to 0.19999, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.1806 - acc: 0.9868 - val_loss: 0.2042 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.19999\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.1775 - acc: 0.9888 - val_loss: 0.1959 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.19999 to 0.19586, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.1749 - acc: 0.9895 - val_loss: 0.1968 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.19586\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.1720 - acc: 0.9901 - val_loss: 0.1917 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.19586 to 0.19172, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.1686 - acc: 0.9908 - val_loss: 0.1909 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.19172 to 0.19087, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.1662 - acc: 0.9901 - val_loss: 0.1869 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.19087 to 0.18688, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.1635 - acc: 0.9921 - val_loss: 0.1840 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.18688 to 0.18396, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.1622 - acc: 0.9914 - val_loss: 0.1828 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.18396 to 0.18284, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.1602 - acc: 0.9921 - val_loss: 0.1781 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.18284 to 0.17810, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.1580 - acc: 0.9914 - val_loss: 0.1765 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.17810 to 0.17655, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.1559 - acc: 0.9921 - val_loss: 0.1771 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.17655\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.1521 - acc: 0.9921 - val_loss: 0.1737 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.17655 to 0.17375, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.1506 - acc: 0.9921 - val_loss: 0.1731 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.17375 to 0.17314, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.1490 - acc: 0.9928 - val_loss: 0.1670 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.17314 to 0.16703, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.1465 - acc: 0.9954 - val_loss: 0.1677 - val_acc: 0.9918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00095: val_loss did not improve from 0.16703\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.1440 - acc: 0.9934 - val_loss: 0.1638 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.16703 to 0.16376, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.1420 - acc: 0.9941 - val_loss: 0.1631 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.16376 to 0.16314, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.1394 - acc: 0.9947 - val_loss: 0.1597 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.16314 to 0.15970, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.1374 - acc: 0.9947 - val_loss: 0.1599 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.15970\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.1366 - acc: 0.9947 - val_loss: 0.1565 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.15970 to 0.15649, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.1358 - acc: 0.9947 - val_loss: 0.1549 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.15649 to 0.15488, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.1326 - acc: 0.9974 - val_loss: 0.1513 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.15488 to 0.15129, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.1307 - acc: 0.9947 - val_loss: 0.1512 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.15129 to 0.15122, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.1285 - acc: 0.9961 - val_loss: 0.1503 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.15122 to 0.15030, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.1286 - acc: 0.9954 - val_loss: 0.1467 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.15030 to 0.14672, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.1264 - acc: 0.9974 - val_loss: 0.1464 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.14672 to 0.14639, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.1234 - acc: 0.9967 - val_loss: 0.1434 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.14639 to 0.14344, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.1219 - acc: 0.9967 - val_loss: 0.1399 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.14344 to 0.13993, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.1205 - acc: 0.9974 - val_loss: 0.1407 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.13993\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.1189 - acc: 0.9967 - val_loss: 0.1369 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.13993 to 0.13694, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.1181 - acc: 0.9974 - val_loss: 0.1376 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.13694\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.1166 - acc: 0.9961 - val_loss: 0.1355 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.13694 to 0.13548, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.1156 - acc: 0.9967 - val_loss: 0.1355 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.13548\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.1140 - acc: 0.9961 - val_loss: 0.1335 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.13548 to 0.13350, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.1115 - acc: 0.9974 - val_loss: 0.1300 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.13350 to 0.12996, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.1100 - acc: 0.9961 - val_loss: 0.1312 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.12996\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.1088 - acc: 0.9967 - val_loss: 0.1270 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.12996 to 0.12697, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.1072 - acc: 0.9974 - val_loss: 0.1284 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.12697\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.1063 - acc: 0.9974 - val_loss: 0.1260 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.12697 to 0.12596, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.1051 - acc: 0.9974 - val_loss: 0.1243 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.12596 to 0.12430, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.1028 - acc: 0.9974 - val_loss: 0.1239 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.12430 to 0.12394, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.1019 - acc: 0.9974 - val_loss: 0.1213 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.12394 to 0.12128, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.1002 - acc: 0.9974 - val_loss: 0.1216 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.12128\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0995 - acc: 0.9974 - val_loss: 0.1198 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.12128 to 0.11979, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0976 - acc: 0.9974 - val_loss: 0.1186 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.11979 to 0.11862, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0966 - acc: 0.9980 - val_loss: 0.1166 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.11862 to 0.11659, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0965 - acc: 0.9987 - val_loss: 0.1163 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.11659 to 0.11633, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0949 - acc: 0.9974 - val_loss: 0.1137 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.11633 to 0.11373, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0936 - acc: 0.9974 - val_loss: 0.1158 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.11373\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0921 - acc: 0.9980 - val_loss: 0.1125 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.11373 to 0.11247, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0914 - acc: 0.9974 - val_loss: 0.1108 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.11247 to 0.11080, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0900 - acc: 0.9980 - val_loss: 0.1105 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.11080 to 0.11048, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0889 - acc: 0.9974 - val_loss: 0.1090 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.11048 to 0.10901, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0885 - acc: 0.9967 - val_loss: 0.1098 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.10901\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0876 - acc: 0.9974 - val_loss: 0.1078 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.10901 to 0.10778, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0866 - acc: 0.9980 - val_loss: 0.1049 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.10778 to 0.10489, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0850 - acc: 0.9974 - val_loss: 0.1081 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.10489\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0842 - acc: 0.9980 - val_loss: 0.1034 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.10489 to 0.10337, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0830 - acc: 0.9980 - val_loss: 0.1039 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.10337\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0821 - acc: 0.9980 - val_loss: 0.1043 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.10337\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0813 - acc: 0.9980 - val_loss: 0.1016 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.10337 to 0.10159, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0802 - acc: 0.9980 - val_loss: 0.1000 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.10159 to 0.09995, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0796 - acc: 0.9974 - val_loss: 0.1009 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.09995\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0794 - acc: 0.9980 - val_loss: 0.0992 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.09995 to 0.09917, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0785 - acc: 0.9980 - val_loss: 0.0993 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.09917\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0772 - acc: 0.9974 - val_loss: 0.0964 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.09917 to 0.09644, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0770 - acc: 0.9974 - val_loss: 0.0972 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.09644\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0758 - acc: 0.9980 - val_loss: 0.0978 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.09644\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0745 - acc: 0.9987 - val_loss: 0.0945 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.09644 to 0.09453, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0749 - acc: 0.9974 - val_loss: 0.0947 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.09453\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0733 - acc: 0.9974 - val_loss: 0.0929 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.09453 to 0.09295, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0727 - acc: 0.9974 - val_loss: 0.0930 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.09295\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0714 - acc: 0.9987 - val_loss: 0.0928 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.09295 to 0.09280, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0708 - acc: 0.9974 - val_loss: 0.0910 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.09280 to 0.09104, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.0698 - acc: 0.9980 - val_loss: 0.0918 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.09104\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.0691 - acc: 0.9974 - val_loss: 0.0887 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.09104 to 0.08875, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0686 - acc: 0.9980 - val_loss: 0.0909 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.08875\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.0680 - acc: 0.9980 - val_loss: 0.0890 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.08875\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.0677 - acc: 0.9974 - val_loss: 0.0861 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.08875 to 0.08611, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.0663 - acc: 0.9980 - val_loss: 0.0906 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.08611\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.0667 - acc: 0.9974 - val_loss: 0.0860 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.08611 to 0.08604, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.0655 - acc: 0.9987 - val_loss: 0.0865 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.08604\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.0643 - acc: 0.9974 - val_loss: 0.0852 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00163: val_loss improved from 0.08604 to 0.08519, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.0641 - acc: 0.9974 - val_loss: 0.0854 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.08519\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.0634 - acc: 0.9980 - val_loss: 0.0840 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.08519 to 0.08397, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.0625 - acc: 0.9974 - val_loss: 0.0826 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00166: val_loss improved from 0.08397 to 0.08257, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.0621 - acc: 0.9974 - val_loss: 0.0834 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.08257\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.0616 - acc: 0.9980 - val_loss: 0.0829 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.08257\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.0606 - acc: 0.9974 - val_loss: 0.0822 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.08257 to 0.08221, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.0606 - acc: 0.9980 - val_loss: 0.0813 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.08221 to 0.08129, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.0596 - acc: 0.9974 - val_loss: 0.0804 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00171: val_loss improved from 0.08129 to 0.08042, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.0591 - acc: 0.9974 - val_loss: 0.0805 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.08042\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.0587 - acc: 0.9980 - val_loss: 0.0800 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.08042 to 0.07997, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.0582 - acc: 0.9980 - val_loss: 0.0787 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.07997 to 0.07873, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.0574 - acc: 0.9980 - val_loss: 0.0781 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00175: val_loss improved from 0.07873 to 0.07809, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.0570 - acc: 0.9974 - val_loss: 0.0787 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.07809\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.0563 - acc: 0.9980 - val_loss: 0.0765 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00177: val_loss improved from 0.07809 to 0.07646, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.0558 - acc: 0.9974 - val_loss: 0.0773 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.07646\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.0556 - acc: 0.9980 - val_loss: 0.0761 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00179: val_loss improved from 0.07646 to 0.07615, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.0547 - acc: 0.9980 - val_loss: 0.0765 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.07615\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.0542 - acc: 0.9980 - val_loss: 0.0753 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00181: val_loss improved from 0.07615 to 0.07535, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.0542 - acc: 0.9980 - val_loss: 0.0747 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00182: val_loss improved from 0.07535 to 0.07469, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.0534 - acc: 0.9980 - val_loss: 0.0748 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.07469\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.0529 - acc: 0.9974 - val_loss: 0.0727 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00184: val_loss improved from 0.07469 to 0.07268, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.0523 - acc: 0.9967 - val_loss: 0.0746 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.07268\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.0522 - acc: 0.9974 - val_loss: 0.0726 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.07268 to 0.07263, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.0517 - acc: 0.9980 - val_loss: 0.0713 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.07263 to 0.07128, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.0512 - acc: 0.9987 - val_loss: 0.0725 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.07128\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.0506 - acc: 0.9974 - val_loss: 0.0713 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.07128 to 0.07126, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.0504 - acc: 0.9974 - val_loss: 0.0714 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.07126\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.0503 - acc: 0.9987 - val_loss: 0.0699 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00191: val_loss improved from 0.07126 to 0.06992, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.0492 - acc: 0.9974 - val_loss: 0.0701 - val_acc: 0.9959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00192: val_loss did not improve from 0.06992\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.0493 - acc: 0.9974 - val_loss: 0.0693 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00193: val_loss improved from 0.06992 to 0.06927, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.0483 - acc: 0.9967 - val_loss: 0.0682 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00194: val_loss improved from 0.06927 to 0.06821, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.0481 - acc: 0.9980 - val_loss: 0.0691 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.06821\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.0475 - acc: 0.9980 - val_loss: 0.0679 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00196: val_loss improved from 0.06821 to 0.06788, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.0473 - acc: 0.9974 - val_loss: 0.0675 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00197: val_loss improved from 0.06788 to 0.06753, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.0470 - acc: 0.9980 - val_loss: 0.0683 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.06753\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.0463 - acc: 0.9974 - val_loss: 0.0666 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00199: val_loss improved from 0.06753 to 0.06664, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.0462 - acc: 0.9974 - val_loss: 0.0672 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.06664\n",
      "batch_size=160   optimizer=Adam\n",
      "Test accuracy: 65.7382%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_47 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 2.3077 - acc: 0.1651 - val_loss: 1.9997 - val_acc: 0.2716\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.99969, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.8792 - acc: 0.3257 - val_loss: 1.6764 - val_acc: 0.3951\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.99969 to 1.67640, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 1.5823 - acc: 0.4743 - val_loss: 1.4391 - val_acc: 0.5021\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.67640 to 1.43908, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 1.3899 - acc: 0.5467 - val_loss: 1.3137 - val_acc: 0.5391\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.43908 to 1.31375, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 1.2621 - acc: 0.5928 - val_loss: 1.2030 - val_acc: 0.5761\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.31375 to 1.20300, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 1.1665 - acc: 0.6276 - val_loss: 1.1327 - val_acc: 0.6337\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.20300 to 1.13266, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 1.0949 - acc: 0.6513 - val_loss: 1.0748 - val_acc: 0.6337\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.13266 to 1.07480, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 0s - loss: 1.0420 - acc: 0.6671 - val_loss: 1.0211 - val_acc: 0.6461\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.07480 to 1.02110, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.9880 - acc: 0.6849 - val_loss: 0.9843 - val_acc: 0.6914\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.02110 to 0.98429, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.9499 - acc: 0.6987 - val_loss: 0.9398 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.98429 to 0.93977, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.9136 - acc: 0.7118 - val_loss: 0.9011 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.93977 to 0.90105, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.8836 - acc: 0.7217 - val_loss: 0.8784 - val_acc: 0.7202\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.90105 to 0.87840, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.8571 - acc: 0.7342 - val_loss: 0.8408 - val_acc: 0.7325\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.87840 to 0.84082, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.8255 - acc: 0.7382 - val_loss: 0.8260 - val_acc: 0.7325\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.84082 to 0.82603, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.8026 - acc: 0.7480 - val_loss: 0.7897 - val_acc: 0.7654\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.82603 to 0.78971, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.7732 - acc: 0.7546 - val_loss: 0.7757 - val_acc: 0.7572\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.78971 to 0.77566, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.7488 - acc: 0.7632 - val_loss: 0.7478 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.77566 to 0.74778, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.7348 - acc: 0.7724 - val_loss: 0.7306 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.74778 to 0.73057, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.7038 - acc: 0.7757 - val_loss: 0.7151 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.73057 to 0.71511, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.6817 - acc: 0.7934 - val_loss: 0.6913 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.71511 to 0.69125, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.6647 - acc: 0.8046 - val_loss: 0.6811 - val_acc: 0.8148\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.69125 to 0.68112, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.6481 - acc: 0.8079 - val_loss: 0.6609 - val_acc: 0.8148\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.68112 to 0.66095, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.6321 - acc: 0.8164 - val_loss: 0.6447 - val_acc: 0.8148\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.66095 to 0.64471, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.6149 - acc: 0.8237 - val_loss: 0.6316 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.64471 to 0.63159, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.5995 - acc: 0.8250 - val_loss: 0.6118 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.63159 to 0.61177, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.5853 - acc: 0.8342 - val_loss: 0.5986 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.61177 to 0.59855, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.5720 - acc: 0.8447 - val_loss: 0.5962 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.59855 to 0.59624, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.5597 - acc: 0.8401 - val_loss: 0.5729 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.59624 to 0.57288, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.5461 - acc: 0.8546 - val_loss: 0.5642 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.57288 to 0.56420, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.5336 - acc: 0.8546 - val_loss: 0.5516 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.56420 to 0.55155, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.5228 - acc: 0.8618 - val_loss: 0.5411 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.55155 to 0.54106, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.5123 - acc: 0.8651 - val_loss: 0.5279 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.54106 to 0.52787, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.5000 - acc: 0.8717 - val_loss: 0.5199 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.52787 to 0.51991, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.4890 - acc: 0.8724 - val_loss: 0.5085 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.51991 to 0.50846, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.4788 - acc: 0.8789 - val_loss: 0.5028 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.50846 to 0.50280, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.4690 - acc: 0.8796 - val_loss: 0.4863 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.50280 to 0.48635, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.4602 - acc: 0.8882 - val_loss: 0.4845 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.48635 to 0.48449, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.4505 - acc: 0.8888 - val_loss: 0.4708 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.48449 to 0.47078, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.4458 - acc: 0.8914 - val_loss: 0.4583 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.47078 to 0.45832, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.4350 - acc: 0.8875 - val_loss: 0.4587 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.45832\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.4239 - acc: 0.9033 - val_loss: 0.4450 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.45832 to 0.44497, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.4168 - acc: 0.9079 - val_loss: 0.4393 - val_acc: 0.9012\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.44497 to 0.43935, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.4093 - acc: 0.9092 - val_loss: 0.4305 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.43935 to 0.43054, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.4019 - acc: 0.9178 - val_loss: 0.4219 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.43054 to 0.42195, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.3973 - acc: 0.9118 - val_loss: 0.4141 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.42195 to 0.41411, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.3910 - acc: 0.9230 - val_loss: 0.4124 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.41411 to 0.41241, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.3873 - acc: 0.9164 - val_loss: 0.4011 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.41241 to 0.40107, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.3748 - acc: 0.9263 - val_loss: 0.3961 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.40107 to 0.39615, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.3678 - acc: 0.9296 - val_loss: 0.3903 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.39615 to 0.39027, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.3621 - acc: 0.9250 - val_loss: 0.3801 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.39027 to 0.38014, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.3526 - acc: 0.9382 - val_loss: 0.3806 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.38014\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.3454 - acc: 0.9395 - val_loss: 0.3668 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.38014 to 0.36679, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.3399 - acc: 0.9461 - val_loss: 0.3642 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.36679 to 0.36420, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.3347 - acc: 0.9441 - val_loss: 0.3578 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.36420 to 0.35785, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.3285 - acc: 0.9467 - val_loss: 0.3543 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.35785 to 0.35425, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.3232 - acc: 0.9441 - val_loss: 0.3449 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.35425 to 0.34491, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.3187 - acc: 0.9493 - val_loss: 0.3422 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.34491 to 0.34221, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.3127 - acc: 0.9520 - val_loss: 0.3385 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.34221 to 0.33854, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.3059 - acc: 0.9566 - val_loss: 0.3318 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.33854 to 0.33178, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.3026 - acc: 0.9559 - val_loss: 0.3251 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.33178 to 0.32506, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.2989 - acc: 0.9605 - val_loss: 0.3244 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.32506 to 0.32439, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.2931 - acc: 0.9566 - val_loss: 0.3149 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.32439 to 0.31492, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.2865 - acc: 0.9638 - val_loss: 0.3157 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.31492\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.2823 - acc: 0.9632 - val_loss: 0.3058 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.31492 to 0.30583, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.2778 - acc: 0.9645 - val_loss: 0.3032 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.30583 to 0.30320, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.2745 - acc: 0.9671 - val_loss: 0.2997 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.30320 to 0.29967, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.2688 - acc: 0.9678 - val_loss: 0.2933 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.29967 to 0.29327, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.2662 - acc: 0.9684 - val_loss: 0.2925 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.29327 to 0.29251, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.2621 - acc: 0.9697 - val_loss: 0.2858 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.29251 to 0.28577, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.2555 - acc: 0.9743 - val_loss: 0.2840 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.28577 to 0.28402, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.2526 - acc: 0.9730 - val_loss: 0.2778 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.28402 to 0.27775, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.2475 - acc: 0.9730 - val_loss: 0.2774 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.27775 to 0.27737, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.2446 - acc: 0.9730 - val_loss: 0.2706 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.27737 to 0.27063, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.2419 - acc: 0.9737 - val_loss: 0.2663 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.27063 to 0.26632, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.2375 - acc: 0.9770 - val_loss: 0.2629 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.26632 to 0.26291, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.2339 - acc: 0.9770 - val_loss: 0.2594 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.26291 to 0.25944, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.2296 - acc: 0.9796 - val_loss: 0.2565 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.25944 to 0.25649, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.2267 - acc: 0.9776 - val_loss: 0.2529 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.25649 to 0.25294, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.2252 - acc: 0.9776 - val_loss: 0.2501 - val_acc: 0.9712\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00079: val_loss improved from 0.25294 to 0.25009, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.2199 - acc: 0.9803 - val_loss: 0.2454 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.25009 to 0.24537, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.2164 - acc: 0.9816 - val_loss: 0.2419 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.24537 to 0.24191, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.2132 - acc: 0.9809 - val_loss: 0.2387 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.24191 to 0.23868, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.2112 - acc: 0.9822 - val_loss: 0.2346 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.23868 to 0.23459, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.2073 - acc: 0.9829 - val_loss: 0.2363 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.23459\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.2055 - acc: 0.9829 - val_loss: 0.2290 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.23459 to 0.22897, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.2032 - acc: 0.9829 - val_loss: 0.2288 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.22897 to 0.22881, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.1993 - acc: 0.9822 - val_loss: 0.2226 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.22881 to 0.22259, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.1963 - acc: 0.9855 - val_loss: 0.2218 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.22259 to 0.22182, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.1954 - acc: 0.9868 - val_loss: 0.2201 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.22182 to 0.22005, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.1930 - acc: 0.9842 - val_loss: 0.2154 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.22005 to 0.21537, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.1880 - acc: 0.9882 - val_loss: 0.2167 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.21537\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.1849 - acc: 0.9888 - val_loss: 0.2093 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.21537 to 0.20934, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.1814 - acc: 0.9901 - val_loss: 0.2100 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.20934\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.1802 - acc: 0.9882 - val_loss: 0.2050 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.20934 to 0.20502, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.1771 - acc: 0.9895 - val_loss: 0.2013 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.20502 to 0.20129, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.1756 - acc: 0.9901 - val_loss: 0.2039 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.20129\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.1724 - acc: 0.9908 - val_loss: 0.1962 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.20129 to 0.19619, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.1702 - acc: 0.9914 - val_loss: 0.1993 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.19619\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.1674 - acc: 0.9928 - val_loss: 0.1928 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.19619 to 0.19280, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.1655 - acc: 0.9921 - val_loss: 0.1907 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.19280 to 0.19069, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.1637 - acc: 0.9941 - val_loss: 0.1912 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.19069\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.1613 - acc: 0.9908 - val_loss: 0.1874 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.19069 to 0.18742, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.1594 - acc: 0.9934 - val_loss: 0.1864 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.18742 to 0.18639, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.1576 - acc: 0.9941 - val_loss: 0.1805 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.18639 to 0.18048, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.1551 - acc: 0.9941 - val_loss: 0.1852 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.18048\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.1530 - acc: 0.9941 - val_loss: 0.1789 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.18048 to 0.17887, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.1523 - acc: 0.9928 - val_loss: 0.1790 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.17887\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.1494 - acc: 0.9947 - val_loss: 0.1756 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.17887 to 0.17557, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.1483 - acc: 0.9941 - val_loss: 0.1753 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.17557 to 0.17530, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.1461 - acc: 0.9934 - val_loss: 0.1727 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.17530 to 0.17272, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.1437 - acc: 0.9961 - val_loss: 0.1704 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.17272 to 0.17040, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.1425 - acc: 0.9954 - val_loss: 0.1700 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.17040 to 0.16996, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.1417 - acc: 0.9947 - val_loss: 0.1674 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.16996 to 0.16738, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.1392 - acc: 0.9954 - val_loss: 0.1659 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.16738 to 0.16588, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.1374 - acc: 0.9947 - val_loss: 0.1637 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.16588 to 0.16371, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.1352 - acc: 0.9954 - val_loss: 0.1607 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.16371 to 0.16072, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.1349 - acc: 0.9934 - val_loss: 0.1606 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.16072 to 0.16058, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.1325 - acc: 0.9961 - val_loss: 0.1585 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.16058 to 0.15852, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.1305 - acc: 0.9961 - val_loss: 0.1568 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.15852 to 0.15684, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.1287 - acc: 0.9954 - val_loss: 0.1548 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.15684 to 0.15481, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.1269 - acc: 0.9961 - val_loss: 0.1548 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.15481 to 0.15476, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.1260 - acc: 0.9967 - val_loss: 0.1517 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.15476 to 0.15173, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.1249 - acc: 0.9961 - val_loss: 0.1499 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.15173 to 0.14986, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.1231 - acc: 0.9967 - val_loss: 0.1509 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.14986\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.1217 - acc: 0.9974 - val_loss: 0.1486 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.14986 to 0.14859, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.1199 - acc: 0.9967 - val_loss: 0.1460 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.14859 to 0.14596, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.1188 - acc: 0.9967 - val_loss: 0.1442 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.14596 to 0.14424, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.1169 - acc: 0.9980 - val_loss: 0.1481 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.14424\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.1161 - acc: 0.9961 - val_loss: 0.1431 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.14424 to 0.14311, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.1143 - acc: 0.9967 - val_loss: 0.1409 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.14311 to 0.14095, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.1134 - acc: 0.9967 - val_loss: 0.1402 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.14095 to 0.14019, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.1120 - acc: 0.9961 - val_loss: 0.1391 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.14019 to 0.13907, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.1110 - acc: 0.9974 - val_loss: 0.1360 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.13907 to 0.13602, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.1104 - acc: 0.9967 - val_loss: 0.1390 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.13602\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.1090 - acc: 0.9974 - val_loss: 0.1353 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.13602 to 0.13528, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.1079 - acc: 0.9980 - val_loss: 0.1330 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.13528 to 0.13301, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.1069 - acc: 0.9974 - val_loss: 0.1345 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.13301\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.1054 - acc: 0.9974 - val_loss: 0.1311 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.13301 to 0.13113, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.1035 - acc: 0.9974 - val_loss: 0.1314 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.13113\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.1028 - acc: 0.9967 - val_loss: 0.1285 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.13113 to 0.12854, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.1021 - acc: 0.9961 - val_loss: 0.1301 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.12854\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.1002 - acc: 0.9974 - val_loss: 0.1268 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.12854 to 0.12681, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0993 - acc: 0.9974 - val_loss: 0.1276 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.12681\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0982 - acc: 0.9974 - val_loss: 0.1250 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.12681 to 0.12500, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0980 - acc: 0.9980 - val_loss: 0.1258 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.12500\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0970 - acc: 0.9967 - val_loss: 0.1238 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.12500 to 0.12378, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0950 - acc: 0.9980 - val_loss: 0.1227 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.12378 to 0.12270, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0945 - acc: 0.9980 - val_loss: 0.1206 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.12270 to 0.12058, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0936 - acc: 0.9974 - val_loss: 0.1206 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.12058\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0928 - acc: 0.9980 - val_loss: 0.1214 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.12058\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0916 - acc: 0.9974 - val_loss: 0.1176 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.12058 to 0.11761, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0906 - acc: 0.9980 - val_loss: 0.1191 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.11761\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0898 - acc: 0.9980 - val_loss: 0.1174 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.11761 to 0.11741, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0887 - acc: 0.9974 - val_loss: 0.1160 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.11741 to 0.11604, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.0877 - acc: 0.9974 - val_loss: 0.1145 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.11604 to 0.11454, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.0869 - acc: 0.9980 - val_loss: 0.1145 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.11454 to 0.11453, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0861 - acc: 0.9980 - val_loss: 0.1127 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.11453 to 0.11274, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.0856 - acc: 0.9980 - val_loss: 0.1127 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.11274 to 0.11271, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.0843 - acc: 0.9980 - val_loss: 0.1116 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.11271 to 0.11165, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.0834 - acc: 0.9980 - val_loss: 0.1108 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.11165 to 0.11080, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.0827 - acc: 0.9980 - val_loss: 0.1096 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.11080 to 0.10956, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.0819 - acc: 0.9980 - val_loss: 0.1101 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.10956\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.0812 - acc: 0.9980 - val_loss: 0.1101 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.10956\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.0804 - acc: 0.9987 - val_loss: 0.1071 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.10956 to 0.10708, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.0798 - acc: 0.9967 - val_loss: 0.1068 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.10708 to 0.10681, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.0796 - acc: 0.9980 - val_loss: 0.1074 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.10681\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.0788 - acc: 0.9967 - val_loss: 0.1056 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.10681 to 0.10562, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.0776 - acc: 0.9980 - val_loss: 0.1049 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.10562 to 0.10485, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.0772 - acc: 0.9974 - val_loss: 0.1034 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.10485 to 0.10337, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.0760 - acc: 0.9980 - val_loss: 0.1041 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.10337\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.0754 - acc: 0.9980 - val_loss: 0.1008 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00171: val_loss improved from 0.10337 to 0.10076, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.0748 - acc: 0.9980 - val_loss: 0.1029 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.10076\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.0738 - acc: 0.9980 - val_loss: 0.1011 - val_acc: 0.9918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00173: val_loss did not improve from 0.10076\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.0735 - acc: 0.9980 - val_loss: 0.1006 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.10076 to 0.10056, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.0726 - acc: 0.9980 - val_loss: 0.1013 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.10056\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.0717 - acc: 0.9980 - val_loss: 0.0993 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00176: val_loss improved from 0.10056 to 0.09931, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.0711 - acc: 0.9980 - val_loss: 0.0983 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00177: val_loss improved from 0.09931 to 0.09827, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.0706 - acc: 0.9980 - val_loss: 0.0990 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.09827\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.0698 - acc: 0.9974 - val_loss: 0.0972 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00179: val_loss improved from 0.09827 to 0.09715, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.0694 - acc: 0.9980 - val_loss: 0.0966 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00180: val_loss improved from 0.09715 to 0.09661, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.0687 - acc: 0.9980 - val_loss: 0.0963 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00181: val_loss improved from 0.09661 to 0.09632, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.0683 - acc: 0.9980 - val_loss: 0.0956 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00182: val_loss improved from 0.09632 to 0.09556, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.0676 - acc: 0.9980 - val_loss: 0.0963 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.09556\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.0668 - acc: 0.9980 - val_loss: 0.0936 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00184: val_loss improved from 0.09556 to 0.09357, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.0665 - acc: 0.9974 - val_loss: 0.0938 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.09357\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.0661 - acc: 0.9980 - val_loss: 0.0923 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.09357 to 0.09226, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.0659 - acc: 0.9980 - val_loss: 0.0919 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.09226 to 0.09189, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.0648 - acc: 0.9974 - val_loss: 0.0939 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.09189\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.0648 - acc: 0.9974 - val_loss: 0.0914 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.09189 to 0.09137, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.0638 - acc: 0.9980 - val_loss: 0.0903 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00190: val_loss improved from 0.09137 to 0.09028, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.0630 - acc: 0.9980 - val_loss: 0.0906 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.09028\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.0626 - acc: 0.9974 - val_loss: 0.0900 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.09028 to 0.09001, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.0626 - acc: 0.9980 - val_loss: 0.0898 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00193: val_loss improved from 0.09001 to 0.08983, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.0620 - acc: 0.9974 - val_loss: 0.0887 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00194: val_loss improved from 0.08983 to 0.08873, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.0612 - acc: 0.9974 - val_loss: 0.0894 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.08873\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.0603 - acc: 0.9980 - val_loss: 0.0879 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00196: val_loss improved from 0.08873 to 0.08786, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.0597 - acc: 0.9980 - val_loss: 0.0869 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00197: val_loss improved from 0.08786 to 0.08692, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.0593 - acc: 0.9980 - val_loss: 0.0873 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.08692\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.0590 - acc: 0.9974 - val_loss: 0.0857 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00199: val_loss improved from 0.08692 to 0.08570, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.0583 - acc: 0.9980 - val_loss: 0.0852 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00200: val_loss improved from 0.08570 to 0.08522, saving model to weights.best.Resnet50.hdf5\n",
      "batch_size=200   optimizer=Adam\n",
      "Test accuracy: 68.2451%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_48 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 2s - loss: 1.6616 - acc: 0.4263 - val_loss: 1.2453 - val_acc: 0.5885\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.24527, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 1s - loss: 1.1676 - acc: 0.6197 - val_loss: 1.0691 - val_acc: 0.6049\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.24527 to 1.06910, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 1s - loss: 1.0153 - acc: 0.6586 - val_loss: 0.9404 - val_acc: 0.6955\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.06910 to 0.94036, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 1s - loss: 0.9023 - acc: 0.7178 - val_loss: 0.8519 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.94036 to 0.85195, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 1s - loss: 0.8222 - acc: 0.7375 - val_loss: 0.7592 - val_acc: 0.7407\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.85195 to 0.75921, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 1s - loss: 0.7528 - acc: 0.7632 - val_loss: 0.7213 - val_acc: 0.7490\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.75921 to 0.72130, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 1s - loss: 0.6977 - acc: 0.7783 - val_loss: 0.6503 - val_acc: 0.8107\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.72130 to 0.65033, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 1s - loss: 0.6505 - acc: 0.7954 - val_loss: 0.6310 - val_acc: 0.8148\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.65033 to 0.63104, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 1s - loss: 0.6081 - acc: 0.8158 - val_loss: 0.5891 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.63104 to 0.58910, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 1s - loss: 0.5782 - acc: 0.8184 - val_loss: 0.5390 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.58910 to 0.53899, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 1s - loss: 0.5353 - acc: 0.8395 - val_loss: 0.5291 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.53899 to 0.52910, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 1s - loss: 0.5103 - acc: 0.8526 - val_loss: 0.4847 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.52910 to 0.48472, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 1s - loss: 0.4831 - acc: 0.8684 - val_loss: 0.4532 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.48472 to 0.45317, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 1s - loss: 0.4541 - acc: 0.8809 - val_loss: 0.4535 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.45317\n",
      "Epoch 15/200\n",
      " - 1s - loss: 0.4351 - acc: 0.8842 - val_loss: 0.4072 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.45317 to 0.40716, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 1s - loss: 0.4059 - acc: 0.8987 - val_loss: 0.3885 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.40716 to 0.38846, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 1s - loss: 0.3909 - acc: 0.9033 - val_loss: 0.3596 - val_acc: 0.9342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00017: val_loss improved from 0.38846 to 0.35963, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/200\n",
      " - 1s - loss: 0.3713 - acc: 0.9118 - val_loss: 0.3787 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.35963\n",
      "Epoch 19/200\n",
      " - 1s - loss: 0.3540 - acc: 0.9191 - val_loss: 0.3313 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.35963 to 0.33127, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 1s - loss: 0.3404 - acc: 0.9184 - val_loss: 0.3146 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.33127 to 0.31456, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 21/200\n",
      " - 1s - loss: 0.3199 - acc: 0.9349 - val_loss: 0.3174 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.31456\n",
      "Epoch 22/200\n",
      " - 1s - loss: 0.3073 - acc: 0.9368 - val_loss: 0.3038 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.31456 to 0.30379, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 1s - loss: 0.2911 - acc: 0.9474 - val_loss: 0.2942 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.30379 to 0.29415, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 24/200\n",
      " - 1s - loss: 0.2796 - acc: 0.9513 - val_loss: 0.2717 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.29415 to 0.27165, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 25/200\n",
      " - 1s - loss: 0.2691 - acc: 0.9513 - val_loss: 0.2593 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.27165 to 0.25935, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 26/200\n",
      " - 1s - loss: 0.2537 - acc: 0.9592 - val_loss: 0.2569 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.25935 to 0.25694, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 27/200\n",
      " - 1s - loss: 0.2413 - acc: 0.9645 - val_loss: 0.2668 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.25694\n",
      "Epoch 28/200\n",
      " - 1s - loss: 0.2357 - acc: 0.9638 - val_loss: 0.2344 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.25694 to 0.23442, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 29/200\n",
      " - 1s - loss: 0.2267 - acc: 0.9678 - val_loss: 0.2169 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.23442 to 0.21693, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 30/200\n",
      " - 1s - loss: 0.2122 - acc: 0.9743 - val_loss: 0.2071 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.21693 to 0.20707, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 31/200\n",
      " - 1s - loss: 0.2021 - acc: 0.9711 - val_loss: 0.2037 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.20707 to 0.20366, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 32/200\n",
      " - 1s - loss: 0.1941 - acc: 0.9789 - val_loss: 0.1932 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.20366 to 0.19324, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 33/200\n",
      " - 1s - loss: 0.1867 - acc: 0.9796 - val_loss: 0.1807 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.19324 to 0.18075, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 34/200\n",
      " - 1s - loss: 0.1793 - acc: 0.9816 - val_loss: 0.1831 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.18075\n",
      "Epoch 35/200\n",
      " - 1s - loss: 0.1710 - acc: 0.9809 - val_loss: 0.1853 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.18075\n",
      "Epoch 36/200\n",
      " - 1s - loss: 0.1658 - acc: 0.9842 - val_loss: 0.1697 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.18075 to 0.16969, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 37/200\n",
      " - 1s - loss: 0.1572 - acc: 0.9875 - val_loss: 0.1497 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.16969 to 0.14969, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 38/200\n",
      " - 1s - loss: 0.1531 - acc: 0.9901 - val_loss: 0.1529 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.14969\n",
      "Epoch 39/200\n",
      " - 1s - loss: 0.1462 - acc: 0.9921 - val_loss: 0.1575 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.14969\n",
      "Epoch 40/200\n",
      " - 1s - loss: 0.1392 - acc: 0.9888 - val_loss: 0.1389 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.14969 to 0.13893, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 41/200\n",
      " - 1s - loss: 0.1326 - acc: 0.9934 - val_loss: 0.1367 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.13893 to 0.13672, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 42/200\n",
      " - 1s - loss: 0.1286 - acc: 0.9934 - val_loss: 0.1303 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.13672 to 0.13032, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 43/200\n",
      " - 1s - loss: 0.1236 - acc: 0.9914 - val_loss: 0.1375 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.13032\n",
      "Epoch 44/200\n",
      " - 1s - loss: 0.1170 - acc: 0.9954 - val_loss: 0.1234 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.13032 to 0.12341, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 45/200\n",
      " - 1s - loss: 0.1144 - acc: 0.9921 - val_loss: 0.1195 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.12341 to 0.11950, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 46/200\n",
      " - 1s - loss: 0.1089 - acc: 0.9961 - val_loss: 0.1135 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.11950 to 0.11348, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 47/200\n",
      " - 1s - loss: 0.1047 - acc: 0.9947 - val_loss: 0.1187 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.11348\n",
      "Epoch 48/200\n",
      " - 1s - loss: 0.1010 - acc: 0.9954 - val_loss: 0.1110 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.11348 to 0.11096, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 49/200\n",
      " - 1s - loss: 0.0959 - acc: 0.9967 - val_loss: 0.1078 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.11096 to 0.10784, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 50/200\n",
      " - 1s - loss: 0.0928 - acc: 0.9967 - val_loss: 0.0994 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.10784 to 0.09942, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 51/200\n",
      " - 1s - loss: 0.0916 - acc: 0.9947 - val_loss: 0.1066 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.09942\n",
      "Epoch 52/200\n",
      " - 1s - loss: 0.0859 - acc: 0.9961 - val_loss: 0.1045 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.09942\n",
      "Epoch 53/200\n",
      " - 1s - loss: 0.0831 - acc: 0.9967 - val_loss: 0.0897 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.09942 to 0.08972, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 54/200\n",
      " - 1s - loss: 0.0792 - acc: 0.9967 - val_loss: 0.0957 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.08972\n",
      "Epoch 55/200\n",
      " - 1s - loss: 0.0752 - acc: 0.9974 - val_loss: 0.0836 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.08972 to 0.08360, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 56/200\n",
      " - 1s - loss: 0.0742 - acc: 0.9954 - val_loss: 0.0841 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.08360\n",
      "Epoch 57/200\n",
      " - 1s - loss: 0.0715 - acc: 0.9974 - val_loss: 0.0901 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.08360\n",
      "Epoch 58/200\n",
      " - 1s - loss: 0.0685 - acc: 0.9967 - val_loss: 0.0824 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.08360 to 0.08235, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 59/200\n",
      " - 1s - loss: 0.0687 - acc: 0.9961 - val_loss: 0.0848 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.08235\n",
      "Epoch 60/200\n",
      " - 1s - loss: 0.0637 - acc: 0.9980 - val_loss: 0.0757 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.08235 to 0.07566, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 61/200\n",
      " - 1s - loss: 0.0636 - acc: 0.9974 - val_loss: 0.0754 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.07566 to 0.07540, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 62/200\n",
      " - 1s - loss: 0.0592 - acc: 0.9967 - val_loss: 0.0791 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.07540\n",
      "Epoch 63/200\n",
      " - 1s - loss: 0.0573 - acc: 0.9967 - val_loss: 0.0708 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.07540 to 0.07082, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 64/200\n",
      " - 1s - loss: 0.0566 - acc: 0.9961 - val_loss: 0.0667 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.07082 to 0.06673, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 65/200\n",
      " - 1s - loss: 0.0530 - acc: 0.9967 - val_loss: 0.0629 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.06673 to 0.06285, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 66/200\n",
      " - 1s - loss: 0.0514 - acc: 0.9980 - val_loss: 0.0804 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.06285\n",
      "Epoch 67/200\n",
      " - 1s - loss: 0.0509 - acc: 0.9974 - val_loss: 0.0715 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.06285\n",
      "Epoch 68/200\n",
      " - 1s - loss: 0.0482 - acc: 0.9980 - val_loss: 0.0610 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.06285 to 0.06104, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 69/200\n",
      " - 1s - loss: 0.0463 - acc: 0.9980 - val_loss: 0.0658 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.06104\n",
      "Epoch 70/200\n",
      " - 1s - loss: 0.0459 - acc: 0.9967 - val_loss: 0.0587 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.06104 to 0.05874, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 71/200\n",
      " - 1s - loss: 0.0430 - acc: 0.9980 - val_loss: 0.0678 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.05874\n",
      "Epoch 72/200\n",
      " - 1s - loss: 0.0430 - acc: 0.9974 - val_loss: 0.0576 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.05874 to 0.05760, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 73/200\n",
      " - 1s - loss: 0.0405 - acc: 0.9980 - val_loss: 0.0579 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.05760\n",
      "Epoch 74/200\n",
      " - 1s - loss: 0.0408 - acc: 0.9974 - val_loss: 0.0664 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.05760\n",
      "Epoch 75/200\n",
      " - 1s - loss: 0.0381 - acc: 0.9974 - val_loss: 0.0543 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.05760 to 0.05430, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 76/200\n",
      " - 1s - loss: 0.0378 - acc: 0.9974 - val_loss: 0.0550 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.05430\n",
      "Epoch 77/200\n",
      " - 1s - loss: 0.0361 - acc: 0.9980 - val_loss: 0.0585 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.05430\n",
      "Epoch 78/200\n",
      " - 1s - loss: 0.0350 - acc: 0.9967 - val_loss: 0.0554 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.05430\n",
      "Epoch 79/200\n",
      " - 1s - loss: 0.0339 - acc: 0.9974 - val_loss: 0.0544 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.05430\n",
      "Epoch 80/200\n",
      " - 1s - loss: 0.0330 - acc: 0.9967 - val_loss: 0.0451 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.05430 to 0.04506, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 81/200\n",
      " - 1s - loss: 0.0329 - acc: 0.9974 - val_loss: 0.0491 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.04506\n",
      "Epoch 82/200\n",
      " - 1s - loss: 0.0305 - acc: 0.9974 - val_loss: 0.0496 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.04506\n",
      "Epoch 83/200\n",
      " - 1s - loss: 0.0303 - acc: 0.9974 - val_loss: 0.0466 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.04506\n",
      "Epoch 84/200\n",
      " - 1s - loss: 0.0291 - acc: 0.9967 - val_loss: 0.0448 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.04506 to 0.04483, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 85/200\n",
      " - 1s - loss: 0.0287 - acc: 0.9974 - val_loss: 0.0466 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.04483\n",
      "Epoch 86/200\n",
      " - 1s - loss: 0.0274 - acc: 0.9961 - val_loss: 0.0436 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.04483 to 0.04360, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 87/200\n",
      " - 1s - loss: 0.0273 - acc: 0.9967 - val_loss: 0.0468 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.04360\n",
      "Epoch 88/200\n",
      " - 1s - loss: 0.0266 - acc: 0.9967 - val_loss: 0.0467 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.04360\n",
      "Epoch 89/200\n",
      " - 1s - loss: 0.0257 - acc: 0.9967 - val_loss: 0.0525 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.04360\n",
      "Epoch 90/200\n",
      " - 1s - loss: 0.0240 - acc: 0.9967 - val_loss: 0.0413 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.04360 to 0.04134, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 91/200\n",
      " - 1s - loss: 0.0240 - acc: 0.9980 - val_loss: 0.0346 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.04134 to 0.03464, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 92/200\n",
      " - 1s - loss: 0.0241 - acc: 0.9961 - val_loss: 0.0386 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.03464\n",
      "Epoch 93/200\n",
      " - 1s - loss: 0.0228 - acc: 0.9980 - val_loss: 0.0435 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.03464\n",
      "Epoch 94/200\n",
      " - 1s - loss: 0.0219 - acc: 0.9974 - val_loss: 0.0448 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.03464\n",
      "Epoch 95/200\n",
      " - 1s - loss: 0.0224 - acc: 0.9967 - val_loss: 0.0407 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.03464\n",
      "Epoch 96/200\n",
      " - 1s - loss: 0.0210 - acc: 0.9980 - val_loss: 0.0385 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.03464\n",
      "Epoch 97/200\n",
      " - 1s - loss: 0.0208 - acc: 0.9961 - val_loss: 0.0420 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.03464\n",
      "Epoch 98/200\n",
      " - 1s - loss: 0.0196 - acc: 0.9967 - val_loss: 0.0386 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.03464\n",
      "Epoch 99/200\n",
      " - 1s - loss: 0.0195 - acc: 0.9967 - val_loss: 0.0356 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.03464\n",
      "Epoch 100/200\n",
      " - 1s - loss: 0.0193 - acc: 0.9961 - val_loss: 0.0412 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.03464\n",
      "Epoch 101/200\n",
      " - 1s - loss: 0.0192 - acc: 0.9967 - val_loss: 0.0307 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.03464 to 0.03072, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 102/200\n",
      " - 1s - loss: 0.0181 - acc: 0.9974 - val_loss: 0.0387 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.03072\n",
      "Epoch 103/200\n",
      " - 1s - loss: 0.0181 - acc: 0.9967 - val_loss: 0.0344 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.03072\n",
      "Epoch 104/200\n",
      " - 1s - loss: 0.0181 - acc: 0.9961 - val_loss: 0.0346 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.03072\n",
      "Epoch 105/200\n",
      " - 1s - loss: 0.0169 - acc: 0.9974 - val_loss: 0.0359 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.03072\n",
      "Epoch 106/200\n",
      " - 1s - loss: 0.0165 - acc: 0.9974 - val_loss: 0.0392 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.03072\n",
      "Epoch 107/200\n",
      " - 1s - loss: 0.0171 - acc: 0.9974 - val_loss: 0.0326 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.03072\n",
      "Epoch 108/200\n",
      " - 1s - loss: 0.0157 - acc: 0.9967 - val_loss: 0.0390 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.03072\n",
      "Epoch 109/200\n",
      " - 1s - loss: 0.0160 - acc: 0.9980 - val_loss: 0.0326 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.03072\n",
      "Epoch 110/200\n",
      " - 1s - loss: 0.0148 - acc: 0.9974 - val_loss: 0.0371 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.03072\n",
      "Epoch 111/200\n",
      " - 1s - loss: 0.0155 - acc: 0.9961 - val_loss: 0.0373 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.03072\n",
      "Epoch 112/200\n",
      " - 1s - loss: 0.0151 - acc: 0.9967 - val_loss: 0.0324 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.03072\n",
      "Epoch 113/200\n",
      " - 1s - loss: 0.0149 - acc: 0.9967 - val_loss: 0.0371 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.03072\n",
      "Epoch 114/200\n",
      " - 1s - loss: 0.0143 - acc: 0.9980 - val_loss: 0.0320 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.03072\n",
      "Epoch 115/200\n",
      " - 1s - loss: 0.0133 - acc: 0.9980 - val_loss: 0.0339 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.03072\n",
      "Epoch 116/200\n",
      " - 1s - loss: 0.0130 - acc: 0.9980 - val_loss: 0.0299 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.03072 to 0.02987, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 117/200\n",
      " - 1s - loss: 0.0136 - acc: 0.9980 - val_loss: 0.0369 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.02987\n",
      "Epoch 118/200\n",
      " - 1s - loss: 0.0135 - acc: 0.9961 - val_loss: 0.0285 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.02987 to 0.02849, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 119/200\n",
      " - 1s - loss: 0.0124 - acc: 0.9967 - val_loss: 0.0322 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.02849\n",
      "Epoch 120/200\n",
      " - 1s - loss: 0.0125 - acc: 0.9974 - val_loss: 0.0342 - val_acc: 0.9918\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00120: val_loss did not improve from 0.02849\n",
      "Epoch 121/200\n",
      " - 1s - loss: 0.0121 - acc: 0.9974 - val_loss: 0.0284 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.02849 to 0.02839, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 122/200\n",
      " - 1s - loss: 0.0122 - acc: 0.9974 - val_loss: 0.0302 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.02839\n",
      "Epoch 123/200\n",
      " - 1s - loss: 0.0118 - acc: 0.9980 - val_loss: 0.0303 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.02839\n",
      "Epoch 124/200\n",
      " - 1s - loss: 0.0115 - acc: 0.9974 - val_loss: 0.0365 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.02839\n",
      "Epoch 125/200\n",
      " - 1s - loss: 0.0115 - acc: 0.9974 - val_loss: 0.0287 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.02839\n",
      "Epoch 126/200\n",
      " - 1s - loss: 0.0113 - acc: 0.9980 - val_loss: 0.0310 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.02839\n",
      "Epoch 127/200\n",
      " - 1s - loss: 0.0110 - acc: 0.9967 - val_loss: 0.0297 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.02839\n",
      "Epoch 128/200\n",
      " - 1s - loss: 0.0114 - acc: 0.9980 - val_loss: 0.0305 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.02839\n",
      "Epoch 129/200\n",
      " - 1s - loss: 0.0114 - acc: 0.9967 - val_loss: 0.0302 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.02839\n",
      "Epoch 130/200\n",
      " - 1s - loss: 0.0110 - acc: 0.9974 - val_loss: 0.0297 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.02839\n",
      "Epoch 131/200\n",
      " - 1s - loss: 0.0106 - acc: 0.9967 - val_loss: 0.0264 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.02839 to 0.02644, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 132/200\n",
      " - 1s - loss: 0.0103 - acc: 0.9967 - val_loss: 0.0303 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.02644\n",
      "Epoch 133/200\n",
      " - 1s - loss: 0.0103 - acc: 0.9967 - val_loss: 0.0297 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.02644\n",
      "Epoch 134/200\n",
      " - 1s - loss: 0.0103 - acc: 0.9974 - val_loss: 0.0263 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.02644 to 0.02627, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 135/200\n",
      " - 1s - loss: 0.0094 - acc: 0.9980 - val_loss: 0.0276 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.02627\n",
      "Epoch 136/200\n",
      " - 1s - loss: 0.0097 - acc: 0.9967 - val_loss: 0.0277 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.02627\n",
      "Epoch 137/200\n",
      " - 1s - loss: 0.0095 - acc: 0.9980 - val_loss: 0.0310 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.02627\n",
      "Epoch 138/200\n",
      " - 1s - loss: 0.0096 - acc: 0.9974 - val_loss: 0.0253 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.02627 to 0.02534, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 139/200\n",
      " - 1s - loss: 0.0097 - acc: 0.9967 - val_loss: 0.0295 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.02534\n",
      "Epoch 140/200\n",
      " - 1s - loss: 0.0090 - acc: 0.9967 - val_loss: 0.0302 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.02534\n",
      "Epoch 141/200\n",
      " - 1s - loss: 0.0086 - acc: 0.9974 - val_loss: 0.0267 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.02534\n",
      "Epoch 142/200\n",
      " - 1s - loss: 0.0094 - acc: 0.9974 - val_loss: 0.0330 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.02534\n",
      "Epoch 143/200\n",
      " - 1s - loss: 0.0088 - acc: 0.9967 - val_loss: 0.0257 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.02534\n",
      "Epoch 144/200\n",
      " - 1s - loss: 0.0092 - acc: 0.9967 - val_loss: 0.0274 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.02534\n",
      "Epoch 145/200\n",
      " - 1s - loss: 0.0085 - acc: 0.9980 - val_loss: 0.0272 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.02534\n",
      "Epoch 146/200\n",
      " - 1s - loss: 0.0090 - acc: 0.9961 - val_loss: 0.0307 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.02534\n",
      "Epoch 147/200\n",
      " - 1s - loss: 0.0089 - acc: 0.9961 - val_loss: 0.0294 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.02534\n",
      "Epoch 148/200\n",
      " - 1s - loss: 0.0087 - acc: 0.9961 - val_loss: 0.0281 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.02534\n",
      "Epoch 149/200\n",
      " - 1s - loss: 0.0081 - acc: 0.9980 - val_loss: 0.0346 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.02534\n",
      "Epoch 150/200\n",
      " - 1s - loss: 0.0084 - acc: 0.9974 - val_loss: 0.0286 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.02534\n",
      "Epoch 151/200\n",
      " - 1s - loss: 0.0080 - acc: 0.9980 - val_loss: 0.0257 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.02534\n",
      "Epoch 152/200\n",
      " - 1s - loss: 0.0080 - acc: 0.9967 - val_loss: 0.0297 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.02534\n",
      "Epoch 153/200\n",
      " - 1s - loss: 0.0075 - acc: 0.9974 - val_loss: 0.0321 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.02534\n",
      "Epoch 154/200\n",
      " - 1s - loss: 0.0076 - acc: 0.9974 - val_loss: 0.0297 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.02534\n",
      "Epoch 155/200\n",
      " - 1s - loss: 0.0079 - acc: 0.9967 - val_loss: 0.0295 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.02534\n",
      "Epoch 156/200\n",
      " - 1s - loss: 0.0076 - acc: 0.9967 - val_loss: 0.0251 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.02534 to 0.02512, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 157/200\n",
      " - 1s - loss: 0.0075 - acc: 0.9967 - val_loss: 0.0299 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.02512\n",
      "Epoch 158/200\n",
      " - 1s - loss: 0.0080 - acc: 0.9974 - val_loss: 0.0336 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.02512\n",
      "Epoch 159/200\n",
      " - 1s - loss: 0.0074 - acc: 0.9967 - val_loss: 0.0261 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.02512\n",
      "Epoch 160/200\n",
      " - 1s - loss: 0.0075 - acc: 0.9967 - val_loss: 0.0288 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.02512\n",
      "Epoch 161/200\n",
      " - 1s - loss: 0.0072 - acc: 0.9967 - val_loss: 0.0280 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.02512\n",
      "Epoch 162/200\n",
      " - 1s - loss: 0.0070 - acc: 0.9974 - val_loss: 0.0264 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.02512\n",
      "Epoch 163/200\n",
      " - 1s - loss: 0.0073 - acc: 0.9974 - val_loss: 0.0257 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.02512\n",
      "Epoch 164/200\n",
      " - 1s - loss: 0.0071 - acc: 0.9974 - val_loss: 0.0278 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.02512\n",
      "Epoch 165/200\n",
      " - 1s - loss: 0.0067 - acc: 0.9974 - val_loss: 0.0328 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.02512\n",
      "Epoch 166/200\n",
      " - 1s - loss: 0.0071 - acc: 0.9974 - val_loss: 0.0262 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.02512\n",
      "Epoch 167/200\n",
      " - 1s - loss: 0.0073 - acc: 0.9974 - val_loss: 0.0279 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.02512\n",
      "Epoch 168/200\n",
      " - 1s - loss: 0.0067 - acc: 0.9974 - val_loss: 0.0291 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.02512\n",
      "Epoch 169/200\n",
      " - 1s - loss: 0.0071 - acc: 0.9974 - val_loss: 0.0322 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.02512\n",
      "Epoch 170/200\n",
      " - 1s - loss: 0.0066 - acc: 0.9974 - val_loss: 0.0311 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.02512\n",
      "Epoch 171/200\n",
      " - 1s - loss: 0.0067 - acc: 0.9974 - val_loss: 0.0303 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.02512\n",
      "Epoch 172/200\n",
      " - 1s - loss: 0.0064 - acc: 0.9974 - val_loss: 0.0321 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.02512\n",
      "Epoch 173/200\n",
      " - 1s - loss: 0.0073 - acc: 0.9974 - val_loss: 0.0273 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.02512\n",
      "Epoch 174/200\n",
      " - 1s - loss: 0.0064 - acc: 0.9980 - val_loss: 0.0285 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.02512\n",
      "Epoch 175/200\n",
      " - 1s - loss: 0.0070 - acc: 0.9967 - val_loss: 0.0287 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.02512\n",
      "Epoch 176/200\n",
      " - 1s - loss: 0.0068 - acc: 0.9967 - val_loss: 0.0281 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.02512\n",
      "Epoch 177/200\n",
      " - 1s - loss: 0.0059 - acc: 0.9980 - val_loss: 0.0266 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.02512\n",
      "Epoch 178/200\n",
      " - 1s - loss: 0.0069 - acc: 0.9967 - val_loss: 0.0298 - val_acc: 0.9918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00178: val_loss did not improve from 0.02512\n",
      "Epoch 179/200\n",
      " - 1s - loss: 0.0060 - acc: 0.9980 - val_loss: 0.0300 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.02512\n",
      "Epoch 180/200\n",
      " - 1s - loss: 0.0065 - acc: 0.9967 - val_loss: 0.0269 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.02512\n",
      "Epoch 181/200\n",
      " - 1s - loss: 0.0066 - acc: 0.9967 - val_loss: 0.0274 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.02512\n",
      "Epoch 182/200\n",
      " - 1s - loss: 0.0061 - acc: 0.9974 - val_loss: 0.0286 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.02512\n",
      "Epoch 183/200\n",
      " - 1s - loss: 0.0063 - acc: 0.9967 - val_loss: 0.0264 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.02512\n",
      "Epoch 184/200\n",
      " - 1s - loss: 0.0063 - acc: 0.9961 - val_loss: 0.0299 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.02512\n",
      "Epoch 185/200\n",
      " - 1s - loss: 0.0065 - acc: 0.9967 - val_loss: 0.0271 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.02512\n",
      "Epoch 186/200\n",
      " - 1s - loss: 0.0056 - acc: 0.9967 - val_loss: 0.0261 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.02512\n",
      "Epoch 187/200\n",
      " - 1s - loss: 0.0065 - acc: 0.9974 - val_loss: 0.0283 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.02512\n",
      "Epoch 188/200\n",
      " - 1s - loss: 0.0063 - acc: 0.9974 - val_loss: 0.0280 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.02512\n",
      "Epoch 189/200\n",
      " - 1s - loss: 0.0062 - acc: 0.9967 - val_loss: 0.0292 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.02512\n",
      "Epoch 190/200\n",
      " - 1s - loss: 0.0067 - acc: 0.9967 - val_loss: 0.0279 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.02512\n",
      "Epoch 191/200\n",
      " - 1s - loss: 0.0060 - acc: 0.9980 - val_loss: 0.0295 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.02512\n",
      "Epoch 192/200\n",
      " - 1s - loss: 0.0062 - acc: 0.9967 - val_loss: 0.0259 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.02512\n",
      "Epoch 193/200\n",
      " - 1s - loss: 0.0058 - acc: 0.9974 - val_loss: 0.0264 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.02512\n",
      "Epoch 194/200\n",
      " - 1s - loss: 0.0059 - acc: 0.9974 - val_loss: 0.0271 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.02512\n",
      "Epoch 195/200\n",
      " - 1s - loss: 0.0061 - acc: 0.9974 - val_loss: 0.0287 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.02512\n",
      "Epoch 196/200\n",
      " - 1s - loss: 0.0059 - acc: 0.9967 - val_loss: 0.0281 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.02512\n",
      "Epoch 197/200\n",
      " - 1s - loss: 0.0058 - acc: 0.9974 - val_loss: 0.0270 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.02512\n",
      "Epoch 198/200\n",
      " - 1s - loss: 0.0060 - acc: 0.9967 - val_loss: 0.0324 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.02512\n",
      "Epoch 199/200\n",
      " - 1s - loss: 0.0061 - acc: 0.9967 - val_loss: 0.0233 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00199: val_loss improved from 0.02512 to 0.02327, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 200/200\n",
      " - 1s - loss: 0.0065 - acc: 0.9961 - val_loss: 0.0308 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.02327\n",
      "batch_size=10   optimizer=Adamax\n",
      "Test accuracy: 68.5237%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_49 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 2s - loss: 1.7464 - acc: 0.3829 - val_loss: 1.3181 - val_acc: 0.5638\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.31808, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.2198 - acc: 0.6125 - val_loss: 1.1281 - val_acc: 0.6214\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.31808 to 1.12805, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 1.0481 - acc: 0.6579 - val_loss: 1.0059 - val_acc: 0.6914\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.12805 to 1.00587, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.9443 - acc: 0.7013 - val_loss: 0.9112 - val_acc: 0.6914\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.00587 to 0.91122, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.8698 - acc: 0.7211 - val_loss: 0.8565 - val_acc: 0.7284\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.91122 to 0.85647, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.8080 - acc: 0.7487 - val_loss: 0.8138 - val_acc: 0.7449\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.85647 to 0.81385, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.7560 - acc: 0.7743 - val_loss: 0.7259 - val_acc: 0.7572\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.81385 to 0.72587, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.7169 - acc: 0.7730 - val_loss: 0.6924 - val_acc: 0.7819\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.72587 to 0.69236, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.6681 - acc: 0.7954 - val_loss: 0.6567 - val_acc: 0.8107\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.69236 to 0.65668, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.6363 - acc: 0.8020 - val_loss: 0.6328 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.65668 to 0.63279, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.6059 - acc: 0.8204 - val_loss: 0.6172 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.63279 to 0.61721, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.5824 - acc: 0.8270 - val_loss: 0.5920 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.61721 to 0.59204, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.5488 - acc: 0.8421 - val_loss: 0.5500 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.59204 to 0.55004, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.5173 - acc: 0.8572 - val_loss: 0.5073 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.55004 to 0.50727, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.5017 - acc: 0.8539 - val_loss: 0.5048 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.50727 to 0.50478, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.4779 - acc: 0.8743 - val_loss: 0.4609 - val_acc: 0.8765\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.50478 to 0.46093, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.4527 - acc: 0.8816 - val_loss: 0.4604 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.46093 to 0.46037, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.4373 - acc: 0.8895 - val_loss: 0.4764 - val_acc: 0.8765\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.46037\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.4230 - acc: 0.8921 - val_loss: 0.4097 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.46037 to 0.40974, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.3993 - acc: 0.9020 - val_loss: 0.4226 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.40974\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.3932 - acc: 0.9026 - val_loss: 0.3975 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.40974 to 0.39751, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.3733 - acc: 0.9171 - val_loss: 0.3718 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.39751 to 0.37176, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.3519 - acc: 0.9230 - val_loss: 0.3465 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.37176 to 0.34649, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.3427 - acc: 0.9322 - val_loss: 0.3449 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.34649 to 0.34493, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.3315 - acc: 0.9276 - val_loss: 0.3729 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.34493\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.3192 - acc: 0.9368 - val_loss: 0.3140 - val_acc: 0.9630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00026: val_loss improved from 0.34493 to 0.31405, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.3041 - acc: 0.9434 - val_loss: 0.3140 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.31405 to 0.31401, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2903 - acc: 0.9513 - val_loss: 0.2991 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.31401 to 0.29914, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2852 - acc: 0.9507 - val_loss: 0.2732 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.29914 to 0.27319, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2637 - acc: 0.9612 - val_loss: 0.2835 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.27319\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2625 - acc: 0.9586 - val_loss: 0.2667 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.27319 to 0.26672, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2502 - acc: 0.9618 - val_loss: 0.2574 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.26672 to 0.25735, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2406 - acc: 0.9651 - val_loss: 0.2420 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.25735 to 0.24199, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2321 - acc: 0.9678 - val_loss: 0.2434 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.24199\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2221 - acc: 0.9757 - val_loss: 0.2430 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.24199\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2175 - acc: 0.9711 - val_loss: 0.2252 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.24199 to 0.22525, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2074 - acc: 0.9770 - val_loss: 0.2182 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.22525 to 0.21824, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.1997 - acc: 0.9822 - val_loss: 0.2010 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.21824 to 0.20095, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.1925 - acc: 0.9842 - val_loss: 0.2021 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.20095\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.1860 - acc: 0.9809 - val_loss: 0.1981 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.20095 to 0.19807, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.1776 - acc: 0.9803 - val_loss: 0.1847 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.19807 to 0.18469, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.1725 - acc: 0.9868 - val_loss: 0.1856 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.18469\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1645 - acc: 0.9901 - val_loss: 0.1814 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.18469 to 0.18135, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1630 - acc: 0.9849 - val_loss: 0.1677 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.18135 to 0.16767, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1561 - acc: 0.9895 - val_loss: 0.1651 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.16767 to 0.16506, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1470 - acc: 0.9908 - val_loss: 0.1699 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.16506\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1430 - acc: 0.9928 - val_loss: 0.1600 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.16506 to 0.16001, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1409 - acc: 0.9914 - val_loss: 0.1647 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.16001\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1344 - acc: 0.9914 - val_loss: 0.1541 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.16001 to 0.15415, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1303 - acc: 0.9934 - val_loss: 0.1481 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.15415 to 0.14809, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1257 - acc: 0.9947 - val_loss: 0.1553 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.14809\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1228 - acc: 0.9914 - val_loss: 0.1339 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.14809 to 0.13386, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1164 - acc: 0.9954 - val_loss: 0.1327 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.13386 to 0.13270, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1134 - acc: 0.9961 - val_loss: 0.1367 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.13270\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1115 - acc: 0.9947 - val_loss: 0.1251 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.13270 to 0.12505, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1049 - acc: 0.9947 - val_loss: 0.1228 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.12505 to 0.12277, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1017 - acc: 0.9980 - val_loss: 0.1224 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.12277 to 0.12243, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.0994 - acc: 0.9961 - val_loss: 0.1090 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.12243 to 0.10899, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.0942 - acc: 0.9961 - val_loss: 0.1085 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.10899 to 0.10852, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.0922 - acc: 0.9954 - val_loss: 0.1089 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.10852\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.0888 - acc: 0.9967 - val_loss: 0.1026 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.10852 to 0.10256, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.0876 - acc: 0.9980 - val_loss: 0.1021 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.10256 to 0.10207, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.0840 - acc: 0.9961 - val_loss: 0.1058 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.10207\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.0813 - acc: 0.9961 - val_loss: 0.1045 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.10207\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.0786 - acc: 0.9967 - val_loss: 0.1060 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.10207\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.0773 - acc: 0.9961 - val_loss: 0.0906 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.10207 to 0.09065, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.0726 - acc: 0.9980 - val_loss: 0.0889 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.09065 to 0.08889, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.0715 - acc: 0.9980 - val_loss: 0.0835 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.08889 to 0.08354, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.0702 - acc: 0.9974 - val_loss: 0.0881 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.08354\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.0679 - acc: 0.9961 - val_loss: 0.0866 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.08354\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.0653 - acc: 0.9974 - val_loss: 0.0857 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.08354\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.0634 - acc: 0.9967 - val_loss: 0.0763 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.08354 to 0.07634, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.0608 - acc: 0.9961 - val_loss: 0.0769 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.07634\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.0587 - acc: 0.9980 - val_loss: 0.0805 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.07634\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.0571 - acc: 0.9974 - val_loss: 0.0772 - val_acc: 0.9918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00075: val_loss did not improve from 0.07634\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.0551 - acc: 0.9967 - val_loss: 0.0726 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.07634 to 0.07261, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.0533 - acc: 0.9974 - val_loss: 0.0839 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.07261\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.0515 - acc: 0.9974 - val_loss: 0.0790 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.07261\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.0517 - acc: 0.9974 - val_loss: 0.0770 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.07261\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0494 - acc: 0.9980 - val_loss: 0.0729 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.07261\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0478 - acc: 0.9967 - val_loss: 0.0767 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.07261\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0465 - acc: 0.9987 - val_loss: 0.0656 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.07261 to 0.06563, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0459 - acc: 0.9974 - val_loss: 0.0628 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.06563 to 0.06283, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0432 - acc: 0.9980 - val_loss: 0.0647 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.06283\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0431 - acc: 0.9967 - val_loss: 0.0539 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.06283 to 0.05392, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0418 - acc: 0.9974 - val_loss: 0.0600 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.05392\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0400 - acc: 0.9980 - val_loss: 0.0628 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.05392\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0395 - acc: 0.9967 - val_loss: 0.0646 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.05392\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0385 - acc: 0.9961 - val_loss: 0.0616 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.05392\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0379 - acc: 0.9974 - val_loss: 0.0549 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.05392\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0364 - acc: 0.9980 - val_loss: 0.0581 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.05392\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0352 - acc: 0.9967 - val_loss: 0.0552 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.05392\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0352 - acc: 0.9967 - val_loss: 0.0517 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.05392 to 0.05167, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0327 - acc: 0.9980 - val_loss: 0.0600 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.05167\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0328 - acc: 0.9967 - val_loss: 0.0529 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.05167\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0323 - acc: 0.9980 - val_loss: 0.0535 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.05167\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0310 - acc: 0.9967 - val_loss: 0.0516 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.05167 to 0.05160, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0301 - acc: 0.9974 - val_loss: 0.0613 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.05160\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0297 - acc: 0.9980 - val_loss: 0.0489 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.05160 to 0.04894, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0293 - acc: 0.9974 - val_loss: 0.0482 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.04894 to 0.04818, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0278 - acc: 0.9967 - val_loss: 0.0518 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.04818\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0276 - acc: 0.9980 - val_loss: 0.0538 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.04818\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0261 - acc: 0.9961 - val_loss: 0.0499 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.04818\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0257 - acc: 0.9974 - val_loss: 0.0501 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.04818\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0258 - acc: 0.9967 - val_loss: 0.0493 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.04818\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0243 - acc: 0.9987 - val_loss: 0.0489 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.04818\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0244 - acc: 0.9974 - val_loss: 0.0468 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.04818 to 0.04678, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0238 - acc: 0.9961 - val_loss: 0.0407 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.04678 to 0.04068, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0236 - acc: 0.9967 - val_loss: 0.0461 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.04068\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0229 - acc: 0.9967 - val_loss: 0.0384 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.04068 to 0.03838, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0224 - acc: 0.9974 - val_loss: 0.0470 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.03838\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0211 - acc: 0.9980 - val_loss: 0.0494 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.03838\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0209 - acc: 0.9974 - val_loss: 0.0419 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.03838\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0206 - acc: 0.9974 - val_loss: 0.0436 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.03838\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0202 - acc: 0.9961 - val_loss: 0.0424 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.03838\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0197 - acc: 0.9967 - val_loss: 0.0419 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.03838\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0198 - acc: 0.9961 - val_loss: 0.0450 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.03838\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0194 - acc: 0.9974 - val_loss: 0.0422 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.03838\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0185 - acc: 0.9980 - val_loss: 0.0423 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.03838\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0187 - acc: 0.9961 - val_loss: 0.0397 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.03838\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0185 - acc: 0.9967 - val_loss: 0.0411 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.03838\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0174 - acc: 0.9980 - val_loss: 0.0381 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.03838 to 0.03810, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0167 - acc: 0.9974 - val_loss: 0.0431 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.03810\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0175 - acc: 0.9967 - val_loss: 0.0433 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.03810\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0165 - acc: 0.9961 - val_loss: 0.0398 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.03810\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0161 - acc: 0.9961 - val_loss: 0.0435 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.03810\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0158 - acc: 0.9974 - val_loss: 0.0369 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.03810 to 0.03693, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0154 - acc: 0.9974 - val_loss: 0.0421 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.03693\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0153 - acc: 0.9974 - val_loss: 0.0323 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.03693 to 0.03231, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0153 - acc: 0.9974 - val_loss: 0.0404 - val_acc: 0.9918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00130: val_loss did not improve from 0.03231\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0150 - acc: 0.9974 - val_loss: 0.0373 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.03231\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0144 - acc: 0.9974 - val_loss: 0.0350 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.03231\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0145 - acc: 0.9967 - val_loss: 0.0391 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.03231\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0143 - acc: 0.9974 - val_loss: 0.0403 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.03231\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0143 - acc: 0.9961 - val_loss: 0.0438 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.03231\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0140 - acc: 0.9967 - val_loss: 0.0367 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.03231\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0130 - acc: 0.9980 - val_loss: 0.0304 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.03231 to 0.03042, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0133 - acc: 0.9967 - val_loss: 0.0360 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.03042\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0132 - acc: 0.9974 - val_loss: 0.0325 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.03042\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0126 - acc: 0.9974 - val_loss: 0.0336 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.03042\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0125 - acc: 0.9974 - val_loss: 0.0339 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.03042\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0127 - acc: 0.9980 - val_loss: 0.0436 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.03042\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0120 - acc: 0.9967 - val_loss: 0.0436 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.03042\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0119 - acc: 0.9961 - val_loss: 0.0339 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.03042\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0121 - acc: 0.9967 - val_loss: 0.0388 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.03042\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0113 - acc: 0.9974 - val_loss: 0.0314 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.03042\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0118 - acc: 0.9967 - val_loss: 0.0337 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.03042\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0108 - acc: 0.9974 - val_loss: 0.0393 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.03042\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0111 - acc: 0.9967 - val_loss: 0.0353 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.03042\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0113 - acc: 0.9974 - val_loss: 0.0338 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.03042\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0106 - acc: 0.9980 - val_loss: 0.0339 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.03042\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0108 - acc: 0.9974 - val_loss: 0.0324 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.03042\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0107 - acc: 0.9974 - val_loss: 0.0342 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.03042\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0103 - acc: 0.9974 - val_loss: 0.0362 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.03042\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.0105 - acc: 0.9967 - val_loss: 0.0351 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.03042\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.0101 - acc: 0.9980 - val_loss: 0.0352 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.03042\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0096 - acc: 0.9980 - val_loss: 0.0382 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.03042\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.0100 - acc: 0.9967 - val_loss: 0.0333 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.03042\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.0098 - acc: 0.9974 - val_loss: 0.0314 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.03042\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.0105 - acc: 0.9967 - val_loss: 0.0339 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.03042\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.0094 - acc: 0.9967 - val_loss: 0.0311 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.03042\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.0097 - acc: 0.9967 - val_loss: 0.0305 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.03042\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.0093 - acc: 0.9967 - val_loss: 0.0396 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.03042\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.0094 - acc: 0.9974 - val_loss: 0.0278 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.03042 to 0.02779, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.0089 - acc: 0.9974 - val_loss: 0.0333 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.02779\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.0090 - acc: 0.9961 - val_loss: 0.0367 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.02779\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.0087 - acc: 0.9974 - val_loss: 0.0321 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.02779\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.0091 - acc: 0.9961 - val_loss: 0.0365 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.02779\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.0083 - acc: 0.9974 - val_loss: 0.0308 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.02779\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.0084 - acc: 0.9967 - val_loss: 0.0307 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.02779\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.0087 - acc: 0.9974 - val_loss: 0.0379 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.02779\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.0088 - acc: 0.9974 - val_loss: 0.0350 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.02779\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.0086 - acc: 0.9967 - val_loss: 0.0324 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.02779\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.0079 - acc: 0.9980 - val_loss: 0.0358 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.02779\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.0078 - acc: 0.9967 - val_loss: 0.0276 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00175: val_loss improved from 0.02779 to 0.02756, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.0078 - acc: 0.9974 - val_loss: 0.0286 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.02756\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.0078 - acc: 0.9974 - val_loss: 0.0413 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.02756\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.0082 - acc: 0.9974 - val_loss: 0.0346 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.02756\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.0077 - acc: 0.9974 - val_loss: 0.0324 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.02756\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.0076 - acc: 0.9967 - val_loss: 0.0286 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.02756\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.0075 - acc: 0.9974 - val_loss: 0.0317 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.02756\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.0076 - acc: 0.9967 - val_loss: 0.0317 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.02756\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.0077 - acc: 0.9967 - val_loss: 0.0316 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.02756\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.0079 - acc: 0.9967 - val_loss: 0.0341 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.02756\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.0073 - acc: 0.9980 - val_loss: 0.0301 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.02756\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.0073 - acc: 0.9974 - val_loss: 0.0377 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.02756\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.0079 - acc: 0.9961 - val_loss: 0.0341 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.02756\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.0075 - acc: 0.9974 - val_loss: 0.0344 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.02756\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.0072 - acc: 0.9967 - val_loss: 0.0333 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.02756\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.0072 - acc: 0.9974 - val_loss: 0.0323 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.02756\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.0072 - acc: 0.9974 - val_loss: 0.0276 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.02756\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.0067 - acc: 0.9980 - val_loss: 0.0325 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.02756\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.0074 - acc: 0.9961 - val_loss: 0.0298 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.02756\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.0069 - acc: 0.9980 - val_loss: 0.0350 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.02756\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.0069 - acc: 0.9967 - val_loss: 0.0323 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.02756\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.0069 - acc: 0.9967 - val_loss: 0.0325 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.02756\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.0069 - acc: 0.9961 - val_loss: 0.0327 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.02756\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.0072 - acc: 0.9974 - val_loss: 0.0299 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.02756\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.0067 - acc: 0.9967 - val_loss: 0.0350 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.02756\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.0070 - acc: 0.9967 - val_loss: 0.0300 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.02756\n",
      "batch_size=20   optimizer=Adamax\n",
      "Test accuracy: 69.0808%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_50 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 1.9902 - acc: 0.3013 - val_loss: 1.5032 - val_acc: 0.5144\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.50321, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.3762 - acc: 0.5355 - val_loss: 1.2538 - val_acc: 0.5967\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.50321 to 1.25376, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 1.1746 - acc: 0.6224 - val_loss: 1.0889 - val_acc: 0.6379\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.25376 to 1.08891, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 1.0608 - acc: 0.6586 - val_loss: 1.0007 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.08891 to 1.00069, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.9852 - acc: 0.6862 - val_loss: 0.9279 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.00069 to 0.92791, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.9231 - acc: 0.6961 - val_loss: 0.8981 - val_acc: 0.7078\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.92791 to 0.89810, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.8616 - acc: 0.7250 - val_loss: 0.8542 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.89810 to 0.85420, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.8178 - acc: 0.7461 - val_loss: 0.7853 - val_acc: 0.7737\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.85420 to 0.78526, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.7747 - acc: 0.7612 - val_loss: 0.7411 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.78526 to 0.74108, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.7437 - acc: 0.7704 - val_loss: 0.7342 - val_acc: 0.7572\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.74108 to 0.73417, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.7075 - acc: 0.7809 - val_loss: 0.6825 - val_acc: 0.7901\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.73417 to 0.68255, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.6802 - acc: 0.7908 - val_loss: 0.6566 - val_acc: 0.8107\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.68255 to 0.65660, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.6490 - acc: 0.8007 - val_loss: 0.6416 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.65660 to 0.64161, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.6360 - acc: 0.8086 - val_loss: 0.6149 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.64161 to 0.61486, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.5993 - acc: 0.8217 - val_loss: 0.5950 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.61486 to 0.59503, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.5744 - acc: 0.8316 - val_loss: 0.5642 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.59503 to 0.56418, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.5552 - acc: 0.8500 - val_loss: 0.5566 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.56418 to 0.55658, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.5377 - acc: 0.8474 - val_loss: 0.5393 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.55658 to 0.53934, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.5166 - acc: 0.8599 - val_loss: 0.5180 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.53934 to 0.51798, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.4982 - acc: 0.8704 - val_loss: 0.5114 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.51798 to 0.51142, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.4862 - acc: 0.8711 - val_loss: 0.4817 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.51142 to 0.48175, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.4719 - acc: 0.8816 - val_loss: 0.4645 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.48175 to 0.46450, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.4591 - acc: 0.8796 - val_loss: 0.4474 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.46450 to 0.44742, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.4404 - acc: 0.8908 - val_loss: 0.4388 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.44742 to 0.43883, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.4239 - acc: 0.8961 - val_loss: 0.4415 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.43883\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.4140 - acc: 0.9033 - val_loss: 0.4111 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.43883 to 0.41115, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.3956 - acc: 0.9086 - val_loss: 0.4092 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.41115 to 0.40920, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.3868 - acc: 0.9158 - val_loss: 0.3948 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.40920 to 0.39483, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.3717 - acc: 0.9138 - val_loss: 0.3794 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.39483 to 0.37936, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.3610 - acc: 0.9217 - val_loss: 0.3673 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.37936 to 0.36730, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.3507 - acc: 0.9289 - val_loss: 0.3521 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.36730 to 0.35215, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.3430 - acc: 0.9257 - val_loss: 0.3407 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.35215 to 0.34070, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.3307 - acc: 0.9316 - val_loss: 0.3402 - val_acc: 0.9547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00033: val_loss improved from 0.34070 to 0.34024, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.3190 - acc: 0.9395 - val_loss: 0.3310 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.34024 to 0.33102, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.3090 - acc: 0.9467 - val_loss: 0.3262 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.33102 to 0.32616, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.3031 - acc: 0.9434 - val_loss: 0.3144 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.32616 to 0.31435, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2908 - acc: 0.9500 - val_loss: 0.2945 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.31435 to 0.29450, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2866 - acc: 0.9592 - val_loss: 0.2978 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.29450\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.2749 - acc: 0.9618 - val_loss: 0.2878 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.29450 to 0.28783, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.2651 - acc: 0.9612 - val_loss: 0.2760 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.28783 to 0.27599, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.2595 - acc: 0.9592 - val_loss: 0.2740 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.27599 to 0.27405, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.2513 - acc: 0.9625 - val_loss: 0.2611 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.27405 to 0.26115, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.2424 - acc: 0.9697 - val_loss: 0.2509 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.26115 to 0.25091, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.2346 - acc: 0.9757 - val_loss: 0.2531 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.25091\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.2300 - acc: 0.9750 - val_loss: 0.2410 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.25091 to 0.24102, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.2247 - acc: 0.9730 - val_loss: 0.2314 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.24102 to 0.23135, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.2176 - acc: 0.9770 - val_loss: 0.2259 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.23135 to 0.22591, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.2075 - acc: 0.9796 - val_loss: 0.2299 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.22591\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.2039 - acc: 0.9816 - val_loss: 0.2143 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.22591 to 0.21429, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1980 - acc: 0.9822 - val_loss: 0.2136 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.21429 to 0.21360, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1948 - acc: 0.9809 - val_loss: 0.2008 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.21360 to 0.20084, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1868 - acc: 0.9868 - val_loss: 0.2032 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.20084\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1839 - acc: 0.9849 - val_loss: 0.1977 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.20084 to 0.19774, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1774 - acc: 0.9875 - val_loss: 0.1937 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.19774 to 0.19372, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1715 - acc: 0.9895 - val_loss: 0.1929 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.19372 to 0.19293, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1665 - acc: 0.9882 - val_loss: 0.1818 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.19293 to 0.18185, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1620 - acc: 0.9888 - val_loss: 0.1768 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.18185 to 0.17680, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1578 - acc: 0.9882 - val_loss: 0.1655 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.17680 to 0.16546, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1535 - acc: 0.9901 - val_loss: 0.1715 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.16546\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1475 - acc: 0.9921 - val_loss: 0.1689 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.16546\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1448 - acc: 0.9908 - val_loss: 0.1607 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.16546 to 0.16069, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1400 - acc: 0.9934 - val_loss: 0.1544 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.16069 to 0.15440, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1369 - acc: 0.9928 - val_loss: 0.1621 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.15440\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1341 - acc: 0.9928 - val_loss: 0.1414 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.15440 to 0.14143, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1302 - acc: 0.9914 - val_loss: 0.1391 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.14143 to 0.13907, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1258 - acc: 0.9941 - val_loss: 0.1367 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.13907 to 0.13667, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1229 - acc: 0.9961 - val_loss: 0.1356 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.13667 to 0.13555, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1200 - acc: 0.9954 - val_loss: 0.1324 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.13555 to 0.13237, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1170 - acc: 0.9934 - val_loss: 0.1324 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.13237\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1135 - acc: 0.9961 - val_loss: 0.1285 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.13237 to 0.12845, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1094 - acc: 0.9947 - val_loss: 0.1201 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.12845 to 0.12008, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1058 - acc: 0.9967 - val_loss: 0.1235 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.12008\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1047 - acc: 0.9954 - val_loss: 0.1244 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.12008\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1027 - acc: 0.9954 - val_loss: 0.1161 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.12008 to 0.11612, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.0997 - acc: 0.9954 - val_loss: 0.1109 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.11612 to 0.11088, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.0954 - acc: 0.9974 - val_loss: 0.1140 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.11088\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.0954 - acc: 0.9961 - val_loss: 0.1183 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.11088\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.0941 - acc: 0.9961 - val_loss: 0.1133 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.11088\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.0922 - acc: 0.9941 - val_loss: 0.1104 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.11088 to 0.11039, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0877 - acc: 0.9974 - val_loss: 0.1110 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.11039\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0847 - acc: 0.9967 - val_loss: 0.1020 - val_acc: 0.9918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00081: val_loss improved from 0.11039 to 0.10202, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0821 - acc: 0.9967 - val_loss: 0.0987 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.10202 to 0.09874, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0816 - acc: 0.9967 - val_loss: 0.0966 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.09874 to 0.09659, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0791 - acc: 0.9980 - val_loss: 0.0952 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.09659 to 0.09525, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0750 - acc: 0.9974 - val_loss: 0.0975 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.09525\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0745 - acc: 0.9974 - val_loss: 0.0902 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.09525 to 0.09021, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0742 - acc: 0.9980 - val_loss: 0.0863 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.09021 to 0.08631, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0696 - acc: 0.9980 - val_loss: 0.0904 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.08631\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0684 - acc: 0.9980 - val_loss: 0.0898 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.08631\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0692 - acc: 0.9974 - val_loss: 0.0867 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.08631\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0654 - acc: 0.9967 - val_loss: 0.0853 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.08631 to 0.08535, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0646 - acc: 0.9961 - val_loss: 0.0825 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.08535 to 0.08248, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0624 - acc: 0.9961 - val_loss: 0.0789 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.08248 to 0.07888, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0616 - acc: 0.9967 - val_loss: 0.0818 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.07888\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0592 - acc: 0.9980 - val_loss: 0.0754 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.07888 to 0.07541, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0586 - acc: 0.9967 - val_loss: 0.0760 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.07541\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0572 - acc: 0.9974 - val_loss: 0.0787 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.07541\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0546 - acc: 0.9974 - val_loss: 0.0776 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.07541\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0546 - acc: 0.9974 - val_loss: 0.0709 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.07541 to 0.07088, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0520 - acc: 0.9974 - val_loss: 0.0762 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.07088\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0513 - acc: 0.9980 - val_loss: 0.0710 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.07088\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0505 - acc: 0.9974 - val_loss: 0.0711 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.07088\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0487 - acc: 0.9980 - val_loss: 0.0697 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.07088 to 0.06970, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0476 - acc: 0.9980 - val_loss: 0.0729 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.06970\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0465 - acc: 0.9967 - val_loss: 0.0691 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.06970 to 0.06909, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0458 - acc: 0.9967 - val_loss: 0.0675 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.06909 to 0.06750, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0451 - acc: 0.9974 - val_loss: 0.0653 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.06750 to 0.06533, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0437 - acc: 0.9961 - val_loss: 0.0651 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.06533 to 0.06514, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0428 - acc: 0.9987 - val_loss: 0.0675 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.06514\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0420 - acc: 0.9967 - val_loss: 0.0606 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.06514 to 0.06060, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0414 - acc: 0.9967 - val_loss: 0.0579 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.06060 to 0.05793, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0398 - acc: 0.9967 - val_loss: 0.0595 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.05793\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0390 - acc: 0.9974 - val_loss: 0.0591 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.05793\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0387 - acc: 0.9980 - val_loss: 0.0587 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.05793\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0381 - acc: 0.9967 - val_loss: 0.0629 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.05793\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0370 - acc: 0.9967 - val_loss: 0.0536 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.05793 to 0.05363, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0355 - acc: 0.9974 - val_loss: 0.0580 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.05363\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0349 - acc: 0.9974 - val_loss: 0.0563 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.05363\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0344 - acc: 0.9974 - val_loss: 0.0550 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.05363\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0340 - acc: 0.9967 - val_loss: 0.0536 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.05363\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0330 - acc: 0.9974 - val_loss: 0.0531 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.05363 to 0.05310, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0320 - acc: 0.9967 - val_loss: 0.0516 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.05310 to 0.05160, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0314 - acc: 0.9961 - val_loss: 0.0556 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.05160\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0308 - acc: 0.9967 - val_loss: 0.0498 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.05160 to 0.04983, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0297 - acc: 0.9961 - val_loss: 0.0490 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.04983 to 0.04902, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0297 - acc: 0.9967 - val_loss: 0.0483 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.04902 to 0.04828, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0294 - acc: 0.9974 - val_loss: 0.0493 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.04828\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0287 - acc: 0.9967 - val_loss: 0.0491 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.04828\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0284 - acc: 0.9974 - val_loss: 0.0468 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.04828 to 0.04683, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0272 - acc: 0.9980 - val_loss: 0.0462 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.04683 to 0.04623, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0266 - acc: 0.9967 - val_loss: 0.0488 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.04623\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0263 - acc: 0.9967 - val_loss: 0.0478 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.04623\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0257 - acc: 0.9980 - val_loss: 0.0486 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.04623\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0248 - acc: 0.9974 - val_loss: 0.0451 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.04623 to 0.04509, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0255 - acc: 0.9961 - val_loss: 0.0433 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.04509 to 0.04325, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0242 - acc: 0.9967 - val_loss: 0.0475 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.04325\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0246 - acc: 0.9967 - val_loss: 0.0491 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.04325\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0234 - acc: 0.9967 - val_loss: 0.0437 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.04325\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0235 - acc: 0.9967 - val_loss: 0.0446 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.04325\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0231 - acc: 0.9974 - val_loss: 0.0464 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.04325\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0219 - acc: 0.9980 - val_loss: 0.0466 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.04325\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0221 - acc: 0.9967 - val_loss: 0.0439 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.04325\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0215 - acc: 0.9967 - val_loss: 0.0405 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.04325 to 0.04054, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0207 - acc: 0.9974 - val_loss: 0.0400 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.04054 to 0.03995, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0207 - acc: 0.9967 - val_loss: 0.0432 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.03995\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0204 - acc: 0.9967 - val_loss: 0.0437 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.03995\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0196 - acc: 0.9974 - val_loss: 0.0353 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.03995 to 0.03534, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0198 - acc: 0.9967 - val_loss: 0.0400 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.03534\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0191 - acc: 0.9967 - val_loss: 0.0390 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.03534\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0194 - acc: 0.9967 - val_loss: 0.0396 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.03534\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0187 - acc: 0.9980 - val_loss: 0.0479 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.03534\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0180 - acc: 0.9967 - val_loss: 0.0393 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.03534\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0176 - acc: 0.9974 - val_loss: 0.0391 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.03534\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0179 - acc: 0.9974 - val_loss: 0.0362 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.03534\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.0173 - acc: 0.9980 - val_loss: 0.0373 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.03534\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.0172 - acc: 0.9974 - val_loss: 0.0418 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.03534\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0168 - acc: 0.9967 - val_loss: 0.0370 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.03534\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.0160 - acc: 0.9974 - val_loss: 0.0375 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.03534\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.0160 - acc: 0.9980 - val_loss: 0.0414 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.03534\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.0157 - acc: 0.9967 - val_loss: 0.0391 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.03534\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.0162 - acc: 0.9974 - val_loss: 0.0378 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.03534\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.0158 - acc: 0.9967 - val_loss: 0.0337 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.03534 to 0.03369, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.0149 - acc: 0.9974 - val_loss: 0.0365 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.03369\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.0149 - acc: 0.9974 - val_loss: 0.0373 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.03369\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.0143 - acc: 0.9980 - val_loss: 0.0355 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.03369\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.0141 - acc: 0.9967 - val_loss: 0.0349 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.03369\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.0144 - acc: 0.9967 - val_loss: 0.0369 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.03369\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.0140 - acc: 0.9974 - val_loss: 0.0360 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.03369\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.0139 - acc: 0.9967 - val_loss: 0.0393 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.03369\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.0136 - acc: 0.9974 - val_loss: 0.0378 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.03369\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.0133 - acc: 0.9967 - val_loss: 0.0360 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.03369\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.0129 - acc: 0.9974 - val_loss: 0.0341 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.03369\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.0132 - acc: 0.9974 - val_loss: 0.0362 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.03369\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.0129 - acc: 0.9967 - val_loss: 0.0344 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.03369\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.0127 - acc: 0.9974 - val_loss: 0.0339 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.03369\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.0124 - acc: 0.9974 - val_loss: 0.0363 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.03369\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.0120 - acc: 0.9974 - val_loss: 0.0355 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.03369\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.0120 - acc: 0.9974 - val_loss: 0.0322 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00178: val_loss improved from 0.03369 to 0.03220, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.0119 - acc: 0.9967 - val_loss: 0.0325 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.03220\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.0122 - acc: 0.9967 - val_loss: 0.0365 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.03220\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.0115 - acc: 0.9967 - val_loss: 0.0354 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.03220\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.0116 - acc: 0.9967 - val_loss: 0.0360 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.03220\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.0117 - acc: 0.9961 - val_loss: 0.0302 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00183: val_loss improved from 0.03220 to 0.03024, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.0121 - acc: 0.9961 - val_loss: 0.0324 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.03024\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.0108 - acc: 0.9980 - val_loss: 0.0391 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.03024\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.0107 - acc: 0.9961 - val_loss: 0.0348 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.03024\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.0110 - acc: 0.9967 - val_loss: 0.0304 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.03024\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.0106 - acc: 0.9974 - val_loss: 0.0306 - val_acc: 0.9959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00188: val_loss did not improve from 0.03024\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.0108 - acc: 0.9967 - val_loss: 0.0330 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.03024\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.0105 - acc: 0.9974 - val_loss: 0.0304 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.03024\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.0105 - acc: 0.9967 - val_loss: 0.0330 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.03024\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.0103 - acc: 0.9980 - val_loss: 0.0331 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.03024\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.0100 - acc: 0.9967 - val_loss: 0.0322 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.03024\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.0098 - acc: 0.9974 - val_loss: 0.0342 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.03024\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.0098 - acc: 0.9967 - val_loss: 0.0334 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.03024\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.0098 - acc: 0.9974 - val_loss: 0.0373 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.03024\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.0102 - acc: 0.9967 - val_loss: 0.0338 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.03024\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.0096 - acc: 0.9974 - val_loss: 0.0344 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.03024\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.0096 - acc: 0.9980 - val_loss: 0.0346 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.03024\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.0095 - acc: 0.9967 - val_loss: 0.0315 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.03024\n",
      "batch_size=40   optimizer=Adamax\n",
      "Test accuracy: 68.5237%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_51 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 2.0486 - acc: 0.2809 - val_loss: 1.6232 - val_acc: 0.4280\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.62320, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.4778 - acc: 0.5125 - val_loss: 1.3427 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.62320 to 1.34270, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 1.2576 - acc: 0.5803 - val_loss: 1.1969 - val_acc: 0.5844\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.34270 to 1.19689, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 1.1447 - acc: 0.6270 - val_loss: 1.1146 - val_acc: 0.6337\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.19689 to 1.11455, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 1.0558 - acc: 0.6546 - val_loss: 1.0713 - val_acc: 0.6379\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.11455 to 1.07132, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 1.0032 - acc: 0.6796 - val_loss: 0.9932 - val_acc: 0.6420\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.07132 to 0.99316, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.9433 - acc: 0.6993 - val_loss: 0.9541 - val_acc: 0.6502\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.99316 to 0.95410, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.9005 - acc: 0.7197 - val_loss: 0.9038 - val_acc: 0.6708\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.95410 to 0.90375, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.8578 - acc: 0.7296 - val_loss: 0.8634 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.90375 to 0.86345, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.8273 - acc: 0.7421 - val_loss: 0.8342 - val_acc: 0.7078\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.86345 to 0.83415, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.7914 - acc: 0.7507 - val_loss: 0.8245 - val_acc: 0.7202\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.83415 to 0.82447, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.7676 - acc: 0.7697 - val_loss: 0.7699 - val_acc: 0.7366\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.82447 to 0.76985, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.7354 - acc: 0.7737 - val_loss: 0.7580 - val_acc: 0.7325\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.76985 to 0.75800, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.7163 - acc: 0.7763 - val_loss: 0.7361 - val_acc: 0.7490\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.75800 to 0.73613, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.6923 - acc: 0.7961 - val_loss: 0.7096 - val_acc: 0.7572\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.73613 to 0.70956, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.6695 - acc: 0.8059 - val_loss: 0.6781 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.70956 to 0.67811, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.6500 - acc: 0.8013 - val_loss: 0.6704 - val_acc: 0.7737\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.67811 to 0.67041, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.6294 - acc: 0.8092 - val_loss: 0.6563 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.67041 to 0.65631, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.6088 - acc: 0.8197 - val_loss: 0.6215 - val_acc: 0.8148\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.65631 to 0.62146, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.5981 - acc: 0.8296 - val_loss: 0.6175 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.62146 to 0.61745, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.5771 - acc: 0.8276 - val_loss: 0.5960 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.61745 to 0.59598, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.5645 - acc: 0.8342 - val_loss: 0.5902 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.59598 to 0.59024, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.5486 - acc: 0.8467 - val_loss: 0.5644 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.59024 to 0.56444, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.5316 - acc: 0.8461 - val_loss: 0.5599 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.56444 to 0.55992, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.5209 - acc: 0.8599 - val_loss: 0.5354 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.55992 to 0.53537, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.5082 - acc: 0.8572 - val_loss: 0.5242 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.53537 to 0.52417, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.4982 - acc: 0.8572 - val_loss: 0.5163 - val_acc: 0.8765\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.52417 to 0.51628, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.4853 - acc: 0.8678 - val_loss: 0.5199 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.51628\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.4738 - acc: 0.8809 - val_loss: 0.4972 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.51628 to 0.49716, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.4587 - acc: 0.8868 - val_loss: 0.4768 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.49716 to 0.47678, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.4567 - acc: 0.8789 - val_loss: 0.4760 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.47678 to 0.47596, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.4400 - acc: 0.8934 - val_loss: 0.4703 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.47596 to 0.47028, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.4284 - acc: 0.8941 - val_loss: 0.4528 - val_acc: 0.8930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00033: val_loss improved from 0.47028 to 0.45276, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.4276 - acc: 0.8967 - val_loss: 0.4401 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.45276 to 0.44005, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.4104 - acc: 0.9046 - val_loss: 0.4353 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.44005 to 0.43525, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.4019 - acc: 0.9099 - val_loss: 0.4141 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.43525 to 0.41408, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.3948 - acc: 0.9197 - val_loss: 0.4129 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.41408 to 0.41285, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.3860 - acc: 0.9184 - val_loss: 0.4204 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.41285\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.3763 - acc: 0.9263 - val_loss: 0.3914 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.41285 to 0.39142, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.3675 - acc: 0.9276 - val_loss: 0.3924 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.39142\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.3574 - acc: 0.9349 - val_loss: 0.3786 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.39142 to 0.37865, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.3539 - acc: 0.9375 - val_loss: 0.3714 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.37865 to 0.37140, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.3493 - acc: 0.9349 - val_loss: 0.3639 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.37140 to 0.36388, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.3332 - acc: 0.9434 - val_loss: 0.3498 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.36388 to 0.34977, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.3326 - acc: 0.9421 - val_loss: 0.3531 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.34977\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.3251 - acc: 0.9408 - val_loss: 0.3406 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.34977 to 0.34064, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.3138 - acc: 0.9487 - val_loss: 0.3273 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.34064 to 0.32732, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.3083 - acc: 0.9487 - val_loss: 0.3286 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.32732\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.3009 - acc: 0.9553 - val_loss: 0.3303 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.32732\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.2915 - acc: 0.9493 - val_loss: 0.3079 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.32732 to 0.30788, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.2877 - acc: 0.9539 - val_loss: 0.3044 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.30788 to 0.30437, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.2832 - acc: 0.9605 - val_loss: 0.2980 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.30437 to 0.29801, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.2789 - acc: 0.9592 - val_loss: 0.3048 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.29801\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.2711 - acc: 0.9592 - val_loss: 0.3010 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.29801\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.2654 - acc: 0.9651 - val_loss: 0.2859 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.29801 to 0.28586, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.2602 - acc: 0.9618 - val_loss: 0.2759 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.28586 to 0.27593, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.2522 - acc: 0.9697 - val_loss: 0.2750 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.27593 to 0.27497, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.2474 - acc: 0.9684 - val_loss: 0.2724 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.27497 to 0.27238, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.2460 - acc: 0.9664 - val_loss: 0.2691 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.27238 to 0.26911, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.2390 - acc: 0.9730 - val_loss: 0.2639 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.26911 to 0.26387, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.2330 - acc: 0.9717 - val_loss: 0.2560 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.26387 to 0.25601, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.2276 - acc: 0.9743 - val_loss: 0.2518 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.25601 to 0.25180, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.2242 - acc: 0.9750 - val_loss: 0.2518 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.25180 to 0.25177, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.2210 - acc: 0.9796 - val_loss: 0.2509 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.25177 to 0.25094, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.2156 - acc: 0.9750 - val_loss: 0.2351 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.25094 to 0.23514, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.2101 - acc: 0.9796 - val_loss: 0.2317 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.23514 to 0.23169, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.2048 - acc: 0.9796 - val_loss: 0.2244 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.23169 to 0.22444, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1996 - acc: 0.9842 - val_loss: 0.2213 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.22444 to 0.22131, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1981 - acc: 0.9796 - val_loss: 0.2246 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.22131\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1941 - acc: 0.9836 - val_loss: 0.2235 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.22131\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1913 - acc: 0.9849 - val_loss: 0.2109 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.22131 to 0.21089, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1898 - acc: 0.9809 - val_loss: 0.2055 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.21089 to 0.20548, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1810 - acc: 0.9888 - val_loss: 0.1978 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.20548 to 0.19775, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1771 - acc: 0.9875 - val_loss: 0.1984 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.19775\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1736 - acc: 0.9888 - val_loss: 0.2027 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.19775\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1710 - acc: 0.9888 - val_loss: 0.1950 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.19775 to 0.19496, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1677 - acc: 0.9882 - val_loss: 0.1896 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.19496 to 0.18964, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.1658 - acc: 0.9901 - val_loss: 0.1851 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.18964 to 0.18507, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.1602 - acc: 0.9888 - val_loss: 0.1864 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.18507\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.1570 - acc: 0.9921 - val_loss: 0.1817 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.18507 to 0.18173, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.1535 - acc: 0.9908 - val_loss: 0.1770 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.18173 to 0.17701, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.1510 - acc: 0.9914 - val_loss: 0.1730 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.17701 to 0.17296, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.1472 - acc: 0.9954 - val_loss: 0.1714 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.17296 to 0.17144, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.1454 - acc: 0.9928 - val_loss: 0.1712 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.17144 to 0.17119, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.1447 - acc: 0.9921 - val_loss: 0.1642 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.17119 to 0.16421, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.1388 - acc: 0.9947 - val_loss: 0.1613 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.16421 to 0.16133, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.1367 - acc: 0.9941 - val_loss: 0.1654 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.16133\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.1350 - acc: 0.9954 - val_loss: 0.1577 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.16133 to 0.15771, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.1317 - acc: 0.9947 - val_loss: 0.1527 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.15771 to 0.15266, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.1292 - acc: 0.9941 - val_loss: 0.1509 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.15266 to 0.15091, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.1259 - acc: 0.9967 - val_loss: 0.1443 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.15091 to 0.14426, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.1242 - acc: 0.9954 - val_loss: 0.1506 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.14426\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.1232 - acc: 0.9961 - val_loss: 0.1454 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.14426\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.1183 - acc: 0.9967 - val_loss: 0.1405 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.14426 to 0.14047, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.1171 - acc: 0.9980 - val_loss: 0.1399 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.14047 to 0.13994, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.1128 - acc: 0.9974 - val_loss: 0.1338 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.13994 to 0.13380, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.1129 - acc: 0.9967 - val_loss: 0.1376 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.13380\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.1121 - acc: 0.9954 - val_loss: 0.1370 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.13380\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.1076 - acc: 0.9974 - val_loss: 0.1311 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.13380 to 0.13105, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.1073 - acc: 0.9967 - val_loss: 0.1254 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.13105 to 0.12537, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.1037 - acc: 0.9961 - val_loss: 0.1302 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.12537\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.1021 - acc: 0.9967 - val_loss: 0.1227 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.12537 to 0.12273, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0998 - acc: 0.9967 - val_loss: 0.1187 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.12273 to 0.11869, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0974 - acc: 0.9967 - val_loss: 0.1229 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.11869\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0965 - acc: 0.9961 - val_loss: 0.1200 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.11869\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0940 - acc: 0.9967 - val_loss: 0.1168 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.11869 to 0.11680, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0920 - acc: 0.9987 - val_loss: 0.1189 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.11680\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0919 - acc: 0.9974 - val_loss: 0.1141 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.11680 to 0.11413, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0890 - acc: 0.9967 - val_loss: 0.1100 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.11413 to 0.10997, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0867 - acc: 0.9980 - val_loss: 0.1129 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.10997\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0865 - acc: 0.9974 - val_loss: 0.1086 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.10997 to 0.10855, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0837 - acc: 0.9980 - val_loss: 0.1126 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.10855\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0826 - acc: 0.9974 - val_loss: 0.1042 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.10855 to 0.10415, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0802 - acc: 0.9980 - val_loss: 0.1027 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.10415 to 0.10269, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0791 - acc: 0.9980 - val_loss: 0.1033 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.10269\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0776 - acc: 0.9980 - val_loss: 0.1040 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.10269\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0782 - acc: 0.9967 - val_loss: 0.1039 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.10269\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0768 - acc: 0.9980 - val_loss: 0.0947 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.10269 to 0.09469, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0739 - acc: 0.9980 - val_loss: 0.0989 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.09469\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0722 - acc: 0.9967 - val_loss: 0.0963 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.09469\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0720 - acc: 0.9974 - val_loss: 0.0959 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.09469\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0704 - acc: 0.9974 - val_loss: 0.0899 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.09469 to 0.08986, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0686 - acc: 0.9980 - val_loss: 0.0919 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.08986\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0679 - acc: 0.9974 - val_loss: 0.0895 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.08986 to 0.08953, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0659 - acc: 0.9980 - val_loss: 0.0936 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.08953\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0656 - acc: 0.9974 - val_loss: 0.0890 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.08953 to 0.08899, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0638 - acc: 0.9974 - val_loss: 0.0878 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.08899 to 0.08784, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0637 - acc: 0.9974 - val_loss: 0.0869 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.08784 to 0.08693, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0640 - acc: 0.9967 - val_loss: 0.0871 - val_acc: 0.9918\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00129: val_loss did not improve from 0.08693\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0614 - acc: 0.9974 - val_loss: 0.0828 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.08693 to 0.08276, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0591 - acc: 0.9974 - val_loss: 0.0870 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.08276\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0587 - acc: 0.9974 - val_loss: 0.0822 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.08276 to 0.08223, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0580 - acc: 0.9987 - val_loss: 0.0812 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.08223 to 0.08123, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0566 - acc: 0.9987 - val_loss: 0.0819 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.08123\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0556 - acc: 0.9967 - val_loss: 0.0755 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.08123 to 0.07550, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0560 - acc: 0.9974 - val_loss: 0.0774 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.07550\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0536 - acc: 0.9974 - val_loss: 0.0772 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.07550\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0532 - acc: 0.9974 - val_loss: 0.0742 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.07550 to 0.07419, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0515 - acc: 0.9980 - val_loss: 0.0769 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.07419\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0507 - acc: 0.9967 - val_loss: 0.0789 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.07419\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0502 - acc: 0.9967 - val_loss: 0.0732 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.07419 to 0.07320, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0497 - acc: 0.9974 - val_loss: 0.0736 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.07320\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0492 - acc: 0.9974 - val_loss: 0.0752 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.07320\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0473 - acc: 0.9974 - val_loss: 0.0715 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.07320 to 0.07150, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0465 - acc: 0.9974 - val_loss: 0.0677 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.07150 to 0.06772, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0462 - acc: 0.9980 - val_loss: 0.0711 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.06772\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0454 - acc: 0.9974 - val_loss: 0.0675 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.06772 to 0.06750, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0450 - acc: 0.9974 - val_loss: 0.0698 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.06750\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0445 - acc: 0.9980 - val_loss: 0.0661 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.06750 to 0.06610, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0441 - acc: 0.9980 - val_loss: 0.0694 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.06610\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0431 - acc: 0.9980 - val_loss: 0.0670 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.06610\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0425 - acc: 0.9974 - val_loss: 0.0655 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.06610 to 0.06545, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0417 - acc: 0.9974 - val_loss: 0.0648 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.06545 to 0.06481, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0403 - acc: 0.9974 - val_loss: 0.0612 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.06481 to 0.06120, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.0398 - acc: 0.9967 - val_loss: 0.0632 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.06120\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.0396 - acc: 0.9961 - val_loss: 0.0622 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.06120\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0385 - acc: 0.9974 - val_loss: 0.0626 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.06120\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.0379 - acc: 0.9974 - val_loss: 0.0594 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.06120 to 0.05943, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.0377 - acc: 0.9967 - val_loss: 0.0633 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.05943\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.0368 - acc: 0.9967 - val_loss: 0.0610 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.05943\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.0359 - acc: 0.9980 - val_loss: 0.0606 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.05943\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.0357 - acc: 0.9980 - val_loss: 0.0572 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.05943 to 0.05723, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.0348 - acc: 0.9974 - val_loss: 0.0589 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.05723\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.0348 - acc: 0.9974 - val_loss: 0.0597 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.05723\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.0341 - acc: 0.9974 - val_loss: 0.0568 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.05723 to 0.05681, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.0333 - acc: 0.9967 - val_loss: 0.0567 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00166: val_loss improved from 0.05681 to 0.05667, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.0327 - acc: 0.9974 - val_loss: 0.0565 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.05667 to 0.05651, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.0327 - acc: 0.9974 - val_loss: 0.0578 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.05651\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.0336 - acc: 0.9967 - val_loss: 0.0565 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.05651 to 0.05647, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.0316 - acc: 0.9974 - val_loss: 0.0555 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.05647 to 0.05552, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.0313 - acc: 0.9974 - val_loss: 0.0539 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00171: val_loss improved from 0.05552 to 0.05389, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.0306 - acc: 0.9974 - val_loss: 0.0521 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00172: val_loss improved from 0.05389 to 0.05207, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.0301 - acc: 0.9961 - val_loss: 0.0564 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.05207\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.0296 - acc: 0.9974 - val_loss: 0.0525 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.05207\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.0294 - acc: 0.9974 - val_loss: 0.0543 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.05207\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.0290 - acc: 0.9967 - val_loss: 0.0520 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00176: val_loss improved from 0.05207 to 0.05195, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.0283 - acc: 0.9967 - val_loss: 0.0515 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00177: val_loss improved from 0.05195 to 0.05149, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.0279 - acc: 0.9967 - val_loss: 0.0486 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00178: val_loss improved from 0.05149 to 0.04859, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.0285 - acc: 0.9974 - val_loss: 0.0552 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.04859\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.0273 - acc: 0.9980 - val_loss: 0.0515 - val_acc: 0.9918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00180: val_loss did not improve from 0.04859\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.0272 - acc: 0.9967 - val_loss: 0.0483 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00181: val_loss improved from 0.04859 to 0.04831, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.0272 - acc: 0.9967 - val_loss: 0.0505 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.04831\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.0269 - acc: 0.9961 - val_loss: 0.0506 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.04831\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.0258 - acc: 0.9974 - val_loss: 0.0514 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.04831\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.0254 - acc: 0.9974 - val_loss: 0.0482 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00185: val_loss improved from 0.04831 to 0.04818, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.0258 - acc: 0.9967 - val_loss: 0.0467 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.04818 to 0.04670, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.0249 - acc: 0.9974 - val_loss: 0.0504 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.04670\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.0241 - acc: 0.9967 - val_loss: 0.0501 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.04670\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.0235 - acc: 0.9980 - val_loss: 0.0456 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.04670 to 0.04565, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.0234 - acc: 0.9974 - val_loss: 0.0506 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.04565\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.0241 - acc: 0.9967 - val_loss: 0.0446 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00191: val_loss improved from 0.04565 to 0.04457, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.0230 - acc: 0.9961 - val_loss: 0.0459 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.04457\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.0223 - acc: 0.9967 - val_loss: 0.0451 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.04457\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.0222 - acc: 0.9980 - val_loss: 0.0484 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.04457\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.0224 - acc: 0.9967 - val_loss: 0.0465 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.04457\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.0218 - acc: 0.9961 - val_loss: 0.0457 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.04457\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.0218 - acc: 0.9967 - val_loss: 0.0446 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.04457\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.0214 - acc: 0.9967 - val_loss: 0.0440 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.04457 to 0.04397, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.0207 - acc: 0.9974 - val_loss: 0.0446 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.04397\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.0206 - acc: 0.9974 - val_loss: 0.0503 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.04397\n",
      "batch_size=80   optimizer=Adamax\n",
      "Test accuracy: 67.1309%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_52 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 2.1608 - acc: 0.1895 - val_loss: 1.7342 - val_acc: 0.4115\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.73420, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.6283 - acc: 0.4434 - val_loss: 1.4269 - val_acc: 0.5432\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.73420 to 1.42692, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 1.3711 - acc: 0.5612 - val_loss: 1.2799 - val_acc: 0.5802\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.42692 to 1.27987, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 1.2312 - acc: 0.6079 - val_loss: 1.1885 - val_acc: 0.6091\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.27987 to 1.18850, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 1.1406 - acc: 0.6421 - val_loss: 1.1151 - val_acc: 0.6214\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.18850 to 1.11512, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 1.0712 - acc: 0.6691 - val_loss: 1.0558 - val_acc: 0.6461\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.11512 to 1.05580, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 1.0169 - acc: 0.6796 - val_loss: 1.0246 - val_acc: 0.6708\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.05580 to 1.02458, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.9763 - acc: 0.6974 - val_loss: 0.9866 - val_acc: 0.6708\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.02458 to 0.98657, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.9371 - acc: 0.7125 - val_loss: 0.9425 - val_acc: 0.6872\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.98657 to 0.94249, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.9065 - acc: 0.7079 - val_loss: 0.9189 - val_acc: 0.7119\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.94249 to 0.91893, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.8742 - acc: 0.7336 - val_loss: 0.8741 - val_acc: 0.7284\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.91893 to 0.87406, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.8444 - acc: 0.7434 - val_loss: 0.8477 - val_acc: 0.7366\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.87406 to 0.84766, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.8154 - acc: 0.7526 - val_loss: 0.8355 - val_acc: 0.7407\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.84766 to 0.83550, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.7936 - acc: 0.7592 - val_loss: 0.8044 - val_acc: 0.7654\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.83550 to 0.80439, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.7716 - acc: 0.7664 - val_loss: 0.7886 - val_acc: 0.7449\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.80439 to 0.78861, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.7531 - acc: 0.7730 - val_loss: 0.7622 - val_acc: 0.7654\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.78861 to 0.76217, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.7272 - acc: 0.7789 - val_loss: 0.7554 - val_acc: 0.7613\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.76217 to 0.75541, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.7145 - acc: 0.7862 - val_loss: 0.7341 - val_acc: 0.7531\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.75541 to 0.73413, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.6944 - acc: 0.7921 - val_loss: 0.7147 - val_acc: 0.7737\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.73413 to 0.71472, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.6770 - acc: 0.8039 - val_loss: 0.6944 - val_acc: 0.7695\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.71472 to 0.69435, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.6604 - acc: 0.8059 - val_loss: 0.6793 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.69435 to 0.67930, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.6491 - acc: 0.8099 - val_loss: 0.6748 - val_acc: 0.7737\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.67930 to 0.67476, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.6339 - acc: 0.8138 - val_loss: 0.6506 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.67476 to 0.65057, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.6171 - acc: 0.8204 - val_loss: 0.6341 - val_acc: 0.7901\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.65057 to 0.63406, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.6022 - acc: 0.8336 - val_loss: 0.6236 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.63406 to 0.62357, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.5906 - acc: 0.8316 - val_loss: 0.6044 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.62357 to 0.60439, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.5772 - acc: 0.8388 - val_loss: 0.6037 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.60439 to 0.60373, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.5658 - acc: 0.8408 - val_loss: 0.5864 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.60373 to 0.58639, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.5568 - acc: 0.8500 - val_loss: 0.5764 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.58639 to 0.57645, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.5436 - acc: 0.8447 - val_loss: 0.5646 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.57645 to 0.56460, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.5328 - acc: 0.8546 - val_loss: 0.5539 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.56460 to 0.55388, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.5201 - acc: 0.8599 - val_loss: 0.5357 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.55388 to 0.53570, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.5112 - acc: 0.8671 - val_loss: 0.5309 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.53570 to 0.53087, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.5046 - acc: 0.8664 - val_loss: 0.5184 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.53087 to 0.51844, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.4917 - acc: 0.8750 - val_loss: 0.5174 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.51844 to 0.51742, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.4816 - acc: 0.8803 - val_loss: 0.4997 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.51742 to 0.49973, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.4731 - acc: 0.8796 - val_loss: 0.4963 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.49973 to 0.49629, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.4642 - acc: 0.8862 - val_loss: 0.4895 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.49629 to 0.48951, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.4562 - acc: 0.8842 - val_loss: 0.4762 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.48951 to 0.47624, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.4475 - acc: 0.8875 - val_loss: 0.4686 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.47624 to 0.46862, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.4397 - acc: 0.8947 - val_loss: 0.4633 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.46862 to 0.46327, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.4322 - acc: 0.8974 - val_loss: 0.4502 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.46327 to 0.45022, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.4240 - acc: 0.9000 - val_loss: 0.4433 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.45022 to 0.44325, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.4174 - acc: 0.9033 - val_loss: 0.4420 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.44325 to 0.44195, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.4095 - acc: 0.9033 - val_loss: 0.4283 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.44195 to 0.42825, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.4010 - acc: 0.9118 - val_loss: 0.4216 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.42825 to 0.42155, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.3958 - acc: 0.9092 - val_loss: 0.4156 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.42155 to 0.41557, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.3867 - acc: 0.9184 - val_loss: 0.4102 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.41557 to 0.41021, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.3811 - acc: 0.9197 - val_loss: 0.4027 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.41021 to 0.40274, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.3763 - acc: 0.9171 - val_loss: 0.3912 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.40274 to 0.39121, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.3706 - acc: 0.9178 - val_loss: 0.4002 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.39121\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.3662 - acc: 0.9217 - val_loss: 0.3761 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.39121 to 0.37611, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.3565 - acc: 0.9263 - val_loss: 0.3830 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.37611\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.3482 - acc: 0.9303 - val_loss: 0.3627 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.37611 to 0.36265, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.3448 - acc: 0.9322 - val_loss: 0.3699 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.36265\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.3386 - acc: 0.9375 - val_loss: 0.3570 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.36265 to 0.35696, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.3307 - acc: 0.9388 - val_loss: 0.3509 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.35696 to 0.35093, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.3269 - acc: 0.9428 - val_loss: 0.3489 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.35093 to 0.34892, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.3191 - acc: 0.9408 - val_loss: 0.3345 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.34892 to 0.33451, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.3151 - acc: 0.9447 - val_loss: 0.3331 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.33451 to 0.33313, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.3079 - acc: 0.9493 - val_loss: 0.3249 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.33313 to 0.32489, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.3014 - acc: 0.9507 - val_loss: 0.3263 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.32489\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.2992 - acc: 0.9500 - val_loss: 0.3130 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.32489 to 0.31295, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.2933 - acc: 0.9513 - val_loss: 0.3153 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.31295\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.2871 - acc: 0.9533 - val_loss: 0.3066 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.31295 to 0.30660, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.2826 - acc: 0.9599 - val_loss: 0.3018 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.30660 to 0.30177, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.2782 - acc: 0.9566 - val_loss: 0.2976 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.30177 to 0.29763, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.2753 - acc: 0.9605 - val_loss: 0.2975 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.29763 to 0.29747, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.2708 - acc: 0.9586 - val_loss: 0.2944 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.29747 to 0.29441, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.2688 - acc: 0.9638 - val_loss: 0.2875 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.29441 to 0.28745, saving model to weights.best.Resnet50.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/200\n",
      " - 0s - loss: 0.2611 - acc: 0.9658 - val_loss: 0.2761 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.28745 to 0.27613, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.2545 - acc: 0.9684 - val_loss: 0.2815 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.27613\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.2504 - acc: 0.9684 - val_loss: 0.2663 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.27613 to 0.26630, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.2475 - acc: 0.9691 - val_loss: 0.2676 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.26630\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.2461 - acc: 0.9737 - val_loss: 0.2657 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.26630 to 0.26569, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.2412 - acc: 0.9691 - val_loss: 0.2608 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.26569 to 0.26084, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.2368 - acc: 0.9711 - val_loss: 0.2531 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.26084 to 0.25309, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.2376 - acc: 0.9717 - val_loss: 0.2613 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.25309\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.2303 - acc: 0.9757 - val_loss: 0.2450 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.25309 to 0.24500, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.2233 - acc: 0.9783 - val_loss: 0.2435 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.24500 to 0.24351, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.2197 - acc: 0.9809 - val_loss: 0.2390 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.24351 to 0.23900, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.2156 - acc: 0.9809 - val_loss: 0.2377 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.23900 to 0.23772, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.2132 - acc: 0.9789 - val_loss: 0.2294 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.23772 to 0.22943, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.2110 - acc: 0.9816 - val_loss: 0.2336 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.22943\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.2053 - acc: 0.9842 - val_loss: 0.2272 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.22943 to 0.22717, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.2028 - acc: 0.9829 - val_loss: 0.2249 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.22717 to 0.22493, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.1996 - acc: 0.9836 - val_loss: 0.2202 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.22493 to 0.22019, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.1963 - acc: 0.9842 - val_loss: 0.2175 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.22019 to 0.21747, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.1924 - acc: 0.9855 - val_loss: 0.2121 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.21747 to 0.21215, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.1909 - acc: 0.9901 - val_loss: 0.2116 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.21215 to 0.21157, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.1873 - acc: 0.9862 - val_loss: 0.2109 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.21157 to 0.21090, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.1839 - acc: 0.9895 - val_loss: 0.2041 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.21090 to 0.20411, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.1803 - acc: 0.9901 - val_loss: 0.1987 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.20411 to 0.19874, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.1780 - acc: 0.9908 - val_loss: 0.1968 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.19874 to 0.19679, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.1752 - acc: 0.9895 - val_loss: 0.1942 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.19679 to 0.19422, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.1728 - acc: 0.9908 - val_loss: 0.1958 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.19422\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.1717 - acc: 0.9895 - val_loss: 0.1878 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.19422 to 0.18784, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.1708 - acc: 0.9914 - val_loss: 0.1969 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.18784\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.1689 - acc: 0.9875 - val_loss: 0.1832 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.18784 to 0.18319, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.1616 - acc: 0.9921 - val_loss: 0.1872 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.18319\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.1592 - acc: 0.9934 - val_loss: 0.1819 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.18319 to 0.18193, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.1568 - acc: 0.9928 - val_loss: 0.1790 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.18193 to 0.17896, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.1534 - acc: 0.9934 - val_loss: 0.1722 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.17896 to 0.17217, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.1512 - acc: 0.9941 - val_loss: 0.1756 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.17217\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.1491 - acc: 0.9947 - val_loss: 0.1709 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.17217 to 0.17089, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.1466 - acc: 0.9954 - val_loss: 0.1683 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.17089 to 0.16828, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.1445 - acc: 0.9947 - val_loss: 0.1652 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.16828 to 0.16524, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.1433 - acc: 0.9941 - val_loss: 0.1645 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.16524 to 0.16447, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.1407 - acc: 0.9961 - val_loss: 0.1652 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.16447\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.1377 - acc: 0.9941 - val_loss: 0.1562 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.16447 to 0.15624, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.1353 - acc: 0.9954 - val_loss: 0.1595 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.15624\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.1334 - acc: 0.9961 - val_loss: 0.1533 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.15624 to 0.15328, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.1314 - acc: 0.9961 - val_loss: 0.1518 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.15328 to 0.15177, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.1290 - acc: 0.9954 - val_loss: 0.1520 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.15177\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.1279 - acc: 0.9961 - val_loss: 0.1499 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.15177 to 0.14992, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.1268 - acc: 0.9961 - val_loss: 0.1491 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.14992 to 0.14907, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.1244 - acc: 0.9954 - val_loss: 0.1445 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.14907 to 0.14453, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.1215 - acc: 0.9974 - val_loss: 0.1486 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.14453\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.1196 - acc: 0.9961 - val_loss: 0.1414 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.14453 to 0.14143, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.1175 - acc: 0.9974 - val_loss: 0.1432 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.14143\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.1169 - acc: 0.9967 - val_loss: 0.1384 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.14143 to 0.13838, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.1148 - acc: 0.9967 - val_loss: 0.1364 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.13838 to 0.13640, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.1140 - acc: 0.9974 - val_loss: 0.1380 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.13640\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.1111 - acc: 0.9967 - val_loss: 0.1314 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.13640 to 0.13139, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.1107 - acc: 0.9974 - val_loss: 0.1345 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.13139\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.1086 - acc: 0.9961 - val_loss: 0.1309 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.13139 to 0.13086, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.1054 - acc: 0.9980 - val_loss: 0.1306 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.13086 to 0.13057, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.1052 - acc: 0.9961 - val_loss: 0.1270 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.13057 to 0.12701, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.1034 - acc: 0.9974 - val_loss: 0.1236 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.12701 to 0.12357, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.1017 - acc: 0.9987 - val_loss: 0.1262 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.12357\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.1000 - acc: 0.9974 - val_loss: 0.1213 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.12357 to 0.12133, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.1001 - acc: 0.9980 - val_loss: 0.1231 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.12133\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0969 - acc: 0.9967 - val_loss: 0.1190 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.12133 to 0.11896, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0962 - acc: 0.9974 - val_loss: 0.1197 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.11896\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0946 - acc: 0.9980 - val_loss: 0.1211 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.11896\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0950 - acc: 0.9974 - val_loss: 0.1142 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.11896 to 0.11419, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0930 - acc: 0.9974 - val_loss: 0.1164 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.11419\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0913 - acc: 0.9980 - val_loss: 0.1108 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.11419 to 0.11085, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0899 - acc: 0.9980 - val_loss: 0.1141 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.11085\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0881 - acc: 0.9967 - val_loss: 0.1108 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.11085\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0867 - acc: 0.9980 - val_loss: 0.1100 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.11085 to 0.10996, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0858 - acc: 0.9974 - val_loss: 0.1079 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.10996 to 0.10792, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0842 - acc: 0.9974 - val_loss: 0.1066 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.10792 to 0.10664, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0825 - acc: 0.9980 - val_loss: 0.1073 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.10664\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0814 - acc: 0.9980 - val_loss: 0.1037 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.10664 to 0.10373, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0809 - acc: 0.9974 - val_loss: 0.1053 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.10373\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0790 - acc: 0.9980 - val_loss: 0.0998 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.10373 to 0.09978, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0778 - acc: 0.9980 - val_loss: 0.1025 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.09978\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0778 - acc: 0.9967 - val_loss: 0.0990 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.09978 to 0.09895, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0757 - acc: 0.9980 - val_loss: 0.0995 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.09895\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0747 - acc: 0.9980 - val_loss: 0.0976 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.09895 to 0.09755, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0742 - acc: 0.9980 - val_loss: 0.0969 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.09755 to 0.09685, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0731 - acc: 0.9987 - val_loss: 0.0953 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.09685 to 0.09530, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0712 - acc: 0.9974 - val_loss: 0.0947 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.09530 to 0.09474, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.0708 - acc: 0.9980 - val_loss: 0.0946 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.09474 to 0.09462, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.0699 - acc: 0.9980 - val_loss: 0.0926 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.09462 to 0.09263, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0694 - acc: 0.9980 - val_loss: 0.0920 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.09263 to 0.09197, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.0677 - acc: 0.9974 - val_loss: 0.0901 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.09197 to 0.09012, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.0666 - acc: 0.9974 - val_loss: 0.0904 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.09012\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.0662 - acc: 0.9980 - val_loss: 0.0911 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.09012\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.0655 - acc: 0.9980 - val_loss: 0.0893 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.09012 to 0.08929, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.0647 - acc: 0.9980 - val_loss: 0.0878 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.08929 to 0.08783, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.0641 - acc: 0.9967 - val_loss: 0.0857 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00163: val_loss improved from 0.08783 to 0.08568, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.0621 - acc: 0.9974 - val_loss: 0.0852 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.08568 to 0.08523, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.0618 - acc: 0.9987 - val_loss: 0.0860 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.08523\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.0608 - acc: 0.9974 - val_loss: 0.0829 - val_acc: 0.9959\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00166: val_loss improved from 0.08523 to 0.08293, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.0601 - acc: 0.9974 - val_loss: 0.0838 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.08293\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.0592 - acc: 0.9974 - val_loss: 0.0801 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.08293 to 0.08008, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.0582 - acc: 0.9974 - val_loss: 0.0817 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.08008\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.0573 - acc: 0.9967 - val_loss: 0.0812 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.08008\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.0572 - acc: 0.9967 - val_loss: 0.0806 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.08008\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.0572 - acc: 0.9974 - val_loss: 0.0800 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00172: val_loss improved from 0.08008 to 0.08004, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.0554 - acc: 0.9980 - val_loss: 0.0784 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.08004 to 0.07840, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.0540 - acc: 0.9980 - val_loss: 0.0786 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.07840\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.0542 - acc: 0.9967 - val_loss: 0.0769 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00175: val_loss improved from 0.07840 to 0.07688, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.0537 - acc: 0.9974 - val_loss: 0.0746 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00176: val_loss improved from 0.07688 to 0.07462, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.0525 - acc: 0.9974 - val_loss: 0.0759 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.07462\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.0514 - acc: 0.9967 - val_loss: 0.0760 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.07462\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.0512 - acc: 0.9974 - val_loss: 0.0725 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00179: val_loss improved from 0.07462 to 0.07253, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.0504 - acc: 0.9974 - val_loss: 0.0745 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.07253\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.0499 - acc: 0.9980 - val_loss: 0.0725 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00181: val_loss improved from 0.07253 to 0.07250, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.0498 - acc: 0.9974 - val_loss: 0.0723 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00182: val_loss improved from 0.07250 to 0.07229, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.0490 - acc: 0.9967 - val_loss: 0.0725 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.07229\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.0479 - acc: 0.9980 - val_loss: 0.0699 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00184: val_loss improved from 0.07229 to 0.06992, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.0477 - acc: 0.9967 - val_loss: 0.0700 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.06992\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.0471 - acc: 0.9980 - val_loss: 0.0699 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.06992 to 0.06987, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.0463 - acc: 0.9980 - val_loss: 0.0700 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.06987\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.0457 - acc: 0.9980 - val_loss: 0.0690 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00188: val_loss improved from 0.06987 to 0.06903, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.0457 - acc: 0.9967 - val_loss: 0.0702 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.06903\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.0448 - acc: 0.9961 - val_loss: 0.0682 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00190: val_loss improved from 0.06903 to 0.06823, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.0436 - acc: 0.9980 - val_loss: 0.0653 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00191: val_loss improved from 0.06823 to 0.06532, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.0436 - acc: 0.9967 - val_loss: 0.0679 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.06532\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.0425 - acc: 0.9974 - val_loss: 0.0641 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00193: val_loss improved from 0.06532 to 0.06415, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.0418 - acc: 0.9987 - val_loss: 0.0663 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.06415\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.0416 - acc: 0.9980 - val_loss: 0.0648 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.06415\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.0412 - acc: 0.9967 - val_loss: 0.0652 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.06415\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.0403 - acc: 0.9980 - val_loss: 0.0629 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00197: val_loss improved from 0.06415 to 0.06292, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.0401 - acc: 0.9980 - val_loss: 0.0625 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.06292 to 0.06250, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.0403 - acc: 0.9987 - val_loss: 0.0625 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.06250\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.0390 - acc: 0.9974 - val_loss: 0.0619 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00200: val_loss improved from 0.06250 to 0.06192, saving model to weights.best.Resnet50.hdf5\n",
      "batch_size=120   optimizer=Adamax\n",
      "Test accuracy: 68.2451%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_53 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 2.3314 - acc: 0.1658 - val_loss: 1.9732 - val_acc: 0.2881\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.97319, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.8051 - acc: 0.3678 - val_loss: 1.6607 - val_acc: 0.4486\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.97319 to 1.66069, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 1.5209 - acc: 0.4803 - val_loss: 1.4789 - val_acc: 0.5144\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.66069 to 1.47891, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 1.3476 - acc: 0.5539 - val_loss: 1.3312 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.47891 to 1.33117, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 1.2465 - acc: 0.5829 - val_loss: 1.2653 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.33117 to 1.26526, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 1.1618 - acc: 0.6296 - val_loss: 1.1808 - val_acc: 0.6214\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.26526 to 1.18076, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 1.1066 - acc: 0.6454 - val_loss: 1.1339 - val_acc: 0.6214\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.18076 to 1.13394, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 0s - loss: 1.0516 - acc: 0.6664 - val_loss: 1.0866 - val_acc: 0.6420\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.13394 to 1.08663, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 0s - loss: 1.0100 - acc: 0.6855 - val_loss: 1.0538 - val_acc: 0.6502\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.08663 to 1.05376, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.9725 - acc: 0.6967 - val_loss: 1.0110 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.05376 to 1.01096, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.9431 - acc: 0.7099 - val_loss: 0.9939 - val_acc: 0.6790\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.01096 to 0.99394, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.9124 - acc: 0.7283 - val_loss: 0.9519 - val_acc: 0.6708\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.99394 to 0.95192, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.8897 - acc: 0.7237 - val_loss: 0.9364 - val_acc: 0.6790\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.95192 to 0.93642, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.8605 - acc: 0.7382 - val_loss: 0.8991 - val_acc: 0.7078\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.93642 to 0.89913, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.8392 - acc: 0.7487 - val_loss: 0.8844 - val_acc: 0.6872\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.89913 to 0.88442, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.8191 - acc: 0.7546 - val_loss: 0.8642 - val_acc: 0.7078\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.88442 to 0.86424, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.8006 - acc: 0.7605 - val_loss: 0.8467 - val_acc: 0.7078\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.86424 to 0.84668, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.7860 - acc: 0.7691 - val_loss: 0.8264 - val_acc: 0.7119\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.84668 to 0.82644, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.7685 - acc: 0.7711 - val_loss: 0.8058 - val_acc: 0.7284\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.82644 to 0.80582, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.7534 - acc: 0.7750 - val_loss: 0.7900 - val_acc: 0.7160\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.80582 to 0.78996, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.7351 - acc: 0.7776 - val_loss: 0.7755 - val_acc: 0.7366\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.78996 to 0.77550, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.7182 - acc: 0.7928 - val_loss: 0.7599 - val_acc: 0.7366\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.77550 to 0.75990, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.7026 - acc: 0.7862 - val_loss: 0.7406 - val_acc: 0.7531\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.75990 to 0.74064, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.6868 - acc: 0.8000 - val_loss: 0.7342 - val_acc: 0.7613\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.74064 to 0.73422, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.6730 - acc: 0.8026 - val_loss: 0.7145 - val_acc: 0.7572\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.73422 to 0.71449, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.6607 - acc: 0.8105 - val_loss: 0.7085 - val_acc: 0.7860\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.71449 to 0.70846, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.6492 - acc: 0.8086 - val_loss: 0.6895 - val_acc: 0.7819\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.70846 to 0.68949, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.6357 - acc: 0.8211 - val_loss: 0.6788 - val_acc: 0.7942\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.68949 to 0.67881, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.6252 - acc: 0.8204 - val_loss: 0.6735 - val_acc: 0.7819\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.67881 to 0.67354, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.6156 - acc: 0.8237 - val_loss: 0.6549 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.67354 to 0.65492, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.6010 - acc: 0.8296 - val_loss: 0.6454 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.65492 to 0.64544, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.5932 - acc: 0.8322 - val_loss: 0.6363 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.64544 to 0.63631, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.5813 - acc: 0.8447 - val_loss: 0.6235 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.63631 to 0.62349, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.5713 - acc: 0.8401 - val_loss: 0.6174 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.62349 to 0.61744, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.5631 - acc: 0.8474 - val_loss: 0.6040 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.61744 to 0.60399, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.5540 - acc: 0.8487 - val_loss: 0.5960 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.60399 to 0.59602, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.5437 - acc: 0.8559 - val_loss: 0.5867 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.59602 to 0.58670, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.5376 - acc: 0.8553 - val_loss: 0.5779 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.58670 to 0.57793, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.5279 - acc: 0.8592 - val_loss: 0.5694 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.57793 to 0.56944, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.5202 - acc: 0.8645 - val_loss: 0.5637 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.56944 to 0.56365, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.5134 - acc: 0.8632 - val_loss: 0.5523 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.56365 to 0.55233, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.5058 - acc: 0.8671 - val_loss: 0.5418 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.55233 to 0.54181, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.4961 - acc: 0.8743 - val_loss: 0.5340 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.54181 to 0.53397, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.4876 - acc: 0.8770 - val_loss: 0.5280 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.53397 to 0.52805, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.4793 - acc: 0.8770 - val_loss: 0.5170 - val_acc: 0.8765\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.52805 to 0.51699, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.4735 - acc: 0.8809 - val_loss: 0.5106 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.51699 to 0.51057, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.4657 - acc: 0.8868 - val_loss: 0.5024 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.51057 to 0.50239, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.4608 - acc: 0.8862 - val_loss: 0.4952 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.50239 to 0.49523, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.4549 - acc: 0.8888 - val_loss: 0.4919 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.49523 to 0.49192, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.4483 - acc: 0.8914 - val_loss: 0.4790 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.49192 to 0.47899, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.4406 - acc: 0.8954 - val_loss: 0.4829 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.47899\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.4336 - acc: 0.8961 - val_loss: 0.4663 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.47899 to 0.46632, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.4257 - acc: 0.9039 - val_loss: 0.4646 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.46632 to 0.46456, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.4208 - acc: 0.9046 - val_loss: 0.4570 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.46456 to 0.45700, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.4155 - acc: 0.9020 - val_loss: 0.4471 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.45700 to 0.44706, saving model to weights.best.Resnet50.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/200\n",
      " - 0s - loss: 0.4090 - acc: 0.9105 - val_loss: 0.4456 - val_acc: 0.9012\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.44706 to 0.44564, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.4027 - acc: 0.9125 - val_loss: 0.4312 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.44564 to 0.43124, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.3995 - acc: 0.9125 - val_loss: 0.4333 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.43124\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.3909 - acc: 0.9125 - val_loss: 0.4235 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.43124 to 0.42350, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.3893 - acc: 0.9158 - val_loss: 0.4186 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.42350 to 0.41856, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.3833 - acc: 0.9257 - val_loss: 0.4147 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.41856 to 0.41467, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.3774 - acc: 0.9237 - val_loss: 0.4074 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.41467 to 0.40745, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.3714 - acc: 0.9257 - val_loss: 0.4034 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.40745 to 0.40344, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.3646 - acc: 0.9257 - val_loss: 0.3948 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.40344 to 0.39477, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.3598 - acc: 0.9283 - val_loss: 0.3945 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.39477 to 0.39454, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.3553 - acc: 0.9368 - val_loss: 0.3856 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.39454 to 0.38557, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.3488 - acc: 0.9322 - val_loss: 0.3813 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.38557 to 0.38126, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.3441 - acc: 0.9362 - val_loss: 0.3758 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.38126 to 0.37578, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.3419 - acc: 0.9349 - val_loss: 0.3718 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.37578 to 0.37182, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.3369 - acc: 0.9421 - val_loss: 0.3655 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.37182 to 0.36550, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.3330 - acc: 0.9395 - val_loss: 0.3638 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.36550 to 0.36384, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.3273 - acc: 0.9454 - val_loss: 0.3568 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.36384 to 0.35675, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.3231 - acc: 0.9454 - val_loss: 0.3537 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.35675 to 0.35368, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.3181 - acc: 0.9480 - val_loss: 0.3483 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.35368 to 0.34833, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.3152 - acc: 0.9480 - val_loss: 0.3451 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.34833 to 0.34505, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.3099 - acc: 0.9493 - val_loss: 0.3424 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.34505 to 0.34238, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.3054 - acc: 0.9533 - val_loss: 0.3331 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.34238 to 0.33310, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.3024 - acc: 0.9520 - val_loss: 0.3327 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.33310 to 0.33265, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.2975 - acc: 0.9546 - val_loss: 0.3269 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.33265 to 0.32692, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.2939 - acc: 0.9572 - val_loss: 0.3262 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.32692 to 0.32624, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.2898 - acc: 0.9586 - val_loss: 0.3183 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.32624 to 0.31831, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.2855 - acc: 0.9599 - val_loss: 0.3140 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.31831 to 0.31404, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.2821 - acc: 0.9592 - val_loss: 0.3122 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.31404 to 0.31215, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.2790 - acc: 0.9605 - val_loss: 0.3057 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.31215 to 0.30570, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.2747 - acc: 0.9625 - val_loss: 0.3056 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.30570 to 0.30555, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.2719 - acc: 0.9664 - val_loss: 0.2983 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.30555 to 0.29831, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.2711 - acc: 0.9645 - val_loss: 0.2974 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.29831 to 0.29743, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.2655 - acc: 0.9664 - val_loss: 0.2917 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.29743 to 0.29169, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.2638 - acc: 0.9704 - val_loss: 0.2901 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.29169 to 0.29015, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.2602 - acc: 0.9651 - val_loss: 0.2842 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.29015 to 0.28421, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.2546 - acc: 0.9711 - val_loss: 0.2813 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.28421 to 0.28131, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.2513 - acc: 0.9691 - val_loss: 0.2793 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.28131 to 0.27931, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.2467 - acc: 0.9750 - val_loss: 0.2753 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.27931 to 0.27528, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.2439 - acc: 0.9730 - val_loss: 0.2720 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.27528 to 0.27204, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.2411 - acc: 0.9737 - val_loss: 0.2671 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.27204 to 0.26715, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.2393 - acc: 0.9737 - val_loss: 0.2634 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.26715 to 0.26340, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.2355 - acc: 0.9763 - val_loss: 0.2604 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.26340 to 0.26041, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.2319 - acc: 0.9770 - val_loss: 0.2614 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.26041\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.2302 - acc: 0.9757 - val_loss: 0.2546 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.26041 to 0.25460, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.2255 - acc: 0.9783 - val_loss: 0.2528 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.25460 to 0.25279, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.2233 - acc: 0.9776 - val_loss: 0.2503 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.25279 to 0.25029, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.2206 - acc: 0.9776 - val_loss: 0.2462 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.25029 to 0.24619, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.2178 - acc: 0.9803 - val_loss: 0.2449 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.24619 to 0.24488, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.2155 - acc: 0.9789 - val_loss: 0.2403 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.24488 to 0.24033, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.2125 - acc: 0.9822 - val_loss: 0.2373 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.24033 to 0.23731, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.2098 - acc: 0.9816 - val_loss: 0.2353 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.23731 to 0.23529, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.2063 - acc: 0.9842 - val_loss: 0.2338 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.23529 to 0.23376, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.2051 - acc: 0.9836 - val_loss: 0.2305 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.23376 to 0.23047, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.2031 - acc: 0.9836 - val_loss: 0.2257 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.23047 to 0.22574, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.1986 - acc: 0.9849 - val_loss: 0.2264 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.22574\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.1960 - acc: 0.9855 - val_loss: 0.2230 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.22574 to 0.22296, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.1938 - acc: 0.9849 - val_loss: 0.2204 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.22296 to 0.22037, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.1928 - acc: 0.9842 - val_loss: 0.2166 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.22037 to 0.21658, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.1902 - acc: 0.9882 - val_loss: 0.2157 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.21658 to 0.21575, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.1882 - acc: 0.9868 - val_loss: 0.2120 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.21575 to 0.21195, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.1846 - acc: 0.9882 - val_loss: 0.2108 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.21195 to 0.21081, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.1832 - acc: 0.9868 - val_loss: 0.2078 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.21081 to 0.20782, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.1813 - acc: 0.9875 - val_loss: 0.2054 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.20782 to 0.20541, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.1778 - acc: 0.9888 - val_loss: 0.2022 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.20541 to 0.20215, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.1747 - acc: 0.9882 - val_loss: 0.2029 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.20215\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.1733 - acc: 0.9868 - val_loss: 0.1981 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.20215 to 0.19810, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.1700 - acc: 0.9888 - val_loss: 0.2011 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.19810\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.1684 - acc: 0.9895 - val_loss: 0.1938 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.19810 to 0.19379, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.1673 - acc: 0.9882 - val_loss: 0.1940 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.19379\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.1640 - acc: 0.9914 - val_loss: 0.1896 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.19379 to 0.18955, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.1620 - acc: 0.9901 - val_loss: 0.1888 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.18955 to 0.18885, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.1602 - acc: 0.9914 - val_loss: 0.1855 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.18885 to 0.18552, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.1593 - acc: 0.9895 - val_loss: 0.1868 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.18552\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.1574 - acc: 0.9901 - val_loss: 0.1810 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.18552 to 0.18097, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.1552 - acc: 0.9901 - val_loss: 0.1811 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.18097\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.1529 - acc: 0.9921 - val_loss: 0.1794 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.18097 to 0.17941, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.1504 - acc: 0.9921 - val_loss: 0.1763 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.17941 to 0.17633, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.1489 - acc: 0.9908 - val_loss: 0.1756 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.17633 to 0.17555, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.1466 - acc: 0.9914 - val_loss: 0.1733 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.17555 to 0.17325, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.1452 - acc: 0.9934 - val_loss: 0.1719 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.17325 to 0.17186, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.1430 - acc: 0.9928 - val_loss: 0.1688 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.17186 to 0.16880, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.1414 - acc: 0.9921 - val_loss: 0.1665 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.16880 to 0.16650, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.1407 - acc: 0.9941 - val_loss: 0.1637 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.16650 to 0.16371, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.1387 - acc: 0.9921 - val_loss: 0.1657 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.16371\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.1364 - acc: 0.9941 - val_loss: 0.1603 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.16371 to 0.16028, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.1350 - acc: 0.9928 - val_loss: 0.1614 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.16028\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.1324 - acc: 0.9961 - val_loss: 0.1563 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.16028 to 0.15627, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.1314 - acc: 0.9954 - val_loss: 0.1553 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.15627 to 0.15533, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.1294 - acc: 0.9961 - val_loss: 0.1540 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.15533 to 0.15403, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.1283 - acc: 0.9941 - val_loss: 0.1522 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.15403 to 0.15219, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.1268 - acc: 0.9947 - val_loss: 0.1496 - val_acc: 0.9918\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00146: val_loss improved from 0.15219 to 0.14959, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.1253 - acc: 0.9961 - val_loss: 0.1516 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.14959\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.1237 - acc: 0.9961 - val_loss: 0.1488 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.14959 to 0.14880, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.1220 - acc: 0.9961 - val_loss: 0.1470 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.14880 to 0.14698, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.1209 - acc: 0.9967 - val_loss: 0.1457 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.14698 to 0.14572, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.1186 - acc: 0.9961 - val_loss: 0.1429 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.14572 to 0.14286, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.1178 - acc: 0.9961 - val_loss: 0.1411 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.14286 to 0.14113, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.1158 - acc: 0.9967 - val_loss: 0.1410 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.14113 to 0.14099, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.1147 - acc: 0.9967 - val_loss: 0.1388 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.14099 to 0.13878, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.1138 - acc: 0.9967 - val_loss: 0.1376 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.13878 to 0.13757, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.1132 - acc: 0.9974 - val_loss: 0.1372 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.13757 to 0.13722, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.1108 - acc: 0.9974 - val_loss: 0.1332 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.13722 to 0.13320, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.1095 - acc: 0.9974 - val_loss: 0.1365 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.13320\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.1087 - acc: 0.9980 - val_loss: 0.1336 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.13320\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.1094 - acc: 0.9967 - val_loss: 0.1316 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.13320 to 0.13161, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.1076 - acc: 0.9980 - val_loss: 0.1347 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.13161\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.1048 - acc: 0.9980 - val_loss: 0.1280 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.13161 to 0.12796, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.1028 - acc: 0.9974 - val_loss: 0.1289 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.12796\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.1021 - acc: 0.9974 - val_loss: 0.1265 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.12796 to 0.12649, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.1010 - acc: 0.9974 - val_loss: 0.1250 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.12649 to 0.12503, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.0997 - acc: 0.9974 - val_loss: 0.1226 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00166: val_loss improved from 0.12503 to 0.12259, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.0990 - acc: 0.9974 - val_loss: 0.1209 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.12259 to 0.12091, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.0980 - acc: 0.9980 - val_loss: 0.1219 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.12091\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.0954 - acc: 0.9980 - val_loss: 0.1193 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.12091 to 0.11928, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.0951 - acc: 0.9980 - val_loss: 0.1201 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.11928\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.0944 - acc: 0.9974 - val_loss: 0.1176 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00171: val_loss improved from 0.11928 to 0.11761, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.0924 - acc: 0.9974 - val_loss: 0.1171 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00172: val_loss improved from 0.11761 to 0.11711, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.0913 - acc: 0.9980 - val_loss: 0.1130 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.11711 to 0.11303, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.0902 - acc: 0.9980 - val_loss: 0.1164 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.11303\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.0891 - acc: 0.9980 - val_loss: 0.1125 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00175: val_loss improved from 0.11303 to 0.11252, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.0884 - acc: 0.9987 - val_loss: 0.1147 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.11252\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.0873 - acc: 0.9980 - val_loss: 0.1104 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00177: val_loss improved from 0.11252 to 0.11042, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.0863 - acc: 0.9987 - val_loss: 0.1109 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.11042\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.0864 - acc: 0.9980 - val_loss: 0.1077 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00179: val_loss improved from 0.11042 to 0.10770, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.0851 - acc: 0.9987 - val_loss: 0.1096 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.10770\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.0837 - acc: 0.9980 - val_loss: 0.1085 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.10770\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.0821 - acc: 0.9980 - val_loss: 0.1062 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00182: val_loss improved from 0.10770 to 0.10619, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.0816 - acc: 0.9980 - val_loss: 0.1061 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00183: val_loss improved from 0.10619 to 0.10607, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.0809 - acc: 0.9974 - val_loss: 0.1040 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00184: val_loss improved from 0.10607 to 0.10399, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.0797 - acc: 0.9980 - val_loss: 0.1047 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.10399\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.0790 - acc: 0.9980 - val_loss: 0.1020 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.10399 to 0.10196, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.0778 - acc: 0.9974 - val_loss: 0.1014 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.10196 to 0.10135, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.0773 - acc: 0.9980 - val_loss: 0.1019 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.10135\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.0765 - acc: 0.9980 - val_loss: 0.1002 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.10135 to 0.10022, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.0764 - acc: 0.9980 - val_loss: 0.1005 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.10022\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.0750 - acc: 0.9974 - val_loss: 0.0982 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00191: val_loss improved from 0.10022 to 0.09821, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.0755 - acc: 0.9974 - val_loss: 0.0964 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.09821 to 0.09642, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.0738 - acc: 0.9974 - val_loss: 0.0963 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00193: val_loss improved from 0.09642 to 0.09631, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.0720 - acc: 0.9974 - val_loss: 0.0963 - val_acc: 0.9918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00194: val_loss improved from 0.09631 to 0.09630, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.0718 - acc: 0.9974 - val_loss: 0.0943 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00195: val_loss improved from 0.09630 to 0.09433, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.0706 - acc: 0.9980 - val_loss: 0.0950 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.09433\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.0697 - acc: 0.9980 - val_loss: 0.0933 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00197: val_loss improved from 0.09433 to 0.09328, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.0696 - acc: 0.9974 - val_loss: 0.0919 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.09328 to 0.09189, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.0683 - acc: 0.9974 - val_loss: 0.0917 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00199: val_loss improved from 0.09189 to 0.09168, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.0676 - acc: 0.9974 - val_loss: 0.0903 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00200: val_loss improved from 0.09168 to 0.09034, saving model to weights.best.Resnet50.hdf5\n",
      "batch_size=160   optimizer=Adamax\n",
      "Test accuracy: 67.4095%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_54 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 2.2922 - acc: 0.1684 - val_loss: 1.9884 - val_acc: 0.2798\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.98837, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.8502 - acc: 0.3316 - val_loss: 1.6690 - val_acc: 0.4403\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.98837 to 1.66901, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 1.5857 - acc: 0.4414 - val_loss: 1.4926 - val_acc: 0.4979\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.66901 to 1.49261, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 1.4082 - acc: 0.5322 - val_loss: 1.3599 - val_acc: 0.5597\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.49261 to 1.35989, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 1.2891 - acc: 0.5763 - val_loss: 1.2716 - val_acc: 0.6008\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.35989 to 1.27162, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 1.2020 - acc: 0.6132 - val_loss: 1.1980 - val_acc: 0.6132\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.27162 to 1.19795, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 1.1413 - acc: 0.6414 - val_loss: 1.1508 - val_acc: 0.6502\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.19795 to 1.15075, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 0s - loss: 1.0911 - acc: 0.6487 - val_loss: 1.0951 - val_acc: 0.6584\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.15075 to 1.09512, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 0s - loss: 1.0470 - acc: 0.6691 - val_loss: 1.0684 - val_acc: 0.6708\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.09512 to 1.06840, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 0s - loss: 1.0073 - acc: 0.6908 - val_loss: 1.0275 - val_acc: 0.6790\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.06840 to 1.02745, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.9753 - acc: 0.6974 - val_loss: 0.9962 - val_acc: 0.6790\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.02745 to 0.99623, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.9447 - acc: 0.7086 - val_loss: 0.9755 - val_acc: 0.6831\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.99623 to 0.97553, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.9171 - acc: 0.7184 - val_loss: 0.9402 - val_acc: 0.6872\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.97553 to 0.94022, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.8924 - acc: 0.7296 - val_loss: 0.9222 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.94022 to 0.92220, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.8682 - acc: 0.7316 - val_loss: 0.9058 - val_acc: 0.6955\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.92220 to 0.90579, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.8492 - acc: 0.7355 - val_loss: 0.8787 - val_acc: 0.7160\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.90579 to 0.87872, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.8275 - acc: 0.7454 - val_loss: 0.8635 - val_acc: 0.7202\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.87872 to 0.86354, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.8088 - acc: 0.7487 - val_loss: 0.8428 - val_acc: 0.7202\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.86354 to 0.84283, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.7924 - acc: 0.7579 - val_loss: 0.8254 - val_acc: 0.7325\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.84283 to 0.82540, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.7736 - acc: 0.7638 - val_loss: 0.8073 - val_acc: 0.7243\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.82540 to 0.80726, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.7580 - acc: 0.7671 - val_loss: 0.7915 - val_acc: 0.7449\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.80726 to 0.79154, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.7436 - acc: 0.7763 - val_loss: 0.7777 - val_acc: 0.7572\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.79154 to 0.77768, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.7326 - acc: 0.7743 - val_loss: 0.7619 - val_acc: 0.7531\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.77768 to 0.76186, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.7161 - acc: 0.7862 - val_loss: 0.7511 - val_acc: 0.7654\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.76186 to 0.75111, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.7048 - acc: 0.7928 - val_loss: 0.7395 - val_acc: 0.7613\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.75111 to 0.73946, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.6879 - acc: 0.7980 - val_loss: 0.7210 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.73946 to 0.72095, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.6790 - acc: 0.7954 - val_loss: 0.7144 - val_acc: 0.7737\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.72095 to 0.71436, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.6649 - acc: 0.8079 - val_loss: 0.6988 - val_acc: 0.7819\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.71436 to 0.69878, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.6542 - acc: 0.8066 - val_loss: 0.6893 - val_acc: 0.7819\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.69878 to 0.68935, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.6397 - acc: 0.8171 - val_loss: 0.6739 - val_acc: 0.8107\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.68935 to 0.67390, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.6297 - acc: 0.8276 - val_loss: 0.6662 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.67390 to 0.66616, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.6200 - acc: 0.8263 - val_loss: 0.6576 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.66616 to 0.65762, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.6107 - acc: 0.8329 - val_loss: 0.6408 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.65762 to 0.64077, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.6022 - acc: 0.8289 - val_loss: 0.6386 - val_acc: 0.8107\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.64077 to 0.63859, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.5962 - acc: 0.8303 - val_loss: 0.6249 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.63859 to 0.62494, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.5848 - acc: 0.8395 - val_loss: 0.6139 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.62494 to 0.61389, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.5727 - acc: 0.8401 - val_loss: 0.6130 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.61389 to 0.61301, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.5654 - acc: 0.8467 - val_loss: 0.5972 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.61301 to 0.59717, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.5556 - acc: 0.8507 - val_loss: 0.5932 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.59717 to 0.59319, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.5457 - acc: 0.8566 - val_loss: 0.5745 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.59319 to 0.57446, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.5383 - acc: 0.8605 - val_loss: 0.5723 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.57446 to 0.57230, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.5319 - acc: 0.8599 - val_loss: 0.5640 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.57230 to 0.56404, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.5228 - acc: 0.8638 - val_loss: 0.5561 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.56404 to 0.55607, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.5155 - acc: 0.8658 - val_loss: 0.5456 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.55607 to 0.54555, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.5092 - acc: 0.8737 - val_loss: 0.5373 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.54555 to 0.53726, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.5029 - acc: 0.8704 - val_loss: 0.5331 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.53726 to 0.53310, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.4925 - acc: 0.8757 - val_loss: 0.5215 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.53310 to 0.52149, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.4860 - acc: 0.8770 - val_loss: 0.5171 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.52149 to 0.51709, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.4799 - acc: 0.8816 - val_loss: 0.5095 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.51709 to 0.50949, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.4723 - acc: 0.8855 - val_loss: 0.4994 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.50949 to 0.49936, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.4654 - acc: 0.8895 - val_loss: 0.4942 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.49936 to 0.49415, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.4599 - acc: 0.8934 - val_loss: 0.4889 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.49415 to 0.48891, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.4556 - acc: 0.8875 - val_loss: 0.4834 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.48891 to 0.48339, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.4487 - acc: 0.8993 - val_loss: 0.4768 - val_acc: 0.9012\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.48339 to 0.47682, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.4424 - acc: 0.8980 - val_loss: 0.4691 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.47682 to 0.46909, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.4369 - acc: 0.8993 - val_loss: 0.4669 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.46909 to 0.46692, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.4291 - acc: 0.9007 - val_loss: 0.4614 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.46692 to 0.46140, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.4240 - acc: 0.9020 - val_loss: 0.4514 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.46140 to 0.45141, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.4187 - acc: 0.9046 - val_loss: 0.4461 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.45141 to 0.44607, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.4129 - acc: 0.9072 - val_loss: 0.4424 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.44607 to 0.44244, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.4085 - acc: 0.9086 - val_loss: 0.4339 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.44244 to 0.43392, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.4027 - acc: 0.9151 - val_loss: 0.4303 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.43392 to 0.43028, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.3968 - acc: 0.9164 - val_loss: 0.4255 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.43028 to 0.42550, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.3931 - acc: 0.9145 - val_loss: 0.4195 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.42550 to 0.41951, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.3881 - acc: 0.9217 - val_loss: 0.4145 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.41951 to 0.41447, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.3837 - acc: 0.9243 - val_loss: 0.4148 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.41447\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.3782 - acc: 0.9237 - val_loss: 0.4031 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.41447 to 0.40311, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.3752 - acc: 0.9276 - val_loss: 0.4015 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.40311 to 0.40149, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.3711 - acc: 0.9250 - val_loss: 0.3975 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.40149 to 0.39746, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.3654 - acc: 0.9296 - val_loss: 0.3919 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.39746 to 0.39193, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.3592 - acc: 0.9382 - val_loss: 0.3847 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.39193 to 0.38470, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.3549 - acc: 0.9342 - val_loss: 0.3844 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.38470 to 0.38444, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.3508 - acc: 0.9428 - val_loss: 0.3768 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.38444 to 0.37683, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.3477 - acc: 0.9388 - val_loss: 0.3729 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.37683 to 0.37290, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.3446 - acc: 0.9414 - val_loss: 0.3663 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.37290 to 0.36629, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.3387 - acc: 0.9428 - val_loss: 0.3662 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.36629 to 0.36620, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.3337 - acc: 0.9434 - val_loss: 0.3596 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.36620 to 0.35965, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.3309 - acc: 0.9480 - val_loss: 0.3564 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.35965 to 0.35644, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.3269 - acc: 0.9454 - val_loss: 0.3544 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.35644 to 0.35444, saving model to weights.best.Resnet50.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/200\n",
      " - 0s - loss: 0.3214 - acc: 0.9480 - val_loss: 0.3465 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.35444 to 0.34648, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.3188 - acc: 0.9500 - val_loss: 0.3453 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.34648 to 0.34535, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.3143 - acc: 0.9526 - val_loss: 0.3394 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.34535 to 0.33941, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.3112 - acc: 0.9500 - val_loss: 0.3370 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.33941 to 0.33696, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.3070 - acc: 0.9533 - val_loss: 0.3314 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.33696 to 0.33143, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.3056 - acc: 0.9539 - val_loss: 0.3302 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.33143 to 0.33016, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.3004 - acc: 0.9553 - val_loss: 0.3242 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.33016 to 0.32424, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.2959 - acc: 0.9566 - val_loss: 0.3233 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.32424 to 0.32327, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.2931 - acc: 0.9526 - val_loss: 0.3155 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.32327 to 0.31547, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.2884 - acc: 0.9572 - val_loss: 0.3171 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.31547\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.2857 - acc: 0.9586 - val_loss: 0.3114 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.31547 to 0.31136, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.2848 - acc: 0.9592 - val_loss: 0.3104 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.31136 to 0.31044, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.2794 - acc: 0.9612 - val_loss: 0.3024 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.31044 to 0.30237, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.2764 - acc: 0.9599 - val_loss: 0.3045 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.30237\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.2727 - acc: 0.9599 - val_loss: 0.2968 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.30237 to 0.29675, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.2695 - acc: 0.9651 - val_loss: 0.2944 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.29675 to 0.29436, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.2669 - acc: 0.9658 - val_loss: 0.2913 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.29436 to 0.29128, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.2633 - acc: 0.9638 - val_loss: 0.2880 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.29128 to 0.28799, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.2622 - acc: 0.9671 - val_loss: 0.2821 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.28799 to 0.28209, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.2571 - acc: 0.9671 - val_loss: 0.2835 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.28209\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.2539 - acc: 0.9645 - val_loss: 0.2772 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.28209 to 0.27724, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.2525 - acc: 0.9704 - val_loss: 0.2747 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.27724 to 0.27473, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.2487 - acc: 0.9730 - val_loss: 0.2709 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.27473 to 0.27091, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.2460 - acc: 0.9724 - val_loss: 0.2699 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.27091 to 0.26988, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.2431 - acc: 0.9697 - val_loss: 0.2667 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.26988 to 0.26672, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.2406 - acc: 0.9770 - val_loss: 0.2644 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.26672 to 0.26438, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.2375 - acc: 0.9737 - val_loss: 0.2611 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.26438 to 0.26113, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.2346 - acc: 0.9783 - val_loss: 0.2535 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.26113 to 0.25345, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.2321 - acc: 0.9783 - val_loss: 0.2557 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.25345\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.2294 - acc: 0.9809 - val_loss: 0.2524 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.25345 to 0.25240, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.2278 - acc: 0.9757 - val_loss: 0.2484 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.25240 to 0.24837, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.2237 - acc: 0.9822 - val_loss: 0.2477 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.24837 to 0.24769, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.2208 - acc: 0.9822 - val_loss: 0.2440 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.24769 to 0.24404, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.2184 - acc: 0.9829 - val_loss: 0.2421 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.24404 to 0.24209, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.2174 - acc: 0.9816 - val_loss: 0.2395 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.24209 to 0.23945, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.2153 - acc: 0.9816 - val_loss: 0.2379 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.23945 to 0.23788, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.2118 - acc: 0.9842 - val_loss: 0.2360 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.23788 to 0.23601, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.2102 - acc: 0.9862 - val_loss: 0.2302 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.23601 to 0.23018, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.2065 - acc: 0.9855 - val_loss: 0.2311 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.23018\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.2046 - acc: 0.9868 - val_loss: 0.2266 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.23018 to 0.22664, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.2019 - acc: 0.9855 - val_loss: 0.2238 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.22664 to 0.22383, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.2015 - acc: 0.9868 - val_loss: 0.2218 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.22383 to 0.22178, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.1987 - acc: 0.9868 - val_loss: 0.2217 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.22178 to 0.22169, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.1948 - acc: 0.9868 - val_loss: 0.2172 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.22169 to 0.21716, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.1941 - acc: 0.9888 - val_loss: 0.2159 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.21716 to 0.21590, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.1911 - acc: 0.9901 - val_loss: 0.2126 - val_acc: 0.9877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00125: val_loss improved from 0.21590 to 0.21265, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.1883 - acc: 0.9895 - val_loss: 0.2115 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.21265 to 0.21151, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.1860 - acc: 0.9895 - val_loss: 0.2078 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.21151 to 0.20781, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.1842 - acc: 0.9908 - val_loss: 0.2073 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.20781 to 0.20729, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.1825 - acc: 0.9914 - val_loss: 0.2048 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.20729 to 0.20484, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.1807 - acc: 0.9901 - val_loss: 0.2019 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.20484 to 0.20192, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.1795 - acc: 0.9908 - val_loss: 0.1996 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.20192 to 0.19956, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.1772 - acc: 0.9908 - val_loss: 0.1995 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.19956 to 0.19947, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.1741 - acc: 0.9901 - val_loss: 0.1974 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.19947 to 0.19742, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.1733 - acc: 0.9908 - val_loss: 0.1961 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.19742 to 0.19610, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.1706 - acc: 0.9908 - val_loss: 0.1926 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.19610 to 0.19260, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.1697 - acc: 0.9901 - val_loss: 0.1905 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.19260 to 0.19054, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.1679 - acc: 0.9908 - val_loss: 0.1872 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.19054 to 0.18719, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.1664 - acc: 0.9901 - val_loss: 0.1881 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.18719\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.1646 - acc: 0.9921 - val_loss: 0.1871 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.18719 to 0.18706, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.1617 - acc: 0.9941 - val_loss: 0.1814 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.18706 to 0.18138, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.1592 - acc: 0.9928 - val_loss: 0.1834 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.18138\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.1582 - acc: 0.9914 - val_loss: 0.1813 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.18138 to 0.18135, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.1554 - acc: 0.9941 - val_loss: 0.1783 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.18135 to 0.17826, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.1544 - acc: 0.9928 - val_loss: 0.1767 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.17826 to 0.17671, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.1522 - acc: 0.9941 - val_loss: 0.1754 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.17671 to 0.17537, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.1506 - acc: 0.9954 - val_loss: 0.1735 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.17537 to 0.17349, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.1495 - acc: 0.9947 - val_loss: 0.1725 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.17349 to 0.17247, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.1479 - acc: 0.9947 - val_loss: 0.1683 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.17247 to 0.16828, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.1465 - acc: 0.9954 - val_loss: 0.1718 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.16828\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.1448 - acc: 0.9947 - val_loss: 0.1662 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.16828 to 0.16623, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.1437 - acc: 0.9941 - val_loss: 0.1658 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.16623 to 0.16577, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.1419 - acc: 0.9947 - val_loss: 0.1630 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.16577 to 0.16304, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.1404 - acc: 0.9967 - val_loss: 0.1609 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.16304 to 0.16090, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.1401 - acc: 0.9954 - val_loss: 0.1625 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.16090\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.1377 - acc: 0.9954 - val_loss: 0.1576 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.16090 to 0.15756, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.1356 - acc: 0.9954 - val_loss: 0.1569 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.15756 to 0.15688, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.1350 - acc: 0.9961 - val_loss: 0.1556 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.15688 to 0.15555, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.1328 - acc: 0.9967 - val_loss: 0.1558 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.15555\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.1315 - acc: 0.9961 - val_loss: 0.1533 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.15555 to 0.15331, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.1304 - acc: 0.9967 - val_loss: 0.1506 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.15331 to 0.15064, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.1286 - acc: 0.9961 - val_loss: 0.1529 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.15064\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.1268 - acc: 0.9961 - val_loss: 0.1484 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.15064 to 0.14836, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.1260 - acc: 0.9967 - val_loss: 0.1483 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00163: val_loss improved from 0.14836 to 0.14835, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.1246 - acc: 0.9961 - val_loss: 0.1474 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.14835 to 0.14736, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.1229 - acc: 0.9961 - val_loss: 0.1446 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.14736 to 0.14460, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.1216 - acc: 0.9967 - val_loss: 0.1448 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.14460\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.1210 - acc: 0.9967 - val_loss: 0.1429 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.14460 to 0.14292, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.1195 - acc: 0.9961 - val_loss: 0.1422 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.14292 to 0.14223, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.1177 - acc: 0.9974 - val_loss: 0.1404 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.14223 to 0.14037, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.1176 - acc: 0.9974 - val_loss: 0.1390 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.14037 to 0.13899, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.1163 - acc: 0.9974 - val_loss: 0.1395 - val_acc: 0.9918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00171: val_loss did not improve from 0.13899\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.1145 - acc: 0.9967 - val_loss: 0.1372 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00172: val_loss improved from 0.13899 to 0.13715, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.1147 - acc: 0.9974 - val_loss: 0.1368 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.13715 to 0.13684, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.1123 - acc: 0.9967 - val_loss: 0.1331 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.13684 to 0.13308, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.1109 - acc: 0.9967 - val_loss: 0.1321 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00175: val_loss improved from 0.13308 to 0.13206, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.1098 - acc: 0.9980 - val_loss: 0.1331 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.13206\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.1088 - acc: 0.9974 - val_loss: 0.1308 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00177: val_loss improved from 0.13206 to 0.13085, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.1082 - acc: 0.9974 - val_loss: 0.1293 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00178: val_loss improved from 0.13085 to 0.12928, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.1064 - acc: 0.9974 - val_loss: 0.1290 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00179: val_loss improved from 0.12928 to 0.12901, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.1052 - acc: 0.9980 - val_loss: 0.1284 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00180: val_loss improved from 0.12901 to 0.12842, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.1044 - acc: 0.9980 - val_loss: 0.1260 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00181: val_loss improved from 0.12842 to 0.12599, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.1035 - acc: 0.9980 - val_loss: 0.1252 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00182: val_loss improved from 0.12599 to 0.12521, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.1022 - acc: 0.9980 - val_loss: 0.1249 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00183: val_loss improved from 0.12521 to 0.12487, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.1011 - acc: 0.9980 - val_loss: 0.1237 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00184: val_loss improved from 0.12487 to 0.12368, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.1002 - acc: 0.9980 - val_loss: 0.1208 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00185: val_loss improved from 0.12368 to 0.12078, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.0992 - acc: 0.9974 - val_loss: 0.1221 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.12078\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.0983 - acc: 0.9980 - val_loss: 0.1200 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.12078 to 0.11999, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.0975 - acc: 0.9974 - val_loss: 0.1199 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00188: val_loss improved from 0.11999 to 0.11991, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.0964 - acc: 0.9980 - val_loss: 0.1192 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.11991 to 0.11920, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.0952 - acc: 0.9980 - val_loss: 0.1159 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00190: val_loss improved from 0.11920 to 0.11593, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.0946 - acc: 0.9974 - val_loss: 0.1167 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.11593\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.0941 - acc: 0.9980 - val_loss: 0.1161 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.11593\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.0930 - acc: 0.9980 - val_loss: 0.1148 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00193: val_loss improved from 0.11593 to 0.11484, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.0914 - acc: 0.9987 - val_loss: 0.1132 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00194: val_loss improved from 0.11484 to 0.11321, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.0907 - acc: 0.9980 - val_loss: 0.1140 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.11321\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.0896 - acc: 0.9980 - val_loss: 0.1099 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00196: val_loss improved from 0.11321 to 0.10987, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.0891 - acc: 0.9980 - val_loss: 0.1119 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.10987\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.0878 - acc: 0.9980 - val_loss: 0.1102 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.10987\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.0877 - acc: 0.9974 - val_loss: 0.1086 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00199: val_loss improved from 0.10987 to 0.10855, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.0861 - acc: 0.9974 - val_loss: 0.1087 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.10855\n",
      "batch_size=200   optimizer=Adamax\n",
      "Test accuracy: 67.6880%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_55 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 2s - loss: 1.5201 - acc: 0.4645 - val_loss: 0.9791 - val_acc: 0.6543\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.97906, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 1s - loss: 0.9156 - acc: 0.6882 - val_loss: 0.7635 - val_acc: 0.7531\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.97906 to 0.76353, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 1s - loss: 0.7112 - acc: 0.7586 - val_loss: 0.5562 - val_acc: 0.8354\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.76353 to 0.55615, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 1s - loss: 0.5800 - acc: 0.8197 - val_loss: 0.4979 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.55615 to 0.49794, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 1s - loss: 0.4758 - acc: 0.8513 - val_loss: 0.4177 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.49794 to 0.41771, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 1s - loss: 0.3996 - acc: 0.8855 - val_loss: 0.3551 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.41771 to 0.35511, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 1s - loss: 0.3540 - acc: 0.8974 - val_loss: 0.3058 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.35511 to 0.30578, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 1s - loss: 0.2996 - acc: 0.9237 - val_loss: 0.2910 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.30578 to 0.29096, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 1s - loss: 0.2577 - acc: 0.9454 - val_loss: 0.2179 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.29096 to 0.21787, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 1s - loss: 0.2254 - acc: 0.9539 - val_loss: 0.2080 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.21787 to 0.20798, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 1s - loss: 0.1925 - acc: 0.9730 - val_loss: 0.1626 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.20798 to 0.16258, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 1s - loss: 0.1706 - acc: 0.9783 - val_loss: 0.1733 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.16258\n",
      "Epoch 13/200\n",
      " - 1s - loss: 0.1506 - acc: 0.9809 - val_loss: 0.1246 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.16258 to 0.12456, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 1s - loss: 0.1339 - acc: 0.9895 - val_loss: 0.1301 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.12456\n",
      "Epoch 15/200\n",
      " - 1s - loss: 0.1182 - acc: 0.9908 - val_loss: 0.1217 - val_acc: 0.9918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00015: val_loss improved from 0.12456 to 0.12168, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 1s - loss: 0.1067 - acc: 0.9928 - val_loss: 0.1080 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.12168 to 0.10795, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 1s - loss: 0.0929 - acc: 0.9954 - val_loss: 0.0994 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.10795 to 0.09943, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/200\n",
      " - 1s - loss: 0.0835 - acc: 0.9954 - val_loss: 0.0878 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.09943 to 0.08784, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 1s - loss: 0.0770 - acc: 0.9974 - val_loss: 0.0774 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.08784 to 0.07737, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 1s - loss: 0.0708 - acc: 0.9974 - val_loss: 0.0836 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.07737\n",
      "Epoch 21/200\n",
      " - 1s - loss: 0.0629 - acc: 0.9967 - val_loss: 0.0735 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.07737 to 0.07350, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 1s - loss: 0.0596 - acc: 0.9947 - val_loss: 0.0848 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.07350\n",
      "Epoch 23/200\n",
      " - 1s - loss: 0.0539 - acc: 0.9974 - val_loss: 0.0640 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.07350 to 0.06401, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 24/200\n",
      " - 1s - loss: 0.0503 - acc: 0.9967 - val_loss: 0.0542 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.06401 to 0.05417, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 25/200\n",
      " - 1s - loss: 0.0462 - acc: 0.9980 - val_loss: 0.0505 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.05417 to 0.05047, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 26/200\n",
      " - 1s - loss: 0.0442 - acc: 0.9967 - val_loss: 0.0485 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.05047 to 0.04850, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 27/200\n",
      " - 1s - loss: 0.0413 - acc: 0.9974 - val_loss: 0.0664 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.04850\n",
      "Epoch 28/200\n",
      " - 1s - loss: 0.0395 - acc: 0.9961 - val_loss: 0.0515 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.04850\n",
      "Epoch 29/200\n",
      " - 1s - loss: 0.0359 - acc: 0.9961 - val_loss: 0.0538 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.04850\n",
      "Epoch 30/200\n",
      " - 1s - loss: 0.0340 - acc: 0.9967 - val_loss: 0.0463 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.04850 to 0.04629, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 31/200\n",
      " - 1s - loss: 0.0314 - acc: 0.9974 - val_loss: 0.0410 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.04629 to 0.04105, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 32/200\n",
      " - 1s - loss: 0.0297 - acc: 0.9974 - val_loss: 0.0341 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.04105 to 0.03413, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 33/200\n",
      " - 1s - loss: 0.0296 - acc: 0.9974 - val_loss: 0.0537 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.03413\n",
      "Epoch 34/200\n",
      " - 1s - loss: 0.0302 - acc: 0.9967 - val_loss: 0.0412 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.03413\n",
      "Epoch 35/200\n",
      " - 1s - loss: 0.0278 - acc: 0.9967 - val_loss: 0.0317 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.03413 to 0.03169, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 36/200\n",
      " - 1s - loss: 0.0270 - acc: 0.9961 - val_loss: 0.0335 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.03169\n",
      "Epoch 37/200\n",
      " - 1s - loss: 0.0248 - acc: 0.9967 - val_loss: 0.0464 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.03169\n",
      "Epoch 38/200\n",
      " - 1s - loss: 0.0261 - acc: 0.9974 - val_loss: 0.0336 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.03169\n",
      "Epoch 39/200\n",
      " - 1s - loss: 0.0277 - acc: 0.9961 - val_loss: 0.0352 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.03169\n",
      "Epoch 40/200\n",
      " - 1s - loss: 0.0224 - acc: 0.9974 - val_loss: 0.0361 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.03169\n",
      "Epoch 41/200\n",
      " - 1s - loss: 0.0209 - acc: 0.9967 - val_loss: 0.0327 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.03169\n",
      "Epoch 42/200\n",
      " - 1s - loss: 0.0201 - acc: 0.9974 - val_loss: 0.0492 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.03169\n",
      "Epoch 43/200\n",
      " - 1s - loss: 0.0243 - acc: 0.9961 - val_loss: 0.0360 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.03169\n",
      "Epoch 44/200\n",
      " - 1s - loss: 0.0215 - acc: 0.9974 - val_loss: 0.0315 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.03169 to 0.03149, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 45/200\n",
      " - 1s - loss: 0.0257 - acc: 0.9954 - val_loss: 0.0399 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.03149\n",
      "Epoch 46/200\n",
      " - 1s - loss: 0.0219 - acc: 0.9961 - val_loss: 0.0337 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.03149\n",
      "Epoch 47/200\n",
      " - 1s - loss: 0.0157 - acc: 0.9980 - val_loss: 0.0305 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.03149 to 0.03050, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 48/200\n",
      " - 1s - loss: 0.0205 - acc: 0.9967 - val_loss: 0.0534 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.03050\n",
      "Epoch 49/200\n",
      " - 1s - loss: 0.0170 - acc: 0.9974 - val_loss: 0.0901 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.03050\n",
      "Epoch 50/200\n",
      " - 1s - loss: 0.0216 - acc: 0.9961 - val_loss: 0.0274 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.03050 to 0.02736, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 51/200\n",
      " - 1s - loss: 0.0198 - acc: 0.9967 - val_loss: 0.1210 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.02736\n",
      "Epoch 52/200\n",
      " - 1s - loss: 0.0198 - acc: 0.9954 - val_loss: 0.0296 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.02736\n",
      "Epoch 53/200\n",
      " - 1s - loss: 0.0164 - acc: 0.9974 - val_loss: 0.0275 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.02736\n",
      "Epoch 54/200\n",
      " - 1s - loss: 0.0185 - acc: 0.9961 - val_loss: 0.0379 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.02736\n",
      "Epoch 55/200\n",
      " - 1s - loss: 0.0216 - acc: 0.9947 - val_loss: 0.0352 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.02736\n",
      "Epoch 56/200\n",
      " - 1s - loss: 0.0143 - acc: 0.9974 - val_loss: 0.0684 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.02736\n",
      "Epoch 57/200\n",
      " - 1s - loss: 0.0183 - acc: 0.9961 - val_loss: 0.0330 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.02736\n",
      "Epoch 58/200\n",
      " - 1s - loss: 0.0133 - acc: 0.9974 - val_loss: 0.0257 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.02736 to 0.02573, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 59/200\n",
      " - 1s - loss: 0.0159 - acc: 0.9961 - val_loss: 0.0355 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.02573\n",
      "Epoch 60/200\n",
      " - 1s - loss: 0.0133 - acc: 0.9974 - val_loss: 0.0391 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.02573\n",
      "Epoch 61/200\n",
      " - 1s - loss: 0.0135 - acc: 0.9980 - val_loss: 0.0644 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.02573\n",
      "Epoch 62/200\n",
      " - 1s - loss: 0.0164 - acc: 0.9961 - val_loss: 0.0373 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.02573\n",
      "Epoch 63/200\n",
      " - 1s - loss: 0.0155 - acc: 0.9967 - val_loss: 0.0302 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.02573\n",
      "Epoch 64/200\n",
      " - 1s - loss: 0.0114 - acc: 0.9980 - val_loss: 0.0652 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.02573\n",
      "Epoch 65/200\n",
      " - 1s - loss: 0.0174 - acc: 0.9954 - val_loss: 0.0390 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.02573\n",
      "Epoch 66/200\n",
      " - 1s - loss: 0.0143 - acc: 0.9974 - val_loss: 0.0302 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.02573\n",
      "Epoch 67/200\n",
      " - 1s - loss: 0.0117 - acc: 0.9980 - val_loss: 0.0442 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.02573\n",
      "Epoch 68/200\n",
      " - 1s - loss: 0.0179 - acc: 0.9961 - val_loss: 0.0375 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.02573\n",
      "Epoch 69/200\n",
      " - 1s - loss: 0.0178 - acc: 0.9967 - val_loss: 0.0499 - val_acc: 0.9918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00069: val_loss did not improve from 0.02573\n",
      "Epoch 70/200\n",
      " - 1s - loss: 0.0162 - acc: 0.9967 - val_loss: 0.0330 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.02573\n",
      "Epoch 71/200\n",
      " - 1s - loss: 0.0136 - acc: 0.9974 - val_loss: 0.0296 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.02573\n",
      "Epoch 72/200\n",
      " - 1s - loss: 0.0149 - acc: 0.9974 - val_loss: 0.0378 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.02573\n",
      "Epoch 73/200\n",
      " - 1s - loss: 0.0109 - acc: 0.9980 - val_loss: 0.0378 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.02573\n",
      "Epoch 74/200\n",
      " - 1s - loss: 0.0107 - acc: 0.9974 - val_loss: 0.0314 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.02573\n",
      "Epoch 75/200\n",
      " - 1s - loss: 0.0145 - acc: 0.9974 - val_loss: 0.0190 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.02573 to 0.01897, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 76/200\n",
      " - 1s - loss: 0.0212 - acc: 0.9947 - val_loss: 0.0311 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.01897\n",
      "Epoch 77/200\n",
      " - 1s - loss: 0.0187 - acc: 0.9961 - val_loss: 0.1024 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.01897\n",
      "Epoch 78/200\n",
      " - 1s - loss: 0.0172 - acc: 0.9961 - val_loss: 0.0361 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.01897\n",
      "Epoch 79/200\n",
      " - 1s - loss: 0.0174 - acc: 0.9967 - val_loss: 0.0549 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.01897\n",
      "Epoch 80/200\n",
      " - 1s - loss: 0.0167 - acc: 0.9961 - val_loss: 0.0325 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.01897\n",
      "Epoch 81/200\n",
      " - 1s - loss: 0.0165 - acc: 0.9961 - val_loss: 0.0353 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.01897\n",
      "Epoch 82/200\n",
      " - 1s - loss: 0.0099 - acc: 0.9980 - val_loss: 0.0530 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.01897\n",
      "Epoch 83/200\n",
      " - 1s - loss: 0.0172 - acc: 0.9967 - val_loss: 0.0474 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.01897\n",
      "Epoch 84/200\n",
      " - 1s - loss: 0.0156 - acc: 0.9961 - val_loss: 0.0352 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.01897\n",
      "Epoch 85/200\n",
      " - 1s - loss: 0.0136 - acc: 0.9974 - val_loss: 0.0712 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.01897\n",
      "Epoch 86/200\n",
      " - 1s - loss: 0.0096 - acc: 0.9980 - val_loss: 0.0363 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.01897\n",
      "Epoch 87/200\n",
      " - 1s - loss: 0.0193 - acc: 0.9947 - val_loss: 0.0337 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.01897\n",
      "Epoch 88/200\n",
      " - 1s - loss: 0.0127 - acc: 0.9961 - val_loss: 0.0344 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.01897\n",
      "Epoch 89/200\n",
      " - 1s - loss: 0.0130 - acc: 0.9967 - val_loss: 0.0343 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.01897\n",
      "Epoch 90/200\n",
      " - 1s - loss: 0.0204 - acc: 0.9961 - val_loss: 0.0394 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.01897\n",
      "Epoch 91/200\n",
      " - 1s - loss: 0.0110 - acc: 0.9974 - val_loss: 0.0423 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.01897\n",
      "Epoch 92/200\n",
      " - 1s - loss: 0.0131 - acc: 0.9974 - val_loss: 0.0659 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.01897\n",
      "Epoch 93/200\n",
      " - 1s - loss: 0.0125 - acc: 0.9974 - val_loss: 0.0523 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.01897\n",
      "Epoch 94/200\n",
      " - 1s - loss: 0.0130 - acc: 0.9974 - val_loss: 0.0351 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.01897\n",
      "Epoch 95/200\n",
      " - 1s - loss: 0.0143 - acc: 0.9954 - val_loss: 0.0483 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.01897\n",
      "Epoch 96/200\n",
      " - 1s - loss: 0.0131 - acc: 0.9974 - val_loss: 0.0339 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.01897\n",
      "Epoch 97/200\n",
      " - 1s - loss: 0.0226 - acc: 0.9928 - val_loss: 0.0392 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.01897\n",
      "Epoch 98/200\n",
      " - 1s - loss: 0.0210 - acc: 0.9941 - val_loss: 0.0612 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.01897\n",
      "Epoch 99/200\n",
      " - 1s - loss: 0.0094 - acc: 0.9980 - val_loss: 0.0453 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.01897\n",
      "Epoch 100/200\n",
      " - 1s - loss: 0.0132 - acc: 0.9974 - val_loss: 0.0268 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.01897\n",
      "Epoch 101/200\n",
      " - 1s - loss: 0.0115 - acc: 0.9961 - val_loss: 0.0389 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.01897\n",
      "Epoch 102/200\n",
      " - 1s - loss: 0.0131 - acc: 0.9967 - val_loss: 0.0370 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.01897\n",
      "Epoch 103/200\n",
      " - 1s - loss: 0.0112 - acc: 0.9974 - val_loss: 0.0320 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.01897\n",
      "Epoch 104/200\n",
      " - 1s - loss: 0.0155 - acc: 0.9947 - val_loss: 0.0250 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.01897\n",
      "Epoch 105/200\n",
      " - 1s - loss: 0.0163 - acc: 0.9967 - val_loss: 0.0595 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.01897\n",
      "Epoch 106/200\n",
      " - 1s - loss: 0.0144 - acc: 0.9974 - val_loss: 0.0303 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.01897\n",
      "Epoch 107/200\n",
      " - 1s - loss: 0.0111 - acc: 0.9974 - val_loss: 0.0236 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.01897\n",
      "Epoch 108/200\n",
      " - 1s - loss: 0.0137 - acc: 0.9974 - val_loss: 0.0356 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.01897\n",
      "Epoch 109/200\n",
      " - 1s - loss: 0.0129 - acc: 0.9967 - val_loss: 0.0241 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.01897\n",
      "Epoch 110/200\n",
      " - 1s - loss: 0.0146 - acc: 0.9961 - val_loss: 0.0418 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.01897\n",
      "Epoch 111/200\n",
      " - 1s - loss: 0.0114 - acc: 0.9961 - val_loss: 0.0443 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.01897\n",
      "Epoch 112/200\n",
      " - 1s - loss: 0.0112 - acc: 0.9974 - val_loss: 0.0276 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.01897\n",
      "Epoch 113/200\n",
      " - 1s - loss: 0.0144 - acc: 0.9974 - val_loss: 0.0201 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.01897\n",
      "Epoch 114/200\n",
      " - 1s - loss: 0.0110 - acc: 0.9980 - val_loss: 0.0217 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.01897\n",
      "Epoch 115/200\n",
      " - 1s - loss: 0.0113 - acc: 0.9974 - val_loss: 0.0427 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.01897\n",
      "Epoch 116/200\n",
      " - 1s - loss: 0.0138 - acc: 0.9961 - val_loss: 0.0172 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.01897 to 0.01720, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 117/200\n",
      " - 1s - loss: 0.0161 - acc: 0.9967 - val_loss: 0.0416 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.01720\n",
      "Epoch 118/200\n",
      " - 1s - loss: 0.0111 - acc: 0.9967 - val_loss: 0.0492 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.01720\n",
      "Epoch 119/200\n",
      " - 1s - loss: 0.0103 - acc: 0.9980 - val_loss: 0.0144 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.01720 to 0.01436, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 120/200\n",
      " - 1s - loss: 0.0145 - acc: 0.9974 - val_loss: 0.0289 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.01436\n",
      "Epoch 121/200\n",
      " - 1s - loss: 0.0140 - acc: 0.9967 - val_loss: 0.0318 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.01436\n",
      "Epoch 122/200\n",
      " - 1s - loss: 0.0129 - acc: 0.9961 - val_loss: 0.0359 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.01436\n",
      "Epoch 123/200\n",
      " - 1s - loss: 0.0132 - acc: 0.9954 - val_loss: 0.0442 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.01436\n",
      "Epoch 124/200\n",
      " - 1s - loss: 0.0140 - acc: 0.9961 - val_loss: 0.0197 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.01436\n",
      "Epoch 125/200\n",
      " - 1s - loss: 0.0143 - acc: 0.9967 - val_loss: 0.0335 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.01436\n",
      "Epoch 126/200\n",
      " - 1s - loss: 0.0187 - acc: 0.9967 - val_loss: 0.0390 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.01436\n",
      "Epoch 127/200\n",
      " - 1s - loss: 0.0181 - acc: 0.9961 - val_loss: 0.0253 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.01436\n",
      "Epoch 128/200\n",
      " - 1s - loss: 0.0077 - acc: 0.9987 - val_loss: 0.0211 - val_acc: 0.9918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00128: val_loss did not improve from 0.01436\n",
      "Epoch 129/200\n",
      " - 1s - loss: 0.0198 - acc: 0.9934 - val_loss: 0.0298 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.01436\n",
      "Epoch 130/200\n",
      " - 1s - loss: 0.0110 - acc: 0.9974 - val_loss: 0.0379 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.01436\n",
      "Epoch 131/200\n",
      " - 1s - loss: 0.0107 - acc: 0.9974 - val_loss: 0.0342 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.01436\n",
      "Epoch 132/200\n",
      " - 1s - loss: 0.0122 - acc: 0.9974 - val_loss: 0.0261 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.01436\n",
      "Epoch 133/200\n",
      " - 1s - loss: 0.0159 - acc: 0.9967 - val_loss: 0.0506 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.01436\n",
      "Epoch 134/200\n",
      " - 1s - loss: 0.0167 - acc: 0.9974 - val_loss: 0.0340 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.01436\n",
      "Epoch 135/200\n",
      " - 1s - loss: 0.0093 - acc: 0.9974 - val_loss: 0.0369 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.01436\n",
      "Epoch 136/200\n",
      " - 1s - loss: 0.0148 - acc: 0.9974 - val_loss: 0.0318 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.01436\n",
      "Epoch 137/200\n",
      " - 1s - loss: 0.0150 - acc: 0.9967 - val_loss: 0.0577 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.01436\n",
      "Epoch 138/200\n",
      " - 1s - loss: 0.0171 - acc: 0.9967 - val_loss: 0.0329 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.01436\n",
      "Epoch 139/200\n",
      " - 1s - loss: 0.0204 - acc: 0.9961 - val_loss: 0.0264 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.01436\n",
      "Epoch 140/200\n",
      " - 1s - loss: 0.0131 - acc: 0.9974 - val_loss: 0.0321 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.01436\n",
      "Epoch 141/200\n",
      " - 1s - loss: 0.0104 - acc: 0.9967 - val_loss: 0.0450 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.01436\n",
      "Epoch 142/200\n",
      " - 1s - loss: 0.0187 - acc: 0.9967 - val_loss: 0.0294 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.01436\n",
      "Epoch 143/200\n",
      " - 1s - loss: 0.0072 - acc: 0.9980 - val_loss: 0.0390 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.01436\n",
      "Epoch 144/200\n",
      " - 1s - loss: 0.0125 - acc: 0.9980 - val_loss: 0.0266 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.01436\n",
      "Epoch 145/200\n",
      " - 1s - loss: 0.0179 - acc: 0.9961 - val_loss: 0.0318 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.01436\n",
      "Epoch 146/200\n",
      " - 1s - loss: 0.0136 - acc: 0.9967 - val_loss: 0.0540 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.01436\n",
      "Epoch 147/200\n",
      " - 1s - loss: 0.0150 - acc: 0.9974 - val_loss: 0.0318 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.01436\n",
      "Epoch 148/200\n",
      " - 1s - loss: 0.0186 - acc: 0.9967 - val_loss: 0.0286 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.01436\n",
      "Epoch 149/200\n",
      " - 1s - loss: 0.0099 - acc: 0.9974 - val_loss: 0.0256 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.01436\n",
      "Epoch 150/200\n",
      " - 1s - loss: 0.0152 - acc: 0.9974 - val_loss: 0.0188 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.01436\n",
      "Epoch 151/200\n",
      " - 1s - loss: 0.0107 - acc: 0.9980 - val_loss: 0.0289 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.01436\n",
      "Epoch 152/200\n",
      " - 1s - loss: 0.0164 - acc: 0.9954 - val_loss: 0.0330 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.01436\n",
      "Epoch 153/200\n",
      " - 1s - loss: 0.0172 - acc: 0.9967 - val_loss: 0.0452 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.01436\n",
      "Epoch 154/200\n",
      " - 1s - loss: 0.0052 - acc: 0.9987 - val_loss: 0.0360 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.01436\n",
      "Epoch 155/200\n",
      " - 1s - loss: 0.0119 - acc: 0.9967 - val_loss: 0.0346 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.01436\n",
      "Epoch 156/200\n",
      " - 1s - loss: 0.0166 - acc: 0.9961 - val_loss: 0.0293 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.01436\n",
      "Epoch 157/200\n",
      " - 1s - loss: 0.0178 - acc: 0.9967 - val_loss: 0.0591 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.01436\n",
      "Epoch 158/200\n",
      " - 1s - loss: 0.0155 - acc: 0.9967 - val_loss: 0.0366 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.01436\n",
      "Epoch 159/200\n",
      " - 1s - loss: 0.0105 - acc: 0.9961 - val_loss: 0.0593 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.01436\n",
      "Epoch 160/200\n",
      " - 1s - loss: 0.0085 - acc: 0.9980 - val_loss: 0.0547 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.01436\n",
      "Epoch 161/200\n",
      " - 1s - loss: 0.0089 - acc: 0.9974 - val_loss: 0.0223 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.01436\n",
      "Epoch 162/200\n",
      " - 1s - loss: 0.0225 - acc: 0.9967 - val_loss: 0.0575 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.01436\n",
      "Epoch 163/200\n",
      " - 1s - loss: 0.0116 - acc: 0.9967 - val_loss: 0.0474 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.01436\n",
      "Epoch 164/200\n",
      " - 1s - loss: 0.0150 - acc: 0.9974 - val_loss: 0.0340 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.01436\n",
      "Epoch 165/200\n",
      " - 1s - loss: 0.0293 - acc: 0.9908 - val_loss: 0.0527 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.01436\n",
      "Epoch 166/200\n",
      " - 1s - loss: 0.0088 - acc: 0.9980 - val_loss: 0.0263 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.01436\n",
      "Epoch 167/200\n",
      " - 1s - loss: 0.0155 - acc: 0.9974 - val_loss: 0.0351 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.01436\n",
      "Epoch 168/200\n",
      " - 1s - loss: 0.0153 - acc: 0.9967 - val_loss: 0.0442 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.01436\n",
      "Epoch 169/200\n",
      " - 1s - loss: 0.0128 - acc: 0.9967 - val_loss: 0.0664 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.01436\n",
      "Epoch 170/200\n",
      " - 1s - loss: 0.0149 - acc: 0.9961 - val_loss: 0.0484 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.01436\n",
      "Epoch 171/200\n",
      " - 1s - loss: 0.0197 - acc: 0.9974 - val_loss: 0.0510 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.01436\n",
      "Epoch 172/200\n",
      " - 1s - loss: 0.0194 - acc: 0.9961 - val_loss: 0.0522 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.01436\n",
      "Epoch 173/200\n",
      " - 1s - loss: 0.0132 - acc: 0.9967 - val_loss: 0.0670 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.01436\n",
      "Epoch 174/200\n",
      " - 1s - loss: 0.0202 - acc: 0.9967 - val_loss: 0.0663 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.01436\n",
      "Epoch 175/200\n",
      " - 1s - loss: 0.0196 - acc: 0.9961 - val_loss: 0.0377 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.01436\n",
      "Epoch 176/200\n",
      " - 1s - loss: 0.0140 - acc: 0.9974 - val_loss: 0.0345 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.01436\n",
      "Epoch 177/200\n",
      " - 1s - loss: 0.0160 - acc: 0.9974 - val_loss: 0.0969 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.01436\n",
      "Epoch 178/200\n",
      " - 1s - loss: 0.0134 - acc: 0.9961 - val_loss: 0.0564 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.01436\n",
      "Epoch 179/200\n",
      " - 1s - loss: 0.0125 - acc: 0.9967 - val_loss: 0.0349 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.01436\n",
      "Epoch 180/200\n",
      " - 1s - loss: 0.0194 - acc: 0.9974 - val_loss: 0.0691 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.01436\n",
      "Epoch 181/200\n",
      " - 1s - loss: 0.0080 - acc: 0.9974 - val_loss: 0.0529 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.01436\n",
      "Epoch 182/200\n",
      " - 1s - loss: 0.0117 - acc: 0.9974 - val_loss: 0.0526 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.01436\n",
      "Epoch 183/200\n",
      " - 1s - loss: 0.0104 - acc: 0.9980 - val_loss: 0.0408 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.01436\n",
      "Epoch 184/200\n",
      " - 1s - loss: 0.0144 - acc: 0.9961 - val_loss: 0.0374 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.01436\n",
      "Epoch 185/200\n",
      " - 1s - loss: 0.0225 - acc: 0.9967 - val_loss: 0.0470 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.01436\n",
      "Epoch 186/200\n",
      " - 1s - loss: 0.0101 - acc: 0.9974 - val_loss: 0.0553 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.01436\n",
      "Epoch 187/200\n",
      " - 1s - loss: 0.0150 - acc: 0.9980 - val_loss: 0.0434 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.01436\n",
      "Epoch 188/200\n",
      " - 1s - loss: 0.0253 - acc: 0.9941 - val_loss: 0.0408 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.01436\n",
      "Epoch 189/200\n",
      " - 1s - loss: 0.0286 - acc: 0.9921 - val_loss: 0.0256 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.01436\n",
      "Epoch 190/200\n",
      " - 1s - loss: 0.0246 - acc: 0.9961 - val_loss: 0.0574 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.01436\n",
      "Epoch 191/200\n",
      " - 1s - loss: 0.0151 - acc: 0.9967 - val_loss: 0.0490 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.01436\n",
      "Epoch 192/200\n",
      " - 1s - loss: 0.0228 - acc: 0.9961 - val_loss: 0.0451 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.01436\n",
      "Epoch 193/200\n",
      " - 1s - loss: 0.0123 - acc: 0.9967 - val_loss: 0.0357 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.01436\n",
      "Epoch 194/200\n",
      " - 1s - loss: 0.0073 - acc: 0.9987 - val_loss: 0.0402 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.01436\n",
      "Epoch 195/200\n",
      " - 1s - loss: 0.0191 - acc: 0.9967 - val_loss: 0.0350 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.01436\n",
      "Epoch 196/200\n",
      " - 1s - loss: 0.0208 - acc: 0.9967 - val_loss: 0.0352 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.01436\n",
      "Epoch 197/200\n",
      " - 1s - loss: 0.0101 - acc: 0.9974 - val_loss: 0.0633 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.01436\n",
      "Epoch 198/200\n",
      " - 1s - loss: 0.0101 - acc: 0.9974 - val_loss: 0.0374 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.01436\n",
      "Epoch 199/200\n",
      " - 1s - loss: 0.0041 - acc: 0.9987 - val_loss: 0.0520 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.01436\n",
      "Epoch 200/200\n",
      " - 1s - loss: 0.0229 - acc: 0.9967 - val_loss: 0.0370 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.01436\n",
      "batch_size=10   optimizer=Nadam\n",
      "Test accuracy: 67.9666%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_56 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 2s - loss: 1.6409 - acc: 0.4270 - val_loss: 1.1908 - val_acc: 0.5597\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.19077, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.0061 - acc: 0.6553 - val_loss: 0.8767 - val_acc: 0.6955\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.19077 to 0.87672, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.8084 - acc: 0.7362 - val_loss: 0.6811 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.87672 to 0.68111, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6767 - acc: 0.7717 - val_loss: 0.6005 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.68111 to 0.60048, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.5867 - acc: 0.8171 - val_loss: 0.5289 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.60048 to 0.52892, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.5061 - acc: 0.8507 - val_loss: 0.4970 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.52892 to 0.49697, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.4523 - acc: 0.8697 - val_loss: 0.4132 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.49697 to 0.41315, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.3933 - acc: 0.8928 - val_loss: 0.4145 - val_acc: 0.9012\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.41315\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.3631 - acc: 0.9099 - val_loss: 0.3643 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.41315 to 0.36430, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.3165 - acc: 0.9289 - val_loss: 0.2893 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.36430 to 0.28933, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.2834 - acc: 0.9368 - val_loss: 0.2731 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.28933 to 0.27311, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.2554 - acc: 0.9553 - val_loss: 0.2595 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.27311 to 0.25946, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.2320 - acc: 0.9664 - val_loss: 0.2167 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.25946 to 0.21668, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.2081 - acc: 0.9737 - val_loss: 0.2279 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.21668\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.1914 - acc: 0.9757 - val_loss: 0.1927 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.21668 to 0.19267, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.1762 - acc: 0.9796 - val_loss: 0.1841 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.19267 to 0.18415, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.1602 - acc: 0.9822 - val_loss: 0.1593 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.18415 to 0.15929, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.1479 - acc: 0.9901 - val_loss: 0.1493 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.15929 to 0.14926, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.1338 - acc: 0.9901 - val_loss: 0.1541 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.14926\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.1255 - acc: 0.9934 - val_loss: 0.1389 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.14926 to 0.13891, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.1134 - acc: 0.9928 - val_loss: 0.1171 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.13891 to 0.11713, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.1062 - acc: 0.9954 - val_loss: 0.1154 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.11713 to 0.11535, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.0988 - acc: 0.9967 - val_loss: 0.1125 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.11535 to 0.11250, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.0914 - acc: 0.9967 - val_loss: 0.1020 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.11250 to 0.10199, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.0854 - acc: 0.9954 - val_loss: 0.1059 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.10199\n",
      "Epoch 26/200\n",
      " - 1s - loss: 0.0784 - acc: 0.9980 - val_loss: 0.0979 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.10199 to 0.09788, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.0743 - acc: 0.9974 - val_loss: 0.1057 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.09788\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.0715 - acc: 0.9967 - val_loss: 0.0851 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.09788 to 0.08507, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.0672 - acc: 0.9974 - val_loss: 0.0907 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.08507\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.0636 - acc: 0.9961 - val_loss: 0.0873 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.08507\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.0596 - acc: 0.9974 - val_loss: 0.0810 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.08507 to 0.08101, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.0560 - acc: 0.9974 - val_loss: 0.0711 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.08101 to 0.07111, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.0530 - acc: 0.9980 - val_loss: 0.0744 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.07111\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.0505 - acc: 0.9967 - val_loss: 0.0763 - val_acc: 0.9918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00034: val_loss did not improve from 0.07111\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.0476 - acc: 0.9974 - val_loss: 0.0700 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.07111 to 0.07003, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.0470 - acc: 0.9967 - val_loss: 0.0588 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.07003 to 0.05881, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.0435 - acc: 0.9974 - val_loss: 0.0577 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.05881 to 0.05770, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.0411 - acc: 0.9967 - val_loss: 0.0578 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.05770\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.0403 - acc: 0.9967 - val_loss: 0.0624 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.05770\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.0389 - acc: 0.9967 - val_loss: 0.0625 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.05770\n",
      "Epoch 41/200\n",
      " - 1s - loss: 0.0370 - acc: 0.9967 - val_loss: 0.0657 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.05770\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.0346 - acc: 0.9980 - val_loss: 0.0561 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.05770 to 0.05611, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.0342 - acc: 0.9974 - val_loss: 0.0586 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.05611\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.0315 - acc: 0.9967 - val_loss: 0.0664 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.05611\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.0327 - acc: 0.9974 - val_loss: 0.0535 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.05611 to 0.05347, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 46/200\n",
      " - 1s - loss: 0.0298 - acc: 0.9967 - val_loss: 0.0472 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.05347 to 0.04718, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.0276 - acc: 0.9980 - val_loss: 0.0598 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.04718\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.0297 - acc: 0.9967 - val_loss: 0.0498 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.04718\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.0262 - acc: 0.9974 - val_loss: 0.0634 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.04718\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.0262 - acc: 0.9974 - val_loss: 0.0444 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.04718 to 0.04438, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.0255 - acc: 0.9967 - val_loss: 0.0506 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.04438\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.0251 - acc: 0.9974 - val_loss: 0.0489 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.04438\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.0242 - acc: 0.9974 - val_loss: 0.0441 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.04438 to 0.04414, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.0255 - acc: 0.9961 - val_loss: 0.0456 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.04414\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.0247 - acc: 0.9967 - val_loss: 0.0475 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.04414\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.0230 - acc: 0.9974 - val_loss: 0.0429 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.04414 to 0.04292, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.0226 - acc: 0.9967 - val_loss: 0.0394 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.04292 to 0.03943, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.0229 - acc: 0.9961 - val_loss: 0.0438 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.03943\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.0198 - acc: 0.9980 - val_loss: 0.0437 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.03943\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.0198 - acc: 0.9974 - val_loss: 0.0382 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.03943 to 0.03818, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.0193 - acc: 0.9980 - val_loss: 0.0410 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.03818\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.0191 - acc: 0.9967 - val_loss: 0.0437 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.03818\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.0200 - acc: 0.9974 - val_loss: 0.0394 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.03818\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.0187 - acc: 0.9974 - val_loss: 0.0325 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.03818 to 0.03250, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.0169 - acc: 0.9980 - val_loss: 0.0352 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.03250\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.0189 - acc: 0.9967 - val_loss: 0.0466 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.03250\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.0179 - acc: 0.9974 - val_loss: 0.0381 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.03250\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.0187 - acc: 0.9967 - val_loss: 0.0365 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.03250\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.0156 - acc: 0.9974 - val_loss: 0.0405 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.03250\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.0172 - acc: 0.9967 - val_loss: 0.0382 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.03250\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.0159 - acc: 0.9967 - val_loss: 0.0310 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.03250 to 0.03096, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.0166 - acc: 0.9974 - val_loss: 0.0408 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.03096\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.0180 - acc: 0.9967 - val_loss: 0.0457 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.03096\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.0148 - acc: 0.9974 - val_loss: 0.0444 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.03096\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.0149 - acc: 0.9974 - val_loss: 0.0415 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.03096\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.0162 - acc: 0.9974 - val_loss: 0.0338 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.03096\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.0137 - acc: 0.9974 - val_loss: 0.0422 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.03096\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.0132 - acc: 0.9980 - val_loss: 0.0379 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.03096\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.0177 - acc: 0.9961 - val_loss: 0.0392 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.03096\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0150 - acc: 0.9967 - val_loss: 0.0355 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.03096\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0136 - acc: 0.9967 - val_loss: 0.0365 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.03096\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0117 - acc: 0.9980 - val_loss: 0.0298 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.03096 to 0.02978, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0126 - acc: 0.9974 - val_loss: 0.0358 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.02978\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0152 - acc: 0.9967 - val_loss: 0.0354 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.02978\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0127 - acc: 0.9980 - val_loss: 0.0357 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.02978\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0167 - acc: 0.9961 - val_loss: 0.0294 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.02978 to 0.02936, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0122 - acc: 0.9974 - val_loss: 0.0354 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.02936\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0177 - acc: 0.9967 - val_loss: 0.0435 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.02936\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0117 - acc: 0.9974 - val_loss: 0.0431 - val_acc: 0.9918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00089: val_loss did not improve from 0.02936\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0122 - acc: 0.9980 - val_loss: 0.0428 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.02936\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0140 - acc: 0.9974 - val_loss: 0.0315 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.02936\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0114 - acc: 0.9980 - val_loss: 0.0352 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.02936\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0133 - acc: 0.9967 - val_loss: 0.0303 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.02936\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0117 - acc: 0.9967 - val_loss: 0.0286 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.02936 to 0.02864, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0136 - acc: 0.9967 - val_loss: 0.0339 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.02864\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0107 - acc: 0.9974 - val_loss: 0.0377 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.02864\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0102 - acc: 0.9980 - val_loss: 0.0335 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.02864\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0157 - acc: 0.9967 - val_loss: 0.0311 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.02864\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0136 - acc: 0.9967 - val_loss: 0.0292 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.02864\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0103 - acc: 0.9980 - val_loss: 0.0390 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.02864\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0122 - acc: 0.9967 - val_loss: 0.0382 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.02864\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0101 - acc: 0.9980 - val_loss: 0.0322 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.02864\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0100 - acc: 0.9980 - val_loss: 0.0386 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.02864\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0131 - acc: 0.9967 - val_loss: 0.0426 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.02864\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0125 - acc: 0.9967 - val_loss: 0.0301 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.02864\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0133 - acc: 0.9967 - val_loss: 0.0378 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.02864\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0152 - acc: 0.9961 - val_loss: 0.0354 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.02864\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0088 - acc: 0.9980 - val_loss: 0.0447 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.02864\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0130 - acc: 0.9967 - val_loss: 0.0359 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.02864\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0102 - acc: 0.9974 - val_loss: 0.0231 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.02864 to 0.02314, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0122 - acc: 0.9967 - val_loss: 0.0300 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.02314\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0149 - acc: 0.9961 - val_loss: 0.0302 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.02314\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0115 - acc: 0.9974 - val_loss: 0.0325 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.02314\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0099 - acc: 0.9974 - val_loss: 0.0302 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.02314\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0094 - acc: 0.9974 - val_loss: 0.0295 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.02314\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0110 - acc: 0.9974 - val_loss: 0.0309 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.02314\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0121 - acc: 0.9961 - val_loss: 0.0306 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.02314\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0084 - acc: 0.9980 - val_loss: 0.0366 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.02314\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0116 - acc: 0.9967 - val_loss: 0.0469 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.02314\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0113 - acc: 0.9967 - val_loss: 0.0424 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.02314\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0112 - acc: 0.9967 - val_loss: 0.0582 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.02314\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0092 - acc: 0.9974 - val_loss: 0.0270 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.02314\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0100 - acc: 0.9961 - val_loss: 0.0388 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.02314\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0102 - acc: 0.9980 - val_loss: 0.0303 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.02314\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0119 - acc: 0.9967 - val_loss: 0.0322 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.02314\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0159 - acc: 0.9967 - val_loss: 0.0380 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.02314\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0129 - acc: 0.9961 - val_loss: 0.0394 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.02314\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0121 - acc: 0.9961 - val_loss: 0.0234 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.02314\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0122 - acc: 0.9967 - val_loss: 0.0347 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.02314\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0105 - acc: 0.9980 - val_loss: 0.0325 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.02314\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0133 - acc: 0.9967 - val_loss: 0.0306 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.02314\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0138 - acc: 0.9967 - val_loss: 0.0249 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.02314\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0119 - acc: 0.9961 - val_loss: 0.0366 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.02314\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0106 - acc: 0.9974 - val_loss: 0.0235 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.02314\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0097 - acc: 0.9980 - val_loss: 0.0347 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.02314\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0105 - acc: 0.9974 - val_loss: 0.0313 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.02314\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0137 - acc: 0.9961 - val_loss: 0.0367 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.02314\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0090 - acc: 0.9974 - val_loss: 0.0341 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.02314\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0106 - acc: 0.9974 - val_loss: 0.0280 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.02314\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0137 - acc: 0.9967 - val_loss: 0.0352 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.02314\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0135 - acc: 0.9967 - val_loss: 0.0278 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.02314\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0112 - acc: 0.9961 - val_loss: 0.0385 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.02314\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0126 - acc: 0.9967 - val_loss: 0.0395 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.02314\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0112 - acc: 0.9974 - val_loss: 0.0325 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.02314\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0106 - acc: 0.9974 - val_loss: 0.0338 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.02314\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0113 - acc: 0.9974 - val_loss: 0.0399 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.02314\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0102 - acc: 0.9974 - val_loss: 0.0313 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.02314\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0113 - acc: 0.9974 - val_loss: 0.0289 - val_acc: 0.9877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00148: val_loss did not improve from 0.02314\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0123 - acc: 0.9967 - val_loss: 0.0297 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.02314\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0109 - acc: 0.9974 - val_loss: 0.0277 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.02314\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0086 - acc: 0.9974 - val_loss: 0.0415 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.02314\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0124 - acc: 0.9961 - val_loss: 0.0322 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.02314\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0102 - acc: 0.9974 - val_loss: 0.0571 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.02314\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0130 - acc: 0.9974 - val_loss: 0.0262 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.02314\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.0089 - acc: 0.9980 - val_loss: 0.0380 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.02314\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.0140 - acc: 0.9967 - val_loss: 0.0338 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.02314\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0077 - acc: 0.9980 - val_loss: 0.0549 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.02314\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.0116 - acc: 0.9967 - val_loss: 0.0333 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.02314\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.0091 - acc: 0.9967 - val_loss: 0.0483 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.02314\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.0131 - acc: 0.9967 - val_loss: 0.0340 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.02314\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.0099 - acc: 0.9974 - val_loss: 0.0351 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.02314\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.0089 - acc: 0.9974 - val_loss: 0.0357 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.02314\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.0102 - acc: 0.9974 - val_loss: 0.0313 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.02314\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.0087 - acc: 0.9980 - val_loss: 0.0354 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.02314\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.0103 - acc: 0.9974 - val_loss: 0.0274 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.02314\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.0127 - acc: 0.9967 - val_loss: 0.0330 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.02314\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.0123 - acc: 0.9967 - val_loss: 0.0375 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.02314\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.0132 - acc: 0.9967 - val_loss: 0.0309 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.02314\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.0082 - acc: 0.9974 - val_loss: 0.0403 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.02314\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.0109 - acc: 0.9974 - val_loss: 0.0305 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.02314\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.0093 - acc: 0.9967 - val_loss: 0.0365 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.02314\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.0101 - acc: 0.9974 - val_loss: 0.0374 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.02314\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.0155 - acc: 0.9967 - val_loss: 0.0338 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.02314\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.0134 - acc: 0.9967 - val_loss: 0.0361 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.02314\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.0139 - acc: 0.9967 - val_loss: 0.0399 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.02314\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.0057 - acc: 0.9987 - val_loss: 0.0452 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.02314\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.0161 - acc: 0.9967 - val_loss: 0.0476 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.02314\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.0153 - acc: 0.9961 - val_loss: 0.0393 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.02314\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.0103 - acc: 0.9980 - val_loss: 0.0484 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.02314\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.0093 - acc: 0.9980 - val_loss: 0.0379 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.02314\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.0170 - acc: 0.9961 - val_loss: 0.0375 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.02314\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.0155 - acc: 0.9967 - val_loss: 0.0371 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.02314\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.0096 - acc: 0.9974 - val_loss: 0.0408 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.02314\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.0153 - acc: 0.9967 - val_loss: 0.0427 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.02314\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.0126 - acc: 0.9967 - val_loss: 0.0310 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.02314\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.0131 - acc: 0.9974 - val_loss: 0.0285 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.02314\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.0104 - acc: 0.9967 - val_loss: 0.0345 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.02314\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.0116 - acc: 0.9974 - val_loss: 0.0320 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.02314\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.0089 - acc: 0.9974 - val_loss: 0.0380 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.02314\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.0108 - acc: 0.9974 - val_loss: 0.0487 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.02314\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.0126 - acc: 0.9974 - val_loss: 0.0312 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.02314\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.0087 - acc: 0.9980 - val_loss: 0.0684 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.02314\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.0148 - acc: 0.9961 - val_loss: 0.0363 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.02314\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.0106 - acc: 0.9974 - val_loss: 0.0316 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.02314\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.0101 - acc: 0.9980 - val_loss: 0.0320 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.02314\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.0138 - acc: 0.9967 - val_loss: 0.0331 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.02314\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.0173 - acc: 0.9961 - val_loss: 0.0353 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.02314\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.0141 - acc: 0.9967 - val_loss: 0.0537 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.02314\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.0138 - acc: 0.9961 - val_loss: 0.0349 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.02314\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.0115 - acc: 0.9967 - val_loss: 0.0298 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.02314\n",
      "batch_size=20   optimizer=Nadam\n",
      "Test accuracy: 66.8524%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_57 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 1.7224 - acc: 0.4072 - val_loss: 1.2511 - val_acc: 0.5885\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.25108, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.1169 - acc: 0.6329 - val_loss: 1.0007 - val_acc: 0.6872\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.25108 to 1.00068, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.9096 - acc: 0.7039 - val_loss: 0.8073 - val_acc: 0.7325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: val_loss improved from 1.00068 to 0.80734, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.7903 - acc: 0.7447 - val_loss: 0.7558 - val_acc: 0.7572\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.80734 to 0.75576, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.7014 - acc: 0.7757 - val_loss: 0.6525 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.75576 to 0.65252, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.6278 - acc: 0.8092 - val_loss: 0.5874 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.65252 to 0.58738, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.5630 - acc: 0.8289 - val_loss: 0.5255 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.58738 to 0.52553, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.5091 - acc: 0.8507 - val_loss: 0.5021 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.52553 to 0.50212, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.4623 - acc: 0.8743 - val_loss: 0.4387 - val_acc: 0.9012\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.50212 to 0.43873, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.4223 - acc: 0.8928 - val_loss: 0.4010 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.43873 to 0.40104, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.3903 - acc: 0.9072 - val_loss: 0.3600 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.40104 to 0.36005, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.3620 - acc: 0.9204 - val_loss: 0.3449 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.36005 to 0.34489, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.3284 - acc: 0.9342 - val_loss: 0.3236 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.34489 to 0.32356, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.3082 - acc: 0.9428 - val_loss: 0.3054 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.32356 to 0.30536, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.2887 - acc: 0.9467 - val_loss: 0.2733 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.30536 to 0.27329, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.2682 - acc: 0.9539 - val_loss: 0.2703 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.27329 to 0.27035, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.2512 - acc: 0.9605 - val_loss: 0.2484 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.27035 to 0.24841, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.2274 - acc: 0.9691 - val_loss: 0.2355 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.24841 to 0.23548, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.2198 - acc: 0.9730 - val_loss: 0.2143 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.23548 to 0.21435, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.2026 - acc: 0.9763 - val_loss: 0.2325 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.21435\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.1909 - acc: 0.9803 - val_loss: 0.1980 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.21435 to 0.19804, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.1771 - acc: 0.9862 - val_loss: 0.1729 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.19804 to 0.17289, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.1680 - acc: 0.9868 - val_loss: 0.1859 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.17289\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.1592 - acc: 0.9895 - val_loss: 0.1618 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.17289 to 0.16185, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.1487 - acc: 0.9928 - val_loss: 0.1646 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.16185\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.1416 - acc: 0.9914 - val_loss: 0.1492 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.16185 to 0.14919, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.1332 - acc: 0.9947 - val_loss: 0.1456 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.14919 to 0.14562, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.1235 - acc: 0.9961 - val_loss: 0.1443 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.14562 to 0.14432, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.1199 - acc: 0.9967 - val_loss: 0.1423 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.14432 to 0.14233, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.1130 - acc: 0.9941 - val_loss: 0.1244 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.14233 to 0.12439, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.1083 - acc: 0.9967 - val_loss: 0.1212 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.12439 to 0.12124, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.1027 - acc: 0.9947 - val_loss: 0.1209 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.12124 to 0.12093, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.0984 - acc: 0.9967 - val_loss: 0.1091 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.12093 to 0.10907, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.0945 - acc: 0.9961 - val_loss: 0.1101 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.10907\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.0889 - acc: 0.9967 - val_loss: 0.1031 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.10907 to 0.10311, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.0857 - acc: 0.9961 - val_loss: 0.0965 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.10311 to 0.09645, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.0825 - acc: 0.9967 - val_loss: 0.0966 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.09645\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.0781 - acc: 0.9967 - val_loss: 0.0882 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.09645 to 0.08822, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.0755 - acc: 0.9967 - val_loss: 0.0897 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.08822\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.0717 - acc: 0.9974 - val_loss: 0.0856 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.08822 to 0.08561, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.0685 - acc: 0.9961 - val_loss: 0.0892 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.08561\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.0660 - acc: 0.9980 - val_loss: 0.0972 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.08561\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.0643 - acc: 0.9967 - val_loss: 0.0816 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.08561 to 0.08157, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.0608 - acc: 0.9980 - val_loss: 0.0775 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.08157 to 0.07751, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.0594 - acc: 0.9974 - val_loss: 0.0744 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.07751 to 0.07442, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.0574 - acc: 0.9967 - val_loss: 0.0754 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.07442\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.0549 - acc: 0.9974 - val_loss: 0.0760 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.07442\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.0528 - acc: 0.9980 - val_loss: 0.0795 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.07442\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.0510 - acc: 0.9974 - val_loss: 0.0694 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.07442 to 0.06936, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.0497 - acc: 0.9980 - val_loss: 0.0675 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.06936 to 0.06748, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.0478 - acc: 0.9967 - val_loss: 0.0709 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.06748\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.0468 - acc: 0.9967 - val_loss: 0.0636 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.06748 to 0.06361, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.0445 - acc: 0.9980 - val_loss: 0.0634 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.06361 to 0.06339, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.0445 - acc: 0.9967 - val_loss: 0.0635 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.06339\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.0423 - acc: 0.9974 - val_loss: 0.0643 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.06339\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.0415 - acc: 0.9974 - val_loss: 0.0583 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.06339 to 0.05832, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.0399 - acc: 0.9967 - val_loss: 0.0603 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.05832\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.0390 - acc: 0.9980 - val_loss: 0.0554 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.05832 to 0.05540, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.0377 - acc: 0.9974 - val_loss: 0.0647 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.05540\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.0370 - acc: 0.9987 - val_loss: 0.0566 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.05540\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.0357 - acc: 0.9974 - val_loss: 0.0599 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.05540\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.0349 - acc: 0.9974 - val_loss: 0.0537 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.05540 to 0.05372, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.0332 - acc: 0.9980 - val_loss: 0.0553 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.05372\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.0333 - acc: 0.9974 - val_loss: 0.0540 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.05372\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.0324 - acc: 0.9967 - val_loss: 0.0540 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.05372\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.0309 - acc: 0.9967 - val_loss: 0.0533 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.05372 to 0.05334, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.0311 - acc: 0.9980 - val_loss: 0.0465 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.05334 to 0.04648, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.0298 - acc: 0.9967 - val_loss: 0.0487 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.04648\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.0295 - acc: 0.9967 - val_loss: 0.0487 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.04648\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.0282 - acc: 0.9974 - val_loss: 0.0525 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.04648\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.0280 - acc: 0.9967 - val_loss: 0.0469 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.04648\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.0272 - acc: 0.9967 - val_loss: 0.0467 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.04648\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.0271 - acc: 0.9974 - val_loss: 0.0480 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.04648\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.0268 - acc: 0.9967 - val_loss: 0.0422 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.04648 to 0.04223, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.0257 - acc: 0.9980 - val_loss: 0.0452 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.04223\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.0250 - acc: 0.9967 - val_loss: 0.0477 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.04223\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.0247 - acc: 0.9980 - val_loss: 0.0468 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.04223\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.0239 - acc: 0.9980 - val_loss: 0.0430 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.04223\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.0238 - acc: 0.9974 - val_loss: 0.0434 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.04223\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0234 - acc: 0.9974 - val_loss: 0.0414 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.04223 to 0.04141, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0223 - acc: 0.9974 - val_loss: 0.0399 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.04141 to 0.03989, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0224 - acc: 0.9974 - val_loss: 0.0393 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.03989 to 0.03934, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0217 - acc: 0.9967 - val_loss: 0.0407 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.03934\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0217 - acc: 0.9967 - val_loss: 0.0416 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.03934\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0203 - acc: 0.9974 - val_loss: 0.0382 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.03934 to 0.03818, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0206 - acc: 0.9974 - val_loss: 0.0441 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.03818\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0204 - acc: 0.9974 - val_loss: 0.0411 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.03818\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0207 - acc: 0.9974 - val_loss: 0.0356 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.03818 to 0.03558, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0193 - acc: 0.9967 - val_loss: 0.0375 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.03558\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0189 - acc: 0.9967 - val_loss: 0.0388 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.03558\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0188 - acc: 0.9967 - val_loss: 0.0390 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.03558\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0195 - acc: 0.9974 - val_loss: 0.0394 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.03558\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0181 - acc: 0.9974 - val_loss: 0.0482 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.03558\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0194 - acc: 0.9974 - val_loss: 0.0373 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.03558\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0189 - acc: 0.9967 - val_loss: 0.0383 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.03558\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0169 - acc: 0.9974 - val_loss: 0.0373 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.03558\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0173 - acc: 0.9980 - val_loss: 0.0407 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.03558\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0185 - acc: 0.9967 - val_loss: 0.0372 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.03558\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0169 - acc: 0.9967 - val_loss: 0.0375 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.03558\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0166 - acc: 0.9974 - val_loss: 0.0365 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.03558\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0168 - acc: 0.9967 - val_loss: 0.0350 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.03558 to 0.03496, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0171 - acc: 0.9974 - val_loss: 0.0333 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.03496 to 0.03326, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0151 - acc: 0.9980 - val_loss: 0.0388 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.03326\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0161 - acc: 0.9967 - val_loss: 0.0354 - val_acc: 0.9918\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00104: val_loss did not improve from 0.03326\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0166 - acc: 0.9967 - val_loss: 0.0381 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.03326\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0164 - acc: 0.9974 - val_loss: 0.0332 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.03326 to 0.03317, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0152 - acc: 0.9974 - val_loss: 0.0355 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.03317\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0150 - acc: 0.9967 - val_loss: 0.0354 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.03317\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0162 - acc: 0.9974 - val_loss: 0.0313 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.03317 to 0.03130, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0145 - acc: 0.9974 - val_loss: 0.0316 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.03130\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0149 - acc: 0.9974 - val_loss: 0.0352 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.03130\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0140 - acc: 0.9974 - val_loss: 0.0329 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.03130\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0139 - acc: 0.9974 - val_loss: 0.0340 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.03130\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0142 - acc: 0.9967 - val_loss: 0.0363 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.03130\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0143 - acc: 0.9961 - val_loss: 0.0321 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.03130\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0138 - acc: 0.9967 - val_loss: 0.0323 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.03130\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0162 - acc: 0.9961 - val_loss: 0.0313 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.03130\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0133 - acc: 0.9967 - val_loss: 0.0285 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.03130 to 0.02853, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0135 - acc: 0.9967 - val_loss: 0.0343 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.02853\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0134 - acc: 0.9974 - val_loss: 0.0311 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.02853\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0138 - acc: 0.9974 - val_loss: 0.0316 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.02853\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0132 - acc: 0.9967 - val_loss: 0.0305 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.02853\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0130 - acc: 0.9974 - val_loss: 0.0319 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.02853\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0122 - acc: 0.9974 - val_loss: 0.0306 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.02853\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0144 - acc: 0.9967 - val_loss: 0.0305 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.02853\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0147 - acc: 0.9967 - val_loss: 0.0310 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.02853\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0127 - acc: 0.9961 - val_loss: 0.0342 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.02853\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0125 - acc: 0.9961 - val_loss: 0.0385 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.02853\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0124 - acc: 0.9974 - val_loss: 0.0348 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.02853\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0120 - acc: 0.9974 - val_loss: 0.0320 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.02853\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0104 - acc: 0.9974 - val_loss: 0.0345 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.02853\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0140 - acc: 0.9961 - val_loss: 0.0362 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.02853\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0127 - acc: 0.9967 - val_loss: 0.0358 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.02853\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0109 - acc: 0.9974 - val_loss: 0.0340 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.02853\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0130 - acc: 0.9961 - val_loss: 0.0318 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.02853\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0111 - acc: 0.9974 - val_loss: 0.0312 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.02853\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0129 - acc: 0.9967 - val_loss: 0.0312 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.02853\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0115 - acc: 0.9967 - val_loss: 0.0293 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.02853\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0121 - acc: 0.9967 - val_loss: 0.0281 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.02853 to 0.02808, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0103 - acc: 0.9980 - val_loss: 0.0331 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.02808\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0123 - acc: 0.9961 - val_loss: 0.0302 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.02808\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0102 - acc: 0.9967 - val_loss: 0.0390 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.02808\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0105 - acc: 0.9974 - val_loss: 0.0323 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.02808\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0112 - acc: 0.9974 - val_loss: 0.0350 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.02808\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0098 - acc: 0.9980 - val_loss: 0.0356 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.02808\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0109 - acc: 0.9967 - val_loss: 0.0302 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.02808\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0111 - acc: 0.9967 - val_loss: 0.0271 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.02808 to 0.02710, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0104 - acc: 0.9967 - val_loss: 0.0310 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.02710\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0117 - acc: 0.9967 - val_loss: 0.0356 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.02710\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0106 - acc: 0.9974 - val_loss: 0.0295 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.02710\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0084 - acc: 0.9980 - val_loss: 0.0354 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.02710\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0095 - acc: 0.9974 - val_loss: 0.0343 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.02710\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0109 - acc: 0.9961 - val_loss: 0.0449 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.02710\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0100 - acc: 0.9974 - val_loss: 0.0346 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.02710\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.0096 - acc: 0.9974 - val_loss: 0.0291 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.02710\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.0106 - acc: 0.9974 - val_loss: 0.0291 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.02710\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0121 - acc: 0.9961 - val_loss: 0.0265 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.02710 to 0.02650, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.0100 - acc: 0.9967 - val_loss: 0.0307 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.02650\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.0101 - acc: 0.9967 - val_loss: 0.0322 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.02650\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.0103 - acc: 0.9967 - val_loss: 0.0312 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.02650\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.0097 - acc: 0.9974 - val_loss: 0.0309 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.02650\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.0095 - acc: 0.9974 - val_loss: 0.0268 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.02650\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.0099 - acc: 0.9980 - val_loss: 0.0270 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.02650\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.0090 - acc: 0.9974 - val_loss: 0.0334 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.02650\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.0103 - acc: 0.9967 - val_loss: 0.0304 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.02650\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.0079 - acc: 0.9980 - val_loss: 0.0407 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.02650\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.0099 - acc: 0.9967 - val_loss: 0.0271 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.02650\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.0112 - acc: 0.9967 - val_loss: 0.0265 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.02650\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.0099 - acc: 0.9974 - val_loss: 0.0301 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.02650\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.0096 - acc: 0.9961 - val_loss: 0.0372 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.02650\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.0082 - acc: 0.9980 - val_loss: 0.0294 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.02650\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.0110 - acc: 0.9961 - val_loss: 0.0309 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.02650\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.0114 - acc: 0.9967 - val_loss: 0.0279 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.02650\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.0106 - acc: 0.9967 - val_loss: 0.0242 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.02650 to 0.02424, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.0093 - acc: 0.9980 - val_loss: 0.0298 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.02424\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.0102 - acc: 0.9967 - val_loss: 0.0257 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.02424\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.0086 - acc: 0.9974 - val_loss: 0.0341 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.02424\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.0121 - acc: 0.9961 - val_loss: 0.0264 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.02424\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.0086 - acc: 0.9980 - val_loss: 0.0284 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.02424\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.0085 - acc: 0.9980 - val_loss: 0.0300 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.02424\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.0078 - acc: 0.9974 - val_loss: 0.0309 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.02424\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.0116 - acc: 0.9961 - val_loss: 0.0305 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.02424\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.0089 - acc: 0.9974 - val_loss: 0.0266 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.02424\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.0094 - acc: 0.9967 - val_loss: 0.0307 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.02424\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.0105 - acc: 0.9974 - val_loss: 0.0388 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.02424\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.0092 - acc: 0.9974 - val_loss: 0.0270 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.02424\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.0094 - acc: 0.9967 - val_loss: 0.0303 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.02424\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.0098 - acc: 0.9974 - val_loss: 0.0398 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.02424\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.0100 - acc: 0.9974 - val_loss: 0.0244 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.02424\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.0093 - acc: 0.9967 - val_loss: 0.0372 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.02424\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.0094 - acc: 0.9974 - val_loss: 0.0258 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.02424\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.0104 - acc: 0.9967 - val_loss: 0.0255 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.02424\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.0104 - acc: 0.9967 - val_loss: 0.0245 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.02424\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.0110 - acc: 0.9967 - val_loss: 0.0312 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.02424\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.0084 - acc: 0.9974 - val_loss: 0.0273 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.02424\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.0090 - acc: 0.9967 - val_loss: 0.0272 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.02424\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.0108 - acc: 0.9967 - val_loss: 0.0262 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.02424\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.0089 - acc: 0.9967 - val_loss: 0.0267 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.02424\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.0075 - acc: 0.9980 - val_loss: 0.0286 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.02424\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.0116 - acc: 0.9961 - val_loss: 0.0277 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.02424\n",
      "batch_size=40   optimizer=Nadam\n",
      "Test accuracy: 66.2953%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_58 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 2.0178 - acc: 0.2862 - val_loss: 1.5599 - val_acc: 0.4938\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.55989, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.3579 - acc: 0.5474 - val_loss: 1.1950 - val_acc: 0.5967\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.55989 to 1.19498, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 1.1049 - acc: 0.6237 - val_loss: 1.0434 - val_acc: 0.6337\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.19498 to 1.04343, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.9780 - acc: 0.6803 - val_loss: 0.9067 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.04343 to 0.90666, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.8721 - acc: 0.7211 - val_loss: 0.8218 - val_acc: 0.7613\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.90666 to 0.82176, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.7878 - acc: 0.7487 - val_loss: 0.7744 - val_acc: 0.7490\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.82176 to 0.77439, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.7334 - acc: 0.7717 - val_loss: 0.6839 - val_acc: 0.8148\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.77439 to 0.68388, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.6772 - acc: 0.7895 - val_loss: 0.6350 - val_acc: 0.8354\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.68388 to 0.63505, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.6245 - acc: 0.8125 - val_loss: 0.5968 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.63505 to 0.59684, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.5781 - acc: 0.8283 - val_loss: 0.5691 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.59684 to 0.56911, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.5415 - acc: 0.8362 - val_loss: 0.5321 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.56911 to 0.53213, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.5103 - acc: 0.8507 - val_loss: 0.4997 - val_acc: 0.8765\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00012: val_loss improved from 0.53213 to 0.49971, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.4784 - acc: 0.8711 - val_loss: 0.4785 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.49971 to 0.47851, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.4532 - acc: 0.8757 - val_loss: 0.4431 - val_acc: 0.9012\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.47851 to 0.44311, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.4291 - acc: 0.8868 - val_loss: 0.4233 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.44311 to 0.42325, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.4047 - acc: 0.9039 - val_loss: 0.3928 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.42325 to 0.39279, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.3869 - acc: 0.9112 - val_loss: 0.3883 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.39279 to 0.38834, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.3662 - acc: 0.9178 - val_loss: 0.3810 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.38834 to 0.38095, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.3405 - acc: 0.9336 - val_loss: 0.3682 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.38095 to 0.36821, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.3288 - acc: 0.9329 - val_loss: 0.3321 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.36821 to 0.33213, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.3075 - acc: 0.9434 - val_loss: 0.3150 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.33213 to 0.31503, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.2967 - acc: 0.9526 - val_loss: 0.3083 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.31503 to 0.30826, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.2869 - acc: 0.9553 - val_loss: 0.2789 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.30826 to 0.27891, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.2733 - acc: 0.9566 - val_loss: 0.2701 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.27891 to 0.27015, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.2605 - acc: 0.9638 - val_loss: 0.2616 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.27015 to 0.26164, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.2437 - acc: 0.9724 - val_loss: 0.2600 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.26164 to 0.26004, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2352 - acc: 0.9717 - val_loss: 0.2407 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.26004 to 0.24075, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2285 - acc: 0.9724 - val_loss: 0.2327 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.24075 to 0.23270, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2166 - acc: 0.9803 - val_loss: 0.2223 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.23270 to 0.22228, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2045 - acc: 0.9789 - val_loss: 0.2095 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.22228 to 0.20950, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.1966 - acc: 0.9836 - val_loss: 0.2104 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.20950\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.1884 - acc: 0.9836 - val_loss: 0.2098 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.20950\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.1810 - acc: 0.9822 - val_loss: 0.1922 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.20950 to 0.19223, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.1774 - acc: 0.9868 - val_loss: 0.1869 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.19223 to 0.18686, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.1678 - acc: 0.9901 - val_loss: 0.1818 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.18686 to 0.18184, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.1600 - acc: 0.9895 - val_loss: 0.1885 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.18184\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.1573 - acc: 0.9895 - val_loss: 0.1720 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.18184 to 0.17202, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.1514 - acc: 0.9888 - val_loss: 0.1688 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.17202 to 0.16879, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.1432 - acc: 0.9914 - val_loss: 0.1614 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.16879 to 0.16138, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.1404 - acc: 0.9921 - val_loss: 0.1513 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.16138 to 0.15130, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.1338 - acc: 0.9921 - val_loss: 0.1571 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.15130\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.1293 - acc: 0.9961 - val_loss: 0.1460 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.15130 to 0.14603, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1252 - acc: 0.9947 - val_loss: 0.1401 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.14603 to 0.14011, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1210 - acc: 0.9941 - val_loss: 0.1467 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.14011\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1170 - acc: 0.9947 - val_loss: 0.1321 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.14011 to 0.13211, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1135 - acc: 0.9954 - val_loss: 0.1274 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.13211 to 0.12743, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1094 - acc: 0.9967 - val_loss: 0.1252 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.12743 to 0.12516, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1056 - acc: 0.9961 - val_loss: 0.1296 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.12516\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1028 - acc: 0.9967 - val_loss: 0.1255 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.12516\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1001 - acc: 0.9954 - val_loss: 0.1182 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.12516 to 0.11815, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.0963 - acc: 0.9961 - val_loss: 0.1127 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.11815 to 0.11270, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.0941 - acc: 0.9974 - val_loss: 0.1116 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.11270 to 0.11162, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.0916 - acc: 0.9974 - val_loss: 0.1051 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.11162 to 0.10506, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.0884 - acc: 0.9974 - val_loss: 0.1037 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.10506 to 0.10374, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.0861 - acc: 0.9974 - val_loss: 0.1028 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.10374 to 0.10285, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.0831 - acc: 0.9974 - val_loss: 0.1011 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.10285 to 0.10109, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.0812 - acc: 0.9967 - val_loss: 0.0984 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.10109 to 0.09844, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.0798 - acc: 0.9974 - val_loss: 0.0976 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.09844 to 0.09756, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.0771 - acc: 0.9974 - val_loss: 0.1014 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.09756\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.0750 - acc: 0.9967 - val_loss: 0.0960 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.09756 to 0.09597, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.0729 - acc: 0.9974 - val_loss: 0.0899 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.09597 to 0.08989, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.0710 - acc: 0.9967 - val_loss: 0.0882 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.08989 to 0.08822, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.0694 - acc: 0.9961 - val_loss: 0.0895 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.08822\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.0678 - acc: 0.9980 - val_loss: 0.0830 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.08822 to 0.08304, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.0658 - acc: 0.9974 - val_loss: 0.0844 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.08304\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.0648 - acc: 0.9967 - val_loss: 0.0853 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.08304\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.0629 - acc: 0.9967 - val_loss: 0.0825 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.08304 to 0.08253, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.0614 - acc: 0.9974 - val_loss: 0.0857 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.08253\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.0611 - acc: 0.9967 - val_loss: 0.0751 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.08253 to 0.07505, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.0589 - acc: 0.9974 - val_loss: 0.0764 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.07505\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.0569 - acc: 0.9974 - val_loss: 0.0791 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.07505\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.0563 - acc: 0.9974 - val_loss: 0.0760 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.07505\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.0546 - acc: 0.9974 - val_loss: 0.0724 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.07505 to 0.07241, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.0542 - acc: 0.9967 - val_loss: 0.0739 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.07241\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.0525 - acc: 0.9967 - val_loss: 0.0684 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.07241 to 0.06837, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.0512 - acc: 0.9974 - val_loss: 0.0691 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.06837\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.0502 - acc: 0.9967 - val_loss: 0.0703 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.06837\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.0490 - acc: 0.9974 - val_loss: 0.0687 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.06837\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.0488 - acc: 0.9961 - val_loss: 0.0674 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.06837 to 0.06743, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0473 - acc: 0.9961 - val_loss: 0.0673 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.06743 to 0.06727, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0464 - acc: 0.9974 - val_loss: 0.0650 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.06727 to 0.06502, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0453 - acc: 0.9961 - val_loss: 0.0629 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.06502 to 0.06288, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0445 - acc: 0.9980 - val_loss: 0.0650 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.06288\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0434 - acc: 0.9967 - val_loss: 0.0620 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.06288 to 0.06204, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0428 - acc: 0.9967 - val_loss: 0.0628 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.06204\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0421 - acc: 0.9980 - val_loss: 0.0607 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.06204 to 0.06073, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0412 - acc: 0.9961 - val_loss: 0.0588 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.06073 to 0.05878, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0406 - acc: 0.9967 - val_loss: 0.0618 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.05878\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0396 - acc: 0.9967 - val_loss: 0.0602 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.05878\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0391 - acc: 0.9967 - val_loss: 0.0582 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.05878 to 0.05817, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0380 - acc: 0.9974 - val_loss: 0.0610 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.05817\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0380 - acc: 0.9961 - val_loss: 0.0563 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.05817 to 0.05631, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0369 - acc: 0.9961 - val_loss: 0.0588 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.05631\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0362 - acc: 0.9961 - val_loss: 0.0566 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.05631\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0357 - acc: 0.9967 - val_loss: 0.0550 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.05631 to 0.05502, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0352 - acc: 0.9967 - val_loss: 0.0557 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.05502\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0347 - acc: 0.9974 - val_loss: 0.0537 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.05502 to 0.05369, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0343 - acc: 0.9967 - val_loss: 0.0545 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.05369\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0334 - acc: 0.9974 - val_loss: 0.0583 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.05369\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0336 - acc: 0.9967 - val_loss: 0.0519 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.05369 to 0.05191, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0324 - acc: 0.9974 - val_loss: 0.0537 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.05191\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0315 - acc: 0.9974 - val_loss: 0.0516 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.05191 to 0.05163, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0314 - acc: 0.9961 - val_loss: 0.0526 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.05163\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0312 - acc: 0.9967 - val_loss: 0.0521 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.05163\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0304 - acc: 0.9974 - val_loss: 0.0524 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.05163\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0303 - acc: 0.9974 - val_loss: 0.0529 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.05163\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0293 - acc: 0.9980 - val_loss: 0.0480 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.05163 to 0.04804, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0292 - acc: 0.9974 - val_loss: 0.0463 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.04804 to 0.04625, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0289 - acc: 0.9974 - val_loss: 0.0482 - val_acc: 0.9959\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00109: val_loss did not improve from 0.04625\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0278 - acc: 0.9974 - val_loss: 0.0492 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.04625\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0275 - acc: 0.9980 - val_loss: 0.0486 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.04625\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0279 - acc: 0.9961 - val_loss: 0.0494 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.04625\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0271 - acc: 0.9974 - val_loss: 0.0461 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.04625 to 0.04606, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0262 - acc: 0.9980 - val_loss: 0.0471 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.04606\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0262 - acc: 0.9974 - val_loss: 0.0455 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.04606 to 0.04547, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0259 - acc: 0.9967 - val_loss: 0.0455 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.04547\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0255 - acc: 0.9967 - val_loss: 0.0457 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.04547\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0253 - acc: 0.9967 - val_loss: 0.0457 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.04547\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0250 - acc: 0.9967 - val_loss: 0.0452 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.04547 to 0.04515, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0246 - acc: 0.9974 - val_loss: 0.0442 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.04515 to 0.04421, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0242 - acc: 0.9974 - val_loss: 0.0460 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.04421\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0234 - acc: 0.9967 - val_loss: 0.0438 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.04421 to 0.04382, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0235 - acc: 0.9980 - val_loss: 0.0430 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.04382 to 0.04302, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0229 - acc: 0.9974 - val_loss: 0.0442 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.04302\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0229 - acc: 0.9980 - val_loss: 0.0438 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.04302\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0225 - acc: 0.9974 - val_loss: 0.0414 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.04302 to 0.04135, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0226 - acc: 0.9967 - val_loss: 0.0403 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.04135 to 0.04031, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0217 - acc: 0.9980 - val_loss: 0.0415 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.04031\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0218 - acc: 0.9967 - val_loss: 0.0421 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.04031\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0221 - acc: 0.9967 - val_loss: 0.0416 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.04031\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0214 - acc: 0.9974 - val_loss: 0.0429 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.04031\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0210 - acc: 0.9974 - val_loss: 0.0412 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.04031\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0208 - acc: 0.9961 - val_loss: 0.0409 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.04031\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0200 - acc: 0.9980 - val_loss: 0.0412 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.04031\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0207 - acc: 0.9967 - val_loss: 0.0424 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.04031\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0205 - acc: 0.9967 - val_loss: 0.0386 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.04031 to 0.03861, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0199 - acc: 0.9974 - val_loss: 0.0405 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.03861\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0192 - acc: 0.9980 - val_loss: 0.0421 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.03861\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0196 - acc: 0.9967 - val_loss: 0.0376 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.03861 to 0.03755, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0196 - acc: 0.9961 - val_loss: 0.0382 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.03755\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0187 - acc: 0.9980 - val_loss: 0.0399 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.03755\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0192 - acc: 0.9961 - val_loss: 0.0395 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.03755\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0188 - acc: 0.9967 - val_loss: 0.0389 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.03755\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0185 - acc: 0.9967 - val_loss: 0.0396 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.03755\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0183 - acc: 0.9974 - val_loss: 0.0405 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.03755\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0183 - acc: 0.9967 - val_loss: 0.0383 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.03755\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0178 - acc: 0.9974 - val_loss: 0.0389 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.03755\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0177 - acc: 0.9967 - val_loss: 0.0383 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.03755\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0171 - acc: 0.9974 - val_loss: 0.0373 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.03755 to 0.03735, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0172 - acc: 0.9980 - val_loss: 0.0370 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.03735 to 0.03698, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0177 - acc: 0.9967 - val_loss: 0.0364 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.03698 to 0.03635, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0167 - acc: 0.9980 - val_loss: 0.0377 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.03635\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0170 - acc: 0.9980 - val_loss: 0.0402 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.03635\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0167 - acc: 0.9961 - val_loss: 0.0355 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.03635 to 0.03554, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.0168 - acc: 0.9967 - val_loss: 0.0362 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.03554\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.0164 - acc: 0.9974 - val_loss: 0.0363 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.03554\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0160 - acc: 0.9974 - val_loss: 0.0388 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.03554\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.0160 - acc: 0.9974 - val_loss: 0.0348 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.03554 to 0.03480, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.0159 - acc: 0.9974 - val_loss: 0.0351 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.03480\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.0160 - acc: 0.9974 - val_loss: 0.0379 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.03480\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.0157 - acc: 0.9967 - val_loss: 0.0396 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.03480\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.0156 - acc: 0.9967 - val_loss: 0.0353 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.03480\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.0158 - acc: 0.9974 - val_loss: 0.0340 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00163: val_loss improved from 0.03480 to 0.03404, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.0157 - acc: 0.9967 - val_loss: 0.0343 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.03404\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.0152 - acc: 0.9974 - val_loss: 0.0330 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.03404 to 0.03297, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.0152 - acc: 0.9974 - val_loss: 0.0339 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.03297\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.0149 - acc: 0.9974 - val_loss: 0.0360 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.03297\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.0146 - acc: 0.9974 - val_loss: 0.0372 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.03297\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.0151 - acc: 0.9967 - val_loss: 0.0324 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.03297 to 0.03237, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.0149 - acc: 0.9967 - val_loss: 0.0335 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.03237\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.0144 - acc: 0.9967 - val_loss: 0.0331 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.03237\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.0139 - acc: 0.9967 - val_loss: 0.0340 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.03237\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.0142 - acc: 0.9974 - val_loss: 0.0320 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.03237 to 0.03197, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.0141 - acc: 0.9974 - val_loss: 0.0349 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.03197\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.0143 - acc: 0.9967 - val_loss: 0.0331 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.03197\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.0136 - acc: 0.9980 - val_loss: 0.0351 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.03197\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.0142 - acc: 0.9974 - val_loss: 0.0324 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.03197\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.0139 - acc: 0.9980 - val_loss: 0.0338 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.03197\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.0127 - acc: 0.9980 - val_loss: 0.0319 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00179: val_loss improved from 0.03197 to 0.03188, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.0137 - acc: 0.9961 - val_loss: 0.0320 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.03188\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.0136 - acc: 0.9967 - val_loss: 0.0318 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00181: val_loss improved from 0.03188 to 0.03181, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.0126 - acc: 0.9980 - val_loss: 0.0351 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.03181\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.0131 - acc: 0.9967 - val_loss: 0.0299 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00183: val_loss improved from 0.03181 to 0.02992, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.0128 - acc: 0.9974 - val_loss: 0.0355 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.02992\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.0134 - acc: 0.9961 - val_loss: 0.0319 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.02992\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.0129 - acc: 0.9967 - val_loss: 0.0334 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.02992\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.0129 - acc: 0.9961 - val_loss: 0.0312 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.02992\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.0128 - acc: 0.9974 - val_loss: 0.0315 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.02992\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.0126 - acc: 0.9967 - val_loss: 0.0310 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.02992\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.0126 - acc: 0.9974 - val_loss: 0.0329 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.02992\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.0117 - acc: 0.9967 - val_loss: 0.0377 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.02992\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.0124 - acc: 0.9980 - val_loss: 0.0319 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.02992\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.0128 - acc: 0.9967 - val_loss: 0.0315 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.02992\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.0115 - acc: 0.9980 - val_loss: 0.0308 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.02992\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.0121 - acc: 0.9967 - val_loss: 0.0317 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.02992\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.0115 - acc: 0.9974 - val_loss: 0.0356 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.02992\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.0124 - acc: 0.9967 - val_loss: 0.0353 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.02992\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.0116 - acc: 0.9974 - val_loss: 0.0314 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.02992\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.0128 - acc: 0.9967 - val_loss: 0.0313 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.02992\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.0115 - acc: 0.9974 - val_loss: 0.0326 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.02992\n",
      "batch_size=80   optimizer=Nadam\n",
      "Test accuracy: 69.6379%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_59 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 2.1270 - acc: 0.2395 - val_loss: 1.6020 - val_acc: 0.4774\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.60195, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.4513 - acc: 0.5046 - val_loss: 1.3528 - val_acc: 0.5350\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.60195 to 1.35278, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 1.1877 - acc: 0.5914 - val_loss: 1.1157 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.35278 to 1.11566, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 1.0339 - acc: 0.6717 - val_loss: 1.0059 - val_acc: 0.6420\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.11566 to 1.00588, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.9363 - acc: 0.6947 - val_loss: 0.9342 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.00588 to 0.93421, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.8547 - acc: 0.7237 - val_loss: 0.8429 - val_acc: 0.7202\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.93421 to 0.84289, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.7899 - acc: 0.7507 - val_loss: 0.8299 - val_acc: 0.6831\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.84289 to 0.82994, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.7394 - acc: 0.7684 - val_loss: 0.7513 - val_acc: 0.7613\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.82994 to 0.75134, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.6913 - acc: 0.7796 - val_loss: 0.7069 - val_acc: 0.7695\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.75134 to 0.70685, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.6470 - acc: 0.7980 - val_loss: 0.6850 - val_acc: 0.7942\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.70685 to 0.68505, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.6084 - acc: 0.8191 - val_loss: 0.6436 - val_acc: 0.7942\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.68505 to 0.64364, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.5688 - acc: 0.8336 - val_loss: 0.6192 - val_acc: 0.8025\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00012: val_loss improved from 0.64364 to 0.61924, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.5422 - acc: 0.8592 - val_loss: 0.5756 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.61924 to 0.57556, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.5173 - acc: 0.8546 - val_loss: 0.5311 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.57556 to 0.53112, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.4902 - acc: 0.8697 - val_loss: 0.4986 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.53112 to 0.49857, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.4704 - acc: 0.8711 - val_loss: 0.4903 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.49857 to 0.49033, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.4386 - acc: 0.8888 - val_loss: 0.4782 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.49033 to 0.47823, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.4288 - acc: 0.8882 - val_loss: 0.4337 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.47823 to 0.43372, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.4153 - acc: 0.9020 - val_loss: 0.4212 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.43372 to 0.42117, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.3843 - acc: 0.9125 - val_loss: 0.4340 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.42117\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.3762 - acc: 0.9211 - val_loss: 0.3860 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.42117 to 0.38603, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.3584 - acc: 0.9257 - val_loss: 0.3584 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.38603 to 0.35843, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.3436 - acc: 0.9270 - val_loss: 0.3615 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.35843\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.3271 - acc: 0.9414 - val_loss: 0.3489 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.35843 to 0.34888, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.3141 - acc: 0.9414 - val_loss: 0.3197 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.34888 to 0.31966, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.3027 - acc: 0.9500 - val_loss: 0.3489 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.31966\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.2885 - acc: 0.9566 - val_loss: 0.3082 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.31966 to 0.30815, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.2812 - acc: 0.9566 - val_loss: 0.3046 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.30815 to 0.30458, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.2729 - acc: 0.9599 - val_loss: 0.2757 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.30458 to 0.27573, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.2581 - acc: 0.9618 - val_loss: 0.3059 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.27573\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2549 - acc: 0.9586 - val_loss: 0.2748 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.27573 to 0.27480, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2370 - acc: 0.9730 - val_loss: 0.2888 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.27480\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2311 - acc: 0.9704 - val_loss: 0.2658 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.27480 to 0.26584, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2259 - acc: 0.9743 - val_loss: 0.2412 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.26584 to 0.24123, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2161 - acc: 0.9796 - val_loss: 0.2253 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.24123 to 0.22534, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2084 - acc: 0.9796 - val_loss: 0.2271 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.22534\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2050 - acc: 0.9783 - val_loss: 0.2114 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.22534 to 0.21138, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.1943 - acc: 0.9836 - val_loss: 0.2221 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.21138\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.1897 - acc: 0.9849 - val_loss: 0.2082 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.21138 to 0.20821, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.1827 - acc: 0.9882 - val_loss: 0.2076 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.20821 to 0.20764, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.1799 - acc: 0.9875 - val_loss: 0.1997 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.20764 to 0.19972, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.1713 - acc: 0.9895 - val_loss: 0.1925 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.19972 to 0.19247, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.1674 - acc: 0.9901 - val_loss: 0.1817 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.19247 to 0.18168, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1614 - acc: 0.9921 - val_loss: 0.1757 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.18168 to 0.17571, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1562 - acc: 0.9908 - val_loss: 0.1934 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.17571\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1505 - acc: 0.9934 - val_loss: 0.1749 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.17571 to 0.17489, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1455 - acc: 0.9934 - val_loss: 0.1645 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.17489 to 0.16451, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1458 - acc: 0.9921 - val_loss: 0.1599 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.16451 to 0.15994, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1403 - acc: 0.9947 - val_loss: 0.1617 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.15994\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1342 - acc: 0.9941 - val_loss: 0.1503 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.15994 to 0.15033, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1315 - acc: 0.9961 - val_loss: 0.1454 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.15033 to 0.14544, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1283 - acc: 0.9928 - val_loss: 0.1422 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.14544 to 0.14224, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1260 - acc: 0.9954 - val_loss: 0.1440 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.14224\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1214 - acc: 0.9928 - val_loss: 0.1371 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.14224 to 0.13706, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1189 - acc: 0.9967 - val_loss: 0.1365 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.13706 to 0.13648, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1144 - acc: 0.9954 - val_loss: 0.1297 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.13648 to 0.12970, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1113 - acc: 0.9961 - val_loss: 0.1312 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.12970\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1090 - acc: 0.9967 - val_loss: 0.1267 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.12970 to 0.12669, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1061 - acc: 0.9961 - val_loss: 0.1236 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.12669 to 0.12362, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1038 - acc: 0.9974 - val_loss: 0.1242 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.12362\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1003 - acc: 0.9954 - val_loss: 0.1195 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.12362 to 0.11950, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.0988 - acc: 0.9967 - val_loss: 0.1162 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.11950 to 0.11622, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.0954 - acc: 0.9974 - val_loss: 0.1228 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.11622\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.0940 - acc: 0.9987 - val_loss: 0.1130 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.11622 to 0.11296, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.0912 - acc: 0.9967 - val_loss: 0.1147 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.11296\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.0897 - acc: 0.9980 - val_loss: 0.1079 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.11296 to 0.10791, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.0885 - acc: 0.9967 - val_loss: 0.1082 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.10791\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.0857 - acc: 0.9974 - val_loss: 0.1071 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.10791 to 0.10714, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.0830 - acc: 0.9980 - val_loss: 0.0999 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.10714 to 0.09986, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.0827 - acc: 0.9974 - val_loss: 0.1010 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.09986\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.0799 - acc: 0.9967 - val_loss: 0.1128 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.09986\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.0786 - acc: 0.9980 - val_loss: 0.0983 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.09986 to 0.09827, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.0765 - acc: 0.9980 - val_loss: 0.0971 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.09827 to 0.09712, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.0753 - acc: 0.9974 - val_loss: 0.0956 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.09712 to 0.09558, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.0739 - acc: 0.9974 - val_loss: 0.0912 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.09558 to 0.09123, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.0725 - acc: 0.9974 - val_loss: 0.0944 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.09123\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.0705 - acc: 0.9980 - val_loss: 0.0886 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.09123 to 0.08862, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.0693 - acc: 0.9980 - val_loss: 0.0910 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.08862\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.0677 - acc: 0.9974 - val_loss: 0.0875 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.08862 to 0.08745, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0670 - acc: 0.9974 - val_loss: 0.0836 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.08745 to 0.08356, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0654 - acc: 0.9967 - val_loss: 0.0873 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.08356\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0643 - acc: 0.9974 - val_loss: 0.0855 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.08356\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0633 - acc: 0.9974 - val_loss: 0.0844 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.08356\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0617 - acc: 0.9980 - val_loss: 0.0820 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.08356 to 0.08197, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0602 - acc: 0.9967 - val_loss: 0.0782 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.08197 to 0.07821, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0596 - acc: 0.9967 - val_loss: 0.0812 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.07821\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0590 - acc: 0.9967 - val_loss: 0.0756 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.07821 to 0.07558, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0573 - acc: 0.9974 - val_loss: 0.0772 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.07558\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0569 - acc: 0.9974 - val_loss: 0.0814 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.07558\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0556 - acc: 0.9967 - val_loss: 0.0774 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.07558\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0544 - acc: 0.9974 - val_loss: 0.0758 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.07558\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0533 - acc: 0.9974 - val_loss: 0.0736 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.07558 to 0.07357, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0531 - acc: 0.9967 - val_loss: 0.0715 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.07357 to 0.07153, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0522 - acc: 0.9967 - val_loss: 0.0702 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.07153 to 0.07018, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0510 - acc: 0.9980 - val_loss: 0.0728 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.07018\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0498 - acc: 0.9961 - val_loss: 0.0700 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.07018 to 0.07002, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0494 - acc: 0.9967 - val_loss: 0.0691 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.07002 to 0.06909, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0486 - acc: 0.9980 - val_loss: 0.0712 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.06909\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0473 - acc: 0.9980 - val_loss: 0.0723 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.06909\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0475 - acc: 0.9961 - val_loss: 0.0660 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.06909 to 0.06600, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0459 - acc: 0.9980 - val_loss: 0.0659 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.06600 to 0.06595, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0451 - acc: 0.9980 - val_loss: 0.0654 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.06595 to 0.06543, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0455 - acc: 0.9967 - val_loss: 0.0634 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.06543 to 0.06344, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0439 - acc: 0.9980 - val_loss: 0.0622 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.06344 to 0.06220, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0431 - acc: 0.9967 - val_loss: 0.0634 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.06220\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0433 - acc: 0.9974 - val_loss: 0.0625 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.06220\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0420 - acc: 0.9967 - val_loss: 0.0694 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.06220\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0417 - acc: 0.9974 - val_loss: 0.0604 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.06220 to 0.06039, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0404 - acc: 0.9974 - val_loss: 0.0656 - val_acc: 0.9918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00109: val_loss did not improve from 0.06039\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0408 - acc: 0.9974 - val_loss: 0.0612 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.06039\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0396 - acc: 0.9987 - val_loss: 0.0587 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.06039 to 0.05870, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0393 - acc: 0.9974 - val_loss: 0.0602 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.05870\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0384 - acc: 0.9967 - val_loss: 0.0613 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.05870\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0381 - acc: 0.9967 - val_loss: 0.0589 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.05870\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0377 - acc: 0.9980 - val_loss: 0.0574 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.05870 to 0.05737, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0371 - acc: 0.9974 - val_loss: 0.0581 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.05737\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0369 - acc: 0.9974 - val_loss: 0.0550 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.05737 to 0.05502, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0360 - acc: 0.9967 - val_loss: 0.0558 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.05502\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0355 - acc: 0.9980 - val_loss: 0.0549 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.05502 to 0.05493, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0348 - acc: 0.9980 - val_loss: 0.0575 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.05493\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0348 - acc: 0.9967 - val_loss: 0.0570 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.05493\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0339 - acc: 0.9974 - val_loss: 0.0580 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.05493\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0337 - acc: 0.9980 - val_loss: 0.0535 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.05493 to 0.05347, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0337 - acc: 0.9967 - val_loss: 0.0567 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.05347\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0330 - acc: 0.9974 - val_loss: 0.0520 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.05347 to 0.05202, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0325 - acc: 0.9974 - val_loss: 0.0520 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.05202 to 0.05200, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0319 - acc: 0.9974 - val_loss: 0.0529 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.05200\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0318 - acc: 0.9961 - val_loss: 0.0546 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.05200\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0311 - acc: 0.9980 - val_loss: 0.0511 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.05200 to 0.05105, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0310 - acc: 0.9967 - val_loss: 0.0519 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.05105\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0306 - acc: 0.9974 - val_loss: 0.0538 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.05105\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0298 - acc: 0.9974 - val_loss: 0.0507 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.05105 to 0.05070, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0299 - acc: 0.9980 - val_loss: 0.0501 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.05070 to 0.05012, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0290 - acc: 0.9967 - val_loss: 0.0487 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.05012 to 0.04873, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0292 - acc: 0.9974 - val_loss: 0.0486 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.04873 to 0.04859, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0289 - acc: 0.9967 - val_loss: 0.0505 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.04859\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0285 - acc: 0.9961 - val_loss: 0.0462 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.04859 to 0.04624, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0282 - acc: 0.9974 - val_loss: 0.0481 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.04624\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0275 - acc: 0.9974 - val_loss: 0.0477 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.04624\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0278 - acc: 0.9961 - val_loss: 0.0469 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.04624\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0270 - acc: 0.9967 - val_loss: 0.0510 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.04624\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0265 - acc: 0.9974 - val_loss: 0.0466 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.04624\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0265 - acc: 0.9967 - val_loss: 0.0497 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.04624\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0263 - acc: 0.9980 - val_loss: 0.0442 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.04624 to 0.04421, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0260 - acc: 0.9974 - val_loss: 0.0471 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.04421\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0253 - acc: 0.9980 - val_loss: 0.0489 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.04421\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0254 - acc: 0.9974 - val_loss: 0.0469 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.04421\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0256 - acc: 0.9961 - val_loss: 0.0452 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.04421\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0248 - acc: 0.9967 - val_loss: 0.0451 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.04421\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0249 - acc: 0.9974 - val_loss: 0.0439 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.04421 to 0.04390, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0246 - acc: 0.9974 - val_loss: 0.0424 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.04390 to 0.04236, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0240 - acc: 0.9974 - val_loss: 0.0471 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.04236\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0241 - acc: 0.9980 - val_loss: 0.0458 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.04236\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0236 - acc: 0.9967 - val_loss: 0.0434 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.04236\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.0236 - acc: 0.9974 - val_loss: 0.0443 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.04236\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.0230 - acc: 0.9967 - val_loss: 0.0431 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.04236\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0228 - acc: 0.9961 - val_loss: 0.0437 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.04236\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.0225 - acc: 0.9974 - val_loss: 0.0423 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.04236 to 0.04235, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.0224 - acc: 0.9967 - val_loss: 0.0412 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.04235 to 0.04121, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.0220 - acc: 0.9967 - val_loss: 0.0422 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.04121\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.0220 - acc: 0.9967 - val_loss: 0.0411 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.04121 to 0.04110, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.0219 - acc: 0.9974 - val_loss: 0.0413 - val_acc: 0.9918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00162: val_loss did not improve from 0.04110\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.0217 - acc: 0.9974 - val_loss: 0.0415 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.04110\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.0212 - acc: 0.9974 - val_loss: 0.0412 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.04110\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.0211 - acc: 0.9961 - val_loss: 0.0427 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.04110\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.0209 - acc: 0.9974 - val_loss: 0.0427 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.04110\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.0211 - acc: 0.9974 - val_loss: 0.0407 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.04110 to 0.04073, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.0202 - acc: 0.9974 - val_loss: 0.0412 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.04073\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.0209 - acc: 0.9967 - val_loss: 0.0390 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.04073 to 0.03900, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.0202 - acc: 0.9967 - val_loss: 0.0396 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.03900\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.0201 - acc: 0.9974 - val_loss: 0.0418 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.03900\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.0204 - acc: 0.9980 - val_loss: 0.0424 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.03900\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.0201 - acc: 0.9967 - val_loss: 0.0395 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.03900\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.0199 - acc: 0.9967 - val_loss: 0.0389 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.03900 to 0.03885, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.0195 - acc: 0.9980 - val_loss: 0.0411 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.03885\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.0189 - acc: 0.9967 - val_loss: 0.0388 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00176: val_loss improved from 0.03885 to 0.03880, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.0194 - acc: 0.9974 - val_loss: 0.0397 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.03880\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.0192 - acc: 0.9961 - val_loss: 0.0397 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.03880\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.0189 - acc: 0.9974 - val_loss: 0.0374 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00179: val_loss improved from 0.03880 to 0.03743, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.0186 - acc: 0.9967 - val_loss: 0.0381 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.03743\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.0188 - acc: 0.9967 - val_loss: 0.0383 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.03743\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.0181 - acc: 0.9974 - val_loss: 0.0385 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.03743\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.0181 - acc: 0.9967 - val_loss: 0.0422 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.03743\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.0181 - acc: 0.9967 - val_loss: 0.0380 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.03743\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.0177 - acc: 0.9980 - val_loss: 0.0387 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.03743\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.0175 - acc: 0.9974 - val_loss: 0.0384 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.03743\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.0173 - acc: 0.9974 - val_loss: 0.0372 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.03743 to 0.03720, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.0171 - acc: 0.9974 - val_loss: 0.0378 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.03720\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.0171 - acc: 0.9974 - val_loss: 0.0374 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.03720\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.0175 - acc: 0.9961 - val_loss: 0.0367 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00190: val_loss improved from 0.03720 to 0.03672, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.0170 - acc: 0.9980 - val_loss: 0.0408 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.03672\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.0170 - acc: 0.9961 - val_loss: 0.0371 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.03672\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.0169 - acc: 0.9967 - val_loss: 0.0360 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00193: val_loss improved from 0.03672 to 0.03598, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.0167 - acc: 0.9961 - val_loss: 0.0380 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.03598\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.0165 - acc: 0.9967 - val_loss: 0.0379 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.03598\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.0162 - acc: 0.9980 - val_loss: 0.0381 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.03598\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.0168 - acc: 0.9967 - val_loss: 0.0370 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.03598\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.0168 - acc: 0.9974 - val_loss: 0.0359 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.03598 to 0.03592, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.0164 - acc: 0.9961 - val_loss: 0.0359 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00199: val_loss improved from 0.03592 to 0.03588, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.0163 - acc: 0.9974 - val_loss: 0.0367 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.03588\n",
      "batch_size=120   optimizer=Nadam\n",
      "Test accuracy: 68.5237%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_60 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 2.0869 - acc: 0.2467 - val_loss: 1.6499 - val_acc: 0.3951\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.64991, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.5085 - acc: 0.4789 - val_loss: 1.4322 - val_acc: 0.4568\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.64991 to 1.43224, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 1.2401 - acc: 0.5961 - val_loss: 1.1545 - val_acc: 0.6049\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.43224 to 1.15454, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 1.0895 - acc: 0.6480 - val_loss: 1.0304 - val_acc: 0.6708\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.15454 to 1.03044, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.9830 - acc: 0.6822 - val_loss: 0.9207 - val_acc: 0.7202\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.03044 to 0.92065, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.8971 - acc: 0.7178 - val_loss: 0.8842 - val_acc: 0.7284\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.92065 to 0.88420, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.8373 - acc: 0.7428 - val_loss: 0.8446 - val_acc: 0.7243\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.88420 to 0.84459, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.7898 - acc: 0.7533 - val_loss: 0.8008 - val_acc: 0.7407\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.84459 to 0.80077, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.7460 - acc: 0.7664 - val_loss: 0.7473 - val_acc: 0.7572\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.80077 to 0.74729, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.6963 - acc: 0.7961 - val_loss: 0.7018 - val_acc: 0.7860\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.74729 to 0.70179, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.6614 - acc: 0.7993 - val_loss: 0.6992 - val_acc: 0.7613\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.70179 to 0.69923, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.6290 - acc: 0.8145 - val_loss: 0.6355 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.69923 to 0.63554, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.5992 - acc: 0.8243 - val_loss: 0.5969 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.63554 to 0.59692, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.5702 - acc: 0.8342 - val_loss: 0.6146 - val_acc: 0.8107\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.59692\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.5581 - acc: 0.8362 - val_loss: 0.5451 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.59692 to 0.54509, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.5252 - acc: 0.8539 - val_loss: 0.5821 - val_acc: 0.8148\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.54509\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.5048 - acc: 0.8539 - val_loss: 0.5296 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.54509 to 0.52964, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.4767 - acc: 0.8717 - val_loss: 0.4744 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.52964 to 0.47442, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.4614 - acc: 0.8789 - val_loss: 0.4610 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.47442 to 0.46098, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.4423 - acc: 0.8928 - val_loss: 0.4465 - val_acc: 0.9012\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.46098 to 0.44653, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.4260 - acc: 0.8961 - val_loss: 0.4568 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.44653\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.4068 - acc: 0.9079 - val_loss: 0.4051 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.44653 to 0.40507, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.3995 - acc: 0.9039 - val_loss: 0.4060 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.40507\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.3776 - acc: 0.9211 - val_loss: 0.3984 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.40507 to 0.39844, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.3669 - acc: 0.9211 - val_loss: 0.3745 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.39844 to 0.37449, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.3491 - acc: 0.9309 - val_loss: 0.4137 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.37449\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.3567 - acc: 0.9204 - val_loss: 0.3468 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.37449 to 0.34676, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.3266 - acc: 0.9408 - val_loss: 0.3289 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.34676 to 0.32891, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.3151 - acc: 0.9447 - val_loss: 0.3361 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.32891\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.3107 - acc: 0.9421 - val_loss: 0.3199 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.32891 to 0.31990, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.2970 - acc: 0.9526 - val_loss: 0.3094 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.31990 to 0.30938, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.2901 - acc: 0.9507 - val_loss: 0.3083 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.30938 to 0.30832, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.2838 - acc: 0.9553 - val_loss: 0.2986 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.30832 to 0.29863, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.2709 - acc: 0.9592 - val_loss: 0.2928 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.29863 to 0.29280, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.2633 - acc: 0.9638 - val_loss: 0.3049 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.29280\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.2562 - acc: 0.9684 - val_loss: 0.2686 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.29280 to 0.26863, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.2464 - acc: 0.9684 - val_loss: 0.2547 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.26863 to 0.25474, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2406 - acc: 0.9658 - val_loss: 0.2640 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.25474\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.2323 - acc: 0.9717 - val_loss: 0.2422 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.25474 to 0.24216, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.2231 - acc: 0.9757 - val_loss: 0.2317 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.24216 to 0.23170, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.2195 - acc: 0.9776 - val_loss: 0.2294 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.23170 to 0.22945, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.2146 - acc: 0.9750 - val_loss: 0.2395 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.22945\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.2088 - acc: 0.9783 - val_loss: 0.2149 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.22945 to 0.21494, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.1992 - acc: 0.9829 - val_loss: 0.2197 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.21494\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.1961 - acc: 0.9855 - val_loss: 0.2053 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.21494 to 0.20534, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.1894 - acc: 0.9868 - val_loss: 0.2095 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.20534\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.1846 - acc: 0.9855 - val_loss: 0.1916 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.20534 to 0.19162, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.1781 - acc: 0.9875 - val_loss: 0.1871 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.19162 to 0.18713, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.1756 - acc: 0.9862 - val_loss: 0.1922 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.18713\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.1732 - acc: 0.9882 - val_loss: 0.1784 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.18713 to 0.17841, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.1647 - acc: 0.9928 - val_loss: 0.1729 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.17841 to 0.17290, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.1627 - acc: 0.9888 - val_loss: 0.1693 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.17290 to 0.16930, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.1564 - acc: 0.9921 - val_loss: 0.1809 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.16930\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1543 - acc: 0.9928 - val_loss: 0.1675 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.16930 to 0.16754, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1502 - acc: 0.9914 - val_loss: 0.1720 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.16754\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1455 - acc: 0.9934 - val_loss: 0.1562 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.16754 to 0.15617, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1406 - acc: 0.9947 - val_loss: 0.1611 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.15617\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1380 - acc: 0.9947 - val_loss: 0.1540 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.15617 to 0.15403, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1358 - acc: 0.9954 - val_loss: 0.1494 - val_acc: 0.9918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00059: val_loss improved from 0.15403 to 0.14939, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1308 - acc: 0.9954 - val_loss: 0.1574 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.14939\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1287 - acc: 0.9954 - val_loss: 0.1417 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.14939 to 0.14170, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1275 - acc: 0.9954 - val_loss: 0.1511 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.14170\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1250 - acc: 0.9941 - val_loss: 0.1353 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.14170 to 0.13527, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1215 - acc: 0.9961 - val_loss: 0.1387 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.13527\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1182 - acc: 0.9961 - val_loss: 0.1320 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.13527 to 0.13202, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1153 - acc: 0.9947 - val_loss: 0.1357 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.13202\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1116 - acc: 0.9974 - val_loss: 0.1278 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.13202 to 0.12784, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1097 - acc: 0.9967 - val_loss: 0.1279 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.12784\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1086 - acc: 0.9961 - val_loss: 0.1259 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.12784 to 0.12586, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1057 - acc: 0.9967 - val_loss: 0.1210 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.12586 to 0.12101, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1040 - acc: 0.9974 - val_loss: 0.1239 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.12101\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1030 - acc: 0.9947 - val_loss: 0.1146 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.12101 to 0.11460, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.0996 - acc: 0.9954 - val_loss: 0.1296 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.11460\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.0995 - acc: 0.9980 - val_loss: 0.1114 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.11460 to 0.11135, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.0983 - acc: 0.9961 - val_loss: 0.1182 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.11135\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.0937 - acc: 0.9974 - val_loss: 0.1105 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.11135 to 0.11047, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.0918 - acc: 0.9967 - val_loss: 0.1084 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.11047 to 0.10842, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.0903 - acc: 0.9974 - val_loss: 0.1052 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.10842 to 0.10524, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.0892 - acc: 0.9974 - val_loss: 0.1139 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.10524\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0873 - acc: 0.9974 - val_loss: 0.1062 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.10524\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0851 - acc: 0.9980 - val_loss: 0.1011 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.10524 to 0.10105, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0838 - acc: 0.9967 - val_loss: 0.1036 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.10105\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0818 - acc: 0.9980 - val_loss: 0.0970 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.10105 to 0.09704, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0803 - acc: 0.9974 - val_loss: 0.0993 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.09704\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0789 - acc: 0.9974 - val_loss: 0.1002 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.09704\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0778 - acc: 0.9974 - val_loss: 0.0975 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.09704\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0766 - acc: 0.9967 - val_loss: 0.0935 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.09704 to 0.09345, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0744 - acc: 0.9980 - val_loss: 0.0962 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.09345\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0742 - acc: 0.9974 - val_loss: 0.0921 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.09345 to 0.09212, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0720 - acc: 0.9974 - val_loss: 0.0900 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.09212 to 0.09000, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0710 - acc: 0.9987 - val_loss: 0.0889 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.09000 to 0.08893, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0699 - acc: 0.9980 - val_loss: 0.0881 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.08893 to 0.08812, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0686 - acc: 0.9980 - val_loss: 0.0866 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.08812 to 0.08661, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0685 - acc: 0.9967 - val_loss: 0.0824 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.08661 to 0.08235, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0668 - acc: 0.9974 - val_loss: 0.0868 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.08235\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0656 - acc: 0.9987 - val_loss: 0.0837 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.08235\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0644 - acc: 0.9967 - val_loss: 0.0864 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.08235\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0635 - acc: 0.9980 - val_loss: 0.0808 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.08235 to 0.08077, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0623 - acc: 0.9974 - val_loss: 0.0789 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.08077 to 0.07889, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0616 - acc: 0.9974 - val_loss: 0.0779 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.07889 to 0.07795, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0606 - acc: 0.9980 - val_loss: 0.0821 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.07795\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0595 - acc: 0.9980 - val_loss: 0.0816 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.07795\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0590 - acc: 0.9967 - val_loss: 0.0775 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.07795 to 0.07748, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0581 - acc: 0.9967 - val_loss: 0.0755 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.07748 to 0.07548, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0575 - acc: 0.9967 - val_loss: 0.0738 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.07548 to 0.07376, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0568 - acc: 0.9974 - val_loss: 0.0768 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.07376\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0557 - acc: 0.9980 - val_loss: 0.0721 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.07376 to 0.07206, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0561 - acc: 0.9980 - val_loss: 0.0768 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.07206\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0539 - acc: 0.9974 - val_loss: 0.0730 - val_acc: 0.9959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00109: val_loss did not improve from 0.07206\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0535 - acc: 0.9967 - val_loss: 0.0725 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.07206\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0521 - acc: 0.9980 - val_loss: 0.0690 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.07206 to 0.06901, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0516 - acc: 0.9980 - val_loss: 0.0722 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.06901\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0508 - acc: 0.9967 - val_loss: 0.0700 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.06901\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0502 - acc: 0.9980 - val_loss: 0.0712 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.06901\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0493 - acc: 0.9974 - val_loss: 0.0727 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.06901\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0494 - acc: 0.9974 - val_loss: 0.0686 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.06901 to 0.06864, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0482 - acc: 0.9974 - val_loss: 0.0656 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.06864 to 0.06560, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0472 - acc: 0.9967 - val_loss: 0.0707 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.06560\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0474 - acc: 0.9961 - val_loss: 0.0667 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.06560\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0462 - acc: 0.9974 - val_loss: 0.0673 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.06560\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0461 - acc: 0.9974 - val_loss: 0.0640 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.06560 to 0.06399, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0454 - acc: 0.9974 - val_loss: 0.0639 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.06399 to 0.06387, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0446 - acc: 0.9974 - val_loss: 0.0633 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.06387 to 0.06332, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0439 - acc: 0.9974 - val_loss: 0.0650 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.06332\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0433 - acc: 0.9987 - val_loss: 0.0634 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.06332\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0432 - acc: 0.9961 - val_loss: 0.0601 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.06332 to 0.06007, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0423 - acc: 0.9967 - val_loss: 0.0639 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.06007\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0423 - acc: 0.9967 - val_loss: 0.0606 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.06007\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0414 - acc: 0.9974 - val_loss: 0.0575 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.06007 to 0.05753, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0412 - acc: 0.9974 - val_loss: 0.0596 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.05753\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0401 - acc: 0.9974 - val_loss: 0.0608 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.05753\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0399 - acc: 0.9961 - val_loss: 0.0586 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.05753\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0396 - acc: 0.9974 - val_loss: 0.0604 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.05753\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0391 - acc: 0.9967 - val_loss: 0.0564 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.05753 to 0.05636, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0386 - acc: 0.9980 - val_loss: 0.0583 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.05636\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0378 - acc: 0.9974 - val_loss: 0.0593 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.05636\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0377 - acc: 0.9967 - val_loss: 0.0583 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.05636\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0374 - acc: 0.9974 - val_loss: 0.0571 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.05636\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0373 - acc: 0.9980 - val_loss: 0.0553 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.05636 to 0.05525, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0362 - acc: 0.9974 - val_loss: 0.0548 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.05525 to 0.05479, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0362 - acc: 0.9974 - val_loss: 0.0550 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.05479\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0358 - acc: 0.9967 - val_loss: 0.0571 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.05479\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0352 - acc: 0.9967 - val_loss: 0.0553 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.05479\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0347 - acc: 0.9980 - val_loss: 0.0551 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.05479\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0341 - acc: 0.9980 - val_loss: 0.0528 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.05479 to 0.05282, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0338 - acc: 0.9974 - val_loss: 0.0535 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.05282\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0337 - acc: 0.9967 - val_loss: 0.0533 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.05282\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0333 - acc: 0.9967 - val_loss: 0.0523 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.05282 to 0.05231, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0331 - acc: 0.9967 - val_loss: 0.0533 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.05231\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0326 - acc: 0.9967 - val_loss: 0.0522 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.05231 to 0.05220, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0322 - acc: 0.9974 - val_loss: 0.0510 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.05220 to 0.05100, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0322 - acc: 0.9974 - val_loss: 0.0496 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.05100 to 0.04956, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0318 - acc: 0.9980 - val_loss: 0.0521 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.04956\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0315 - acc: 0.9961 - val_loss: 0.0518 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.04956\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.0309 - acc: 0.9974 - val_loss: 0.0511 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.04956\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.0303 - acc: 0.9974 - val_loss: 0.0490 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.04956 to 0.04902, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0304 - acc: 0.9967 - val_loss: 0.0487 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.04902 to 0.04874, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.0299 - acc: 0.9980 - val_loss: 0.0490 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.04874\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.0296 - acc: 0.9967 - val_loss: 0.0498 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.04874\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.0294 - acc: 0.9974 - val_loss: 0.0482 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.04874 to 0.04822, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.0295 - acc: 0.9980 - val_loss: 0.0479 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.04822 to 0.04794, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.0288 - acc: 0.9961 - val_loss: 0.0495 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.04794\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.0294 - acc: 0.9967 - val_loss: 0.0478 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00163: val_loss improved from 0.04794 to 0.04783, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.0284 - acc: 0.9967 - val_loss: 0.0467 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.04783 to 0.04671, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.0283 - acc: 0.9974 - val_loss: 0.0461 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.04671 to 0.04606, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.0278 - acc: 0.9974 - val_loss: 0.0478 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.04606\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.0277 - acc: 0.9974 - val_loss: 0.0450 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.04606 to 0.04505, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.0272 - acc: 0.9974 - val_loss: 0.0454 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.04505\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.0268 - acc: 0.9974 - val_loss: 0.0456 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.04505\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.0270 - acc: 0.9974 - val_loss: 0.0471 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.04505\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.0268 - acc: 0.9980 - val_loss: 0.0461 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.04505\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.0265 - acc: 0.9974 - val_loss: 0.0448 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00172: val_loss improved from 0.04505 to 0.04480, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.0263 - acc: 0.9961 - val_loss: 0.0456 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.04480\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.0259 - acc: 0.9974 - val_loss: 0.0450 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.04480\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.0255 - acc: 0.9980 - val_loss: 0.0472 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.04480\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.0260 - acc: 0.9967 - val_loss: 0.0438 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00176: val_loss improved from 0.04480 to 0.04385, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.0255 - acc: 0.9980 - val_loss: 0.0445 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.04385\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.0254 - acc: 0.9967 - val_loss: 0.0428 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00178: val_loss improved from 0.04385 to 0.04283, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.0244 - acc: 0.9974 - val_loss: 0.0430 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.04283\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.0245 - acc: 0.9980 - val_loss: 0.0429 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.04283\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.0240 - acc: 0.9967 - val_loss: 0.0429 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.04283\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.0241 - acc: 0.9967 - val_loss: 0.0431 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.04283\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.0241 - acc: 0.9967 - val_loss: 0.0424 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00183: val_loss improved from 0.04283 to 0.04235, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.0239 - acc: 0.9974 - val_loss: 0.0468 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.04235\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.0238 - acc: 0.9967 - val_loss: 0.0435 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.04235\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.0233 - acc: 0.9961 - val_loss: 0.0428 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.04235\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.0233 - acc: 0.9967 - val_loss: 0.0427 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.04235\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.0233 - acc: 0.9967 - val_loss: 0.0413 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00188: val_loss improved from 0.04235 to 0.04130, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.0229 - acc: 0.9974 - val_loss: 0.0417 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.04130\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.0226 - acc: 0.9974 - val_loss: 0.0417 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.04130\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.0227 - acc: 0.9974 - val_loss: 0.0425 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.04130\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.0222 - acc: 0.9980 - val_loss: 0.0403 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.04130 to 0.04033, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.0224 - acc: 0.9967 - val_loss: 0.0404 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.04033\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.0222 - acc: 0.9974 - val_loss: 0.0418 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.04033\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.0215 - acc: 0.9967 - val_loss: 0.0407 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.04033\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.0215 - acc: 0.9967 - val_loss: 0.0398 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00196: val_loss improved from 0.04033 to 0.03976, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.0213 - acc: 0.9974 - val_loss: 0.0404 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.03976\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.0210 - acc: 0.9974 - val_loss: 0.0400 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.03976\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.0209 - acc: 0.9974 - val_loss: 0.0407 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.03976\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.0206 - acc: 0.9974 - val_loss: 0.0400 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.03976\n",
      "batch_size=160   optimizer=Nadam\n",
      "Test accuracy: 68.5237%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_61 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1520 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 2.2265 - acc: 0.2151 - val_loss: 1.9215 - val_acc: 0.2716\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.92151, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.6969 - acc: 0.4020 - val_loss: 1.5343 - val_acc: 0.4938\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.92151 to 1.53430, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 3/200\n",
      " - 0s - loss: 1.3848 - acc: 0.5428 - val_loss: 1.3478 - val_acc: 0.5638\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.53430 to 1.34777, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 4/200\n",
      " - 0s - loss: 1.2140 - acc: 0.6046 - val_loss: 1.2081 - val_acc: 0.6008\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.34777 to 1.20809, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 5/200\n",
      " - 0s - loss: 1.0878 - acc: 0.6618 - val_loss: 1.0750 - val_acc: 0.6626\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.20809 to 1.07495, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 6/200\n",
      " - 0s - loss: 1.0084 - acc: 0.6855 - val_loss: 1.0346 - val_acc: 0.6626\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.07495 to 1.03459, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.9381 - acc: 0.7046 - val_loss: 0.9426 - val_acc: 0.6872\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.03459 to 0.94258, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.8739 - acc: 0.7257 - val_loss: 0.9117 - val_acc: 0.6955\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.94258 to 0.91171, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.8286 - acc: 0.7454 - val_loss: 0.8825 - val_acc: 0.7325\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.91171 to 0.88245, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.7853 - acc: 0.7651 - val_loss: 0.8073 - val_acc: 0.7449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: val_loss improved from 0.88245 to 0.80733, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.7538 - acc: 0.7757 - val_loss: 0.7758 - val_acc: 0.7737\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.80733 to 0.77580, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.7119 - acc: 0.7882 - val_loss: 0.7346 - val_acc: 0.7695\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.77580 to 0.73458, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.6870 - acc: 0.7928 - val_loss: 0.7055 - val_acc: 0.7860\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.73458 to 0.70552, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.6552 - acc: 0.8079 - val_loss: 0.6840 - val_acc: 0.8107\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.70552 to 0.68397, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.6279 - acc: 0.8276 - val_loss: 0.6545 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.68397 to 0.65447, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.6092 - acc: 0.8217 - val_loss: 0.6400 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.65447 to 0.63999, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.5916 - acc: 0.8329 - val_loss: 0.6635 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.63999\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.5590 - acc: 0.8467 - val_loss: 0.5744 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.63999 to 0.57438, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.5349 - acc: 0.8638 - val_loss: 0.5767 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.57438\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.5224 - acc: 0.8553 - val_loss: 0.5653 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.57438 to 0.56526, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.5054 - acc: 0.8599 - val_loss: 0.5468 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.56526 to 0.54681, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.4826 - acc: 0.8704 - val_loss: 0.5235 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.54681 to 0.52352, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.4662 - acc: 0.8842 - val_loss: 0.4835 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.52352 to 0.48355, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.4482 - acc: 0.8849 - val_loss: 0.4867 - val_acc: 0.8765\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.48355\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.4345 - acc: 0.8882 - val_loss: 0.4635 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.48355 to 0.46348, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.4198 - acc: 0.8980 - val_loss: 0.4637 - val_acc: 0.9012\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.46348\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.4120 - acc: 0.9079 - val_loss: 0.4333 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.46348 to 0.43332, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.3970 - acc: 0.9092 - val_loss: 0.4041 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.43332 to 0.40408, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.3806 - acc: 0.9158 - val_loss: 0.4054 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.40408\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.3744 - acc: 0.9243 - val_loss: 0.3929 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.40408 to 0.39288, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.3634 - acc: 0.9263 - val_loss: 0.3765 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.39288 to 0.37650, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.3501 - acc: 0.9303 - val_loss: 0.3727 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.37650 to 0.37274, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.3451 - acc: 0.9322 - val_loss: 0.3865 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.37274\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.3337 - acc: 0.9309 - val_loss: 0.3496 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.37274 to 0.34963, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.3188 - acc: 0.9368 - val_loss: 0.3407 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.34963 to 0.34070, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.3078 - acc: 0.9474 - val_loss: 0.3405 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.34070 to 0.34048, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.3065 - acc: 0.9434 - val_loss: 0.3159 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.34048 to 0.31592, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.2961 - acc: 0.9513 - val_loss: 0.3140 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.31592 to 0.31395, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.2890 - acc: 0.9553 - val_loss: 0.3213 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.31395\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.2820 - acc: 0.9566 - val_loss: 0.2999 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.31395 to 0.29992, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.2729 - acc: 0.9612 - val_loss: 0.2863 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.29992 to 0.28633, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.2644 - acc: 0.9618 - val_loss: 0.2741 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.28633 to 0.27409, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.2553 - acc: 0.9678 - val_loss: 0.2849 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.27409\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.2521 - acc: 0.9697 - val_loss: 0.2966 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.27409\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.2464 - acc: 0.9711 - val_loss: 0.2508 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.27409 to 0.25076, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.2364 - acc: 0.9757 - val_loss: 0.2561 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.25076\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.2310 - acc: 0.9743 - val_loss: 0.2509 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.25076\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.2250 - acc: 0.9763 - val_loss: 0.2488 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.25076 to 0.24885, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.2218 - acc: 0.9763 - val_loss: 0.2480 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.24885 to 0.24803, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.2170 - acc: 0.9783 - val_loss: 0.2406 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.24803 to 0.24063, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.2126 - acc: 0.9796 - val_loss: 0.2210 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.24063 to 0.22104, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.2042 - acc: 0.9789 - val_loss: 0.2212 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.22104\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.2030 - acc: 0.9796 - val_loss: 0.2265 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.22104\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.1994 - acc: 0.9763 - val_loss: 0.2102 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.22104 to 0.21023, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.1926 - acc: 0.9836 - val_loss: 0.2143 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.21023\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.1846 - acc: 0.9862 - val_loss: 0.2084 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.21023 to 0.20844, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.1861 - acc: 0.9855 - val_loss: 0.2055 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.20844 to 0.20546, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.1790 - acc: 0.9849 - val_loss: 0.1985 - val_acc: 0.9835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00058: val_loss improved from 0.20546 to 0.19848, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.1745 - acc: 0.9882 - val_loss: 0.2019 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.19848\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.1725 - acc: 0.9842 - val_loss: 0.1966 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.19848 to 0.19662, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.1682 - acc: 0.9842 - val_loss: 0.1876 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.19662 to 0.18764, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.1628 - acc: 0.9882 - val_loss: 0.1872 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.18764 to 0.18718, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.1588 - acc: 0.9882 - val_loss: 0.1966 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.18718\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.1605 - acc: 0.9868 - val_loss: 0.1721 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.18718 to 0.17212, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.1529 - acc: 0.9914 - val_loss: 0.1763 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.17212\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.1486 - acc: 0.9947 - val_loss: 0.1764 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.17212\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.1487 - acc: 0.9908 - val_loss: 0.1650 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.17212 to 0.16501, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.1433 - acc: 0.9908 - val_loss: 0.1651 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.16501\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.1393 - acc: 0.9934 - val_loss: 0.1672 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.16501\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.1370 - acc: 0.9954 - val_loss: 0.1612 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.16501 to 0.16118, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.1360 - acc: 0.9941 - val_loss: 0.1555 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.16118 to 0.15545, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.1334 - acc: 0.9954 - val_loss: 0.1591 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.15545\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.1310 - acc: 0.9934 - val_loss: 0.1607 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.15545\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.1281 - acc: 0.9941 - val_loss: 0.1504 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.15545 to 0.15040, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.1240 - acc: 0.9967 - val_loss: 0.1413 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.15040 to 0.14134, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.1218 - acc: 0.9961 - val_loss: 0.1437 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.14134\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.1214 - acc: 0.9941 - val_loss: 0.1447 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.14134\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.1185 - acc: 0.9961 - val_loss: 0.1397 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.14134 to 0.13970, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.1153 - acc: 0.9961 - val_loss: 0.1416 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.13970\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.1137 - acc: 0.9967 - val_loss: 0.1405 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.13970\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.1117 - acc: 0.9974 - val_loss: 0.1336 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.13970 to 0.13359, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.1112 - acc: 0.9974 - val_loss: 0.1328 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.13359 to 0.13283, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.1072 - acc: 0.9980 - val_loss: 0.1290 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.13283 to 0.12903, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.1064 - acc: 0.9961 - val_loss: 0.1262 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.12903 to 0.12622, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.1050 - acc: 0.9967 - val_loss: 0.1246 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.12622 to 0.12459, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.1030 - acc: 0.9967 - val_loss: 0.1234 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.12459 to 0.12344, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0998 - acc: 0.9967 - val_loss: 0.1213 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.12344 to 0.12131, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0988 - acc: 0.9967 - val_loss: 0.1223 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.12131\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0968 - acc: 0.9967 - val_loss: 0.1238 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.12131\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0963 - acc: 0.9980 - val_loss: 0.1265 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.12131\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0956 - acc: 0.9980 - val_loss: 0.1139 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.12131 to 0.11387, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0922 - acc: 0.9974 - val_loss: 0.1159 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.11387\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0902 - acc: 0.9987 - val_loss: 0.1118 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.11387 to 0.11180, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0895 - acc: 0.9980 - val_loss: 0.1167 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.11180\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0874 - acc: 0.9974 - val_loss: 0.1069 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.11180 to 0.10694, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0863 - acc: 0.9980 - val_loss: 0.1095 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.10694\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0851 - acc: 0.9974 - val_loss: 0.1123 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.10694\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0835 - acc: 0.9980 - val_loss: 0.1075 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.10694\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0821 - acc: 0.9974 - val_loss: 0.1087 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.10694\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0810 - acc: 0.9974 - val_loss: 0.1029 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.10694 to 0.10286, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0792 - acc: 0.9974 - val_loss: 0.0995 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.10286 to 0.09953, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0790 - acc: 0.9987 - val_loss: 0.1005 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.09953\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0774 - acc: 0.9980 - val_loss: 0.1025 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.09953\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0773 - acc: 0.9974 - val_loss: 0.0975 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.09953 to 0.09753, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0751 - acc: 0.9967 - val_loss: 0.0985 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.09753\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0741 - acc: 0.9967 - val_loss: 0.1006 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.09753\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0727 - acc: 0.9974 - val_loss: 0.0915 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.09753 to 0.09153, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0720 - acc: 0.9980 - val_loss: 0.0984 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.09153\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0716 - acc: 0.9967 - val_loss: 0.0928 - val_acc: 0.9959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00109: val_loss did not improve from 0.09153\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0703 - acc: 0.9974 - val_loss: 0.0928 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.09153\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0691 - acc: 0.9987 - val_loss: 0.0933 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.09153\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0683 - acc: 0.9974 - val_loss: 0.0916 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.09153\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0672 - acc: 0.9974 - val_loss: 0.0901 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.09153 to 0.09006, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0658 - acc: 0.9974 - val_loss: 0.0897 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.09006 to 0.08973, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0651 - acc: 0.9987 - val_loss: 0.0931 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.08973\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0646 - acc: 0.9974 - val_loss: 0.0889 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.08973 to 0.08894, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0638 - acc: 0.9974 - val_loss: 0.0859 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.08894 to 0.08588, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0629 - acc: 0.9967 - val_loss: 0.0869 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.08588\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0619 - acc: 0.9967 - val_loss: 0.0808 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.08588 to 0.08082, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0616 - acc: 0.9967 - val_loss: 0.0825 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.08082\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0601 - acc: 0.9980 - val_loss: 0.0828 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.08082\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0594 - acc: 0.9967 - val_loss: 0.0837 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.08082\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0588 - acc: 0.9980 - val_loss: 0.0865 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.08082\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0580 - acc: 0.9974 - val_loss: 0.0805 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.08082 to 0.08050, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0577 - acc: 0.9967 - val_loss: 0.0797 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.08050 to 0.07969, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0564 - acc: 0.9980 - val_loss: 0.0786 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.07969 to 0.07861, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0559 - acc: 0.9974 - val_loss: 0.0775 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.07861 to 0.07747, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0552 - acc: 0.9967 - val_loss: 0.0798 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.07747\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0542 - acc: 0.9974 - val_loss: 0.0787 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.07747\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0542 - acc: 0.9980 - val_loss: 0.0760 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.07747 to 0.07604, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0536 - acc: 0.9974 - val_loss: 0.0756 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.07604 to 0.07556, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0529 - acc: 0.9967 - val_loss: 0.0751 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.07556 to 0.07506, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0517 - acc: 0.9980 - val_loss: 0.0739 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.07506 to 0.07389, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0513 - acc: 0.9961 - val_loss: 0.0750 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.07389\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0512 - acc: 0.9980 - val_loss: 0.0741 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.07389\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0503 - acc: 0.9980 - val_loss: 0.0715 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.07389 to 0.07152, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0494 - acc: 0.9980 - val_loss: 0.0709 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.07152 to 0.07086, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0489 - acc: 0.9980 - val_loss: 0.0702 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.07086 to 0.07022, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.0481 - acc: 0.9987 - val_loss: 0.0719 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.07022\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.0481 - acc: 0.9980 - val_loss: 0.0697 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.07022 to 0.06974, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.0473 - acc: 0.9967 - val_loss: 0.0694 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.06974 to 0.06943, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.0471 - acc: 0.9974 - val_loss: 0.0691 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.06943 to 0.06913, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.0462 - acc: 0.9974 - val_loss: 0.0683 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.06913 to 0.06833, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.0462 - acc: 0.9980 - val_loss: 0.0678 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.06833 to 0.06777, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.0453 - acc: 0.9974 - val_loss: 0.0684 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.06777\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.0450 - acc: 0.9974 - val_loss: 0.0685 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.06777\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.0440 - acc: 0.9980 - val_loss: 0.0672 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.06777 to 0.06719, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.0443 - acc: 0.9974 - val_loss: 0.0691 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.06719\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.0432 - acc: 0.9974 - val_loss: 0.0662 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.06719 to 0.06622, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.0430 - acc: 0.9980 - val_loss: 0.0657 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.06622 to 0.06570, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.0427 - acc: 0.9967 - val_loss: 0.0648 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.06570 to 0.06484, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.0422 - acc: 0.9967 - val_loss: 0.0636 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.06484 to 0.06365, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.0418 - acc: 0.9967 - val_loss: 0.0659 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.06365\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.0416 - acc: 0.9967 - val_loss: 0.0654 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.06365\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.0410 - acc: 0.9980 - val_loss: 0.0647 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.06365\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.0405 - acc: 0.9980 - val_loss: 0.0648 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.06365\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.0400 - acc: 0.9974 - val_loss: 0.0618 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.06365 to 0.06182, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.0394 - acc: 0.9974 - val_loss: 0.0640 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.06182\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.0394 - acc: 0.9974 - val_loss: 0.0627 - val_acc: 0.9959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00159: val_loss did not improve from 0.06182\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.0391 - acc: 0.9974 - val_loss: 0.0597 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.06182 to 0.05973, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.0384 - acc: 0.9974 - val_loss: 0.0618 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.05973\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.0378 - acc: 0.9980 - val_loss: 0.0571 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.05973 to 0.05707, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.0379 - acc: 0.9974 - val_loss: 0.0598 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.05707\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.0374 - acc: 0.9967 - val_loss: 0.0604 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.05707\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.0370 - acc: 0.9974 - val_loss: 0.0601 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.05707\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.0368 - acc: 0.9974 - val_loss: 0.0584 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.05707\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.0368 - acc: 0.9974 - val_loss: 0.0583 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.05707\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.0360 - acc: 0.9974 - val_loss: 0.0583 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.05707\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.0356 - acc: 0.9974 - val_loss: 0.0601 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.05707\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.0361 - acc: 0.9961 - val_loss: 0.0587 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.05707\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.0350 - acc: 0.9967 - val_loss: 0.0572 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.05707\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.0347 - acc: 0.9967 - val_loss: 0.0554 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00172: val_loss improved from 0.05707 to 0.05540, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.0344 - acc: 0.9974 - val_loss: 0.0572 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.05540\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.0341 - acc: 0.9967 - val_loss: 0.0560 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.05540\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.0338 - acc: 0.9961 - val_loss: 0.0556 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.05540\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.0333 - acc: 0.9974 - val_loss: 0.0569 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.05540\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.0330 - acc: 0.9974 - val_loss: 0.0543 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00177: val_loss improved from 0.05540 to 0.05435, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.0327 - acc: 0.9987 - val_loss: 0.0559 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.05435\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.0321 - acc: 0.9974 - val_loss: 0.0548 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.05435\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.0323 - acc: 0.9974 - val_loss: 0.0542 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00180: val_loss improved from 0.05435 to 0.05419, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.0318 - acc: 0.9980 - val_loss: 0.0542 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.05419\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.0316 - acc: 0.9974 - val_loss: 0.0548 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.05419\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.0313 - acc: 0.9974 - val_loss: 0.0543 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.05419\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.0310 - acc: 0.9974 - val_loss: 0.0538 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00184: val_loss improved from 0.05419 to 0.05381, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.0310 - acc: 0.9974 - val_loss: 0.0543 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.05381\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.0307 - acc: 0.9974 - val_loss: 0.0551 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.05381\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.0303 - acc: 0.9974 - val_loss: 0.0520 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.05381 to 0.05204, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.0303 - acc: 0.9974 - val_loss: 0.0524 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.05204\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.0302 - acc: 0.9961 - val_loss: 0.0536 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.05204\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.0298 - acc: 0.9980 - val_loss: 0.0506 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00190: val_loss improved from 0.05204 to 0.05063, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.0293 - acc: 0.9967 - val_loss: 0.0507 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.05063\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.0293 - acc: 0.9961 - val_loss: 0.0509 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.05063\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.0288 - acc: 0.9961 - val_loss: 0.0514 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.05063\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.0287 - acc: 0.9974 - val_loss: 0.0522 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.05063\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.0285 - acc: 0.9974 - val_loss: 0.0505 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00195: val_loss improved from 0.05063 to 0.05047, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.0279 - acc: 0.9987 - val_loss: 0.0511 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.05047\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.0283 - acc: 0.9974 - val_loss: 0.0503 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00197: val_loss improved from 0.05047 to 0.05032, saving model to weights.best.Resnet50.hdf5\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.0276 - acc: 0.9974 - val_loss: 0.0507 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.05032\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.0277 - acc: 0.9974 - val_loss: 0.0533 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.05032\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.0276 - acc: 0.9967 - val_loss: 0.0512 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.05032\n",
      "batch_size=200   optimizer=Nadam\n",
      "Test accuracy: 68.2451%\n"
     ]
    }
   ],
   "source": [
    "# initialize the model parameter to find the best solution that achieve the highest accuracy\n",
    "optimizer = [ 'SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "epoch=200\n",
    "batch=[10,20,40,80,120,160,200]\n",
    "measures={ \"optimizer\":[] , \"batch\":[] , \"accuracy\":[] } \n",
    "\n",
    "for opti in optimizer:\n",
    "    for batch1 in batch:\n",
    "        my_model = Sequential()\n",
    "\n",
    "\n",
    "        my_model.add(Dense(9, activation='softmax',input_shape=train_mobile.shape[1:]))\n",
    "\n",
    "\n",
    "        my_model.summary()\n",
    "        \n",
    "        my_model.compile(optimizer=opti, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        checkpointer = ModelCheckpoint(filepath='weights.best.Resnet50.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "        history1=my_model.fit(train_mobile, y_train, \n",
    "                  validation_data=(valid_mobile, y_valid),\n",
    "                  epochs=epoch, batch_size=batch1, callbacks=[checkpointer], verbose=2)\n",
    "\n",
    "\n",
    "        my_model_predictions = [np.argmax(my_model.predict(np.expand_dims(feature, axis=0))) for feature in test_mobile]\n",
    "\n",
    "        # report test accuracy\n",
    "        test_accuracy = 100*np.sum(np.array(my_model_predictions)==np.argmax(y_test, axis=1))/len(my_model_predictions)\n",
    "        measures[\"optimizer\"].append(opti)\n",
    "        measures[\"batch\"].append(batch1)\n",
    "        measures[\"accuracy\"].append(test_accuracy)\n",
    "        print(\"batch_size={}   optimizer={}\".format(batch1,opti))\n",
    "        print('Test accuracy: %.4f%%' % test_accuracy)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=zip(measures[\"optimizer\"],measures[\"batch\"],measures[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SGD', 10, 64.9025069637883),\n",
       " ('SGD', 20, 66.57381615598885),\n",
       " ('SGD', 40, 66.85236768802228),\n",
       " ('SGD', 80, 65.18105849582173),\n",
       " ('SGD', 120, 67.40947075208913),\n",
       " ('SGD', 160, 66.29526462395543),\n",
       " ('SGD', 200, 66.016713091922),\n",
       " ('RMSprop', 10, 66.57381615598885),\n",
       " ('RMSprop', 20, 67.13091922005572),\n",
       " ('RMSprop', 40, 68.80222841225627),\n",
       " ('RMSprop', 80, 69.91643454038997),\n",
       " ('RMSprop', 120, 68.80222841225627),\n",
       " ('RMSprop', 160, 68.52367688022284),\n",
       " ('RMSprop', 200, 68.52367688022284),\n",
       " ('Adagrad', 10, 65.45961002785515),\n",
       " ('Adagrad', 20, 68.52367688022284),\n",
       " ('Adagrad', 40, 68.24512534818942),\n",
       " ('Adagrad', 80, 67.96657381615599),\n",
       " ('Adagrad', 120, 67.13091922005572),\n",
       " ('Adagrad', 160, 67.68802228412257),\n",
       " ('Adagrad', 200, 68.24512534818942),\n",
       " ('Adadelta', 10, 67.68802228412257),\n",
       " ('Adadelta', 20, 68.52367688022284),\n",
       " ('Adadelta', 40, 67.96657381615599),\n",
       " ('Adadelta', 80, 67.68802228412257),\n",
       " ('Adadelta', 120, 68.52367688022284),\n",
       " ('Adadelta', 160, 68.24512534818942),\n",
       " ('Adadelta', 200, 66.29526462395543),\n",
       " ('Adam', 10, 68.24512534818942),\n",
       " ('Adam', 20, 68.52367688022284),\n",
       " ('Adam', 40, 67.13091922005572),\n",
       " ('Adam', 80, 67.68802228412257),\n",
       " ('Adam', 120, 67.96657381615599),\n",
       " ('Adam', 160, 65.73816155988858),\n",
       " ('Adam', 200, 68.24512534818942),\n",
       " ('Adamax', 10, 68.52367688022284),\n",
       " ('Adamax', 20, 69.08077994428969),\n",
       " ('Adamax', 40, 68.52367688022284),\n",
       " ('Adamax', 80, 67.13091922005572),\n",
       " ('Adamax', 120, 68.24512534818942),\n",
       " ('Adamax', 160, 67.40947075208913),\n",
       " ('Adamax', 200, 67.68802228412257),\n",
       " ('Nadam', 10, 67.96657381615599),\n",
       " ('Nadam', 20, 66.85236768802228),\n",
       " ('Nadam', 40, 66.29526462395543),\n",
       " ('Nadam', 80, 69.63788300835654),\n",
       " ('Nadam', 120, 68.52367688022284),\n",
       " ('Nadam', 160, 68.52367688022284),\n",
       " ('Nadam', 200, 68.24512534818942)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history1.history['acc'])\n",
    "plt.plot(history1.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Valid'], loc='upper left')\n",
    "plt.savefig('mobilenet_accuracy.png')\n",
    "\n",
    "plt.show()\n",
    "plt.plot(history1.history['loss'])\n",
    "plt.plot(history1.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Valid'], loc='upper left')\n",
    "plt.savefig('mobilenet_loss.png')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 68.5237%\n"
     ]
    }
   ],
   "source": [
    "my_model.load_weights('weights.best.mobile_model.hdf5')\n",
    "\n",
    "my_model_predictions = [np.argmax(my_model.predict(np.expand_dims(feature, axis=0))) for feature in test_mobile]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(my_model_predictions)==np.argmax(y_test, axis=1))/len(my_model_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a measurement of the robustness of the model iam going to use an augmented training dataset by rotation by 20 degree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 80.7661%\n"
     ]
    }
   ],
   "source": [
    "my_model.load_weights('weights.best.mobile_model.hdf5')\n",
    "\n",
    "my_model_predictions = [np.argmax(my_model.predict(np.expand_dims(feature, axis=0))) for feature in train_tensor_aug]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(my_model_predictions)==np.argmax(y_train_aug, axis=1))/len(my_model_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time taken to process one frame is =0.1994647979736328\n"
     ]
    }
   ],
   "source": [
    "prev_class_num=20\n",
    "accuracy=0.8\n",
    "cap = cv2.VideoCapture(0)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "while 1:\n",
    "    start=time.time()\n",
    "    ret, img = cap.read()\n",
    "    frame=cv2.resize(img, (224, 224))\n",
    "    frame = image.img_to_array(frame)\n",
    "    frame=np.expand_dims(frame,axis=0)\n",
    "    prediction=my_model.predict(model.predict(preprocess_input(frame)))\n",
    "    class_num=np.argmax(prediction)\n",
    "    if(prediction[0][class_num]>accuracy):\n",
    "        cv2.putText(img,classes_name[class_num],(10,224), font, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        if( (class_num != prev_class_num)):\n",
    "\n",
    "            prev_class_num=class_num\n",
    "            voice_assist(class_num)\n",
    "    cv2.imshow('img',img)\n",
    "    end=time.time()\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"The time taken to process one frame is ={}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27 images belonging to 1 classes.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-eea88b1b3c6f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mfollow_links\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m )\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mdatagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\keras_preprocessing\\image.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, augment, rounds, seed)\u001b[0m\n\u001b[0;32m   1167\u001b[0m             \u001b[0mseed\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mInt\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mRandom\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m        \"\"\"\n\u001b[1;32m-> 1169\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1170\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1171\u001b[0m             raise ValueError('Input to `.fit()` should have rank 4. '\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m     \"\"\"\n\u001b[1;32m--> 501\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\keras_preprocessing\\image.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1297\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1298\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1300\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\keras_preprocessing\\image.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1775\u001b[0m         \u001b[1;31m# The transformation of images is not under thread lock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1776\u001b[0m         \u001b[1;31m# so it can be done in parallel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1777\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\keras_preprocessing\\image.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[1;34m(self, index_array)\u001b[0m\n\u001b[0;32m   1735\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1736\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_data_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_random_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1737\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_data_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1738\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_data_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstandardize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1739\u001b[0m             \u001b[0mbatch_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\keras_preprocessing\\image.py\u001b[0m in \u001b[0;36mapply_transform\u001b[1;34m(self, x, transform_parameters)\u001b[0m\n\u001b[0;32m   1112\u001b[0m                                    \u001b[0mrow_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg_row_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg_col_axis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m                                    \u001b[0mchannel_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg_channel_axis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m                                    fill_mode=self.fill_mode, cval=self.cval)\n\u001b[0m\u001b[0;32m   1115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtransform_parameters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'channel_shift_intensity'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\keras_preprocessing\\image.py\u001b[0m in \u001b[0;36mapply_affine_transform\u001b[1;34m(x, theta, tx, ty, shear, zx, zy, row_axis, col_axis, channel_axis, fill_mode, cval)\u001b[0m\n\u001b[0;32m    323\u001b[0m             \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m             \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m             cval=cval) for x_channel in x]\n\u001b[0m\u001b[0;32m    326\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchannel_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrollaxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannel_axis\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\keras_preprocessing\\image.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    323\u001b[0m             \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m             \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m             cval=cval) for x_channel in x]\n\u001b[0m\u001b[0;32m    326\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchannel_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrollaxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannel_axis\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\scipy\\ndimage\\interpolation.py\u001b[0m in \u001b[0;36maffine_transform\u001b[1;34m(input, matrix, offset, output_shape, output, order, mode, cval, prefilter)\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         _nd_image.geometric_transform(filtered, None, None, matrix, offset,\n\u001b[1;32m--> 458\u001b[1;33m                                       output, order, mode, cval, None, None)\n\u001b[0m\u001b[0;32m    459\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# a built in function in keras to augment the data \n",
    "datagen = ImageDataGenerator(rotation_range=20)\n",
    "\n",
    "subdirectory=classes_name[8]\n",
    "\n",
    "train_generator =datagen.flow_from_directory(\n",
    "    directory=\"./data/validation_aug/\",\n",
    "    classes=[subdirectory],\n",
    "    color_mode=\"rgb\",\n",
    "    save_format='jpg',\n",
    "    batch_size=20,\n",
    "    class_mode=\"categorical\",\n",
    "    save_to_dir=\"./data/validation_aug///\"+subdirectory,\n",
    "    save_prefix=\"augmented\",\n",
    "    follow_links=True,\n",
    ")\n",
    "datagen.fit(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 11,529\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_model_augement = Sequential()\n",
    "my_model_augement.add(Dense(9, activation='softmax',input_shape=train_tensor_aug.shape[1:]))\n",
    "my_model_augement.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3655 samples, validate on 243 samples\n",
      "Epoch 1/200\n",
      " - 2s - loss: 0.0521 - acc: 0.9956 - val_loss: 0.0908 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09081, saving model to weights.best.mobile_model_augement.hdf5\n",
      "Epoch 2/200\n",
      " - 1s - loss: 0.0357 - acc: 0.9992 - val_loss: 0.1044 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09081\n",
      "Epoch 3/200\n",
      " - 1s - loss: 0.0343 - acc: 0.9984 - val_loss: 0.0855 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.09081 to 0.08549, saving model to weights.best.mobile_model_augement.hdf5\n",
      "Epoch 4/200\n",
      " - 1s - loss: 0.0327 - acc: 0.9989 - val_loss: 0.0895 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.08549\n",
      "Epoch 5/200\n",
      " - 1s - loss: 0.0317 - acc: 0.9992 - val_loss: 0.0926 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.08549\n",
      "Epoch 6/200\n",
      " - 1s - loss: 0.0311 - acc: 0.9989 - val_loss: 0.0888 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.08549\n",
      "Epoch 7/200\n",
      " - 1s - loss: 0.0305 - acc: 0.9992 - val_loss: 0.0911 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.08549\n",
      "Epoch 8/200\n",
      " - 1s - loss: 0.0299 - acc: 0.9986 - val_loss: 0.0844 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.08549 to 0.08441, saving model to weights.best.mobile_model_augement.hdf5\n",
      "Epoch 9/200\n",
      " - 1s - loss: 0.0295 - acc: 0.9992 - val_loss: 0.0857 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.08441\n",
      "Epoch 10/200\n",
      " - 1s - loss: 0.0288 - acc: 0.9989 - val_loss: 0.0879 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.08441\n",
      "Epoch 11/200\n",
      " - 1s - loss: 0.0286 - acc: 0.9989 - val_loss: 0.0908 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.08441\n",
      "Epoch 12/200\n",
      " - 1s - loss: 0.0282 - acc: 0.9986 - val_loss: 0.0887 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.08441\n",
      "Epoch 13/200\n",
      " - 1s - loss: 0.0277 - acc: 0.9989 - val_loss: 0.0881 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.08441\n",
      "Epoch 14/200\n",
      " - 1s - loss: 0.0275 - acc: 0.9986 - val_loss: 0.0889 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.08441\n",
      "Epoch 15/200\n",
      " - 1s - loss: 0.0270 - acc: 0.9989 - val_loss: 0.0926 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.08441\n",
      "Epoch 16/200\n",
      " - 1s - loss: 0.0269 - acc: 0.9986 - val_loss: 0.0828 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.08441 to 0.08279, saving model to weights.best.mobile_model_augement.hdf5\n",
      "Epoch 17/200\n",
      " - 1s - loss: 0.0266 - acc: 0.9992 - val_loss: 0.0881 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.08279\n",
      "Epoch 18/200\n",
      " - 1s - loss: 0.0265 - acc: 0.9989 - val_loss: 0.0888 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.08279\n",
      "Epoch 19/200\n",
      " - 1s - loss: 0.0261 - acc: 0.9992 - val_loss: 0.0873 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.08279\n",
      "Epoch 20/200\n",
      " - 1s - loss: 0.0260 - acc: 0.9986 - val_loss: 0.0845 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.08279\n",
      "Epoch 21/200\n",
      " - 1s - loss: 0.0257 - acc: 0.9992 - val_loss: 0.0859 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.08279\n",
      "Epoch 22/200\n",
      " - 1s - loss: 0.0255 - acc: 0.9986 - val_loss: 0.0870 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.08279\n",
      "Epoch 23/200\n",
      " - 1s - loss: 0.0253 - acc: 0.9984 - val_loss: 0.0854 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.08279\n",
      "Epoch 24/200\n",
      " - 1s - loss: 0.0250 - acc: 0.9992 - val_loss: 0.0833 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.08279\n",
      "Epoch 25/200\n",
      " - 1s - loss: 0.0247 - acc: 0.9986 - val_loss: 0.0882 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.08279\n",
      "Epoch 26/200\n",
      " - 1s - loss: 0.0247 - acc: 0.9986 - val_loss: 0.0878 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.08279\n",
      "Epoch 27/200\n",
      " - 1s - loss: 0.0244 - acc: 0.9989 - val_loss: 0.0854 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.08279\n",
      "Epoch 28/200\n",
      " - 1s - loss: 0.0241 - acc: 0.9989 - val_loss: 0.0879 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.08279\n",
      "Epoch 29/200\n",
      " - 1s - loss: 0.0241 - acc: 0.9989 - val_loss: 0.0881 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.08279\n",
      "Epoch 30/200\n",
      " - 1s - loss: 0.0239 - acc: 0.9992 - val_loss: 0.0838 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.08279\n",
      "Epoch 31/200\n",
      " - 1s - loss: 0.0238 - acc: 0.9986 - val_loss: 0.0825 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.08279 to 0.08251, saving model to weights.best.mobile_model_augement.hdf5\n",
      "Epoch 32/200\n",
      " - 1s - loss: 0.0236 - acc: 0.9989 - val_loss: 0.0864 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.08251\n",
      "Epoch 33/200\n",
      " - 1s - loss: 0.0235 - acc: 0.9989 - val_loss: 0.0818 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.08251 to 0.08178, saving model to weights.best.mobile_model_augement.hdf5\n",
      "Epoch 34/200\n",
      " - 1s - loss: 0.0232 - acc: 0.9992 - val_loss: 0.0831 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.08178\n",
      "Epoch 35/200\n",
      " - 1s - loss: 0.0231 - acc: 0.9989 - val_loss: 0.0887 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.08178\n",
      "Epoch 36/200\n",
      " - 1s - loss: 0.0230 - acc: 0.9989 - val_loss: 0.0874 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.08178\n",
      "Epoch 37/200\n",
      " - 1s - loss: 0.0227 - acc: 0.9989 - val_loss: 0.0840 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.08178\n",
      "Epoch 38/200\n",
      " - 1s - loss: 0.0227 - acc: 0.9986 - val_loss: 0.0804 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.08178 to 0.08043, saving model to weights.best.mobile_model_augement.hdf5\n",
      "Epoch 39/200\n",
      " - 1s - loss: 0.0226 - acc: 0.9984 - val_loss: 0.0832 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.08043\n",
      "Epoch 40/200\n",
      " - 1s - loss: 0.0225 - acc: 0.9989 - val_loss: 0.0869 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.08043\n",
      "Epoch 41/200\n",
      " - 1s - loss: 0.0223 - acc: 0.9986 - val_loss: 0.0869 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.08043\n",
      "Epoch 42/200\n",
      " - 1s - loss: 0.0220 - acc: 0.9992 - val_loss: 0.0839 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.08043\n",
      "Epoch 43/200\n",
      " - 1s - loss: 0.0220 - acc: 0.9992 - val_loss: 0.0844 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.08043\n",
      "Epoch 44/200\n",
      " - 1s - loss: 0.0219 - acc: 0.9989 - val_loss: 0.0841 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.08043\n",
      "Epoch 45/200\n",
      " - 1s - loss: 0.0219 - acc: 0.9986 - val_loss: 0.0869 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.08043\n",
      "Epoch 46/200\n",
      " - 1s - loss: 0.0216 - acc: 0.9986 - val_loss: 0.0857 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.08043\n",
      "Epoch 47/200\n",
      " - 1s - loss: 0.0216 - acc: 0.9986 - val_loss: 0.0823 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.08043\n",
      "Epoch 48/200\n",
      " - 1s - loss: 0.0214 - acc: 0.9989 - val_loss: 0.0834 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.08043\n",
      "Epoch 49/200\n",
      " - 1s - loss: 0.0214 - acc: 0.9989 - val_loss: 0.0841 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.08043\n",
      "Epoch 50/200\n",
      " - 1s - loss: 0.0213 - acc: 0.9989 - val_loss: 0.0830 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.08043\n",
      "Epoch 51/200\n",
      " - 1s - loss: 0.0211 - acc: 0.9989 - val_loss: 0.0819 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.08043\n",
      "Epoch 52/200\n",
      " - 1s - loss: 0.0210 - acc: 0.9992 - val_loss: 0.0836 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.08043\n",
      "Epoch 53/200\n",
      " - 1s - loss: 0.0210 - acc: 0.9989 - val_loss: 0.0862 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.08043\n",
      "Epoch 54/200\n",
      " - 1s - loss: 0.0207 - acc: 0.9995 - val_loss: 0.0842 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.08043\n",
      "Epoch 55/200\n",
      " - 1s - loss: 0.0208 - acc: 0.9986 - val_loss: 0.0832 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.08043\n",
      "Epoch 56/200\n",
      " - 1s - loss: 0.0206 - acc: 0.9989 - val_loss: 0.0839 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.08043\n",
      "Epoch 57/200\n",
      " - 1s - loss: 0.0205 - acc: 0.9989 - val_loss: 0.0807 - val_acc: 0.9835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00057: val_loss did not improve from 0.08043\n",
      "Epoch 58/200\n",
      " - 1s - loss: 0.0205 - acc: 0.9986 - val_loss: 0.0848 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.08043\n",
      "Epoch 59/200\n",
      " - 1s - loss: 0.0204 - acc: 0.9986 - val_loss: 0.0809 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.08043\n",
      "Epoch 60/200\n",
      " - 1s - loss: 0.0203 - acc: 0.9989 - val_loss: 0.0820 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.08043\n",
      "Epoch 61/200\n",
      " - 1s - loss: 0.0202 - acc: 0.9986 - val_loss: 0.0801 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.08043 to 0.08005, saving model to weights.best.mobile_model_augement.hdf5\n",
      "Epoch 62/200\n",
      " - 1s - loss: 0.0201 - acc: 0.9989 - val_loss: 0.0827 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.08005\n",
      "Epoch 63/200\n",
      " - 1s - loss: 0.0200 - acc: 0.9986 - val_loss: 0.0827 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.08005\n",
      "Epoch 64/200\n",
      " - 1s - loss: 0.0199 - acc: 0.9992 - val_loss: 0.0836 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.08005\n",
      "Epoch 65/200\n",
      " - 1s - loss: 0.0198 - acc: 0.9989 - val_loss: 0.0831 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.08005\n",
      "Epoch 66/200\n",
      " - 1s - loss: 0.0198 - acc: 0.9989 - val_loss: 0.0879 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.08005\n",
      "Epoch 67/200\n",
      " - 1s - loss: 0.0196 - acc: 0.9992 - val_loss: 0.0837 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.08005\n",
      "Epoch 68/200\n",
      " - 1s - loss: 0.0196 - acc: 0.9986 - val_loss: 0.0836 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.08005\n",
      "Epoch 69/200\n",
      " - 1s - loss: 0.0195 - acc: 0.9986 - val_loss: 0.0835 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.08005\n",
      "Epoch 70/200\n",
      " - 1s - loss: 0.0194 - acc: 0.9986 - val_loss: 0.0839 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.08005\n",
      "Epoch 71/200\n",
      " - 1s - loss: 0.0193 - acc: 0.9992 - val_loss: 0.0821 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.08005\n",
      "Epoch 72/200\n",
      " - 1s - loss: 0.0193 - acc: 0.9989 - val_loss: 0.0822 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.08005\n",
      "Epoch 73/200\n",
      " - 1s - loss: 0.0192 - acc: 0.9986 - val_loss: 0.0827 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.08005\n",
      "Epoch 74/200\n",
      " - 1s - loss: 0.0191 - acc: 0.9989 - val_loss: 0.0830 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.08005\n",
      "Epoch 75/200\n",
      " - 1s - loss: 0.0190 - acc: 0.9989 - val_loss: 0.0831 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.08005\n",
      "Epoch 76/200\n",
      " - 1s - loss: 0.0190 - acc: 0.9986 - val_loss: 0.0858 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.08005\n",
      "Epoch 77/200\n",
      " - 1s - loss: 0.0189 - acc: 0.9986 - val_loss: 0.0853 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.08005\n",
      "Epoch 78/200\n",
      " - 1s - loss: 0.0188 - acc: 0.9989 - val_loss: 0.0814 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.08005\n",
      "Epoch 79/200\n",
      " - 1s - loss: 0.0188 - acc: 0.9989 - val_loss: 0.0808 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.08005\n",
      "Epoch 80/200\n",
      " - 1s - loss: 0.0188 - acc: 0.9986 - val_loss: 0.0850 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.08005\n",
      "Epoch 81/200\n",
      " - 1s - loss: 0.0187 - acc: 0.9986 - val_loss: 0.0820 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.08005\n",
      "Epoch 82/200\n",
      " - 1s - loss: 0.0186 - acc: 0.9984 - val_loss: 0.0857 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.08005\n",
      "Epoch 83/200\n",
      " - 1s - loss: 0.0185 - acc: 0.9989 - val_loss: 0.0840 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.08005\n",
      "Epoch 84/200\n",
      " - 1s - loss: 0.0184 - acc: 0.9989 - val_loss: 0.0833 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.08005\n",
      "Epoch 85/200\n",
      " - 1s - loss: 0.0183 - acc: 0.9995 - val_loss: 0.0784 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.08005 to 0.07836, saving model to weights.best.mobile_model_augement.hdf5\n",
      "Epoch 86/200\n",
      " - 1s - loss: 0.0183 - acc: 0.9989 - val_loss: 0.0829 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.07836\n",
      "Epoch 87/200\n",
      " - 1s - loss: 0.0182 - acc: 0.9986 - val_loss: 0.0827 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.07836\n",
      "Epoch 88/200\n",
      " - 1s - loss: 0.0181 - acc: 0.9989 - val_loss: 0.0852 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.07836\n",
      "Epoch 89/200\n",
      " - 1s - loss: 0.0182 - acc: 0.9992 - val_loss: 0.0819 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.07836\n",
      "Epoch 90/200\n",
      " - 1s - loss: 0.0180 - acc: 0.9989 - val_loss: 0.0822 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.07836\n",
      "Epoch 91/200\n",
      " - 1s - loss: 0.0180 - acc: 0.9989 - val_loss: 0.0812 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.07836\n",
      "Epoch 92/200\n",
      " - 1s - loss: 0.0179 - acc: 0.9989 - val_loss: 0.0838 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.07836\n",
      "Epoch 93/200\n",
      " - 1s - loss: 0.0178 - acc: 0.9989 - val_loss: 0.0834 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.07836\n",
      "Epoch 94/200\n",
      " - 1s - loss: 0.0178 - acc: 0.9986 - val_loss: 0.0818 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.07836\n",
      "Epoch 95/200\n",
      " - 1s - loss: 0.0177 - acc: 0.9992 - val_loss: 0.0834 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.07836\n",
      "Epoch 96/200\n",
      " - 1s - loss: 0.0177 - acc: 0.9984 - val_loss: 0.0821 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.07836\n",
      "Epoch 97/200\n",
      " - 1s - loss: 0.0176 - acc: 0.9989 - val_loss: 0.0799 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.07836\n",
      "Epoch 98/200\n",
      " - 1s - loss: 0.0176 - acc: 0.9986 - val_loss: 0.0843 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.07836\n",
      "Epoch 99/200\n",
      " - 1s - loss: 0.0175 - acc: 0.9989 - val_loss: 0.0818 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.07836\n",
      "Epoch 100/200\n",
      " - 1s - loss: 0.0175 - acc: 0.9989 - val_loss: 0.0848 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.07836\n",
      "Epoch 101/200\n",
      " - 1s - loss: 0.0174 - acc: 0.9992 - val_loss: 0.0852 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.07836\n",
      "Epoch 102/200\n",
      " - 1s - loss: 0.0173 - acc: 0.9986 - val_loss: 0.0814 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.07836\n",
      "Epoch 103/200\n",
      " - 1s - loss: 0.0174 - acc: 0.9992 - val_loss: 0.0827 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.07836\n",
      "Epoch 104/200\n",
      " - 1s - loss: 0.0172 - acc: 0.9986 - val_loss: 0.0822 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.07836\n",
      "Epoch 105/200\n",
      " - 1s - loss: 0.0172 - acc: 0.9989 - val_loss: 0.0837 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.07836\n",
      "Epoch 106/200\n",
      " - 1s - loss: 0.0172 - acc: 0.9986 - val_loss: 0.0817 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.07836\n",
      "Epoch 107/200\n",
      " - 1s - loss: 0.0171 - acc: 0.9986 - val_loss: 0.0814 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.07836\n",
      "Epoch 108/200\n",
      " - 1s - loss: 0.0170 - acc: 0.9989 - val_loss: 0.0857 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.07836\n",
      "Epoch 109/200\n",
      " - 1s - loss: 0.0170 - acc: 0.9992 - val_loss: 0.0806 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.07836\n",
      "Epoch 110/200\n",
      " - 1s - loss: 0.0170 - acc: 0.9986 - val_loss: 0.0806 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.07836\n",
      "Epoch 111/200\n",
      " - 1s - loss: 0.0169 - acc: 0.9989 - val_loss: 0.0830 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.07836\n",
      "Epoch 112/200\n",
      " - 1s - loss: 0.0169 - acc: 0.9986 - val_loss: 0.0811 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.07836\n",
      "Epoch 113/200\n",
      " - 1s - loss: 0.0168 - acc: 0.9992 - val_loss: 0.0820 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.07836\n",
      "Epoch 114/200\n",
      " - 1s - loss: 0.0168 - acc: 0.9989 - val_loss: 0.0824 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.07836\n",
      "Epoch 115/200\n",
      " - 1s - loss: 0.0167 - acc: 0.9986 - val_loss: 0.0835 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.07836\n",
      "Epoch 116/200\n",
      " - 1s - loss: 0.0166 - acc: 0.9986 - val_loss: 0.0821 - val_acc: 0.9835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00116: val_loss did not improve from 0.07836\n",
      "Epoch 117/200\n",
      " - 1s - loss: 0.0166 - acc: 0.9989 - val_loss: 0.0808 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.07836\n",
      "Epoch 118/200\n",
      " - 1s - loss: 0.0166 - acc: 0.9989 - val_loss: 0.0806 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.07836\n",
      "Epoch 119/200\n",
      " - 1s - loss: 0.0165 - acc: 0.9989 - val_loss: 0.0814 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.07836\n",
      "Epoch 120/200\n",
      " - 1s - loss: 0.0165 - acc: 0.9986 - val_loss: 0.0823 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.07836\n",
      "Epoch 121/200\n",
      " - 1s - loss: 0.0164 - acc: 0.9989 - val_loss: 0.0823 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.07836\n",
      "Epoch 122/200\n",
      " - 1s - loss: 0.0164 - acc: 0.9989 - val_loss: 0.0812 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.07836\n",
      "Epoch 123/200\n",
      " - 1s - loss: 0.0163 - acc: 0.9986 - val_loss: 0.0847 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.07836\n",
      "Epoch 124/200\n",
      " - 1s - loss: 0.0162 - acc: 0.9992 - val_loss: 0.0836 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.07836\n",
      "Epoch 125/200\n",
      " - 1s - loss: 0.0163 - acc: 0.9989 - val_loss: 0.0821 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.07836\n",
      "Epoch 126/200\n",
      " - 1s - loss: 0.0162 - acc: 0.9986 - val_loss: 0.0809 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.07836\n",
      "Epoch 127/200\n",
      " - 1s - loss: 0.0162 - acc: 0.9986 - val_loss: 0.0813 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.07836\n",
      "Epoch 128/200\n",
      " - 1s - loss: 0.0161 - acc: 0.9986 - val_loss: 0.0827 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.07836\n",
      "Epoch 129/200\n",
      " - 1s - loss: 0.0161 - acc: 0.9984 - val_loss: 0.0832 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.07836\n",
      "Epoch 130/200\n",
      " - 1s - loss: 0.0161 - acc: 0.9986 - val_loss: 0.0806 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.07836\n",
      "Epoch 131/200\n",
      " - 1s - loss: 0.0160 - acc: 0.9986 - val_loss: 0.0843 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.07836\n",
      "Epoch 132/200\n",
      " - 1s - loss: 0.0159 - acc: 0.9986 - val_loss: 0.0826 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.07836\n",
      "Epoch 133/200\n",
      " - 1s - loss: 0.0159 - acc: 0.9984 - val_loss: 0.0819 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.07836\n",
      "Epoch 134/200\n",
      " - 1s - loss: 0.0159 - acc: 0.9984 - val_loss: 0.0825 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.07836\n",
      "Epoch 135/200\n",
      " - 1s - loss: 0.0158 - acc: 0.9989 - val_loss: 0.0848 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.07836\n",
      "Epoch 136/200\n",
      " - 1s - loss: 0.0157 - acc: 0.9995 - val_loss: 0.0818 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.07836\n",
      "Epoch 137/200\n",
      " - 1s - loss: 0.0158 - acc: 0.9989 - val_loss: 0.0812 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.07836\n",
      "Epoch 138/200\n",
      " - 1s - loss: 0.0157 - acc: 0.9992 - val_loss: 0.0811 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.07836\n",
      "Epoch 139/200\n",
      " - 1s - loss: 0.0157 - acc: 0.9986 - val_loss: 0.0808 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.07836\n",
      "Epoch 140/200\n",
      " - 1s - loss: 0.0156 - acc: 0.9986 - val_loss: 0.0834 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.07836\n",
      "Epoch 141/200\n",
      " - 1s - loss: 0.0156 - acc: 0.9986 - val_loss: 0.0831 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.07836\n",
      "Epoch 142/200\n",
      " - 1s - loss: 0.0156 - acc: 0.9984 - val_loss: 0.0814 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.07836\n",
      "Epoch 143/200\n",
      " - 1s - loss: 0.0155 - acc: 0.9986 - val_loss: 0.0835 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.07836\n",
      "Epoch 144/200\n",
      " - 1s - loss: 0.0155 - acc: 0.9989 - val_loss: 0.0832 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.07836\n",
      "Epoch 145/200\n",
      " - 1s - loss: 0.0155 - acc: 0.9992 - val_loss: 0.0851 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.07836\n",
      "Epoch 146/200\n",
      " - 1s - loss: 0.0154 - acc: 0.9992 - val_loss: 0.0816 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.07836\n",
      "Epoch 147/200\n",
      " - 1s - loss: 0.0154 - acc: 0.9989 - val_loss: 0.0833 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.07836\n",
      "Epoch 148/200\n",
      " - 1s - loss: 0.0153 - acc: 0.9989 - val_loss: 0.0830 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.07836\n",
      "Epoch 149/200\n",
      " - 1s - loss: 0.0153 - acc: 0.9986 - val_loss: 0.0834 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.07836\n",
      "Epoch 150/200\n",
      " - 1s - loss: 0.0152 - acc: 0.9989 - val_loss: 0.0826 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.07836\n",
      "Epoch 151/200\n",
      " - 1s - loss: 0.0152 - acc: 0.9989 - val_loss: 0.0819 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.07836\n",
      "Epoch 152/200\n",
      " - 1s - loss: 0.0152 - acc: 0.9989 - val_loss: 0.0828 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.07836\n",
      "Epoch 153/200\n",
      " - 1s - loss: 0.0151 - acc: 0.9989 - val_loss: 0.0813 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.07836\n",
      "Epoch 154/200\n",
      " - 1s - loss: 0.0151 - acc: 0.9992 - val_loss: 0.0800 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.07836\n",
      "Epoch 155/200\n",
      " - 1s - loss: 0.0150 - acc: 0.9989 - val_loss: 0.0829 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.07836\n",
      "Epoch 156/200\n",
      " - 1s - loss: 0.0150 - acc: 0.9992 - val_loss: 0.0820 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.07836\n",
      "Epoch 157/200\n",
      " - 1s - loss: 0.0149 - acc: 0.9992 - val_loss: 0.0836 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.07836\n",
      "Epoch 158/200\n",
      " - 1s - loss: 0.0150 - acc: 0.9989 - val_loss: 0.0819 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.07836\n",
      "Epoch 159/200\n",
      " - 1s - loss: 0.0149 - acc: 0.9989 - val_loss: 0.0828 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.07836\n",
      "Epoch 160/200\n",
      " - 1s - loss: 0.0149 - acc: 0.9989 - val_loss: 0.0818 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.07836\n",
      "Epoch 161/200\n",
      " - 1s - loss: 0.0148 - acc: 0.9992 - val_loss: 0.0811 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.07836\n",
      "Epoch 162/200\n",
      " - 1s - loss: 0.0148 - acc: 0.9989 - val_loss: 0.0834 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.07836\n",
      "Epoch 163/200\n",
      " - 1s - loss: 0.0148 - acc: 0.9992 - val_loss: 0.0794 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.07836\n",
      "Epoch 164/200\n",
      " - 1s - loss: 0.0147 - acc: 0.9986 - val_loss: 0.0818 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.07836\n",
      "Epoch 165/200\n",
      " - 1s - loss: 0.0147 - acc: 0.9989 - val_loss: 0.0803 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.07836\n",
      "Epoch 166/200\n",
      " - 1s - loss: 0.0147 - acc: 0.9984 - val_loss: 0.0816 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.07836\n",
      "Epoch 167/200\n",
      " - 1s - loss: 0.0147 - acc: 0.9986 - val_loss: 0.0817 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.07836\n",
      "Epoch 168/200\n",
      " - 1s - loss: 0.0146 - acc: 0.9986 - val_loss: 0.0823 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.07836\n",
      "Epoch 169/200\n",
      " - 1s - loss: 0.0146 - acc: 0.9986 - val_loss: 0.0831 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.07836\n",
      "Epoch 170/200\n",
      " - 1s - loss: 0.0146 - acc: 0.9986 - val_loss: 0.0829 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.07836\n",
      "Epoch 171/200\n",
      " - 1s - loss: 0.0146 - acc: 0.9984 - val_loss: 0.0820 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.07836\n",
      "Epoch 172/200\n",
      " - 1s - loss: 0.0145 - acc: 0.9986 - val_loss: 0.0828 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.07836\n",
      "Epoch 173/200\n",
      " - 1s - loss: 0.0145 - acc: 0.9989 - val_loss: 0.0813 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.07836\n",
      "Epoch 174/200\n",
      " - 1s - loss: 0.0144 - acc: 0.9992 - val_loss: 0.0836 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.07836\n",
      "Epoch 175/200\n",
      " - 1s - loss: 0.0144 - acc: 0.9989 - val_loss: 0.0817 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.07836\n",
      "Epoch 176/200\n",
      " - 1s - loss: 0.0144 - acc: 0.9989 - val_loss: 0.0798 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.07836\n",
      "Epoch 177/200\n",
      " - 1s - loss: 0.0144 - acc: 0.9989 - val_loss: 0.0827 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.07836\n",
      "Epoch 178/200\n",
      " - 1s - loss: 0.0143 - acc: 0.9984 - val_loss: 0.0806 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.07836\n",
      "Epoch 179/200\n",
      " - 1s - loss: 0.0143 - acc: 0.9984 - val_loss: 0.0802 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.07836\n",
      "Epoch 180/200\n",
      " - 1s - loss: 0.0142 - acc: 0.9989 - val_loss: 0.0804 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.07836\n",
      "Epoch 181/200\n",
      " - 1s - loss: 0.0143 - acc: 0.9984 - val_loss: 0.0828 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.07836\n",
      "Epoch 182/200\n",
      " - 1s - loss: 0.0142 - acc: 0.9986 - val_loss: 0.0836 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.07836\n",
      "Epoch 183/200\n",
      " - 1s - loss: 0.0142 - acc: 0.9984 - val_loss: 0.0831 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.07836\n",
      "Epoch 184/200\n",
      " - 1s - loss: 0.0142 - acc: 0.9992 - val_loss: 0.0833 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.07836\n",
      "Epoch 185/200\n",
      " - 1s - loss: 0.0141 - acc: 0.9992 - val_loss: 0.0833 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.07836\n",
      "Epoch 186/200\n",
      " - 1s - loss: 0.0141 - acc: 0.9992 - val_loss: 0.0844 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.07836\n",
      "Epoch 187/200\n",
      " - 1s - loss: 0.0141 - acc: 0.9984 - val_loss: 0.0836 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.07836\n",
      "Epoch 188/200\n",
      " - 1s - loss: 0.0140 - acc: 0.9992 - val_loss: 0.0840 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.07836\n",
      "Epoch 189/200\n",
      " - 1s - loss: 0.0140 - acc: 0.9989 - val_loss: 0.0818 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.07836\n",
      "Epoch 190/200\n",
      " - 1s - loss: 0.0140 - acc: 0.9992 - val_loss: 0.0817 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.07836\n",
      "Epoch 191/200\n",
      " - 1s - loss: 0.0139 - acc: 0.9986 - val_loss: 0.0810 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.07836\n",
      "Epoch 192/200\n",
      " - 1s - loss: 0.0139 - acc: 0.9989 - val_loss: 0.0817 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.07836\n",
      "Epoch 193/200\n",
      " - 1s - loss: 0.0139 - acc: 0.9992 - val_loss: 0.0821 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.07836\n",
      "Epoch 194/200\n",
      " - 1s - loss: 0.0139 - acc: 0.9984 - val_loss: 0.0830 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.07836\n",
      "Epoch 195/200\n",
      " - 1s - loss: 0.0139 - acc: 0.9986 - val_loss: 0.0822 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.07836\n",
      "Epoch 196/200\n",
      " - 1s - loss: 0.0138 - acc: 0.9989 - val_loss: 0.0813 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.07836\n",
      "Epoch 197/200\n",
      " - 1s - loss: 0.0138 - acc: 0.9989 - val_loss: 0.0801 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.07836\n",
      "Epoch 198/200\n",
      " - 1s - loss: 0.0138 - acc: 0.9989 - val_loss: 0.0818 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.07836\n",
      "Epoch 199/200\n",
      " - 1s - loss: 0.0137 - acc: 0.9989 - val_loss: 0.0822 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.07836\n",
      "Epoch 200/200\n",
      " - 1s - loss: 0.0137 - acc: 0.9989 - val_loss: 0.0821 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.07836\n"
     ]
    }
   ],
   "source": [
    "\n",
    "my_model_augement.compile(optimizer='adagrad', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "checkpointer = ModelCheckpoint(filepath='weights.best.mobile_model_augement.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "history1=my_model_augement.fit(train_tensor_aug, y_train_aug, \n",
    "          validation_data=(valid_mobile, y_valid),\n",
    "          epochs=200, batch_size=10, callbacks=[checkpointer], verbose=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEWCAYAAABbgYH9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3Xl4VOXZ+PHvnclkg4QlhDXsIBAhIkZErUJdqqgVt1ZprdYutFZr3/a1LtXavlRr9bWttVp/tZaqdaHWpW4oKrKp+Coge1giggQCJAESsmcy9++Pc2ZyZjJJhsgEgftzXXPlnOec85znTJK551nOc0RVMcYYYw62pENdAGOMMUcmCzDGGGMSwgKMMcaYhLAAY4wxJiEswBhjjEkICzDGGGMSwgKMMR0gIkNEREUkOY59vy0i73ZGuYz5IrEAY454IrJFRBpEpFdU+go3SAw5NCUz5shmAcYcLT4FpodWRGQckH7oivPFEE8NzJiOsgBjjhb/BK7yrF8NPOHdQUS6icgTIlIqIltF5HYRSXK3+UTkPhEpE5HNwPkxjv27iJSIyHYRuVNEfPEUTET+LSI7RaRCRBaJyLGebeki8nu3PBUi8q6IpLvbviQi74vIPhHZJiLfdtMXiMj3PHlENNG5tbbrRGQTsMlN+5ObR6WILBOR0zz7+0TkFyLyiYjsd7cPFJGHROT3Udfyioj8VzzXbY58FmDM0eIDIEtExrgf/JcDT0bt82egGzAMmIwTkK5xt30fuAA4HigALos69nEgAIxw9/kK8D3i8zowEugNLAee8my7DzgBOAXoCdwEBEVkkHvcn4EcYDywIs7zAVwEnATkuesfuXn0BJ4G/i0iae62n+HU/s4DsoDvADXuNU/3BOFewJnAMwdQDnMkU1V72euIfgFbgLOA24G7gXOBt4BkQIEhgA+oB/I8x/0AWOAuvwP80LPtK+6xyUAf99h0z/bpwHx3+dvAu3GWtbubbzecL4C1wHEx9rsVeLGVPBYA3/OsR5zfzf+MdsqxN3ReYAMwrZX9CoGz3eXrgTmH+vdtry/Oy9pfzdHkn8AiYChRzWNALyAF2OpJ2woMcJf7A9uitoUMBvxAiYiE0pKi9o/JrU3dBXwNpyYS9JQnFUgDPolx6MBW0uMVUTYR+W+cGld/nACU5ZahvXM9DlyJE7CvBP70OcpkjjDWRGaOGqq6Faez/zzghajNZUAjTrAIGQRsd5dLcD5ovdtCtuHUYHqpanf3laWqx9K+bwDTcGpY3XBqUwDilqkOGB7juG2tpANUAxme9b4x9glPo+72t9wMfB3ooardgQq3DO2d60lgmogcB4wB/tPKfuYoZAHGHG2+i9M8VO1NVNUm4FngLhHJFJHBOH0PoX6aZ4EbRCRXRHoAt3iOLQHeBH4vIlkikiQiw0VkchzlycQJTuU4QeG3nnyDwCzgDyLS3+1sP1lEUnH6ac4Ska+LSLKIZIvIePfQFcAlIpIhIiPca26vDAGgFEgWkTtwajAhjwK/EZGR4sgXkWy3jMU4/Tf/BJ5X1do4rtkcJSzAmKOKqn6iqktb2fxjnG//m4F3cTq7Z7nb/gbMBVbidMRH14CuwmliW4fTf/Ec0C+OIj2B09y23T32g6jtNwKrcT7E9wD3AEmq+hlOTey/3fQVwHHuMX8EGoBdOE1YT9G2uTgDBja6ZakjsgntDzgB9k2gEvg7kUO8HwfG4QQZY8JE1R44ZozpOBE5HaemN8StdRkDWA3GGPM5iIgf+AnwqAUXE80CjDGmQ0RkDLAPpynw/kNcHPMFZE1kxhhjEsJqMMYYYxLiqL7RslevXjpkyJBDXQxjjDmsLFu2rExVc9rb76gOMEOGDGHp0tZGrBpjjIlFRLa2v1eCm8hEZJaI7BaRNa1sFxF5QESKRGSViEzwbLtaRDa5r6s96SeIyGr3mAfEnZtDRHqKyFvu/m+5N8MZY4w5RBLdB/MYzsSCrZmKM4vsSGAG8DA4wQL4Fc5srxOBX3kCxsPuvqHjQvnfAsxT1ZHAPDx3WhtjjOl8CQ0wqroI5y7j1kwDnlDHB0B3EekHnAO8pap7VHUvzkR657rbslR1iTrD357AmXY8lNfj7vLjnnRjjDGHwKHugxlA5JQUxW5aW+nFMdIB+rhzQqGqJSLSO9YJRWQGTg2IQYMGtdje2NhIcXExdXV1Hbmew1JaWhq5ubn4/f5DXRRjzBHkUAcYiZGmHUiPm6o+AjwCUFBQ0OLY4uJiMjMzGTJkCJ6p149Yqkp5eTnFxcUMHTr0UBfHGHMEOdT3wRQTOQV6LrCjnfTcGOkAu9wmNNyfuztSoLq6OrKzs4+K4AIgImRnZx9VNTZjTOc41AHmZeAqdzTZJKDCbeaaC3xFRHq4nftfAea62/aLyCR39NhVwEuevEKjza72pB+woyW4hBxt12uM6RyJHqb8DLAEGCUixSLyXRH5oYj80N1lDs7U6EU406H/CEBV9wC/wZmi/CNgppsGcC3O8ymKcJ6y97qb/jvgbBHZBJztrpsvqPpAE898+BmBpsNzfsTFm0rZsHP/oS7GYefdTWWs31l5qIthOklC+2BUdXo72xW4rpVts2h+Foc3fSkwNkZ6OXBmx0r6xVFeXs6ZZzqXsXPnTnw+Hzk5zg2zH374ISkpKe3mcc0113DLLbcwatSohJb183h5xQ5ufWE1fbJSOWN0n0NdnAPS2BTkR08uZ+yAbjwzY9KhLs5ho7EpyLVPLuPYAVnMnnHyoS6O6QSHupPfRMnOzmbFihUA/PrXv6Zr167ceOONEfuoKqpKUlLsCug//vGPhJfz81qwsRSAdTsqD7sAs2zrXvbXB1i6dQ9V9QG6ptq/UTyWh963LXvZX9dIZpqNWjzSHeo+mMNa6f469lTXh9cbAkG2lldT39hEoCnIlrJq6hqbCAaVLWXVVNcH4s67pKKWmgZn/50VtXy0ch1jx47l6u9+n/zxx1NSUsKMGTMoKCjgmNFjuONXvw4f+6UvfYkVK1YQCATo3r07N998M3ljxzHxpEns3t089kFVKamoZU91Q9zlen5ZMec/sJhL/vIeK7bti/s4gI279nPd08vZXVnHu5vKAFhXcuDNJarKfz+7krfW7Qqnrdi2j+8/sZTahqaIfXfsq+Waf3zI9n0H70m+C93g2NikvFdUFrHt0cWbeXjBJ20e/+bandzxUszJLcK817OlrJrvPf4RFbWNre6/p7qB7z3+EUW7I5vtmoLK9U8vD7/fHbGnuoHvPPYRn5RWdTgPaH7fAkHl/U/KuW/uBp5YsqXd46rqA/zgn0s5/4HF3PrCKoLB+AaObnL/3sqq6vmsvIZv/O0Dzn9gcczfz38+3s5vXl2HqvLaqhJufWHVgVxaC/H8HbRm2da9THvwXc5/YDHnP7CYq2Z9SF1jE1vLq/nuYx9Rut+5nmv+8SG79zcPznn8/S384a2Nn6vcB5t99WrD/7yylnU7Wv8ArG1oAoF0vw+A+kCQQFMQX5KQJEJjUxB/chI+Eeoam0hKEk4Y1INfXXhsm+cNNAUp219PVV2AzIYAu/fXU15dz7p167j93j9z02/uo3+/LH73u9/hz8hk084Krv3GNK64/Ovk5eVF5FVRUcGEk07lmz++lT/d9UtmzZrFLbc4kxzsrwtQur+eJBGI85/20Xc/ZU91PU1B5ZbnV/HaDafhS2p/kICqcvuLa/hwyx6K99ZSUdtI19Rk1rbx/ramaHcVzy8vZtGmUk4enk2638cvXljNupJK3isq46y85hrRyyt3MH9DKXfPKeTBb0xoI9f4LdhQyoRB3dm4q4qFG0s559i+ABSWVPLbOYUocNrIXowd0C3m8Y+++ykffrqH//7KKLqlt/wW3xTUiOtZsW0fbxfu5p31u7j4+NwYOcL9b2/k7cLdDO/dlVunjgmnr9i2j1dXlbCyeB9v/XQyae7f6oF4Y81O3lm/m0BQeeI7Ew/4+BDv+/aX+UWsLK6gb1Ya35o0uM2BJg8vKGLu2l1MHNqTZz7cRsHgnlx6Quz3IURVue0/a/jw0z1kpSVTur+eFdv2MSynC/e8sZ4vjejFuFzn97O7so5fvLiamoYmRvfN5K45heyraeRHU0YwsGfGAV/n+p3O30FQiThPvF5bVUJhyX5OP6YX+2oaWbSxlNXbK1i5bR/z1u/m929uoKyqgfkbSnl99U6uPmUIn5XXcNdrhaQmJ/HTs0Z+YQbuWA3mc1AIf5sKqhJoCpIkQlNQaXQ7r5uCSlNon6BS29gU3hY6zrusqlTVB1A3/301zrfWQJMydNgw8vKPpymo1DQ08cwzz3DqpIlcMXUyGzesZ926deG8GpuCNAaCpKenM27SFABG5uXz6aefEgwqDYEgJRV1pPiSUKCitpGdFXXsrKhr8U25yd1/V2UdhSWVXHPqUGZOG8v6nfv510fbiKWsqj6c386KOp5fvp0Pt+xheE4XVm7bR5LAFScOZGt5DfvrGqmsc87fGNXp710PLS/Y4HwTLt1fzwPzNvHkB1vDNaHQt+SQhe6+r64qYdlWZ5yIqrKzoo69MWpuuyvrKKuqb5EOUNfYRGFJJYUllZyV14dThmezcENpuMnyztfWkZXup2dGCjNfXRdx/Tsr6mgIBKmsa2T51r0ArC+pRFWpa2yudZVV1be4ntA1ha4l+j3atGs/T/3fZzH3CR27bU8tj72/JeK4+kBTRPlCz4YKNAUj/g4WbnRqvYs2ljJ/Q4dG/7O7so51nvdtZXEFADsr69i4q/WaUfHeGv62+FMuGt+f2d+fxHG53bh37nq27amJqK1G/729+PF2PvzU+Xt75sNtvF24mx+fMZKnvz+J7C4p/Mbz+7nnjQ00NgUZ2DOdm55fFf6fW7CxtMXvpz2qyp2vFpKZ5m9xnvKov6vQ/2G0dSUV5PXP4tGrTwx/KVq7vSL8ZXf2R9t4u9CpvS9wfx93v15IQ1OQ/fUBivc219ar6wMt/g5Dr8q61mvEB4vVYNrwq6+2XdNYt6OSQDDIyN5d2VlZT21jE8f07kpRaRVNQaVnlxRK99eTnJREeoqPYFCpbghQWFJJv25p9MhIYdPuKnpkpJCTmcqm3fvJSvPTFFR8SUJGivNts29WGp8B/lTn25QAK9eu509/+hPPv7EATcng1htmUFVTAzhNdZ+WVePbWUmy308gGKRvVhqSlERtfSMbd+8P/2EPye5CdUOAnQ1NTLp7HgApyUk8ds2JnDK8FwA3PbeKwpJKvnXyYAAmH5PD6L6ZTBzSkz+8tYGvHtcvoj390cWbufO1whbv16g+mTz9/ZM44/cLGdm7K6eMyObRdz/liSVbeWDeJuoDQfJzu/H8tafg9yWxubSKi//yPjedO4ozRvfmggfeZcbpw1i8qYxj+nQlr18WjyzaDMCEQd3pkZHCgo27UVVEhCq3n+Sqkwczd+1OZr5ayIvXnsJ1Ty/n9TU7SRL44+XjmTbemQziN6+u4+/vfgrArVNH84PJw8NlV1XOuX8RW8ud9/jLo3rTLd3Pm+t2sfyzfeytbuC9onJ+/dU8kn1J3P6fNeH3M2RE7678+IwRBNwvHGt3VLKquIKHF37Cmz89nZdW7OA3rzpfEo4f1J3sLim8vmYnZVX1+H3Cok1lvLN+Fzc8s4JHvnUCp4xwfj93zSkkI8XHN04axF8XbmbJJ+X88Mll/PycUSzcsJsTBvege7qfB98p4rITcunVNZXq+gDnPbA4fD0Alxw/gP/92nF87a9L+PizfaQkJ/G3qwp4r6icr52Qy9Kte7nrtUK+NKIXft+BfTcNBbopx/SmZ0YKb67bxc/PGcX/zt3Agg27GdU3M+Zx97yxgSSBm84dTVKScPsFeXzt/y3htHvnk5OZyus/OS3iffM6pk9Xnvn+JM78w0K6piZzzalDSPP7+OnZx7T4/Xz/tKGcMqIX1/zjIy4vGMiSzeUs3LCb0so6nv7wM969+Yy4an/vrN/Nu0Vl/OqreaQkJ3Hbi5HnefSqgnAN+8/vFPHc8m0suPHL4VYAVWXdjkq+elx/APpkpZLdJYV1JZWsK6nkhME9+KS0iq6pyZw2shcvfrydxZtKeX3NTs4a05u3C3ezdkcFA3tm8GlZNdMefJfKuthN8z+cPJxbpo5u95o+Dwswn0Oo9lHd0ERVfYBeXVNI9iUxrFdXtzbifMsOBINkpqXSPd1PZV0j+2oa2VVZT02DU5spraqnoSlIQyBIWVU9PhG6piXTNTWZlPRUcjJTSfUnAUpGSjICFJXvITMzk+S0LpSV7mLJwnf46vnnUdvQRCAYpGtqMgN6pCMiDM/pSrrfh4hQ3RCgIRCkb7c00v0+uqYm0zUtmR1dUrj7knEAPPhOETNfWcdrN5xGUJU31+5kf32A372+nj5ZqYzum4mIcPsFY7jwwfd4aP4n4T/U3ZV1/OGtjZwyPDv8TxJy5pjeZHdN5V8/mES630dqsvMP+/s3N9A3K41LJuTy4PwinvnwM646eQi/nVNIRW0j97y+ngUbSimvbuD+tzfRFFSuPmUwPz37GE4bmUMgGOTsvL68tmoH89bv5tOyaobldOX9ojIam5Rzx/YlP7c7N/57JTc/v4rX1+xk+sSBrN5ewZ2vFXLWmD5s21vDP977lKlj+7K/LsD9b29i2vgB9O2WBjh9RVvLa/jmSYOYfEwOY/plMbBnBn98ayN3vbaOfTWNDM/pwjcnDcYnQk5makTfVnlVPfe9uZE7XlpLZmoyKclJrCup5JPSKvZUN3DHS2tYuKGUk4dlc9Hx/Z3rWV3C24XON9RrTh3KI4s289N/raSqPsDMV53fz7tFZSzYUMpt543htGN68deFm/nhk8uc9+2N9VTVB/jpWcdwfn4/zvnjIv7w1kZ+e/E4Hl7wCVvLa7hl6mi6pftZtnUvzy0rxpckfPzZPq6dMpxXVu7ghmc+pqo+wFl5fTg7rw8z/rks/Ps5EAs2ltI7M5Ux/TIZ0bsrfbLSmDIqh1dW7mDhxtKIYB6ybOtepwxnjKB/93QAThzSk9kzJrG+pJI7XysMv2+ThvUMf1EI/72Ndv7enr/2FNL8vnCA+MbEQRG/n4wUH1PH9sPvE579wcnk53bjrtcK+feybSzaWEZDU5CPtuzhtJFtP/6ksSnIXXMKGZbThStDfwddUyl3z/O719c7gcANMK+u2sG2PbWs3l7B+IHdASjeW0tlXYC8/lmAc49aXv8sPv5sH5+WVfODycO497J80vw+Nu7czzMfbuP6pz+mX7c0/vey4zjhzrdYt6OSc8f247dzCmkKKndeNDZmM/aYfllx//46ygJMB6lqOMCUVdWjqmS6o4lSkpPC+/h9STQ2BclMTSbZl0TPLql0SU1m464qKmob6ZbuZ39dgH01DWSl+alpCBAIKplpfkSE1OQkRIQubt6Zac7PYaPHMXr0GC6YchLDhg3j+BMnUV0fcDuzhd6ZqWR3SUUgfGyaPwlV6J6RQu/MtPC1CM4/2fTjBoXPcf3TH/PvpdsY2qsL++sDdM/ws6+mkXOOzQ237+bndueSCQOY9e6n9MlKxe9L4p31u2lsCvLbi8cxpFeXmO/d6L5Z4fcnu0sK5dUN3Dx1NBce15+lW/fwx7c2sqe6gbcLd3PZCbm8sLyYt9bt4uLjB/DaqhIamoJMGdWbjJTkiLb4KaN6A2t5cH4REwb1YO7anXRJ8VEwuCfJQ4XH39/Cv5cVMyQ7g/+5cCxrdlRwyV/e5xcvrmbbnhoy0/zcfck49tcFOPP3C7n5+VWcO7Yv543tF26W+8lZI8PvXdfUZG78yihueWE1ALO+XRD+Zh/ql/FaVVzBm+t2ce6xfaltbOKDzeXs2FdL9ww/c1bvxO8T7r6k+X2bcozzgdarayozTh/G3xZvpqK2kStOHMjsj7Yx85W1vFtUxuDsDK46ZTApviT6ZqWxs7Iu/L6pOjXO4TlduXLSYJ5YsoWBPTL42+LNXHhcf37ofrBfNH4A7xeV8e9lxZw4pAc3nTOKsf27cd3Ty0lOEk4Znk3X1GROHpbNH9/aiIggQGpyEhfk9yc9xcf7RWVsLqsGwJcknDe2H90y/ASagry7qYyv5PVBREhJFr482pkqcPIxOcx671P+uWQLIkJmWjLnjeuHT4TfvLqO3pmpLYLPpGHZTBqWzZbyGh57f4v7vuUztJW/t+E5XSPWk5Ik5u8HYOLQnuFy/fODraT7faRIktt/1IPXVpe0aNY6a0wf+nZL48kPtrK5tJq/X938d/AVz3neKypj4cZSgkGlpLKOTbudpsEFG3YzLKcLm3btp6zKCUZ5ng//vH5ZLHYHaeT16xa+np4ZKaQkJ1FR28j/XHgsPbqkMDynK+tKKnn/kzLecmuJV04aHPNaO4MFmA7y9ok3BJy+l4yo4aoiQrd0P9X1AVI91evUZB+93W9QA7qns6+mkd376+nfPZ2q+kZ27KsjMy2ZX//61+Fjxh87mn+/+S5Z6X5Q2FVZx11/+iuVdY0Mzu5CdX2Asqp6ahoCvDV/AdldUgHYt695pNeV3/gGZ55/MX2zmoNLLOeP68djg7dw35sbOX9cX5KThL9eeQJXzfqQqeP6Rex70zmjWbSxlP95pbmJ4oYzR7YaXKLfn0nDsynbX8+Fx/VHRPjlBXlc/tcPuP/tTRzTpyt3XjSWnl1SeGPNTmZOO5ZBPTN4+sPPKBjS8nE/A3tmMG5AN15Yvp0Xlm8H4KLx/cMB/1dfzeM7j33EHW7zxYRBPZg+cSDPfLgNEfjtxePonpFC94wUfnzGCH7/1kYWbixlzuoS6huDHNs/KyIwA3ytYCDPLSsmu2sKXx4Vc37VsF+cN4b3iso4L78fhSWV4WajP359PLe9uJrLCgZGvG8De2Zw3MDujM/tRq+uqZwyPJu0ZB93XzKOkoo6Hl+yFb9P+H9XnhCuDZ6f34/5G3Zz50VjyUrz81bhTsa5gw3+66yRvLl2J/e8sZ6eXVK42dM8kp7i45cX5HHLC6v55QV5iAjnjevLqSOcc4aaQH95QR5f/+sSfvmf5lFwS7fs5dITcvnGo/8Xcb1zVpfwxHcmsrJ4HxW1jUwe1bIGcO7Yvvx10WZ++dLacNqWshqG9MpgxbZ9/O9l+eEvSNFC13PZCbmtBpeOOmVENj0y/Hz/9GEs+aSchRtLKauq56UVO1rs+/j7W3hmxiTuf3sTXxrRizNGx/47mDKqN6+uKmFdidM0CtA7M5WFG0tZVVzBO+t3c8bo3iRJ85cwIFybATjWs5ye4uOsMb0p29/AhW5rwbH9s/hg8x7ufLWQAd3T+e6XDu38gqJ6QHNFHlEKCgo0+omWhYWFjBkzppUjmjU2BSksqUREUFWy0vwxP1RD72+sUR2hvoLo5aCqM7Irijd9a3l1uBN2dN9M/L4kAkFFgORW2sdVFYWYeUdf98pt+5j20HuA863u2R+cTEMgGP6w9qprbAp3GPpEyO6aGvP8sQSDTk3QW+bq+gDVDQG6p6eEzxdoCpLsS0JVaWzSmOUAJ9jvq21umsrukhrRPBDKJ0RVKatqwO8TumdE3sRaXlXPv5cV87vX1wPwoynDuenclm3WTUElSeKbcif0Hr6ycgc/fuZjemT4WXr72WjUe+Atb5IISUkSHiziSxKCQaWsup40v48sT/+XqhIIOjVn73JI6HeVmeonPaVln0L0+xNoCiIiEe9h6PcD8Jf5n/D4ki0M7plBfSDIc9eegt8nvLB8O797fT2zvl3Ais/28eD8Ipb/8uwW7zE4A0zqA05H+h3/WcvCjaV0S/fTKzOFl6/7EkltjFKMLu/BFPpd/f3dT8N9PD84fRjfPa35Q3vJJ+X8ZPYKhvXqwpbyaub85LSI4OC1e38dE++ax8/PGcWq4n2s2V7JZSfk8qd5mwAQAVWnr+7tn00OH1e0ez9n/WERXVJ8rP71ORHvR/T/zyOLPuG3c5y/1wemHx8OPAebiCxT1YL29rNRZB0Uah7LcGsmoaaraCLS6gePN927HCsARKf37ZYW/sf3+5xmNL8vqc1/NhFpNe9oxw3szsXHO23aU9xvnq19qKf5ffTOTKN3ZtoBBRdwmiuiy9wlNZnemWkR5wvt4zSxtH6NKclJ4bL0zkxr0fYcfS5x+0tiffBld03lu18ayrBQk1UrNRRfUuu/41jlg+ZvpaeNzMEX4z3wljf0geJLav6gT0oSememRQSX0PX4Pe9VdGd86HcVK7iEzhe9Hv0ehn4/vTPT+OnZx9A93c+W8hpuOncUA7qn0zszLfy+3fz8ap7+8DOOH9Qj5nsM0C3dH87vF+eNoSmo7Kys4/bz89oMLrHKezCFfleT3abKnMxUbjhzZMTf14XH9WfSsJ5sLqvm8hMHtRpcAHpnpnFs/ywee38LCzeWMnlUTvh/a1DPDH7tDirKi+obGdqrK2n+JMb0y2rxfkT//+T1c2qrEwZ156v5ka0Nh4I1kXVQ0G2G7Zbhx5ckMe9nSKTUZB/9uqXRFNS4P9wO1C1TR7O/LtCi8/Ro4vclcfcl43jy/z7j+EHdD1q+Q7O7cOmEXKZPHNj+zl9g3dL93HvZcSzeVMq045r/Tvy+JP73a/ncPWc9jU1BvnNqfE01g7Iz+M1Fx7JjXx2ThmUnqtgHZHhOFy4vGMjZeX1aNNeJCHdeNJY/v1PEf3/lmHbz+v5pw5j13qfk9kjn8oKBjB3QjWnj+3N5wUBOGpbNmu0VXBBV6/AlCT+cPDyuZsAJg7tzzrF9+MmZx3wh7oWxJrIONpFV1wf4pLSKob26HBFTXsR73cYYY01kCRZqIou3yckYY442FmA6KDSKLI5ZUowx5qhkAaaD2hod9nlMmTKFuXPnRqTdf//9/OhHP2r1mK5dnXHxO3bs4LLLLms13+jmQGOMSaREP3DsXBHZICJFInJLjO2DRWSeiKwSkQUikuvZdo+IrHFfl3vSF4vICve1Q0T+46ZPEZEKz7Y7EnltoSGjB7uJbPr06cyePTsibfbs2Uyf3uajdQDo378/zz333EEtjzHGdFTCAoyI+ICHgKlAHjBdRPKidrsPeEJV84GZwN3usecDE4DxwEnAz0UkC0BVT1PV8ao6HufNt5d/AAAgAElEQVRpmS948lsc2qaqMxN1beBpIjvI7+Bll13Gq6++Sn29MzHeli1b2LFjB+PHj+fMM89kwoQJjBs3jpdeavlE6C1btjB2rPMsttraWq644gry8/O5/PLLqa09eNPVG2NMPBI5THkiUKSqmwFEZDYwDfDOSpcH/NRdng/8x5O+UFUDQEBEVgLnAs+GDhSRTOAM4JqEXcHrt8DO1TE3dWsKkh4I4kv14Uy2Eqe+42Bq609zzs7OZuLEibzxxhtMmzaN2bNnc/nll5Oens6LL75IVlYWZWVlTJo0iQsvvLDVJrqHH36YjIwMVq1axapVq5gw4eBMVW+MMfFKZBPZAMA7l3uxm+a1ErjUXb4YyBSRbDd9qohkiEgv4MtA9A0DFwPzVNX7QJGTRWSliLwuIm1Phfw5KQoCciDBJU7eZrJQ85iq8otf/IL8/HzOOusstm/fzq5du1rNY9GiRVx55ZUA5Ofnk5+ff9DLaYwxbUlkDSbWJ2/0TTc3Ag+KyLeBRcB2IKCqb4rIicD7QClOU1j0nNPTgUc968uBwapaJSLn4dSGRrYolMgMYAbAoEGD2r6CNmoa5ftq2VvTwLH9D+xhQvG46KKL+NnPfsby5cupra1lwoQJPPbYY5SWlrJs2TL8fj9Dhgyhrq6uzXy+CDdaGWOOXomswRQTWevIBSJmilPVHap6iaoeD9zmplW4P+9y+1LOxglWm0LHubWcicBrnrwqVbXKXZ4D+N3aTwRVfURVC1S1ICen7em32xIMxp4v7GDo2rUrU6ZM4Tvf+U64c7+iooLevXvj9/uZP38+W7dubTOP008/naeeegqANWvWsGrV53sErDHGHKhEBpiPgJEiMlREUoArgJe9O4hILxEJleFWYJab7nODCCKSD+QDb3oO/RrwqqrWefLqK+5XdhGZiHNt5Qm5MlqfkPJgmT59OitXruSKK64A4Jvf/CZLly6loKCAp556itGj235Q0LXXXktVVRX5+fnce++9TJzY8UfdGmNMRySsiUxVAyJyPTAX8AGzVHWtiMwElqrqy8AU4G4RUZwmsuvcw/3AYjdeVAJXuh3+IVcA0e1XlwHXikgAqAWu0ATOgxPUxN5kefHFF+Mtfq9evViyZEnMfauqnOdKDBkyhDVrnGnU09PTWwx3NsaYzpTQyS7dpqo5UWl3eJafA1rcuOHWTKKHNHu3T4mR9iDw4Oco7gFpSnANxhhjDnd2J38HqWq7U4kbY8zRzAJMDPG0rAWDR848ZEfzjNrGmMSxABMlLS2N8vLydj90E93J31lUlfLyctLS2n6MsjHGHCh74FiU3NxciouLKS0tbXO/kn21pKf4qNoV+yl9h5O0tDRyc3Pb39EYYw6ABZgofr+foUPbf/reRbe/ztWnDOEX59lDuowxJhZrIuuApqBSHwiS7o/9XHNjjDEWYDqktrEJgIwUCzDGGNMaCzAdUNPg3POZkWotjMYY0xoLMB1Q2+DWYKyJzBhjWmUBpgNqGqyJzBhj2mMBpgNCTWTpFmCMMaZVFmA6oLkGY30wxhjTGgswHWBNZMYY0z4LMB2QkeJj7IAsuqX7D3VRjDHmC8vaeDrgtJE5nDay40/DNMaYo4HVYIwxxiREQgOMiJwrIhtEpEhEbomxfbCIzBORVSKyQERyPdvuEZE17utyT/pjIvKpiKxwX+PddBGRB9xzrRKRCYm8NmOMMW1LWIARER/wEDAV5+mU00Uk+imV9wFPqGo+MBO42z32fGACMB44Cfi5iGR5jvu5qo53XyvctKnASPc1A3g4MVdmjDEmHomswUwEilR1s6o2ALOBaVH75AHz3OX5nu15wEJVDahqNbASOLed803DCVaqqh8A3UWk38G4EGOMMQcukQFmALDNs17spnmtBC51ly8GMkUk202fKiIZItIL+DIw0HPcXW4z2B9FJPUAzoeIzBCRpSKytL1nvhhjjOm4RAaYWI97jH5M5I3AZBH5GJgMbAcCqvomMAd4H3gGWAIE3GNuBUYDJwI9gZsP4Hyo6iOqWqCqBTk5NhLMGGMSJZEBppjIWkcusMO7g6ruUNVLVPV44DY3rcL9eZfbx3I2TvDY5KaXuM1g9cA/cJri4jqfMcaYzpPIAPMRMFJEhopICnAF8LJ3BxHpJSKhMtwKzHLTfW5TGSKSD+QDb7rr/dyfAlwErHGPfxm4yh1NNgmoUNWSBF6fMcaYNiTsRktVDYjI9cBcwAfMUtW1IjITWKqqLwNTgLtFRIFFwHXu4X5gsRNDqASuVNVQE9lTIpKDU6tZAfzQTZ8DnAcUATXANYm6NmOMMe0T1RbdFEeNgoICXbp06aEuhjHGHFZEZJmqFrS3n93Jb4wxJiEswBhjjEkICzDGGGMSwgKMMcaYhLAAY4wxJiEswBhjjEkICzDGGGMSwgKMMcaYhLAAY4wxJiEswBhjjEkICzDGGGMSwgKMMcaYhLAAY4wxJiEswBhjjEkICzDGGGMSwgKMMcaYhEhogBGRc0Vkg4gUicgtMbYPFpF5IrJKRBaISK5n2z0issZ9Xe5Jf8rNc42IzBIRv5s+RUQqRGSF+7ojkddmjDGmbQkLMCLiAx4CpgJ5wHQRyYva7T7gCVXNB2YCd7vHng9MAMYDJwE/F5Es95ingNHAOCAd+J4nv8WqOt59zUzMlRljjIlHImswE4EiVd2sqg3AbGBa1D55wDx3eb5nex6wUFUDqloNrATOBVDVOeoCPgRyMcYY84WTyAAzANjmWS9207xWApe6yxcDmSKS7aZPFZEMEekFfBkY6D3QbRr7FvCGJ/lkEVkpIq+LyLGxCiUiM0RkqYgsLS0t7ei1GWOMaUciA4zESNOo9RuBySLyMTAZ2A4EVPVNYA7wPvAMsAQIRB37F2CRqi5215cDg1X1OODPwH9iFUpVH1HVAlUtyMnJ6cBlGWOMiUciA0wxkbWOXGCHdwdV3aGql6jq8cBtblqF+/Muty/lbJxgtSl0nIj8CsgBfubJq1JVq9zlOYDfrf0YY4w5BBIZYD4CRorIUBFJAa4AXvbuICK9RCRUhluBWW66z20qQ0TygXzgTXf9e8A5wHRVDXry6isi4i5PdK+tPIHXZ4wxpg3JicpYVQMicj0wF/ABs1R1rYjMBJaq6svAFOBuEVFgEXCde7gfWOzGi0rgSlUNNZH9P2ArsMTd/oI7Yuwy4FoRCQC1wBXuQABjjDGHgBzNn8EFBQW6dOnSQ10MY4w5rIjIMlUtaG8/u5PfGGNMQliAMcYYkxAWYIwxxiSEBRhjjDEJ0W6AEZHrRaRHZxTGGGPMkSOeGkxf4CMRedadHTnWHfrGGGNMhHYDjKreDowE/g58G9gkIr8VkeEJLpsxxpjDWFx9MO4NizvdVwDoATwnIvcmsGzGGGMOY+3eyS8iNwBXA2XAo8DPVbXRneJlE3BTYotojDHmcBTPVDG9gEtUdas3UVWDInJBYopljDHmcBdPE9kcYE9oRUQyReQkAFUtTFTBjDHGHN7iCTAPA1We9Wo3zRhjjGlVPAFGvLMSu1PkJ2wWZmOMMUeGeALMZhG5QUT87usnwOZEF8wYY8zhLZ4A80PgFJzHGRcDJwEzElkoY4wxh794brTcrapXqGpvVe2jqt9Q1d3xZO7e+b9BRIpE5JYY2weLyDwRWSUiC0Qk17PtHhFZ474u96QPFZH/E5FNIvIv92mZiEiqu17kbh8STxmNMcYkRjxzkaWJyHUi8hcRmRV6xXGcD3gImArkAdNFJC9qt/uAJ1Q1H5gJ3O0eez4wARiPU2P6uYhkucfcA/xRVUcCe4HvuunfBfaq6gjgj+5+xhhjDpF4msj+iTMf2TnAQiAX2B/HcROBIlXdrKoNwGxgWtQ+ecA8d3m+Z3sesFBVA6paDawEQvOgnQE85+73OHCRuzzNXcfdfqbNm2aMMYdOPAFmhKr+EqhW1ceB84FxcRw3ANjmWS9207xWApe6yxcDmSKS7aZPFZEMEekFfBkYCGQD+1Q1ECPP8Pnc7RXu/sYYYw6BeAJMo/tzn4iMBboBQ+I4LlbtQaPWbwQmi8jHwGScgQQBVX0T5wbP94FngCU4c6C1lWc850NEZojIUhFZWlpaGsdlGGOM6Yh4Aswj7vNgbgdeBtYRX/9GMU6tIyQX2OHdQVV3qOolqno8cJubVuH+vEtVx6vq2TjBYxPOfGjdRSQ5Rp7h87nbu+GZgcBzzkdUtUBVC3JycuK4DGOMMR3RZoBxJ7SsVNW9qrpIVYe5o8n+GkfeHwEj3VFfKcAVOAHKm38v9xwAtwKz3HSf21SGiOQD+cCb7g2f84HL3GOuBl5yl19213G3v+O9QdQYY0znajPAuHftX9+RjN1+kOuBuUAh8KyqrhWRmSJyobvbFGCDiGwE+gB3uel+YLGIrAMeAa709LvcDPxMRIpw+lj+7qb/Hch2038GtBgWbYwxpvNIe1/yReSXQC3wL5x5yABQ1RbNT4ebgoICXbp06aEuhjHGHFZEZJmqFrS3Xzxzin3H/XmdJ02BYR0pmDHGmKNDuwFGVYd2RkGMMcYcWeJ5ouVVsdJV9YmDXxxjjDFHiniayE70LKcBZwLLAQswxhhjWhVPE9mPvesi0g1n+hhjjDGmVfHcaBmtBhh5sAtijDHmyBJPH8wrNE+5koQzEeWziSyUMcaYw188fTD3eZYDwFZVLU5QeYwxxhwh4gkwnwElqloHICLpIjJEVbcktGTGGGMOa/H0wfwbCHrWm9w0Y4wxplXxBJhk94FhALjLKYkrkjHGmCNBPAGm1DM5JSIyDWfafGOMMaZV8fTB/BB4SkQedNeLgZh39xtjjDEh8dxo+QkwSUS64sy+vD/xxTLGGHO4a7eJTER+KyLdVbVKVfeLSA8RubMzCmeMMebwFU8fzFRV3RdaUdW9wHmJK5IxxpgjQTwBxiciqaEVEUkHUtvYP0xEzhWRDSJSJCItnjApIoNFZJ6IrBKRBSKS69l2r4isFZFCEXlAHJkissLzKhOR+939vy0ipZ5t34unjMYYYxIjnk7+J4F5IvIPd/0a4PH2DhIRH/AQcDbOwICPRORlVV3n2e0+4AlVfVxEzgDuBr4lIqcApwL57n7vApNVdQEw3nOOZcALnvz+paodesSzMcaYgyueTv57RWQVcBYgwBvA4DjynggUqepmABGZDUwDvAEmD/ipuzwf+E/otDiPBkhxz+kHdnkzF5GRQG9gcRxlMcYY08ninU15J87d/JfiPA+mMI5jBgDbPOvFbprXSjdPgIuBTBHJVtUlOAGnxH3NVdXoc07HqbGoJ+1St7ntOREZGKtQIjJDRJaKyNLS0tI4LsMYY0xHtBpgROQYEblDRAqBB3GChajql1X1wdaO82YRI02j1m8EJovIx8BkYDsQEJERwBggFyconSEip0cdewXwjGf9FWCIquYDb9NKM56qPqKqBapakJOTE8dlGGOM6Yi2ajDrcWorX1XVL6nqn3HmIYtXMeCtReQCO7w7qOoOVb1EVY8HbnPTKnBqMx+4Q6OrgNeBSaHjROQ4nClslnnyKlfVenf1b8AJB1BWY4wxB1lbAeZSnKax+SLyNxE5k9i1ktZ8BIwUkaEikoJT43jZu4OI9BKRUBluBWa5y5/h1GySRcSPU7vxNpFNJ7L2goj086xeSHzNeMYYYxKk1QCjqi+q6uXAaGABTmd8HxF5WES+0l7GqhoArgfm4nzYP6uqa0VkpmdusynABhHZCPQB7nLTnwM+AVbj9NOsVNVXPNl/nagAA9zgDmteCdwAfLu9MhpjjEkciewjb2dnkZ7A14DLVfWMhJWqkxQUFOjSpUsPdTGMMeawIiLLVLWgvf3iHUUGgKruUdW/HgnBxRhjTGIdUIAxxhhj4mUBxhhjTEJYgDHGGJMQFmCMMcYkhAUYY4wxCWEBxhhjTEJYgDHGGJMQFmCMMcYkhAUYY4wxCWEBxhhjTEJYgDHGGJMQFmCMMcYkhAUYY4wxCWEBxhhjTEJYgDHGGJMQCQ0wInKuiGwQkSIRuSXG9sEiMk9EVonIAhHJ9Wy7131CZaGIPCAi4qYvcPNc4b56u+mpIvIv91z/JyJDEnltxhhj2pawACMiPuAhYCqQB0wXkbyo3e4DnlDVfGAmcLd77CnAqUA+MBY4EZjsOe6bqjrefe12074L7FXVEcAfgXsSc2XGGGPikcgazESgSFU3q2oDMBuYFrVPHjDPXZ7v2a5AGpACpAJ+YFc755sGPO4uPwecGar1GGOM6XyJDDADgG2e9WI3zWslcKm7fDGQKSLZqroEJ+CUuK+5qlroOe4fbvPYLz1BJHw+VQ0AFUB2dKFEZIaILBWRpaWlpZ/vCo0xxrQqkQEmVu1Bo9ZvBCaLyMc4TWDbgYCIjADGALk4geMMETndPeabqjoOOM19fesAzoeqPqKqBapakJOTc6DXZIwxJk6JDDDFwEDPei6ww7uDqu5Q1UtU9XjgNjetAqc284GqVqlqFfA6MMndvt39uR94GqcpLuJ8IpIMdAP2JObSjDHGtCeRAeYjYKSIDBWRFOAK4GXvDiLSS0RCZbgVmOUuf4ZTs0kWET9O7abQXe/lHusHLgDWuMe8DFztLl8GvKOqLWowxhhjOkfCAozbD3I9MBcoBJ5V1bUiMlNELnR3mwJsEJGNQB/gLjf9OeATYDVOP81KVX0Fp8N/roisAlbgNKn9zT3m70C2iBQBPwNaDIs2xhjTeeRo/pJfUFCgS5cuPdTFMMaYw4qILFPVgvb2szv5jTHGJIQFGGOMMQlhAcYYY0xCWIAxxhiTEBZgjDHGJIQFGGOMMQlhAcYYY0xCJB/qAhw1Ns6FwadCatfI9E8XQ85o6OrOi9ZQ7aSNOjf+vNe/BiPOguRUZ33fNlj3EiT5YNzXoEsv2PAGlG+CbgPh2Iuaj92+DDKyoccQZz1QDx8/CY01zro/HY7/FvhSYMXTUBs1+07vMc65I65nFHTt7azXVcDK2dDUEP/1HIjQ9USfJ70HjP8mNDXCx/9svh5jjKP/BBhyakJPYQGmM1Tthqe/Dl99AE64ujldFZ66DE65Ac64zUlb+yK8dB38bD1k9Ws/7/JPYPY34GuPwbEXO2lLHoL/e9hZbmpw8n/2W80fviOKITXTWX5hBuSeCBf/P2d96/vw2s8iz9F9iBOAXvpRy/OndYdbtkZdz4/hjNudtHUvw+s3tX8dn8fwbbHPM+AE2L+z5fUYY+DU/7IAc0So3+/+rIxMb2qAQF1kel2l55g4AkxdReRxAA37IbOf8+FaX+Wcp6kBMvvD/h1OLSkUYOoqm8vnLet33oSkZHj0DCe/UBkvmwUjv+IsL7wHPnjYcz2N7vXEyO+/1kB69/av50B8/CS8cYtTO/GeZ8fHTkCtr4KGqubr6RP9vDtjjmK+lISfwgJMZ2isdX/WtZJe60lzm3ICtcQlUBf5M5SfP8Np3mqsac6/S7YTYCLOVxvZfBTKJyPbaWIL7RNKT+/ZHJxSu0Ew4AQWn785n4j8QufOAX9afNcUr7Tuzefznie9R/O5Q9eakd1cbmNMp7AA0xnCgaSmlfTattPazDvGh3pEgPF8yKb3jHG+mtgBzp/u1GDC+4TSM5r39ac35+fzt3E90tw/dDB5z+89T6iM3uAZ2tcY02lsFFlnCH27DtS1ku75QA7tE3eAqYv8GTrWn+580AbqmvPPyI48X1MjaFNUQHDz8ad7PsDrItNDQsvhWlQrAcafAYl4enU4kNRFnici8MQotzGmU1gNpjMcUA2mpmXagebdWOs0RyWnRdZQMnrGPqbdGoynFhQrwETn0yLAHOSmsfD505rP7z1PON1qMMYcSlaD6QytBY02m8jiHFbbWpCIp4msrfMnpznNXknJUU1ksQJMO/l5m9UOpoimMM95wuk1kddjjOlUCQ0wInKuiGwQkSIRafEAMBEZLCLzRGSViCwQkVzPtntFZK2IFIrIA+LIEJHXRGS9u+13nv2/LSKlIrLCfX0vkdd2QBpbafZq6wM+ujmtNdHNU6G0UBOXN8CEmsiizxtxbFSTVnK628wWamryBIvkVgJMi/wSVHsIBY1AbeR5vE130ddjjOk0CQswIuIDHgKmAnnAdBGJHid6H/CEquYDM4G73WNPAU4F8oGxwIk4j00GuE9VRwPHA6eKyFRPfv9S1fHu69EEXdqB61AN5kA7+aPySI4VYOKswXi/7YdHornnid52oPkdTNGd/KHzJHua7hJ5fmNMmxJZg5kIFKnqZlVtAGYD06L2yQPmucvzPdsVSANScB6T7Ad2qWqNqs4HcPNcDuTyRdda0GhrWG/cTWStNUuFOvk9/RDhJrKoodCNtc5NkuFjo0aKhTrRISrAeJqoovPzXmOnNJF5zuPzg/iaO/kTdX5jTJsSGWAGANs868VumtdK4FJ3+WIgU0SyVXUJTsApcV9zVbXQe6CIdAe+SnOAArjUbW57TkQGHrxL+ZxijRaD1u9hAVrcM9OatgJMchoR97CEajDRI9W0yRlR5j02xHsvTXI6JHn+ZPyeJqpWy1KXuCayiM58z3lEnKDSWOcGHuvgN+ZQSGSAidXorVHrNwKTReRjnCaw7UBAREYAY3BqJwOAM0Tk9HDGIsnAM8ADqrrZTX4FGOI2t70NPB6zUCIzRGSpiCwtLS3t+NUdiHZrMJ+nkz8qb9XmD1V/RuRIqoyoGkxro9f80U1ktS3ToWUNprXrSViAierMjwiMnhF0iRrFZoxpUyIDTDHgrUXkAju8O6jqDlW9RFWPB25z0ypwajMfqGqVqlYBrwOTPIc+AmxS1fs9eZWrar27+jfghFiFUtVHVLVAVQtycnI+3xXGq91hyjUx0jo4TLmpAdDYnfxp3QCJfY5wrSaqSSt0L02s0WAthinHGHCQyBqELwUkyS1fTYyaV21zJ78xptMlMsB8BIwUkaEikgJcAbzs3UFEeolIqAy3ArPc5c9wajbJIuLHqd0UusfcCXQD/isqL+/EXReG9v9CaK3ZK5Qemm7Fmxb3VDFRo87CnfHp7rd4T4DxDl32nst7XKAusp8ldC9NIEZneWi9Merc3usJ1DV3uh9sIk7eoWZA73mS05unirFOfmMOiYQFGFUNANcDc3E+7J9V1bUiMlNELnR3mwJsEJGNQB/gLjf9OeATYDVOP81KVX3FHcZ8G87ggOVRw5FvcIcurwRuAL6dqGs7YK02kbXRNHbANZion9Gd/JLkfOOPCDCxak7RNRhPJ3+LGoyniarF9XgGMCSyDyRcS2ulBpPI+3CMMW1K6J38qjoHmBOVdodn+TmcYBJ9XBPwgxjpxcTu20FVb8WpBX3xxBotBi0DTFpWB6aKicrbW1sJfXOv3euZRiXDU0vyDi7wnDdmJ3+MQJGcSkSTW3R+ad0S2wcTLl9tjHJnxE43xnQau5O/M4Q+eION0BTwpNdGLgeDn38usnCASWv+5l6zx3OPSFrsodDefpSYNYG6lp3loXm/WssvdD0JDzDVLc/jbR60AGPMIWEBpjM0RgWSWOne4cTR29rM21ODUY284z70wVq7xzONireJzHO+iE7+qJpAqJktVlNTW/mFy5LgAFO7t+V5QjWYRM4kYIxpkwWYzhCrr6NFeivT5rebd+gYdR537J0zLPTBWrPXM41KRuwmu4hhyt7O8nZqAsneANPK9SSyDyQ53bm+6PN479+xAGPMIWEBpjNET6UfM70u8gP6QOcig8gHbCWnR9VgPDMNx5obLXQ3f6A2cjSWP8MZ+txQHXs0WKuj0mqba2uJHMXlT3euL/o83sCYqFFsxpg2WYDpDI01kVPft5YeChahGYw7knfEKLJQDaY8cqZhb6d8rPPHmjG5dk/smoA3wARqPfnVdU4Nxp/hXF/0efwZULeP8D1BxphOZwGmMzTWtpwHLFa6d86wAxmm7J2G3xtgQt/cvR3goaaj0Dm9MyzHCgj+GHl4ReRX68mvlSn+DzZ/WuuBMdYM0MaYTmMBpjMEalvOAxZa9qaHPuAzehLXXGSq7oe6N8DE6IOB5mCTnB45Ui0iwHlGoIXEqs14+VvLr7b5GhI5VUv0yLH20o0xncYCTGeI/mYfTq+J+sYfCjDZ8TWRBeoBjayFeL/NxwoO0TWOtCzPdCsxajCxpuf3So6uwYQCpjfYJbiTP1y+GDWvRJ/fGNMqCzCJFmxyOsnTezjr0R373vTQB3x6j8gZjlsT8OwfWvd+qLcaYLw3VWZEDun17hvKJ9ayN19vft7aVGcNU4653EqwMcZ0GgswieZt9vKug1uDidEHEz3r8YHk3VjrPAvF54/9IRu6MTIYbB7Cm5wWWYNKbuVDO9ZoMO+ggcaa2H1KiRzFFesJmxA1oswCjDGHggWYRPM2e0HLTv607oSnWwk/tyXq0cYHkrf3AVuxmrdaPE44NK2/Z5h0PLWCcFpa83GBOs+Mzd4mtwR38oeXWyu3BRhjDgULMIkWbsaK6uQPBqGpHlK6NNcqGqP2jTfAhPePmrY+VnAI/QxPwR+a1r/G0yl/AB/UoU7+0LQwKV2ab+bsrGHK7S5bgDHmULAAk2gtmrGiHlecnNZ8L0lbzWnx5h3wzBnm80OSv/k83p/ep1SGhvrGrMG080EdCiYR15MWNWjgUIwia2dwgjEm4SzAJFr43pZQZ37UXe/+jObpVg64BuO5bya0f6zp9kPn8f70Tv/SosbRSl9GzFFknhmbQ/l7ZzKGxPaBRD8DJsRqMMYcchZgEq3Rc7NfaPoSiPx2732miS/FaWaC9h86Fu6z8Q4Njpp7K7q5zPsUylAfTKhcgRhNWvHUYMCZsTl0Pd6HlPlSwJfAp0KEyhR9HhumbMwhZwEm0aKHDceqwYQf71vXXKPw7tNe3qlZ7vQyMebeCtUwwgEmusbh7eSPMXeYv53RWOH8QgEmdD11LcuSCKHzR6z6ub8AAAv0SURBVJ+ntRFlxphOk9AAIyLnisgGESkSkVtibB8sIvNEZJWILHCfWBnadq/7hMpCEXlARMRNP0FEVrt5etN7ishbIrLJ/dkjkdcWt+jns0TPPBzRyV4TOUllvMOUQ9PCtPbgrdA+3nXv/F3emYe9+0LrQ5aj8w/n521yS/DTLL3njz6PjSIz5pBLWIARER/wEDAV5xHH00UkL2q3+4AnVDUfmAnc7R57CnAqkA+MBU4EJrvHPAzMAEa6r3Pd9FuAeao6Epjnrh96gagmslAzVCg91MkfPaoLaHe6mOiJLWMGmNAUMVGd/DWeGYi9D+dKSnYGB4QkJbWsBXmFJ9SMlV+Mh5QdbNE1s+j06OsxxnSaRNZgJgJFqrpZVRuA2cC0qH3ycIIBwHzPdgXSgBQgFfADu0SkH5Clqkv+f3vnHmtHVcXh79fbcr1IAYHSVAq0QAUxFkoaaKygQVAeSnkkUIKhURKQSIQQDJAmSIwmotEYApGANhaDgqKEmoCAxOCL1wVa2qaUFijQ9tIHCqXSAq3LP2afe+eee+a+6Mwc4fclk9mzzp49a9bMmTV7r733REQAtwNnpn3mAAtTemFOXi+9gw2LajCNIP/bLRzMCGow43JxlJYxmKYgf3NQvjd+0yJeMZiDadRwWpZX8JGyXcnYpvNr0HzexpjKKdPBHAC8mttem2R5lgDnpPRZwHhJ+0bEo2QOpyctD0TEirT/2oIyJ0ZED0Ba799KKUkXS+qW1L1p06ZRn9ywGRBrebtJ3qL20etghtlNubfnVosPbBUF+XuD8vnjFzRpNTunfr8NVt621uXtSlqN+YGc43HzmDF1UaaDUQtZNG1fBXxO0jNkTWDrgB2SDgM+CUwmcyAnSjphmGUOSkTcGhEzI2LmhAkTRrLr6BhQy9jeQp6C7Du299VoYBi9yPLTwuSa2VrFTZrX2/K9vrr6xsG0nA6mq+84rX7rV14jHpTOp/Qgf2PWgqbjjBkDHZ0O8BtTI2U6mLXAgbntycD6fIaIWB8RZ0fEDGB+kr1JVpt5LCK2RsRW4H5gVipzckGZjSY00nrjrj+lUZDvmdXvc8XNjuftvgf82E56p48Zquz8A7ZVraH5Tb63xtEU5IesmauollLU1DSgvKZOC6XXYIaID7mJzJjaKNPBPAlMkzRV0m7AXGBRPoOk/SQ1dLgWWJDSr5DVbMZKGkdWu1mRmr7ekjQr9R67ELg37bMImJfS83Lyemk4jTFj+pqOoHU35YZzkPrHawYrO+843t2aTT8z2EDLhsPp16SVG8tS+KAucBQDmshanE+ZDNYU1jyjtDGmUkpzMBGxA7gMeABYAfw2IpZL+q6kM1K2zwMrJT0PTAS+n+R3Ay8AS8niNEsi4o/pt0uBnwOrU577k/wHwMmSVgEnp+362bE914Orq6/3WH5qlbFduaB4rlfUkA5me/83+N5Ae4vR9w0dOsZm08f0fse+i35jWYpG6xf1BusN8ud7kbU4n7JonE9LB/MROxhjaqTEIdYQEfcB9zXJrsul7yZzJs377QQuKSizm6zrcrP8deAL71Pl4bH6z/DA/OHlfasnFyTvgi3r4ebj4D+b+2SNh+Cba3M9tnaHpXfDy/8oLvvNdbDnx/vKeeOVLD1YDKZRdiNvY3wOZLJ9Dh14nHxcaMBvXX37DnY+ZdLoAj5cuTGmEkp1MB9YOveECYcPL++Ew+Hg2Vl6+nkpVhGZfMIRMKYDjjgdNizLPk521PlZ3tmXw5q/DV32YSdl6RlfzT5s1rEbTDu5L8+nz82m8x/T0Sc74SpY1w17TIS9DsoewtPnZrWO6XMHHue4S/pqR810jofZV8C/X+o7n8NPh9eW9j+fMjnpOzDpqIHy46+Ezr3KP74xpiXKhpN8OJk5c2Z0d3fXrYYxxvxfIempiJg5VD7PRWaMMaYU7GCMMcaUgh2MMcaYUrCDMcYYUwp2MMYYY0rBDsYYY0wp2MEYY4wpBTsYY4wxpfChHmgpaRPw8ih33w/YvAvV2ZW0q27Wa2S0q17QvrpZr5ExWr0Ojoghv3fyoXYw7wdJ3cMZyVoH7aqb9RoZ7aoXtK9u1mtklK2Xm8iMMcaUgh2MMcaYUrCDGT231q3AILSrbtZrZLSrXtC+ulmvkVGqXo7BGGOMKQXXYIwxxpSCHYwxxphSsIMZBZJOkbRS0mpJ19Sox4GS/iJphaTlki5P8uslrZO0OC2n1aDbGklL0/G7k2wfSQ9JWpXWH6tBr8NzdlksaYukK+qwmaQFkjZKWpaTtbSRMm5M99yzko6pWK8fSXouHfseSXsn+RRJ23J2u6VivQqvm6Rrk71WSvpSWXoNottdOb3WSFqc5FXarOgZUc19FhFeRrAAHcALwCHAbsAS4MiadJkEHJPS44HngSOB64GrarbTGmC/JtkPgWtS+hrghja4lq8BB9dhM+AE4Bhg2VA2Ak4D7gcEzAIer1ivLwJjU/qGnF5T8vlqsFfL65b+B0uATmBq+s92VKlb0+8/Bq6rwWZFz4hK7jPXYEbOscDqiHgxIt4F7gTm1KFIRPRExNMp/RawAjigDl2GyRxgYUovBM6sUReALwAvRMRoZ3N4X0TEX4F/NYmLbDQHuD0yHgP2ljSpKr0i4sGI2JE2HwMml3Hskeo1CHOAOyPinYh4CVhN9t+tXDdJAs4FflPW8YsY5BlRyX1mBzNyDgBezW2vpQ0e6pKmADOAx5PoslTFXVBHUxQQwIOSnpJ0cZJNjIgeyG58YP8a9Mozl/5/+rptBsU2aqf77utkb7kNpkp6RtIjko6vQZ9W162d7HU8sCEiVuVkldus6RlRyX1mBzNy1EJWa19vSXsAvweuiIgtwM+AQ4GjgR6y6nnVzI6IY4BTgW9KOqEGHQqRtBtwBvC7JGoHmw1GW9x3kuYDO4A7kqgHOCgiZgBXAr+WtGeFKhVdt7awV+J8+r/IVG6zFs+IwqwtZKO2mx3MyFkLHJjbngysr0kXJI0ju3HuiIg/AETEhojYGRH/BW6jxKaBIiJifVpvBO5JOmxoVLfTemPVeuU4FXg6IjZAe9gsUWSj2u87SfOALwMXRGqwT01Qr6f0U2Sxjk9UpdMg1612ewFIGgucDdzVkFVts1bPCCq6z+xgRs6TwDRJU9Nb8FxgUR2KpLbdXwArIuInOXm+zfQsYFnzviXr9VFJ4xtpsgDxMjI7zUvZ5gH3VqlXE/3eKuu2WY4iGy0CLky9fGYBbzaaOKpA0inA1cAZEfF2Tj5BUkdKHwJMA16sUK+i67YImCupU9LUpNcTVemV4yTguYhY2xBUabOiZwRV3WdV9GT4oC1kPS2eJ3vzmF+jHp8lq74+CyxOy2nAr4ClSb4ImFSxXoeQ9eBZAixv2AjYF3gYWJXW+9Rkt92B14G9crLKbUbm4HqA98jeHC8qshFZ08XN6Z5bCsysWK/VZG3zjfvslpT3nHSNlwBPA1+pWK/C6wbMT/ZaCZxa9bVM8l8C32jKW6XNip4RldxnnirGGGNMKbiJzBhjTCnYwRhjjCkFOxhjjDGlYAdjjDGmFOxgjDHGlIIdjDElImmn+s/evMtm306z8tY1XseYIRlbtwLGfMDZFhFH162EMXXgGowxNZC+D3KDpCfScliSHyzp4TR548OSDkryicq+w7IkLZ9JRXVIui196+NBSV21nZQxTdjBGFMuXU1NZOflftsSEccCNwE/TbKbyKZLn042oeSNSX4j8EhEHEX23ZHlST4NuDkiPgW8QTZK3Ji2wCP5jSkRSVsjYo8W8jXAiRHxYpqM8LWI2FfSZrLpTt5L8p6I2E/SJmByRLyTK2MK8FBETEvbVwPjIuJ75Z+ZMUPjGowx9REF6aI8rXgnl96J46qmjbCDMaY+zsutH03pf5LN0A1wAfD3lH4YuBRAUkfF31wxZlT4bceYcumStDi3/aeIaHRV7pT0ONmL3vlJ9i1ggaRvA5uAryX55cCtki4iq6lcSjZ7rzFti2MwxtRAisHMjIjNdetiTFm4icwYY0wpuAZjjDGmFFyDMcYYUwp2MMYYY0rBDsYYY0wp2MEYY4wpBTsYY4wxpfA/mfkZ8OSFVo4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history1.history['acc'])\n",
    "plt.plot(history1.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Valid'], loc='upper left')\n",
    "plt.show()\n",
    "plt.plot(history1.history['loss'])\n",
    "plt.plot(history1.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Valid'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 62.1170%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "my_model_augement.load_weights('weights.best.mobile_model_augement.hdf5')\n",
    "\n",
    "my_model_predictions1 = [np.argmax(my_model_augement.predict(np.expand_dims(feature, axis=0))) for feature in test_mobile]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(my_model_predictions1)==np.argmax(y_test, axis=1))/len(my_model_predictions1)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time taken to process one frame is =0.2323765754699707\n"
     ]
    }
   ],
   "source": [
    "prev_class_num=20\n",
    "accuracy=0.8\n",
    "cap = cv2.VideoCapture(0)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "while 1:\n",
    "    start=time.time()\n",
    "    ret, img = cap.read()\n",
    "    frame=cv2.resize(img, (224, 224))\n",
    "    frame = image.img_to_array(frame)\n",
    "    frame=np.expand_dims(frame,axis=0)\n",
    "    prediction=my_model_augement.predict(model.predict(preprocess_input(frame)))\n",
    "    class_num=np.argmax(prediction)\n",
    "    if(prediction[0][class_num]>accuracy):\n",
    "        cv2.putText(img,classes_name[class_num],(10,224), font, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        if( (class_num != prev_class_num)):\n",
    "\n",
    "            prev_class_num=class_num\n",
    "            voice_assist(class_num)\n",
    "    cv2.imshow('img',img)\n",
    "    end=time.time()\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"The time taken to process one frame is ={}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
